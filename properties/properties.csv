version,jar,plugin,config,description,is_deprecated
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,keystore-user-credential-name,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,case-insensitive-name-matching.config-file.refresh-period,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,metadata.cache-ttl,"Determines how long meta information will be cached",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,metadata.cache-missing,"Determines if missing information will be cached",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,connection-url,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,keystore-file-path,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,unsupported-type-handling,"Unsupported type handling strategy",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,keystore-password,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,keystore-password-credential-password,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,connection-credential-file,"Location of the file where credentials are present",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,keystore-type,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,keystore-password-credential-name,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,connection-password,"Password for JDBC client",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,user-credential-name,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,case-insensitive-name-matching.config-file,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,keystore-user-credential-password,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,case-insensitive-name-matching.cache-ttl,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,topn-pushdown.enabled,"Enable TopN pushdown",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,jdbc-types-mapped-to-varchar,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,connection-user,"user name for JDBC client",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,write.batch-size,"Maximum number of rows to write in a single batch",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,case-insensitive-name-matching,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,join-pushdown.enabled,"Enable join pushdown",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,credential-provider.type,"",false
372,trino-server-372/plugin/memsql/trino-base-jdbc-372.jar,memsql,password-credential-name,"",false
372,trino-server-372/plugin/memsql/trino-plugin-toolkit-372.jar,memsql,security.refresh-period,"",false
372,trino-server-372/plugin/memsql/trino-plugin-toolkit-372.jar,memsql,jmx.base-name,"",false
372,trino-server-372/plugin/memsql/trino-plugin-toolkit-372.jar,memsql,security.config-file,"",false
372,trino-server-372/plugin/memsql/trino-memsql-372.jar,memsql,memsql.auto-reconnect,"",false
372,trino-server-372/plugin/memsql/trino-memsql-372.jar,memsql,memsql.connection-timeout,"",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
372,trino-server-372/plugin/kinesis/trino-kinesis-372.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
372,trino-server-372/plugin/clickhouse/trino-clickhouse-372.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
372,trino-server-372/plugin/clickhouse/trino-clickhouse-372.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
372,trino-server-372/plugin/postgresql/trino-postgresql-372.jar,postgresql,postgresql.include-system-tables,"",false
372,trino-server-372/plugin/postgresql/trino-postgresql-372.jar,postgresql,postgresql.array-mapping,"",false
372,trino-server-372/plugin/postgresql/trino-postgresql-372.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.s3.endpoint,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.s3.region,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.base-directory,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.sink-buffer-pool-min-size,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.encryption-enabled,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.s3.aws-access-key,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.s3.aws-secret-key,"",false
372,trino-server-372/plugin/exchange/trino-exchange-372.jar,exchange,exchange.s3.max-error-retries,"",false
372,trino-server-372/plugin/atop/trino-atop-372.jar,atop,atop.security,"",false
372,trino-server-372/plugin/atop/trino-atop-372.jar,atop,atop.executable-path,"",false
372,trino-server-372/plugin/atop/trino-atop-372.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
372,trino-server-372/plugin/atop/trino-atop-372.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
372,trino-server-372/plugin/atop/trino-atop-372.jar,atop,atop.max-history-days,"",false
372,trino-server-372/plugin/atop/trino-atop-372.jar,atop,atop.concurrent-readers-per-node,"",false
372,trino-server-372/plugin/memory/trino-memory-372.jar,memory,memory.splits-per-node,"",false
372,trino-server-372/plugin/memory/trino-memory-372.jar,memory,memory.max-data-per-node,"",false
372,trino-server-372/plugin/memory/trino-memory-372.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
372,trino-server-372/plugin/accumulo/trino-accumulo-372.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
372,trino-server-372/plugin/accumulo/trino-accumulo-372.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
372,trino-server-372/plugin/accumulo/trino-accumulo-372.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
372,trino-server-372/plugin/accumulo/trino-accumulo-372.jar,accumulo,accumulo.instance,"Accumulo instance name",false
372,trino-server-372/plugin/accumulo/trino-accumulo-372.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
372,trino-server-372/plugin/accumulo/trino-accumulo-372.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
372,trino-server-372/plugin/accumulo/trino-accumulo-372.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.broker.authentication.type,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.request-timeout,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.thread-pool-size,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.controller-urls,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.broker.authentication.user,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.max-connections-per-server,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.metadata-expiry,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.min-connections-per-server,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.prefer-broker-queries,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.segments-per-split,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.controller.authentication.password,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.connection-timeout,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.max-backlog-per-server,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.forbid-segment-queries,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.fetch-retry-count,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.controller.authentication.type,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.broker.authentication.password,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.max-rows-for-broker-queries,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.controller.authentication.user,"",false
372,trino-server-372/plugin/pinot/trino-pinot-372.jar,pinot,pinot.idle-timeout,"",false
372,trino-server-372/plugin/resource-group-managers/trino-resource-group-managers-372.jar,resource-group-managers,resource-groups.config-file,"",false
372,trino-server-372/plugin/resource-group-managers/trino-resource-group-managers-372.jar,resource-group-managers,jmx.base-name,"",false
372,trino-server-372/plugin/resource-group-managers/trino-resource-group-managers-372.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
372,trino-server-372/plugin/resource-group-managers/trino-resource-group-managers-372.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
372,trino-server-372/plugin/resource-group-managers/trino-resource-group-managers-372.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
372,trino-server-372/plugin/resource-group-managers/trino-resource-group-managers-372.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
372,trino-server-372/plugin/resource-group-managers/trino-resource-group-managers-372.jar,resource-group-managers,resource-groups.config-db-url,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.key-prefix-schema-table,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.nodes,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.password,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.scan-count,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.table-description-dir,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.database-index,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.table-names,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.connect-timeout,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.hide-internal-columns,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.default-schema,"",false
372,trino-server-372/plugin/redis/trino-redis-372.jar,redis,redis.key-delimiter,"",false
372,trino-server-372/plugin/example-http/trino-example-http-372.jar,example-http,metadata-uri,"",false
372,trino-server-372/plugin/local-file/trino-local-file-372.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
372,trino-server-372/plugin/local-file/trino-local-file-372.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
372,trino-server-372/plugin/jmx/trino-jmx-372.jar,jmx,jmx.dump-tables,"",false
372,trino-server-372/plugin/jmx/trino-jmx-372.jar,jmx,jmx.max-entries,"",false
372,trino-server-372/plugin/jmx/trino-jmx-372.jar,jmx,jmx.dump-period,"",false
372,trino-server-372/plugin/phoenix/trino-phoenix-372.jar,phoenix,phoenix.connection-url,"",false
372,trino-server-372/plugin/phoenix/trino-phoenix-372.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
372,trino-server-372/plugin/phoenix/trino-phoenix-372.jar,phoenix,phoenix.config.resources,"",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.remarks-reporting.enabled,"",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.synonyms.enabled,"",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.connection-pool.max-size,"",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.number.rounding-mode,"",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.connection-pool.min-size,"",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
372,trino-server-372/plugin/oracle/trino-oracle-372.jar,oracle,oracle.connection-pool.enabled,"",false
372,trino-server-372/plugin/session-property-managers/trino-session-property-managers-372.jar,session-property-managers,session-property-manager.db.username,"",false
372,trino-server-372/plugin/session-property-managers/trino-session-property-managers-372.jar,session-property-managers,session-property-manager.db.url,"",false
372,trino-server-372/plugin/session-property-managers/trino-session-property-managers-372.jar,session-property-managers,session-property-manager.config-file,"",false
372,trino-server-372/plugin/session-property-managers/trino-session-property-managers-372.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
372,trino-server-372/plugin/session-property-managers/trino-session-property-managers-372.jar,session-property-managers,session-property-manager.db.password,"",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
372,trino-server-372/plugin/bigquery/trino-bigquery-372.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.read-preference,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.min-connections-per-host,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.ssl.enabled,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.cursor-batch-size,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.max-wait-time,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.required-replica-set,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.seeds,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.connection-timeout,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.write-concern,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.connections-per-host,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.credentials,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.max-connection-idle-time,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.connection-url,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.schema-collection,"",false
372,trino-server-372/plugin/mongodb/trino-mongodb-372.jar,mongodb,mongodb.socket-timeout,"",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.security,"",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.compression-codec,"",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.catalog.type,"",false
372,trino-server-372/plugin/iceberg/trino-iceberg-372.jar,iceberg,iceberg.file-format,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.username,"Optional username for accessing the Hive metastore",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore-recording-duration,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.compression-codec,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.abfs-access-key,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore-cache-maximum-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.adl-credential,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.abfs.oauth.endpoint,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.security,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.nested-lazy,"ORC lazily read nested data",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.dictionary-max-memory,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-initial-split-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-concurrent-metastore-updates,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.partition-batch-size.min,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore-cache-ttl,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.use-column-names,"Access ORC columns using names from the file",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.ssl.enabled,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.connect-timeout,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs.connect.timeout,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.read-mode,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.writer.page-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.wasb-storage-account,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.max-merge-distance,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.client.principal,"Hive Metastore client principal",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.bloom-filters.enabled,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs.connect.max-retries,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs.replication,"Hadoop FileSystem replication factor",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.per-transaction-metastore-cache-maximum-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.partition-batch-size.max,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore-recording-path,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.authentication.type,"Thrift metastore authentication type",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.socks-proxy,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.alluxio.master.address,"Alluxio master address",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.tiny-stripe-threshold,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore-refresh-max-threads,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-initial-splits,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.max-buffer-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.max-read-block-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.split-loader-concurrency,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.max-error-retries,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.size-based-split-weights-enabled,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs.verify-checksum,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.service.principal,"Hive Metastore service principal",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.file-status-cache-expire-time,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-split-iterator-threads,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.file-status-cache-tables,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.max-backoff-time,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.force-local-scheduling,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.user-metastore-cache-maximum-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-add-column,"Allow Hive connector to add column",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore-timeout,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.max-read-block-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.max-retry-time,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.user-metastore-cache-ttl,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.max-merge-distance,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.abfs.oauth.secret,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.writer.block-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.use-column-index,"Enable using Parquet column indexes",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.socket-timeout,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.adl-refresh-url,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.aws-access-key,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.streaming.enabled,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.stripe-min-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.adl-client-id,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.skip-glacier-objects,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-drop-column,"Allow Hive connector to drop column",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.requester-pays.enabled,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.fs.new-directory-permissions,"File system permissions for new directories",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.max-compression-buffer-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.abfs.oauth.client-id,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs.ipc-ping-interval,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.max-buffer-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.storage-format,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs.key-provider.cache-ttl,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.writer-sort-buffer-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-drop-table,"Allow Hive connector to drop table",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.data-transfer-port,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.hdfs.authentication.type,"HDFS authentication type",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.adl-proxy-host,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.stripe-max-rows,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.replay-metastore-recording,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.endpoint,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.config.resources,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.sse.enabled,"Enable S3 server side encryption",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.signer-class,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3select-pushdown.max-connections,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.path-style-access,"Use path-style access for all request to S3",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.assume-canonical-partition-keys,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.start-server-on-coordinator,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs-timeout,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.file-status-cache-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-concurrent-metastore-drops,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.user,"Hive file-based metastore username for file access",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.parquet.time-zone,"Time zone for Parquet read and write",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3-file-system-type,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.text.max-line-length,"Maximum line length for text files",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.bookkeeper-port,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.version-compatibility,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.abfs-storage-account,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.cache.location,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.timestamp-precision,"Precision used to represent timestamps",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.aws-secret-key,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-concurrent-file-renames,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.optimize-mismatched-bucket-count,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.table-statistics-enabled,"Enable use of table statistics",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.string-statistics-limit,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.dfs.domain-socket-path,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.ignore-absent-partitions,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.recursive-directories,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-register-partition-procedure,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-rename-table,"Allow Hive connector to rename table",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.writer-identification,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.query-partition-filter-required,"Require filter on at least one partition column",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.allow-rename-column,"Allow Hive connector to rename column",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.signer-type,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.row-group-max-rows,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.azure.wasb-access-key,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.max-connections,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.max-client-retries,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore-refresh-interval,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.writer.stripe-max-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.max-split-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.orc.stream-buffer-size,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.hdfs.socks-proxy,"",false
372,trino-server-372/plugin/iceberg/trino-hive-372.jar,iceberg,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
372,trino-server-372/plugin/phoenix5/trino-phoenix5-372.jar,phoenix5,phoenix.connection-url,"",false
372,trino-server-372/plugin/phoenix5/trino-phoenix5-372.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
372,trino-server-372/plugin/phoenix5/trino-phoenix5-372.jar,phoenix5,phoenix.config.resources,"",false
372,trino-server-372/plugin/thrift/trino-thrift-372.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
372,trino-server-372/plugin/thrift/trino-thrift-372.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
372,trino-server-372/plugin/thrift/trino-thrift-372.jar,thrift,trino-thrift.max-response-size,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.orc.nested-lazy,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,metadata.db.url,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.compaction-enabled,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.security,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.orc.max-read-size,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.balancer-enabled,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.organization-enabled,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
372,trino-server-372/plugin/raptor-legacy/trino-raptor-legacy-372.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
372,trino-server-372/plugin/google-sheets/trino-google-sheets-372.jar,google-sheets,credentials-path,"Credential file path to google service account",false
372,trino-server-372/plugin/google-sheets/trino-google-sheets-372.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
372,trino-server-372/plugin/google-sheets/trino-google-sheets-372.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
372,trino-server-372/plugin/google-sheets/trino-google-sheets-372.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
372,trino-server-372/plugin/kafka/trino-kafka-372.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.client.so-linger,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.tls.truststore-path,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.splits-per-node,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.username,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.password,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.contact-points,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.speculative-execution.limit,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.speculative-execution.delay,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.split-size,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.tls.keystore-path,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.batch-size,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.native-protocol-port,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.tls.truststore-password,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.consistency-level,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.tls.keystore-password,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.protocol-version,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.client.read-timeout,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.fetch-size,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.tls.enabled,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.client.connect-timeout,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.retry-policy,"",false
372,trino-server-372/plugin/cassandra/trino-cassandra-372.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
372,trino-server-372/plugin/mysql/trino-mysql-372.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
372,trino-server-372/plugin/mysql/trino-mysql-372.jar,mysql,mysql.connection-timeout,"",false
372,trino-server-372/plugin/mysql/trino-mysql-372.jar,mysql,mysql.auto-reconnect,"",false
372,trino-server-372/plugin/mysql/trino-mysql-372.jar,mysql,mysql.max-reconnects,"",false
372,trino-server-372/plugin/sqlserver/trino-sqlserver-372.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
372,trino-server-372/plugin/http-event-listener/trino-http-event-listener-372.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.client.disable-statistics,"",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.grouped-execution.enabled,"",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.client.default-operation-timeout,"",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.schema-emulation.prefix,"",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.client.master-addresses,"",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.schema-emulation.enabled,"",false
372,trino-server-372/plugin/kudu/trino-kudu-372.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.timeout.connect,"Timeout for establishing a connection",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.url,"URL of the LDAP server",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.ssl-trust-certificate,"Path to the PEM trust certificate for the LDAP server",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.cache-ttl,"",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
372,trino-server-372/plugin/password-authenticators/trino-password-authenticators-372.jar,password-authenticators,ldap.timeout.read,"Timeout for reading data from LDAP",false
372,trino-server-372/plugin/prometheus/trino-prometheus-372.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
372,trino-server-372/plugin/prometheus/trino-prometheus-372.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
372,trino-server-372/plugin/prometheus/trino-prometheus-372.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
372,trino-server-372/plugin/prometheus/trino-prometheus-372.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
372,trino-server-372/plugin/prometheus/trino-prometheus-372.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
372,trino-server-372/plugin/prometheus/trino-prometheus-372.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.port,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.aws.access-key,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.host,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.aws.region,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.auth.password,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.auth.user,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.tls.enabled,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
372,trino-server-372/plugin/elasticsearch/trino-elasticsearch-372.jar,elasticsearch,elasticsearch.security,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.client.timeout,"",false
372,trino-server-372/lib/trino-main-372.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
372,trino-server-372/lib/trino-main-372.jar,,sink.max-broadcast-buffer-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.info.max-age,"",false
372,trino-server-372/lib/trino-main-372.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.jwt.user-mapping.file,"",false
372,trino-server-372/lib/trino-main-372.jar,,regex-library,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.certificate.user-mapping.file,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
372,trino-server-372/lib/trino-main-372.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
372,trino-server-372/lib/trino-main-372.jar,,task.http-timeout-threads,"",false
372,trino-server-372/lib/trino-main-372.jar,,spiller-spill-path,"",false
372,trino-server-372/lib/trino-main-372.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.page-buffer-client.max-callback-threads,"",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,network-cost-weight,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-memory-per-task,"Sets memory limit enforced for a single task; there is no memory limit by default",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-stage-count,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
372,trino-server-372/lib/trino-main-372.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.jwt.principal-field,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
372,trino-server-372/lib/trino-main-372.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
372,trino-server-372/lib/trino-main-372.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
372,trino-server-372/lib/trino-main-372.jar,,task.max-index-memory,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
372,trino-server-372/lib/trino-main-372.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.krb5.principal-hostname,"",false
372,trino-server-372/lib/trino-main-372.jar,,spill-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.min-expire-age,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
372,trino-server-372/lib/trino-main-372.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.client-threads,"",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.compression-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.krb5.name-type,"",false
372,trino-server-372/lib/trino-main-372.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.skip-redundant-sort,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-queued-queries,"",false
372,trino-server-372/lib/trino-main-372.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
372,trino-server-372/lib/trino-main-372.jar,,task.initial-splits-per-node,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.password.user-mapping.pattern,"",false
372,trino-server-372/lib/trino-main-372.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
372,trino-server-372/lib/trino-main-372.jar,,task.max-partial-top-n-memory,"",false
372,trino-server-372/lib/trino-main-372.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.concurrent-request-multiplier,"",false
372,trino-server-372/lib/trino-main-372.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.service-thread-count,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
372,trino-server-372/lib/trino-main-372.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
372,trino-server-372/lib/trino-main-372.jar,,spill-compression-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
372,trino-server-372/lib/trino-main-372.jar,,task.client.timeout,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
372,trino-server-372/lib/trino-main-372.jar,,task.max-local-exchange-buffer-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,failure-detector.enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.https.enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
372,trino-server-372/lib/trino-main-372.jar,,discovery-server.enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
372,trino-server-372/lib/trino-main-372.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
372,trino-server-372/lib/trino-main-372.jar,,query.schedule-split-batch-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.max-splits-per-node,"",false
372,trino-server-372/lib/trino-main-372.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.optimize-metadata-queries,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.use-mark-distinct,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.krb5.user-mapping.file,"",false
372,trino-server-372/lib/trino-main-372.jar,,statistics-precalculation-for-pushdown.enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.optimize-hash-generation,"",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.max-error-duration,"",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.acknowledge-pages,"",false
372,trino-server-372/lib/trino-main-372.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.ignore-downstream-preferences,"",false
372,trino-server-372/lib/trino-main-372.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.optimized-local-scheduling,"",false
372,trino-server-372/lib/trino-main-372.jar,,distributed-sort,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
372,trino-server-372/lib/trino-main-372.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.force-single-node-output,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
372,trino-server-372/lib/trino-main-372.jar,,catalog.disabled-catalogs,"",false
372,trino-server-372/lib/trino-main-372.jar,,jmx.base-name,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
372,trino-server-372/lib/trino-main-372.jar,,failure-detector.heartbeat-interval,"",false
372,trino-server-372/lib/trino-main-372.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
372,trino-server-372/lib/trino-main-372.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-planning-time,"",false
372,trino-server-372/lib/trino-main-372.jar,,join-distribution-type,"",false
372,trino-server-372/lib/trino-main-372.jar,,max-spill-per-node,"",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
372,trino-server-372/lib/trino-main-372.jar,,driver.max-page-partitioning-buffer-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,filter-and-project-min-output-page-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,enable-large-dynamic-filters,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.http-response-threads,"",false
372,trino-server-372/lib/trino-main-372.jar,,scale-writers,"",false
372,trino-server-372/lib/trino-main-372.jar,,query-results.compression-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
372,trino-server-372/lib/trino-main-372.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
372,trino-server-372/lib/trino-main-372.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
372,trino-server-372/lib/trino-main-372.jar,,task.max-partial-aggregation-memory,"",false
372,trino-server-372/lib/trino-main-372.jar,,filter-and-project-min-output-page-row-count,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.prefer-partial-aggregation,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.jwt.key-file,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-length,"",false
372,trino-server-372/lib/trino-main-372.jar,,parse-decimal-literals-as-double,"",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.password.user-mapping.file,"",false
372,trino-server-372/lib/trino-main-372.jar,,spiller-max-used-space-threshold,"",false
372,trino-server-372/lib/trino-main-372.jar,,web-ui.user,"",false
372,trino-server-372/lib/trino-main-372.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
372,trino-server-372/lib/trino-main-372.jar,,re2j.dfa-retries,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-run-time,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
372,trino-server-372/lib/trino-main-372.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
372,trino-server-372/lib/trino-main-372.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
372,trino-server-372/lib/trino-main-372.jar,,sql.default-catalog,"",false
372,trino-server-372/lib/trino-main-372.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
372,trino-server-372/lib/trino-main-372.jar,,query.low-memory-killer.policy,"",false
372,trino-server-372/lib/trino-main-372.jar,,pages-index.eager-compaction-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.krb5.service-name,"",false
372,trino-server-372/lib/trino-main-372.jar,,warning-collector.max-warnings,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.info-update-interval,"Interval between updating task data",false
372,trino-server-372/lib/trino-main-372.jar,,web-ui.enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,internal-communication.https.required,"",false
372,trino-server-372/lib/trino-main-372.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
372,trino-server-372/lib/trino-main-372.jar,,event.max-output-stage-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,compiler.expression-cache-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,cpu-cost-weight,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.share-index-loading,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.enable-intermediate-aggregations,"",false
372,trino-server-372/lib/trino-main-372.jar,,event-listener.config-files,"",false
372,trino-server-372/lib/trino-main-372.jar,,retry-policy,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
372,trino-server-372/lib/trino-main-372.jar,,re2j.dfa-states-limit,"",false
372,trino-server-372/lib/trino-main-372.jar,,internal-communication.https.keystore.path,"",false
372,trino-server-372/lib/trino-main-372.jar,,catalog.config-dir,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
372,trino-server-372/lib/trino-main-372.jar,,deprecated.legacy-row-to-json-cast,"",false
372,trino-server-372/lib/trino-main-372.jar,,retry-attempts,"",false
372,trino-server-372/lib/trino-main-372.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,analyzer.max-grouping-sets,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.network-topology.type,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.status-refresh-max-wait,"",false
372,trino-server-372/lib/trino-main-372.jar,,web-ui.shared-secret,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.default-filter-factor-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.optimize-top-n-ranking,"",false
372,trino-server-372/lib/trino-main-372.jar,,memory-cost-weight,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
372,trino-server-372/lib/trino-main-372.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
372,trino-server-372/lib/trino-main-372.jar,,query.info-url-template,"",false
372,trino-server-372/lib/trino-main-372.jar,,access-control.config-files,"",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,spill-encryption-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
372,trino-server-372/lib/trino-main-372.jar,,distributed-index-joins-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-concurrent-queries,"",false
372,trino-server-372/lib/trino-main-372.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
372,trino-server-372/lib/trino-main-372.jar,,experimental.late-materialization.enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,redistribute-writes,"",false
372,trino-server-372/lib/trino-main-372.jar,,internal-communication.shared-secret,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.policy,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.dictionary-aggregation,"",false
372,trino-server-372/lib/trino-main-372.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
372,trino-server-372/lib/trino-main-372.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.jwt.required-issuer,"",false
372,trino-server-372/lib/trino-main-372.jar,,internal-communication.https.keystore.key,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.network-topology.file,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.min-schedule-split-batch-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
372,trino-server-372/lib/trino-main-372.jar,,use-preferred-write-partitioning,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-cpu-time,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
372,trino-server-372/lib/trino-main-372.jar,,enable-forced-exchange-below-group-id,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-scan-physical-bytes,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-memory,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.manager-executor-pool-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.cpu-timer-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,plugin.dir,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-execution-time,"",false
372,trino-server-372/lib/trino-main-372.jar,,aggregation-operator-unspill-memory-limit,"",false
372,trino-server-372/lib/trino-main-372.jar,,sql.default-schema,"",false
372,trino-server-372/lib/trino-main-372.jar,,enable-stats-calculator,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.remote-task.max-callback-threads,"",false
372,trino-server-372/lib/trino-main-372.jar,,failure-detector.threshold,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.remote-task.max-error-duration,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.complex-expression-pushdown.enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.jwt.required-audience,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-memory-per-node,"",false
372,trino-server-372/lib/trino-main-372.jar,,query-max-spill-per-node,"",false
372,trino-server-372/lib/trino-main-372.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
372,trino-server-372/lib/trino-main-372.jar,,internal-communication.https.truststore.path,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.statistics-cpu-timer-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
372,trino-server-372/lib/trino-main-372.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.max-buffer-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.min-candidates,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.execution-policy,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.push-partial-aggregation-through-join,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.insecure.user-mapping.file,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.push-table-write-through-union,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.krb5.keytab,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
372,trino-server-372/lib/trino-main-372.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.data-integrity-verification,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.remote-task.min-error-duration,"",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.max-response-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,shutdown.grace-period,"",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-history,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.max-pending-splits-per-task,"",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.deduplication-buffer-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
372,trino-server-372/lib/trino-main-372.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
372,trino-server-372/lib/trino-main-372.jar,,task.split-concurrency-adjustment-interval,"",false
372,trino-server-372/lib/trino-main-372.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.per-operator-cpu-timer-enabled,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.push-aggregation-through-outer-join,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.writer-count,"Number of writers per task",false
372,trino-server-372/lib/trino-main-372.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.include-coordinator,"",false
372,trino-server-372/lib/trino-main-372.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
372,trino-server-372/lib/trino-main-372.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
372,trino-server-372/lib/trino-main-372.jar,,query.max-total-memory,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.max-worker-threads,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
372,trino-server-372/lib/trino-main-372.jar,,internal-communication.https.truststore.key,"",false
372,trino-server-372/lib/trino-main-372.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
372,trino-server-372/lib/trino-main-372.jar,,http.include-exception-in-response,"",false
372,trino-server-372/lib/trino-main-372.jar,,task.min-drivers,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.merge-project-with-values,"",false
372,trino-server-372/lib/trino-main-372.jar,,sink.max-buffer-size,"",false
372,trino-server-372/lib/trino-main-372.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.network-topology.refresh-period,"",false
372,trino-server-372/lib/trino-main-372.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
372,trino-server-372/lib/trino-main-372.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
372,trino-server-372/lib/trino-main-372.jar,,web-ui.session-timeout,"",false
372,trino-server-372/lib/trino-main-372.jar,,exchange.min-error-duration,"",false
372,trino-server-372/lib/trino-main-372.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
372,trino-server-372/lib/trino-main-372.jar,,enable-dynamic-filtering,"",false
372,trino-server-372/lib/trino-main-372.jar,,http.authentication.krb5.config,"",false
372,trino-server-372/lib/trino-main-372.jar,,iterative-optimizer-timeout,"",false
372,trino-server-372/lib/trino-main-372.jar,,spiller-threads,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,keystore-password,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,case-insensitive-name-matching.cache-ttl,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,keystore-password-credential-name,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,user-credential-name,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,keystore-file-path,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,connection-url,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,credential-provider.type,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,complex-expression-pushdown.enabled,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,password-credential-name,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,jdbc-types-mapped-to-varchar,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,topn-pushdown.enabled,"Enable TopN pushdown",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,join-pushdown.enabled,"Enable join pushdown",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,case-insensitive-name-matching,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,keystore-user-credential-password,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,metadata.cache-missing,"Determines if missing information will be cached",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,connection-credential-file,"Location of the file where credentials are present",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,connection-user,"user name for JDBC client",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,case-insensitive-name-matching.config-file,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,case-insensitive-name-matching.config-file.refresh-period,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,write.batch-size,"Maximum number of rows to write in a single batch",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,keystore-user-credential-name,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,keystore-type,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,keystore-password-credential-password,"",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,connection-password,"Password for JDBC client",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,metadata.cache-ttl,"Determines how long meta information will be cached",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,unsupported-type-handling,"Unsupported type handling strategy",false
373,trino-server-373/plugin/memsql/trino-base-jdbc-373.jar,memsql,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
373,trino-server-373/plugin/memsql/trino-plugin-toolkit-373.jar,memsql,security.refresh-period,"",false
373,trino-server-373/plugin/memsql/trino-plugin-toolkit-373.jar,memsql,security.config-file,"",false
373,trino-server-373/plugin/memsql/trino-plugin-toolkit-373.jar,memsql,jmx.base-name,"",false
373,trino-server-373/plugin/memsql/trino-memsql-373.jar,memsql,memsql.connection-timeout,"",false
373,trino-server-373/plugin/memsql/trino-memsql-373.jar,memsql,memsql.auto-reconnect,"",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
373,trino-server-373/plugin/kinesis/trino-kinesis-373.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
373,trino-server-373/plugin/clickhouse/trino-clickhouse-373.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
373,trino-server-373/plugin/clickhouse/trino-clickhouse-373.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
373,trino-server-373/plugin/postgresql/trino-postgresql-373.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
373,trino-server-373/plugin/postgresql/trino-postgresql-373.jar,postgresql,postgresql.array-mapping,"",false
373,trino-server-373/plugin/postgresql/trino-postgresql-373.jar,postgresql,postgresql.include-system-tables,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.s3.endpoint,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.s3.max-error-retries,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.s3.aws-secret-key,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.s3.aws-access-key,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.encryption-enabled,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.sink-buffer-pool-min-size,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.base-directory,"",false
373,trino-server-373/plugin/exchange/trino-exchange-373.jar,exchange,exchange.s3.region,"",false
373,trino-server-373/plugin/atop/trino-atop-373.jar,atop,atop.concurrent-readers-per-node,"",false
373,trino-server-373/plugin/atop/trino-atop-373.jar,atop,atop.max-history-days,"",false
373,trino-server-373/plugin/atop/trino-atop-373.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
373,trino-server-373/plugin/atop/trino-atop-373.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
373,trino-server-373/plugin/atop/trino-atop-373.jar,atop,atop.executable-path,"",false
373,trino-server-373/plugin/atop/trino-atop-373.jar,atop,atop.security,"",false
373,trino-server-373/plugin/memory/trino-memory-373.jar,memory,memory.splits-per-node,"",false
373,trino-server-373/plugin/memory/trino-memory-373.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
373,trino-server-373/plugin/memory/trino-memory-373.jar,memory,memory.max-data-per-node,"",false
373,trino-server-373/plugin/accumulo/trino-accumulo-373.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
373,trino-server-373/plugin/accumulo/trino-accumulo-373.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
373,trino-server-373/plugin/accumulo/trino-accumulo-373.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
373,trino-server-373/plugin/accumulo/trino-accumulo-373.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
373,trino-server-373/plugin/accumulo/trino-accumulo-373.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
373,trino-server-373/plugin/accumulo/trino-accumulo-373.jar,accumulo,accumulo.instance,"Accumulo instance name",false
373,trino-server-373/plugin/accumulo/trino-accumulo-373.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.broker.authentication.user,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.controller-urls,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.thread-pool-size,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.request-timeout,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.broker.authentication.type,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.idle-timeout,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.controller.authentication.user,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.max-rows-for-broker-queries,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.broker.authentication.password,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.controller.authentication.type,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.fetch-retry-count,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.forbid-segment-queries,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.max-backlog-per-server,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.connection-timeout,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.controller.authentication.password,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.segments-per-split,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.prefer-broker-queries,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.min-connections-per-server,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.metadata-expiry,"",false
373,trino-server-373/plugin/pinot/trino-pinot-373.jar,pinot,pinot.max-connections-per-server,"",false
373,trino-server-373/plugin/resource-group-managers/trino-resource-group-managers-373.jar,resource-group-managers,resource-groups.config-file,"",false
373,trino-server-373/plugin/resource-group-managers/trino-resource-group-managers-373.jar,resource-group-managers,resource-groups.config-db-url,"",false
373,trino-server-373/plugin/resource-group-managers/trino-resource-group-managers-373.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
373,trino-server-373/plugin/resource-group-managers/trino-resource-group-managers-373.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
373,trino-server-373/plugin/resource-group-managers/trino-resource-group-managers-373.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
373,trino-server-373/plugin/resource-group-managers/trino-resource-group-managers-373.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
373,trino-server-373/plugin/resource-group-managers/trino-resource-group-managers-373.jar,resource-group-managers,jmx.base-name,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.key-delimiter,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.default-schema,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.hide-internal-columns,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.connect-timeout,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.table-names,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.database-index,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.table-description-dir,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.scan-count,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.password,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.nodes,"",false
373,trino-server-373/plugin/redis/trino-redis-373.jar,redis,redis.key-prefix-schema-table,"",false
373,trino-server-373/plugin/example-http/trino-example-http-373.jar,example-http,metadata-uri,"",false
373,trino-server-373/plugin/local-file/trino-local-file-373.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
373,trino-server-373/plugin/local-file/trino-local-file-373.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
373,trino-server-373/plugin/jmx/trino-jmx-373.jar,jmx,jmx.dump-period,"",false
373,trino-server-373/plugin/jmx/trino-jmx-373.jar,jmx,jmx.max-entries,"",false
373,trino-server-373/plugin/jmx/trino-jmx-373.jar,jmx,jmx.dump-tables,"",false
373,trino-server-373/plugin/phoenix/trino-phoenix-373.jar,phoenix,phoenix.config.resources,"",false
373,trino-server-373/plugin/phoenix/trino-phoenix-373.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
373,trino-server-373/plugin/phoenix/trino-phoenix-373.jar,phoenix,phoenix.connection-url,"",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.connection-pool.enabled,"",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.connection-pool.min-size,"",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.number.rounding-mode,"",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.connection-pool.max-size,"",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.synonyms.enabled,"",false
373,trino-server-373/plugin/oracle/trino-oracle-373.jar,oracle,oracle.remarks-reporting.enabled,"",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.max-initial-splits,"",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.max-split-size,"",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.max-initial-split-size,"",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
373,trino-server-373/plugin/delta-lake/trino-delta-lake-373.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.writer-identification,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.file-status-cache-tables,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.max-buffer-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-split-iterator-threads,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.aws-secret-key,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.abfs-access-key,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore-timeout,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.adl-proxy-host,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.streaming.enabled,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore-refresh-interval,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.proxy.username,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.wasb-storage-account,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-concurrent-file-renames,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.proxy.port,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.adl-client-id,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-register-partition-procedure,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore-cache-ttl,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.read-mode,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.recursive-directories,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.writer.page-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.stream-buffer-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.max-merge-distance,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.proxy.host,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.file-status-cache-expire-time,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.max-error-retries,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.hdfs.socks-proxy,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.max-merge-distance,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs.connect.max-retries,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.force-local-scheduling,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs.verify-checksum,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.data-transfer-port,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.max-client-retries,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.bookkeeper-port,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.security,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.max-retry-time,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.endpoint,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.wasb-access-key,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.max-buffer-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.max-backoff-time,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.signer-type,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore-recording-path,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3-file-system-type,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.aws-access-key,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.replay-metastore-recording,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-split-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.config.resources,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs.connect.timeout,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.proxy.password,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.adl-credential,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs-timeout,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.signer-class,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.max-read-block-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.max-connections,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.ignore-absent-partitions,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.ssl.enabled,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.proxy.protocol,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.connect-timeout,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.writer-sort-buffer-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.abfs-storage-account,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.compression-codec,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.socket-timeout,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-initial-splits,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.max-read-block-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.storage-format,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.file-status-cache-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.cache.location,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-initial-split-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.split-loader-concurrency,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.dfs.domain-socket-path,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.version-compatibility,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,parquet.writer.block-size,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.metastore-recording-duration,"",false
373,trino-server-373/plugin/delta-lake/trino-hive-373.jar,delta-lake,hive.azure.adl-refresh-url,"",false
373,trino-server-373/plugin/session-property-managers/trino-session-property-managers-373.jar,session-property-managers,session-property-manager.db.password,"",false
373,trino-server-373/plugin/session-property-managers/trino-session-property-managers-373.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
373,trino-server-373/plugin/session-property-managers/trino-session-property-managers-373.jar,session-property-managers,session-property-manager.config-file,"",false
373,trino-server-373/plugin/session-property-managers/trino-session-property-managers-373.jar,session-property-managers,session-property-manager.db.url,"",false
373,trino-server-373/plugin/session-property-managers/trino-session-property-managers-373.jar,session-property-managers,session-property-manager.db.username,"",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.view-expire-duration,"",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
373,trino-server-373/plugin/bigquery/trino-bigquery-373.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.socket-timeout,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.schema-collection,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.connection-url,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.max-connection-idle-time,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.credentials,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.connections-per-host,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.write-concern,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.connection-timeout,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.seeds,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.required-replica-set,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.max-wait-time,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.cursor-batch-size,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.ssl.enabled,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.min-connections-per-host,"",false
373,trino-server-373/plugin/mongodb/trino-mongodb-373.jar,mongodb,mongodb.read-preference,"",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.compression-codec,"",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.security,"",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.file-format,"",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.catalog.type,"",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
373,trino-server-373/plugin/iceberg/trino-iceberg-373.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
373,trino-server-373/plugin/phoenix5/trino-phoenix5-373.jar,phoenix5,phoenix.config.resources,"",false
373,trino-server-373/plugin/phoenix5/trino-phoenix5-373.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
373,trino-server-373/plugin/phoenix5/trino-phoenix5-373.jar,phoenix5,phoenix.connection-url,"",false
373,trino-server-373/plugin/thrift/trino-thrift-373.jar,thrift,trino-thrift.max-response-size,"",false
373,trino-server-373/plugin/thrift/trino-thrift-373.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
373,trino-server-373/plugin/thrift/trino-thrift-373.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.security,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.compaction-enabled,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,metadata.db.url,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.orc.nested-lazy,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.organization-enabled,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.balancer-enabled,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
373,trino-server-373/plugin/raptor-legacy/trino-raptor-legacy-373.jar,raptor-legacy,storage.orc.max-read-size,"",false
373,trino-server-373/plugin/google-sheets/trino-google-sheets-373.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
373,trino-server-373/plugin/google-sheets/trino-google-sheets-373.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
373,trino-server-373/plugin/google-sheets/trino-google-sheets-373.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
373,trino-server-373/plugin/google-sheets/trino-google-sheets-373.jar,google-sheets,credentials-path,"Credential file path to google service account",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
373,trino-server-373/plugin/kafka/trino-kafka-373.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.tls.truststore-path,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.client.so-linger,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.retry-policy,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.client.connect-timeout,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.tls.enabled,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.fetch-size,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.client.read-timeout,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.protocol-version,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.tls.keystore-password,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.consistency-level,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.tls.truststore-password,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.native-protocol-port,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.batch-size,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.tls.keystore-path,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.split-size,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.speculative-execution.delay,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.speculative-execution.limit,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.contact-points,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.password,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.username,"",false
373,trino-server-373/plugin/cassandra/trino-cassandra-373.jar,cassandra,cassandra.splits-per-node,"",false
373,trino-server-373/plugin/mysql/trino-mysql-373.jar,mysql,mysql.max-reconnects,"",false
373,trino-server-373/plugin/mysql/trino-mysql-373.jar,mysql,mysql.auto-reconnect,"",false
373,trino-server-373/plugin/mysql/trino-mysql-373.jar,mysql,mysql.connection-timeout,"",false
373,trino-server-373/plugin/mysql/trino-mysql-373.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
373,trino-server-373/plugin/sqlserver/trino-sqlserver-373.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
373,trino-server-373/plugin/http-event-listener/trino-http-event-listener-373.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.grouped-execution.enabled,"",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.client.disable-statistics,"",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.schema-emulation.enabled,"",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.client.master-addresses,"",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.schema-emulation.prefix,"",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.client.default-operation-timeout,"",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
373,trino-server-373/plugin/kudu/trino-kudu-373.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.timeout.read,"Timeout for reading data from LDAP",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.cache-ttl,"",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.ssl-trust-certificate,"Path to the PEM trust certificate for the LDAP server",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.url,"URL of the LDAP server",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
373,trino-server-373/plugin/password-authenticators/trino-password-authenticators-373.jar,password-authenticators,ldap.timeout.connect,"Timeout for establishing a connection",false
373,trino-server-373/plugin/prometheus/trino-prometheus-373.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
373,trino-server-373/plugin/prometheus/trino-prometheus-373.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
373,trino-server-373/plugin/prometheus/trino-prometheus-373.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
373,trino-server-373/plugin/prometheus/trino-prometheus-373.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
373,trino-server-373/plugin/prometheus/trino-prometheus-373.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
373,trino-server-373/plugin/prometheus/trino-prometheus-373.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.port,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.security,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.tls.enabled,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.auth.user,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.auth.password,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.aws.region,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.host,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
373,trino-server-373/plugin/elasticsearch/trino-elasticsearch-373.jar,elasticsearch,elasticsearch.aws.access-key,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
373,trino-server-373/lib/trino-main-373.jar,,task.max-partial-top-n-memory,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
373,trino-server-373/lib/trino-main-373.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.password.user-mapping.pattern,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.initial-splits-per-node,"",false
373,trino-server-373/lib/trino-main-373.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-queued-queries,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.skip-redundant-sort,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.krb5.name-type,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.compression-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.client-threads,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
373,trino-server-373/lib/trino-main-373.jar,,query.min-expire-age,"",false
373,trino-server-373/lib/trino-main-373.jar,,spill-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.krb5.principal-hostname,"",false
373,trino-server-373/lib/trino-main-373.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
373,trino-server-373/lib/trino-main-373.jar,,task.max-index-memory,"",false
373,trino-server-373/lib/trino-main-373.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
373,trino-server-373/lib/trino-main-373.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.jwt.principal-field,"",false
373,trino-server-373/lib/trino-main-373.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-stage-count,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-memory-per-task,"Sets memory limit enforced for a single task; there is no memory limit by default",false
373,trino-server-373/lib/trino-main-373.jar,,network-cost-weight,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.page-buffer-client.max-callback-threads,"",false
373,trino-server-373/lib/trino-main-373.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
373,trino-server-373/lib/trino-main-373.jar,,spiller-spill-path,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.http-timeout-threads,"",false
373,trino-server-373/lib/trino-main-373.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.certificate.user-mapping.file,"",false
373,trino-server-373/lib/trino-main-373.jar,,regex-library,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.jwt.user-mapping.file,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
373,trino-server-373/lib/trino-main-373.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
373,trino-server-373/lib/trino-main-373.jar,,task.info.max-age,"",false
373,trino-server-373/lib/trino-main-373.jar,,sink.max-broadcast-buffer-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
373,trino-server-373/lib/trino-main-373.jar,,query.client.timeout,"",false
373,trino-server-373/lib/trino-main-373.jar,,spiller-threads,"",false
373,trino-server-373/lib/trino-main-373.jar,,iterative-optimizer-timeout,"",false
373,trino-server-373/lib/trino-main-373.jar,,http.authentication.krb5.config,"",false
373,trino-server-373/lib/trino-main-373.jar,,enable-dynamic-filtering,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.min-error-duration,"",false
373,trino-server-373/lib/trino-main-373.jar,,web-ui.session-timeout,"",false
373,trino-server-373/lib/trino-main-373.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
373,trino-server-373/lib/trino-main-373.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.network-topology.refresh-period,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
373,trino-server-373/lib/trino-main-373.jar,,sink.max-buffer-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.merge-project-with-values,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.min-drivers,"",false
373,trino-server-373/lib/trino-main-373.jar,,http.include-exception-in-response,"",false
373,trino-server-373/lib/trino-main-373.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
373,trino-server-373/lib/trino-main-373.jar,,internal-communication.https.truststore.key,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
373,trino-server-373/lib/trino-main-373.jar,,task.max-worker-threads,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-total-memory,"",false
373,trino-server-373/lib/trino-main-373.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.include-coordinator,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.writer-count,"Number of writers per task",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.push-aggregation-through-outer-join,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.per-operator-cpu-timer-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
373,trino-server-373/lib/trino-main-373.jar,,task.split-concurrency-adjustment-interval,"",false
373,trino-server-373/lib/trino-main-373.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.deduplication-buffer-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.max-pending-splits-per-task,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-history,"",false
373,trino-server-373/lib/trino-main-373.jar,,shutdown.grace-period,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.max-response-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.remote-task.min-error-duration,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.data-integrity-verification,"",false
373,trino-server-373/lib/trino-main-373.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.krb5.keytab,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.push-table-write-through-union,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.insecure.user-mapping.file,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.push-partial-aggregation-through-join,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.execution-policy,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.min-candidates,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.max-buffer-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
373,trino-server-373/lib/trino-main-373.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
373,trino-server-373/lib/trino-main-373.jar,,task.statistics-cpu-timer-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,internal-communication.https.truststore.path,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
373,trino-server-373/lib/trino-main-373.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
373,trino-server-373/lib/trino-main-373.jar,,query-max-spill-per-node,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-memory-per-node,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.jwt.required-audience,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.complex-expression-pushdown.enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.remote-task.max-error-duration,"",false
373,trino-server-373/lib/trino-main-373.jar,,failure-detector.threshold,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.remote-task.max-callback-threads,"",false
373,trino-server-373/lib/trino-main-373.jar,,enable-stats-calculator,"",false
373,trino-server-373/lib/trino-main-373.jar,,sql.default-schema,"",false
373,trino-server-373/lib/trino-main-373.jar,,aggregation-operator-unspill-memory-limit,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-execution-time,"",false
373,trino-server-373/lib/trino-main-373.jar,,plugin.dir,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.cpu-timer-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.manager-executor-pool-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-memory,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-scan-physical-bytes,"",false
373,trino-server-373/lib/trino-main-373.jar,,enable-forced-exchange-below-group-id,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-cpu-time,"",false
373,trino-server-373/lib/trino-main-373.jar,,use-preferred-write-partitioning,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
373,trino-server-373/lib/trino-main-373.jar,,query.min-schedule-split-batch-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.network-topology.file,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
373,trino-server-373/lib/trino-main-373.jar,,internal-communication.https.keystore.key,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.jwt.required-issuer,"",false
373,trino-server-373/lib/trino-main-373.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
373,trino-server-373/lib/trino-main-373.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.dictionary-aggregation,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.policy,"",false
373,trino-server-373/lib/trino-main-373.jar,,internal-communication.shared-secret,"",false
373,trino-server-373/lib/trino-main-373.jar,,redistribute-writes,"",false
373,trino-server-373/lib/trino-main-373.jar,,experimental.late-materialization.enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-concurrent-queries,"",false
373,trino-server-373/lib/trino-main-373.jar,,distributed-index-joins-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
373,trino-server-373/lib/trino-main-373.jar,,spill-encryption-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,access-control.config-files,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.info-url-template,"",false
373,trino-server-373/lib/trino-main-373.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
373,trino-server-373/lib/trino-main-373.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
373,trino-server-373/lib/trino-main-373.jar,,memory-cost-weight,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.optimize-top-n-ranking,"",false
373,trino-server-373/lib/trino-main-373.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.default-filter-factor-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,web-ui.shared-secret,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.status-refresh-max-wait,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.network-topology.type,"",false
373,trino-server-373/lib/trino-main-373.jar,,analyzer.max-grouping-sets,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
373,trino-server-373/lib/trino-main-373.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
373,trino-server-373/lib/trino-main-373.jar,,retry-attempts,"",false
373,trino-server-373/lib/trino-main-373.jar,,deprecated.legacy-row-to-json-cast,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
373,trino-server-373/lib/trino-main-373.jar,,catalog.config-dir,"",false
373,trino-server-373/lib/trino-main-373.jar,,internal-communication.https.keystore.path,"",false
373,trino-server-373/lib/trino-main-373.jar,,re2j.dfa-states-limit,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
373,trino-server-373/lib/trino-main-373.jar,,retry-policy,"",false
373,trino-server-373/lib/trino-main-373.jar,,event-listener.config-files,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.enable-intermediate-aggregations,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.share-index-loading,"",false
373,trino-server-373/lib/trino-main-373.jar,,cpu-cost-weight,"",false
373,trino-server-373/lib/trino-main-373.jar,,compiler.expression-cache-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,event.max-output-stage-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
373,trino-server-373/lib/trino-main-373.jar,,internal-communication.https.required,"",false
373,trino-server-373/lib/trino-main-373.jar,,web-ui.enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.info-update-interval,"Interval between updating task data",false
373,trino-server-373/lib/trino-main-373.jar,,warning-collector.max-warnings,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.krb5.service-name,"",false
373,trino-server-373/lib/trino-main-373.jar,,pages-index.eager-compaction-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.low-memory-killer.policy,"",false
373,trino-server-373/lib/trino-main-373.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
373,trino-server-373/lib/trino-main-373.jar,,sql.default-catalog,"",false
373,trino-server-373/lib/trino-main-373.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
373,trino-server-373/lib/trino-main-373.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-run-time,"",false
373,trino-server-373/lib/trino-main-373.jar,,re2j.dfa-retries,"",false
373,trino-server-373/lib/trino-main-373.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
373,trino-server-373/lib/trino-main-373.jar,,web-ui.user,"",false
373,trino-server-373/lib/trino-main-373.jar,,spiller-max-used-space-threshold,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.password.user-mapping.file,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,parse-decimal-literals-as-double,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-length,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.jwt.key-file,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.prefer-partial-aggregation,"",false
373,trino-server-373/lib/trino-main-373.jar,,filter-and-project-min-output-page-row-count,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.max-partial-aggregation-memory,"",false
373,trino-server-373/lib/trino-main-373.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
373,trino-server-373/lib/trino-main-373.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
373,trino-server-373/lib/trino-main-373.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
373,trino-server-373/lib/trino-main-373.jar,,query-results.compression-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,scale-writers,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.http-response-threads,"",false
373,trino-server-373/lib/trino-main-373.jar,,enable-large-dynamic-filters,"",false
373,trino-server-373/lib/trino-main-373.jar,,filter-and-project-min-output-page-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,driver.max-page-partitioning-buffer-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
373,trino-server-373/lib/trino-main-373.jar,,max-spill-per-node,"",false
373,trino-server-373/lib/trino-main-373.jar,,join-distribution-type,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.max-planning-time,"",false
373,trino-server-373/lib/trino-main-373.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
373,trino-server-373/lib/trino-main-373.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
373,trino-server-373/lib/trino-main-373.jar,,failure-detector.heartbeat-interval,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
373,trino-server-373/lib/trino-main-373.jar,,jmx.base-name,"",false
373,trino-server-373/lib/trino-main-373.jar,,catalog.disabled-catalogs,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.force-single-node-output,"",false
373,trino-server-373/lib/trino-main-373.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
373,trino-server-373/lib/trino-main-373.jar,,distributed-sort,"",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.optimized-local-scheduling,"",false
373,trino-server-373/lib/trino-main-373.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.ignore-downstream-preferences,"",false
373,trino-server-373/lib/trino-main-373.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.acknowledge-pages,"",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.max-error-duration,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.optimize-hash-generation,"",false
373,trino-server-373/lib/trino-main-373.jar,,statistics-precalculation-for-pushdown.enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.krb5.user-mapping.file,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.use-mark-distinct,"",false
373,trino-server-373/lib/trino-main-373.jar,,optimizer.optimize-metadata-queries,"",false
373,trino-server-373/lib/trino-main-373.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
373,trino-server-373/lib/trino-main-373.jar,,node-scheduler.max-splits-per-node,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
373,trino-server-373/lib/trino-main-373.jar,,query.schedule-split-batch-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
373,trino-server-373/lib/trino-main-373.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
373,trino-server-373/lib/trino-main-373.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
373,trino-server-373/lib/trino-main-373.jar,,discovery-server.enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.https.enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,failure-detector.enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,task.max-local-exchange-buffer-size,"",false
373,trino-server-373/lib/trino-main-373.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
373,trino-server-373/lib/trino-main-373.jar,,task.client.timeout,"",false
373,trino-server-373/lib/trino-main-373.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
373,trino-server-373/lib/trino-main-373.jar,,spill-compression-enabled,"",false
373,trino-server-373/lib/trino-main-373.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
373,trino-server-373/lib/trino-main-373.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
373,trino-server-373/lib/trino-main-373.jar,,dynamic-filtering.service-thread-count,"",false
373,trino-server-373/lib/trino-main-373.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
373,trino-server-373/lib/trino-main-373.jar,,exchange.concurrent-request-multiplier,"",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
374,trino-server-374/plugin/kinesis/trino-kinesis-374.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
374,trino-server-374/plugin/kinesis/trino-plugin-toolkit-374.jar,kinesis,jmx.base-name,"",false
374,trino-server-374/plugin/kinesis/trino-plugin-toolkit-374.jar,kinesis,security.config-file,"",false
374,trino-server-374/plugin/kinesis/trino-plugin-toolkit-374.jar,kinesis,security.refresh-period,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,user-credential-name,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,keystore-password-credential-name,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,keystore-password,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,connection-password,"Password for JDBC client",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,keystore-password-credential-password,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,keystore-type,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,keystore-user-credential-name,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,connection-user,"user name for JDBC client",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,keystore-user-credential-password,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,case-insensitive-name-matching,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,password-credential-name,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,complex-expression-pushdown.enabled,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,credential-provider.type,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,connection-url,"",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
374,trino-server-374/plugin/clickhouse/trino-base-jdbc-374.jar,clickhouse,keystore-file-path,"",false
374,trino-server-374/plugin/clickhouse/trino-clickhouse-374.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
374,trino-server-374/plugin/clickhouse/trino-clickhouse-374.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
374,trino-server-374/plugin/postgresql/trino-postgresql-374.jar,postgresql,postgresql.include-system-tables,"",false
374,trino-server-374/plugin/postgresql/trino-postgresql-374.jar,postgresql,postgresql.array-mapping,"",false
374,trino-server-374/plugin/postgresql/trino-postgresql-374.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.encryption-enabled,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.sink-buffer-pool-min-size,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.s3.max-error-retries,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.base-directory,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.s3.endpoint,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.s3.aws-access-key,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.s3.region,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.source-concurrent-readers,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.s3.aws-secret-key,"",false
374,trino-server-374/plugin/exchange/trino-exchange-374.jar,exchange,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
374,trino-server-374/plugin/atop/trino-atop-374.jar,atop,atop.security,"",false
374,trino-server-374/plugin/atop/trino-atop-374.jar,atop,atop.executable-path,"",false
374,trino-server-374/plugin/atop/trino-atop-374.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
374,trino-server-374/plugin/atop/trino-atop-374.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
374,trino-server-374/plugin/atop/trino-atop-374.jar,atop,atop.max-history-days,"",false
374,trino-server-374/plugin/atop/trino-atop-374.jar,atop,atop.concurrent-readers-per-node,"",false
374,trino-server-374/plugin/memory/trino-memory-374.jar,memory,memory.max-data-per-node,"",false
374,trino-server-374/plugin/memory/trino-memory-374.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
374,trino-server-374/plugin/memory/trino-memory-374.jar,memory,memory.splits-per-node,"",false
374,trino-server-374/plugin/accumulo/trino-accumulo-374.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
374,trino-server-374/plugin/accumulo/trino-accumulo-374.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
374,trino-server-374/plugin/accumulo/trino-accumulo-374.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
374,trino-server-374/plugin/accumulo/trino-accumulo-374.jar,accumulo,accumulo.instance,"Accumulo instance name",false
374,trino-server-374/plugin/accumulo/trino-accumulo-374.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
374,trino-server-374/plugin/accumulo/trino-accumulo-374.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
374,trino-server-374/plugin/accumulo/trino-accumulo-374.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.broker.authentication.type,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.request-timeout,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.thread-pool-size,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.controller-urls,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.broker.authentication.user,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.max-connections-per-server,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.metadata-expiry,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.min-connections-per-server,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.prefer-broker-queries,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.segments-per-split,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.controller.authentication.password,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.connection-timeout,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.max-backlog-per-server,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.forbid-segment-queries,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.fetch-retry-count,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.controller.authentication.type,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.broker.authentication.password,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.max-rows-for-broker-queries,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.controller.authentication.user,"",false
374,trino-server-374/plugin/pinot/trino-pinot-374.jar,pinot,pinot.idle-timeout,"",false
374,trino-server-374/plugin/resource-group-managers/trino-resource-group-managers-374.jar,resource-group-managers,resource-groups.config-file,"",false
374,trino-server-374/plugin/resource-group-managers/trino-resource-group-managers-374.jar,resource-group-managers,jmx.base-name,"",false
374,trino-server-374/plugin/resource-group-managers/trino-resource-group-managers-374.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
374,trino-server-374/plugin/resource-group-managers/trino-resource-group-managers-374.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
374,trino-server-374/plugin/resource-group-managers/trino-resource-group-managers-374.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
374,trino-server-374/plugin/resource-group-managers/trino-resource-group-managers-374.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
374,trino-server-374/plugin/resource-group-managers/trino-resource-group-managers-374.jar,resource-group-managers,resource-groups.config-db-url,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.key-prefix-schema-table,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.nodes,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.password,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.scan-count,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.table-description-dir,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.database-index,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.table-names,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.connect-timeout,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.hide-internal-columns,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.default-schema,"",false
374,trino-server-374/plugin/redis/trino-redis-374.jar,redis,redis.key-delimiter,"",false
374,trino-server-374/plugin/example-http/trino-example-http-374.jar,example-http,metadata-uri,"",false
374,trino-server-374/plugin/local-file/trino-local-file-374.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
374,trino-server-374/plugin/local-file/trino-local-file-374.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
374,trino-server-374/plugin/jmx/trino-jmx-374.jar,jmx,jmx.dump-tables,"",false
374,trino-server-374/plugin/jmx/trino-jmx-374.jar,jmx,jmx.max-entries,"",false
374,trino-server-374/plugin/jmx/trino-jmx-374.jar,jmx,jmx.dump-period,"",false
374,trino-server-374/plugin/phoenix/trino-phoenix-374.jar,phoenix,phoenix.connection-url,"",false
374,trino-server-374/plugin/phoenix/trino-phoenix-374.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
374,trino-server-374/plugin/phoenix/trino-phoenix-374.jar,phoenix,phoenix.config.resources,"",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.remarks-reporting.enabled,"",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.synonyms.enabled,"",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.connection-pool.max-size,"",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.number.rounding-mode,"",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.connection-pool.min-size,"",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
374,trino-server-374/plugin/oracle/trino-oracle-374.jar,oracle,oracle.connection-pool.enabled,"",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.max-initial-split-size,"",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.max-split-size,"",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.max-initial-splits,"",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
374,trino-server-374/plugin/delta-lake/trino-delta-lake-374.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs.verify-checksum,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore-recording-path,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs.connect.max-retries,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.adl-credential,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.max-read-block-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.max-buffer-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.proxy.password,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.max-backoff-time,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs.domain-socket-path,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs-timeout,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.writer-sort-buffer-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore-cache-ttl,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.wasb-storage-account,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-split-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-initial-split-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.wasb-access-key,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-register-partition-procedure,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.sts.region,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.max-retry-time,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.version-compatibility,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.recursive-directories,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.streaming.enabled,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.writer.page-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3-file-system-type,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.socket-timeout,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.endpoint,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.max-error-retries,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.max-merge-distance,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.ignore-absent-partitions,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.config.resources,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.storage-format,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.writer.block-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.proxy.username,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore-refresh-interval,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.hdfs.socks-proxy,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.force-local-scheduling,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.proxy.protocol,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.proxy.port,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.max-merge-distance,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.sts.endpoint,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.replay-metastore-recording,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.proxy.host,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.compression-codec,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.data-transfer-port,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.max-client-retries,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.bookkeeper-port,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.stream-buffer-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.abfs-access-key,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.signer-class,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.max-connections,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.writer-identification,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.aws-secret-key,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.connect-timeout,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.adl-proxy-host,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.adl-client-id,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,parquet.max-buffer-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-concurrent-file-renames,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.max-read-block-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.file-status-cache-expire-time,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.split-loader-concurrency,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.abfs-storage-account,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.read-mode,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.signer-type,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.dfs.connect.timeout,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-initial-splits,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.ssl.enabled,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore-recording-duration,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.file-status-cache-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore-timeout,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.file-status-cache-tables,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.location,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.max-split-iterator-threads,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.aws-access-key,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.security,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.azure.adl-refresh-url,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
374,trino-server-374/plugin/delta-lake/trino-hive-374.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
374,trino-server-374/plugin/session-property-managers/trino-session-property-managers-374.jar,session-property-managers,session-property-manager.db.username,"",false
374,trino-server-374/plugin/session-property-managers/trino-session-property-managers-374.jar,session-property-managers,session-property-manager.db.url,"",false
374,trino-server-374/plugin/session-property-managers/trino-session-property-managers-374.jar,session-property-managers,session-property-manager.config-file,"",false
374,trino-server-374/plugin/session-property-managers/trino-session-property-managers-374.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
374,trino-server-374/plugin/session-property-managers/trino-session-property-managers-374.jar,session-property-managers,session-property-manager.db.password,"",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
374,trino-server-374/plugin/bigquery/trino-bigquery-374.jar,bigquery,bigquery.view-expire-duration,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.read-preference,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.min-connections-per-host,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.ssl.enabled,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.cursor-batch-size,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.max-wait-time,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.required-replica-set,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.seeds,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.connection-timeout,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.write-concern,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.connections-per-host,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.credentials,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.max-connection-idle-time,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.connection-url,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.schema-collection,"",false
374,trino-server-374/plugin/mongodb/trino-mongodb-374.jar,mongodb,mongodb.socket-timeout,"",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.security,"",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.compression-codec,"",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.catalog.type,"",false
374,trino-server-374/plugin/iceberg/trino-iceberg-374.jar,iceberg,iceberg.file-format,"",false
374,trino-server-374/plugin/phoenix5/trino-phoenix5-374.jar,phoenix5,phoenix.connection-url,"",false
374,trino-server-374/plugin/phoenix5/trino-phoenix5-374.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
374,trino-server-374/plugin/phoenix5/trino-phoenix5-374.jar,phoenix5,phoenix.config.resources,"",false
374,trino-server-374/plugin/thrift/trino-thrift-374.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
374,trino-server-374/plugin/thrift/trino-thrift-374.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
374,trino-server-374/plugin/thrift/trino-thrift-374.jar,thrift,trino-thrift.max-response-size,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,metadata.db.url,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.compaction-enabled,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.security,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.orc.max-read-size,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.balancer-enabled,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.organization-enabled,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.orc.nested-lazy,"",false
374,trino-server-374/plugin/raptor-legacy/trino-raptor-legacy-374.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
374,trino-server-374/plugin/google-sheets/trino-google-sheets-374.jar,google-sheets,credentials-path,"Credential file path to google service account",false
374,trino-server-374/plugin/google-sheets/trino-google-sheets-374.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
374,trino-server-374/plugin/google-sheets/trino-google-sheets-374.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
374,trino-server-374/plugin/google-sheets/trino-google-sheets-374.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
374,trino-server-374/plugin/kafka/trino-kafka-374.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.client.so-linger,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.tls.truststore-path,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.splits-per-node,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.username,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.password,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.contact-points,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.speculative-execution.limit,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.speculative-execution.delay,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.split-size,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.tls.keystore-path,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.batch-size,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.native-protocol-port,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.tls.truststore-password,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.consistency-level,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.tls.keystore-password,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.protocol-version,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.client.read-timeout,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.fetch-size,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.tls.enabled,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.client.connect-timeout,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.retry-policy,"",false
374,trino-server-374/plugin/cassandra/trino-cassandra-374.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
374,trino-server-374/plugin/mysql/trino-mysql-374.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
374,trino-server-374/plugin/mysql/trino-mysql-374.jar,mysql,mysql.connection-timeout,"",false
374,trino-server-374/plugin/mysql/trino-mysql-374.jar,mysql,mysql.auto-reconnect,"",false
374,trino-server-374/plugin/mysql/trino-mysql-374.jar,mysql,mysql.max-reconnects,"",false
374,trino-server-374/plugin/sqlserver/trino-sqlserver-374.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
374,trino-server-374/plugin/http-event-listener/trino-http-event-listener-374.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.grouped-execution.enabled,"",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.client.default-operation-timeout,"",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.schema-emulation.prefix,"",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.client.master-addresses,"",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.schema-emulation.enabled,"",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
374,trino-server-374/plugin/kudu/trino-kudu-374.jar,kudu,kudu.client.disable-statistics,"",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.timeout.connect,"Timeout for establishing a connection",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.url,"URL of the LDAP server",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.ssl-trust-certificate,"Path to the PEM trust certificate for the LDAP server",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.cache-ttl,"",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,ldap.timeout.read,"Timeout for reading data from LDAP",false
374,trino-server-374/plugin/password-authenticators/trino-password-authenticators-374.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
374,trino-server-374/plugin/prometheus/trino-prometheus-374.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
374,trino-server-374/plugin/prometheus/trino-prometheus-374.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
374,trino-server-374/plugin/prometheus/trino-prometheus-374.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
374,trino-server-374/plugin/prometheus/trino-prometheus-374.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
374,trino-server-374/plugin/prometheus/trino-prometheus-374.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
374,trino-server-374/plugin/prometheus/trino-prometheus-374.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.port,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.aws.access-key,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.host,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.aws.region,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.auth.password,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.auth.user,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.tls.enabled,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
374,trino-server-374/plugin/elasticsearch/trino-elasticsearch-374.jar,elasticsearch,elasticsearch.security,"",false
374,trino-server-374/plugin/singlestore/trino-singlestore-374.jar,singlestore,singlestore.auto-reconnect,"",false
374,trino-server-374/plugin/singlestore/trino-singlestore-374.jar,singlestore,singlestore.connection-timeout,"",false
374,trino-server-374/lib/trino-main-374.jar,,internal-communication.shared-secret,"",false
374,trino-server-374/lib/trino-main-374.jar,,regex-library,"",false
374,trino-server-374/lib/trino-main-374.jar,,catalog.disabled-catalogs,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.execution-policy,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.min-drivers,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
374,trino-server-374/lib/trino-main-374.jar,,internal-communication.https.required,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
374,trino-server-374/lib/trino-main-374.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
374,trino-server-374/lib/trino-main-374.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
374,trino-server-374/lib/trino-main-374.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.min-candidates,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.jwt.key-file,"",false
374,trino-server-374/lib/trino-main-374.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
374,trino-server-374/lib/trino-main-374.jar,,internal-communication.https.keystore.key,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.push-partial-aggregation-through-join,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.include-coordinator,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.krb5.keytab,"",false
374,trino-server-374/lib/trino-main-374.jar,,network-cost-weight,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.jwt.principal-field,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.certificate.user-mapping.file,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.max-splits-per-node,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.max-fraction-full-nodes-per-query,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
374,trino-server-374/lib/trino-main-374.jar,,iterative-optimizer-timeout,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.optimized-local-scheduling,"",false
374,trino-server-374/lib/trino-main-374.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-history,"",false
374,trino-server-374/lib/trino-main-374.jar,,web-ui.session-timeout,"",false
374,trino-server-374/lib/trino-main-374.jar,,event-listener.config-files,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.manager-executor-pool-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
374,trino-server-374/lib/trino-main-374.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
374,trino-server-374/lib/trino-main-374.jar,,task.max-partial-top-n-memory,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.https.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,join-distribution-type,"",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.client-threads,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-memory,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.cpu-timer-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-planning-time,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.krb5.principal-hostname,"",false
374,trino-server-374/lib/trino-main-374.jar,,adaptive-partial-aggregation.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
374,trino-server-374/lib/trino-main-374.jar,,task.max-partial-aggregation-memory,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.max-index-memory,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.max-worker-threads,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-queued-queries,"",false
374,trino-server-374/lib/trino-main-374.jar,,compiler.expression-cache-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
374,trino-server-374/lib/trino-main-374.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
374,trino-server-374/lib/trino-main-374.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
374,trino-server-374/lib/trino-main-374.jar,,failure-detector.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.http-timeout-threads,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
374,trino-server-374/lib/trino-main-374.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
374,trino-server-374/lib/trino-main-374.jar,,experimental.late-materialization.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-total-memory,"",false
374,trino-server-374/lib/trino-main-374.jar,,re2j.dfa-states-limit,"",false
374,trino-server-374/lib/trino-main-374.jar,,sql.default-schema,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.schedule-split-batch-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,sql.default-catalog,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.jwt.required-audience,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-memory-per-node,"",false
374,trino-server-374/lib/trino-main-374.jar,,warning-collector.max-warnings,"",false
374,trino-server-374/lib/trino-main-374.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
374,trino-server-374/lib/trino-main-374.jar,,query.info-url-template,"",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.acknowledge-pages,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
374,trino-server-374/lib/trino-main-374.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
374,trino-server-374/lib/trino-main-374.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
374,trino-server-374/lib/trino-main-374.jar,,max-spill-per-node,"",false
374,trino-server-374/lib/trino-main-374.jar,,task-retry-attempts-overall,"",false
374,trino-server-374/lib/trino-main-374.jar,,driver.max-page-partitioning-buffer-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
374,trino-server-374/lib/trino-main-374.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.service-thread-count,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.remote-task.max-callback-threads,"",false
374,trino-server-374/lib/trino-main-374.jar,,spill-encryption-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-length,"",false
374,trino-server-374/lib/trino-main-374.jar,,filter-and-project-min-output-page-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,task-retry-attempts-per-task,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.statistics-cpu-timer-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.network-topology.type,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
374,trino-server-374/lib/trino-main-374.jar,,web-ui.user,"",false
374,trino-server-374/lib/trino-main-374.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.data-integrity-verification,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.krb5.name-type,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.dictionary-aggregation,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.push-aggregation-through-outer-join,"",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.max-buffer-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,http.include-exception-in-response,"",false
374,trino-server-374/lib/trino-main-374.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.page-buffer-client.max-callback-threads,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
374,trino-server-374/lib/trino-main-374.jar,,aggregation-operator-unspill-memory-limit,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-concurrent-queries,"",false
374,trino-server-374/lib/trino-main-374.jar,,query-results.compression-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.initial-splits-per-node,"",false
374,trino-server-374/lib/trino-main-374.jar,,parse-decimal-literals-as-double,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.krb5.service-name,"",false
374,trino-server-374/lib/trino-main-374.jar,,query-retry-attempts,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.push-table-write-through-union,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,spill-compression-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,scale-writers,"",false
374,trino-server-374/lib/trino-main-374.jar,,analyzer.max-grouping-sets,"",false
374,trino-server-374/lib/trino-main-374.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
374,trino-server-374/lib/trino-main-374.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
374,trino-server-374/lib/trino-main-374.jar,,query.low-memory-killer.policy,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.jwt.required-issuer,"",false
374,trino-server-374/lib/trino-main-374.jar,,sink.max-buffer-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.compression-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.prefer-partial-aggregation,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.per-operator-cpu-timer-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
374,trino-server-374/lib/trino-main-374.jar,,catalog.config-dir,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
374,trino-server-374/lib/trino-main-374.jar,,enable-forced-exchange-below-group-id,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.allocator-type,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.max-local-exchange-buffer-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.krb5.user-mapping.file,"",false
374,trino-server-374/lib/trino-main-374.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
374,trino-server-374/lib/trino-main-374.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
374,trino-server-374/lib/trino-main-374.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.use-mark-distinct,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.default-filter-factor-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.network-topology.file,"",false
374,trino-server-374/lib/trino-main-374.jar,,use-preferred-write-partitioning,"",false
374,trino-server-374/lib/trino-main-374.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
374,trino-server-374/lib/trino-main-374.jar,,failure-detector.threshold,"",false
374,trino-server-374/lib/trino-main-374.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
374,trino-server-374/lib/trino-main-374.jar,,internal-communication.https.keystore.path,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.complex-expression-pushdown.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.share-index-loading,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
374,trino-server-374/lib/trino-main-374.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.network-topology.refresh-period,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.password.user-mapping.file,"",false
374,trino-server-374/lib/trino-main-374.jar,,web-ui.shared-secret,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
374,trino-server-374/lib/trino-main-374.jar,,web-ui.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.max-error-duration,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
374,trino-server-374/lib/trino-main-374.jar,,query.remote-task.max-error-duration,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
374,trino-server-374/lib/trino-main-374.jar,,spill-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.min-expire-age,"",false
374,trino-server-374/lib/trino-main-374.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.deduplication-buffer-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
374,trino-server-374/lib/trino-main-374.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
374,trino-server-374/lib/trino-main-374.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
374,trino-server-374/lib/trino-main-374.jar,,failure-detector.heartbeat-interval,"",false
374,trino-server-374/lib/trino-main-374.jar,,sink.max-broadcast-buffer-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,deprecated.legacy-row-to-json-cast,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.ignore-downstream-preferences,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
374,trino-server-374/lib/trino-main-374.jar,,spiller-threads,"",false
374,trino-server-374/lib/trino-main-374.jar,,discovery-server.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
374,trino-server-374/lib/trino-main-374.jar,,access-control.config-files,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.jwt.user-mapping.file,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.max-pending-splits-per-task,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-execution-time,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
374,trino-server-374/lib/trino-main-374.jar,,internal-communication.https.truststore.key,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,distributed-index-joins-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
374,trino-server-374/lib/trino-main-374.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
374,trino-server-374/lib/trino-main-374.jar,,task.client.timeout,"",false
374,trino-server-374/lib/trino-main-374.jar,,memory-cost-weight,"",false
374,trino-server-374/lib/trino-main-374.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.merge-project-with-values,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.optimize-metadata-queries,"",false
374,trino-server-374/lib/trino-main-374.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
374,trino-server-374/lib/trino-main-374.jar,,query-max-spill-per-node,"",false
374,trino-server-374/lib/trino-main-374.jar,,re2j.dfa-retries,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.info-update-interval,"Interval between updating task data",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
374,trino-server-374/lib/trino-main-374.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.skip-redundant-sort,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-cpu-time,"",false
374,trino-server-374/lib/trino-main-374.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
374,trino-server-374/lib/trino-main-374.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
374,trino-server-374/lib/trino-main-374.jar,,spiller-spill-path,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
374,trino-server-374/lib/trino-main-374.jar,,event.max-output-stage-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.optimize-top-n-ranking,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-stage-count,"",false
374,trino-server-374/lib/trino-main-374.jar,,enable-large-dynamic-filters,"",false
374,trino-server-374/lib/trino-main-374.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
374,trino-server-374/lib/trino-main-374.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
374,trino-server-374/lib/trino-main-374.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.writer-count,"Number of writers per task",false
374,trino-server-374/lib/trino-main-374.jar,,task.info.max-age,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.enable-intermediate-aggregations,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
374,trino-server-374/lib/trino-main-374.jar,,shutdown.grace-period,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.optimize-hash-generation,"",false
374,trino-server-374/lib/trino-main-374.jar,,enable-stats-calculator,"",false
374,trino-server-374/lib/trino-main-374.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.min-error-duration,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
374,trino-server-374/lib/trino-main-374.jar,,http.authentication.krb5.config,"",false
374,trino-server-374/lib/trino-main-374.jar,,statistics-precalculation-for-pushdown.enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
374,trino-server-374/lib/trino-main-374.jar,,internal-communication.https.truststore.path,"",false
374,trino-server-374/lib/trino-main-374.jar,,optimizer.force-single-node-output,"",false
374,trino-server-374/lib/trino-main-374.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.remote-task.min-error-duration,"",false
374,trino-server-374/lib/trino-main-374.jar,,cpu-cost-weight,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
374,trino-server-374/lib/trino-main-374.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
374,trino-server-374/lib/trino-main-374.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
374,trino-server-374/lib/trino-main-374.jar,,pages-index.eager-compaction-enabled,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-scan-physical-bytes,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.insecure.user-mapping.file,"",false
374,trino-server-374/lib/trino-main-374.jar,,http-server.authentication.password.user-mapping.pattern,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.status-refresh-max-wait,"",false
374,trino-server-374/lib/trino-main-374.jar,,retry-policy,"",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.concurrent-request-multiplier,"",false
374,trino-server-374/lib/trino-main-374.jar,,spiller-max-used-space-threshold,"",false
374,trino-server-374/lib/trino-main-374.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
374,trino-server-374/lib/trino-main-374.jar,,query.max-run-time,"",false
374,trino-server-374/lib/trino-main-374.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
374,trino-server-374/lib/trino-main-374.jar,,jmx.base-name,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.client.timeout,"",false
374,trino-server-374/lib/trino-main-374.jar,,query.min-schedule-split-batch-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
374,trino-server-374/lib/trino-main-374.jar,,task.http-response-threads,"",false
374,trino-server-374/lib/trino-main-374.jar,,plugin.dir,"",false
374,trino-server-374/lib/trino-main-374.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
374,trino-server-374/lib/trino-main-374.jar,,redistribute-writes,"",false
374,trino-server-374/lib/trino-main-374.jar,,exchange.max-response-size,"",false
374,trino-server-374/lib/trino-main-374.jar,,filter-and-project-min-output-page-row-count,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.policy,"",false
374,trino-server-374/lib/trino-main-374.jar,,task.split-concurrency-adjustment-interval,"",false
374,trino-server-374/lib/trino-main-374.jar,,enable-dynamic-filtering,"",false
374,trino-server-374/lib/trino-main-374.jar,,distributed-sort,"",false
374,trino-server-374/lib/trino-main-374.jar,,node-scheduler.max-absolute-full-nodes-per-query,"",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
375,trino-server-375/plugin/kinesis/trino-kinesis-375.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
375,trino-server-375/plugin/kinesis/trino-plugin-toolkit-375.jar,kinesis,security.config-file,"",false
375,trino-server-375/plugin/kinesis/trino-plugin-toolkit-375.jar,kinesis,jmx.base-name,"",false
375,trino-server-375/plugin/kinesis/trino-plugin-toolkit-375.jar,kinesis,security.refresh-period,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,keystore-password,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,join-pushdown.strategy,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,statistics.enabled,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,credential-provider.type,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,password-credential-name,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,user-credential-name,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,keystore-user-credential-name,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,keystore-password-credential-name,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,keystore-type,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,case-insensitive-name-matching,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,connection-url,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,connection-password,"Password for JDBC client",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,connection-user,"user name for JDBC client",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,keystore-file-path,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,keystore-password-credential-password,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,complex-expression-pushdown.enabled,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,keystore-user-credential-password,"",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
375,trino-server-375/plugin/clickhouse/trino-base-jdbc-375.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
375,trino-server-375/plugin/clickhouse/trino-clickhouse-375.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
375,trino-server-375/plugin/clickhouse/trino-clickhouse-375.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
375,trino-server-375/plugin/postgresql/trino-postgresql-375.jar,postgresql,postgresql.array-mapping,"",false
375,trino-server-375/plugin/postgresql/trino-postgresql-375.jar,postgresql,postgresql.include-system-tables,"",false
375,trino-server-375/plugin/postgresql/trino-postgresql-375.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.aws-access-key,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.base-directory,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.region,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.max-error-retries,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.sink-buffer-pool-min-size,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.storage-class,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.endpoint,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.aws-secret-key,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.sink-buffers-per-partition,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.use-web-identity-token-credentials,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.encryption-enabled,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.s3.async-client-concurrency,"",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
375,trino-server-375/plugin/exchange/trino-exchange-375.jar,exchange,exchange.source-concurrent-readers,"",false
375,trino-server-375/plugin/atop/trino-atop-375.jar,atop,atop.max-history-days,"",false
375,trino-server-375/plugin/atop/trino-atop-375.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
375,trino-server-375/plugin/atop/trino-atop-375.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
375,trino-server-375/plugin/atop/trino-atop-375.jar,atop,atop.executable-path,"",false
375,trino-server-375/plugin/atop/trino-atop-375.jar,atop,atop.security,"",false
375,trino-server-375/plugin/atop/trino-atop-375.jar,atop,atop.concurrent-readers-per-node,"",false
375,trino-server-375/plugin/memory/trino-memory-375.jar,memory,memory.max-data-per-node,"",false
375,trino-server-375/plugin/memory/trino-memory-375.jar,memory,memory.splits-per-node,"",false
375,trino-server-375/plugin/memory/trino-memory-375.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
375,trino-server-375/plugin/accumulo/trino-accumulo-375.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
375,trino-server-375/plugin/accumulo/trino-accumulo-375.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
375,trino-server-375/plugin/accumulo/trino-accumulo-375.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
375,trino-server-375/plugin/accumulo/trino-accumulo-375.jar,accumulo,accumulo.instance,"Accumulo instance name",false
375,trino-server-375/plugin/accumulo/trino-accumulo-375.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
375,trino-server-375/plugin/accumulo/trino-accumulo-375.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
375,trino-server-375/plugin/accumulo/trino-accumulo-375.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.controller.authentication.user,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.max-rows-for-broker-queries,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.broker.authentication.password,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.controller.authentication.type,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.fetch-retry-count,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.forbid-segment-queries,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.max-backlog-per-server,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.connection-timeout,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.controller.authentication.password,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.segments-per-split,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.prefer-broker-queries,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.min-connections-per-server,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.metadata-expiry,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.max-connections-per-server,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.broker.authentication.user,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.controller-urls,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.thread-pool-size,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.request-timeout,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.broker.authentication.type,"",false
375,trino-server-375/plugin/pinot/trino-pinot-375.jar,pinot,pinot.idle-timeout,"",false
375,trino-server-375/plugin/resource-group-managers/trino-resource-group-managers-375.jar,resource-group-managers,resource-groups.config-db-url,"",false
375,trino-server-375/plugin/resource-group-managers/trino-resource-group-managers-375.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
375,trino-server-375/plugin/resource-group-managers/trino-resource-group-managers-375.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
375,trino-server-375/plugin/resource-group-managers/trino-resource-group-managers-375.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
375,trino-server-375/plugin/resource-group-managers/trino-resource-group-managers-375.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
375,trino-server-375/plugin/resource-group-managers/trino-resource-group-managers-375.jar,resource-group-managers,jmx.base-name,"",false
375,trino-server-375/plugin/resource-group-managers/trino-resource-group-managers-375.jar,resource-group-managers,resource-groups.config-file,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.default-schema,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.hide-internal-columns,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.connect-timeout,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.table-names,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.database-index,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.table-description-dir,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.scan-count,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.password,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.nodes,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.key-prefix-schema-table,"",false
375,trino-server-375/plugin/redis/trino-redis-375.jar,redis,redis.key-delimiter,"",false
375,trino-server-375/plugin/example-http/trino-example-http-375.jar,example-http,metadata-uri,"",false
375,trino-server-375/plugin/local-file/trino-local-file-375.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
375,trino-server-375/plugin/local-file/trino-local-file-375.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
375,trino-server-375/plugin/jmx/trino-jmx-375.jar,jmx,jmx.dump-period,"",false
375,trino-server-375/plugin/jmx/trino-jmx-375.jar,jmx,jmx.max-entries,"",false
375,trino-server-375/plugin/jmx/trino-jmx-375.jar,jmx,jmx.dump-tables,"",false
375,trino-server-375/plugin/phoenix/trino-phoenix-375.jar,phoenix,phoenix.config.resources,"",false
375,trino-server-375/plugin/phoenix/trino-phoenix-375.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
375,trino-server-375/plugin/phoenix/trino-phoenix-375.jar,phoenix,phoenix.connection-url,"",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.connection-pool.enabled,"",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.connection-pool.min-size,"",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.number.rounding-mode,"",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.connection-pool.max-size,"",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.synonyms.enabled,"",false
375,trino-server-375/plugin/oracle/trino-oracle-375.jar,oracle,oracle.remarks-reporting.enabled,"",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.max-initial-splits,"",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.max-split-size,"",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.max-initial-split-size,"",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
375,trino-server-375/plugin/delta-lake/trino-delta-lake-375.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.aws-access-key,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-split-iterator-threads,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.location,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.file-status-cache-tables,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore-timeout,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.file-status-cache-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore-recording-duration,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.ssl.enabled,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-initial-splits,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs.connect.timeout,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.signer-type,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.read-mode,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.abfs-storage-account,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.split-loader-concurrency,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.file-status-cache-expire-time,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.max-read-block-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-concurrent-file-renames,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.max-buffer-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.adl-client-id,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.adl-proxy-host,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.connect-timeout,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.aws-secret-key,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.writer-identification,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.max-connections,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.signer-class,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.abfs-access-key,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.stream-buffer-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.bookkeeper-port,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.max-client-retries,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.data-transfer-port,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.compression-codec,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.proxy.host,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.replay-metastore-recording,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.sts.endpoint,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.max-merge-distance,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.proxy.port,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.proxy.protocol,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.force-local-scheduling,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.hdfs.socks-proxy,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore-refresh-interval,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.proxy.username,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.writer.block-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.storage-format,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.config.resources,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.ignore-absent-partitions,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.max-merge-distance,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.max-error-retries,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.endpoint,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.socket-timeout,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3-file-system-type,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.writer.page-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.streaming.enabled,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.recursive-directories,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.version-compatibility,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.max-retry-time,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.sts.region,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-register-partition-procedure,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.wasb-access-key,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-initial-split-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-split-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.wasb-storage-account,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore-cache-ttl,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.writer-sort-buffer-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs-timeout,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs.domain-socket-path,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.max-backoff-time,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.proxy.password,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.max-buffer-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,parquet.max-read-block-size,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.adl-credential,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs.connect.max-retries,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore-recording-path,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.dfs.verify-checksum,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.adl-refresh-url,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.security,"",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
375,trino-server-375/plugin/delta-lake/trino-hive-375.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
375,trino-server-375/plugin/session-property-managers/trino-session-property-managers-375.jar,session-property-managers,session-property-manager.db.password,"",false
375,trino-server-375/plugin/session-property-managers/trino-session-property-managers-375.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
375,trino-server-375/plugin/session-property-managers/trino-session-property-managers-375.jar,session-property-managers,session-property-manager.config-file,"",false
375,trino-server-375/plugin/session-property-managers/trino-session-property-managers-375.jar,session-property-managers,session-property-manager.db.url,"",false
375,trino-server-375/plugin/session-property-managers/trino-session-property-managers-375.jar,session-property-managers,session-property-manager.db.username,"",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.view-expire-duration,"",false
375,trino-server-375/plugin/bigquery/trino-bigquery-375.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.schema-collection,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.connection-url,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.max-connection-idle-time,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.credentials,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.connections-per-host,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.write-concern,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.connection-timeout,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.seeds,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.required-replica-set,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.max-wait-time,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.cursor-batch-size,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.ssl.enabled,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.min-connections-per-host,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.read-preference,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
375,trino-server-375/plugin/mongodb/trino-mongodb-375.jar,mongodb,mongodb.socket-timeout,"",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.file-format,"",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.catalog.type,"",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.compression-codec,"",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
375,trino-server-375/plugin/iceberg/trino-iceberg-375.jar,iceberg,iceberg.security,"",false
375,trino-server-375/plugin/phoenix5/trino-phoenix5-375.jar,phoenix5,phoenix.config.resources,"",false
375,trino-server-375/plugin/phoenix5/trino-phoenix5-375.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
375,trino-server-375/plugin/phoenix5/trino-phoenix5-375.jar,phoenix5,phoenix.connection-url,"",false
375,trino-server-375/plugin/thrift/trino-thrift-375.jar,thrift,trino-thrift.max-response-size,"",false
375,trino-server-375/plugin/thrift/trino-thrift-375.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
375,trino-server-375/plugin/thrift/trino-thrift-375.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.organization-enabled,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.balancer-enabled,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.orc.max-read-size,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.security,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.compaction-enabled,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,metadata.db.url,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.orc.nested-lazy,"",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
375,trino-server-375/plugin/raptor-legacy/trino-raptor-legacy-375.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
375,trino-server-375/plugin/google-sheets/trino-google-sheets-375.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
375,trino-server-375/plugin/google-sheets/trino-google-sheets-375.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
375,trino-server-375/plugin/google-sheets/trino-google-sheets-375.jar,google-sheets,credentials-path,"Credential file path to google service account",false
375,trino-server-375/plugin/google-sheets/trino-google-sheets-375.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
375,trino-server-375/plugin/kafka/trino-kafka-375.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.client.connect-timeout,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.tls.enabled,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.fetch-size,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.client.read-timeout,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.protocol-version,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.tls.keystore-password,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.consistency-level,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.tls.truststore-password,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.native-protocol-port,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.batch-size,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.tls.keystore-path,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.split-size,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.speculative-execution.delay,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.speculative-execution.limit,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.contact-points,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.password,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.username,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.splits-per-node,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.tls.truststore-path,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.client.so-linger,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
375,trino-server-375/plugin/cassandra/trino-cassandra-375.jar,cassandra,cassandra.retry-policy,"",false
375,trino-server-375/plugin/mysql/trino-mysql-375.jar,mysql,mysql.auto-reconnect,"",false
375,trino-server-375/plugin/mysql/trino-mysql-375.jar,mysql,mysql.connection-timeout,"",false
375,trino-server-375/plugin/mysql/trino-mysql-375.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
375,trino-server-375/plugin/mysql/trino-mysql-375.jar,mysql,mysql.max-reconnects,"",false
375,trino-server-375/plugin/sqlserver/trino-sqlserver-375.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
375,trino-server-375/plugin/http-event-listener/trino-http-event-listener-375.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.schema-emulation.enabled,"",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.client.master-addresses,"",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.schema-emulation.prefix,"",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.client.default-operation-timeout,"",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.grouped-execution.enabled,"",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
375,trino-server-375/plugin/kudu/trino-kudu-375.jar,kudu,kudu.client.disable-statistics,"",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.timeout.read,"Timeout for reading data from LDAP",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.cache-ttl,"",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.ssl-trust-certificate,"Path to the PEM trust certificate for the LDAP server",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.url,"URL of the LDAP server",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.timeout.connect,"Timeout for establishing a connection",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
375,trino-server-375/plugin/password-authenticators/trino-password-authenticators-375.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
375,trino-server-375/plugin/prometheus/trino-prometheus-375.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
375,trino-server-375/plugin/prometheus/trino-prometheus-375.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
375,trino-server-375/plugin/prometheus/trino-prometheus-375.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
375,trino-server-375/plugin/prometheus/trino-prometheus-375.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
375,trino-server-375/plugin/prometheus/trino-prometheus-375.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
375,trino-server-375/plugin/prometheus/trino-prometheus-375.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.tls.enabled,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.auth.user,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.auth.password,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.aws.region,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.host,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.aws.access-key,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.port,"",false
375,trino-server-375/plugin/elasticsearch/trino-elasticsearch-375.jar,elasticsearch,elasticsearch.security,"",false
375,trino-server-375/plugin/singlestore/trino-singlestore-375.jar,singlestore,singlestore.connection-timeout,"",false
375,trino-server-375/plugin/singlestore/trino-singlestore-375.jar,singlestore,singlestore.auto-reconnect,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
375,trino-server-375/lib/trino-main-375.jar,,query.client.timeout,"",false
375,trino-server-375/lib/trino-main-375.jar,,distributed-sort,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.optimized-local-scheduling,"",false
375,trino-server-375/lib/trino-main-375.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.jwt.required-issuer,"",false
375,trino-server-375/lib/trino-main-375.jar,,event.max-output-stage-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.use-mark-distinct,"",false
375,trino-server-375/lib/trino-main-375.jar,,spiller-max-used-space-threshold,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.min-expire-age,"",false
375,trino-server-375/lib/trino-main-375.jar,,aggregation-operator-unspill-memory-limit,"",false
375,trino-server-375/lib/trino-main-375.jar,,failure-detector.heartbeat-interval,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
375,trino-server-375/lib/trino-main-375.jar,,enable-forced-exchange-below-group-id,"",false
375,trino-server-375/lib/trino-main-375.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
375,trino-server-375/lib/trino-main-375.jar,,memory-cost-weight,"",false
375,trino-server-375/lib/trino-main-375.jar,,spiller-spill-path,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.prefer-partial-aggregation,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-execution-time,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.remote-task.min-error-duration,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.compression-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.optimize-top-n-ranking,"",false
375,trino-server-375/lib/trino-main-375.jar,,deprecated.legacy-row-to-json-cast,"",false
375,trino-server-375/lib/trino-main-375.jar,,web-ui.shared-secret,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
375,trino-server-375/lib/trino-main-375.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
375,trino-server-375/lib/trino-main-375.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.jwt.principal-field,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.https.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,spill-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.password.user-mapping.file,"",false
375,trino-server-375/lib/trino-main-375.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
375,trino-server-375/lib/trino-main-375.jar,,spill-compression-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,sql.default-catalog,"",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.max-buffer-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
375,trino-server-375/lib/trino-main-375.jar,,task.split-concurrency-adjustment-interval,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.force-single-node-output,"",false
375,trino-server-375/lib/trino-main-375.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
375,trino-server-375/lib/trino-main-375.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
375,trino-server-375/lib/trino-main-375.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.optimize-hash-generation,"",false
375,trino-server-375/lib/trino-main-375.jar,,enable-dynamic-filtering,"",false
375,trino-server-375/lib/trino-main-375.jar,,internal-communication.https.truststore.key,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.max-pending-splits-per-task,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.certificate.user-mapping.file,"",false
375,trino-server-375/lib/trino-main-375.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
375,trino-server-375/lib/trino-main-375.jar,,task.share-index-loading,"",false
375,trino-server-375/lib/trino-main-375.jar,,failure-detector.threshold,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.min-candidates,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.push-table-write-through-union,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.password.user-mapping.pattern,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-memory-per-node,"",false
375,trino-server-375/lib/trino-main-375.jar,,regex-library,"",false
375,trino-server-375/lib/trino-main-375.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-run-time,"",false
375,trino-server-375/lib/trino-main-375.jar,,task-retry-attempts-overall,"",false
375,trino-server-375/lib/trino-main-375.jar,,enable-stats-calculator,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
375,trino-server-375/lib/trino-main-375.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-memory,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.complex-expression-pushdown.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.max-partial-top-n-memory,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.client.timeout,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
375,trino-server-375/lib/trino-main-375.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
375,trino-server-375/lib/trino-main-375.jar,,web-ui.user,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.max-local-exchange-buffer-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,join-distribution-type,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-scan-physical-bytes,"",false
375,trino-server-375/lib/trino-main-375.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
375,trino-server-375/lib/trino-main-375.jar,,sql.default-schema,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.max-index-memory,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.jwt.required-audience,"",false
375,trino-server-375/lib/trino-main-375.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
375,trino-server-375/lib/trino-main-375.jar,,internal-communication.https.keystore.path,"",false
375,trino-server-375/lib/trino-main-375.jar,,enable-large-dynamic-filters,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.merge-project-with-values,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
375,trino-server-375/lib/trino-main-375.jar,,query.remote-task.max-callback-threads,"",false
375,trino-server-375/lib/trino-main-375.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.acknowledge-pages,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
375,trino-server-375/lib/trino-main-375.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
375,trino-server-375/lib/trino-main-375.jar,,plugin.dir,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.krb5.name-type,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
375,trino-server-375/lib/trino-main-375.jar,,max-spill-per-node,"",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.max-response-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,internal-communication.shared-secret,"",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.min-error-duration,"",false
375,trino-server-375/lib/trino-main-375.jar,,internal-communication.https.required,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.concurrent-request-multiplier,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
375,trino-server-375/lib/trino-main-375.jar,,task.max-partial-aggregation-memory,"",false
375,trino-server-375/lib/trino-main-375.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,event-listener.config-files,"",false
375,trino-server-375/lib/trino-main-375.jar,,iterative-optimizer-timeout,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.info-update-interval,"Interval between updating task data",false
375,trino-server-375/lib/trino-main-375.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
375,trino-server-375/lib/trino-main-375.jar,,task.max-worker-threads,"",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.max-error-duration,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.policy,"",false
375,trino-server-375/lib/trino-main-375.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
375,trino-server-375/lib/trino-main-375.jar,,query-max-spill-per-node,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
375,trino-server-375/lib/trino-main-375.jar,,internal-communication.https.keystore.key,"",false
375,trino-server-375/lib/trino-main-375.jar,,warning-collector.max-warnings,"",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.data-integrity-verification,"",false
375,trino-server-375/lib/trino-main-375.jar,,analyzer.max-grouping-sets,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
375,trino-server-375/lib/trino-main-375.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
375,trino-server-375/lib/trino-main-375.jar,,task.cpu-timer-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,failure-detector.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
375,trino-server-375/lib/trino-main-375.jar,,retry-policy,"",false
375,trino-server-375/lib/trino-main-375.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
375,trino-server-375/lib/trino-main-375.jar,,http.authentication.krb5.config,"",false
375,trino-server-375/lib/trino-main-375.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-concurrent-queries,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.manager-executor-pool-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.push-aggregation-through-outer-join,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.info.max-age,"",false
375,trino-server-375/lib/trino-main-375.jar,,filter-and-project-min-output-page-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,shutdown.grace-period,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
375,trino-server-375/lib/trino-main-375.jar,,web-ui.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
375,trino-server-375/lib/trino-main-375.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
375,trino-server-375/lib/trino-main-375.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
375,trino-server-375/lib/trino-main-375.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
375,trino-server-375/lib/trino-main-375.jar,,spill-encryption-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-length,"",false
375,trino-server-375/lib/trino-main-375.jar,,statistics-precalculation-for-pushdown.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,internal-communication.https.truststore.path,"",false
375,trino-server-375/lib/trino-main-375.jar,,sink.max-broadcast-buffer-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.krb5.user-mapping.file,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
375,trino-server-375/lib/trino-main-375.jar,,pages-index.eager-compaction-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,compiler.expression-cache-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,http.include-exception-in-response,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.jwt.user-mapping.file,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
375,trino-server-375/lib/trino-main-375.jar,,query-retry-attempts,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-queued-queries,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.optimize-metadata-queries,"",false
375,trino-server-375/lib/trino-main-375.jar,,re2j.dfa-states-limit,"",false
375,trino-server-375/lib/trino-main-375.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
375,trino-server-375/lib/trino-main-375.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
375,trino-server-375/lib/trino-main-375.jar,,driver.max-page-partitioning-buffer-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.service-thread-count,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.execution-policy,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.dictionary-aggregation,"",false
375,trino-server-375/lib/trino-main-375.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.page-buffer-client.max-callback-threads,"",false
375,trino-server-375/lib/trino-main-375.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
375,trino-server-375/lib/trino-main-375.jar,,query.remote-task.max-error-duration,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-stage-count,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.krb5.keytab,"",false
375,trino-server-375/lib/trino-main-375.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
375,trino-server-375/lib/trino-main-375.jar,,jmx.base-name,"",false
375,trino-server-375/lib/trino-main-375.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-history,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.per-operator-cpu-timer-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.min-schedule-split-batch-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
375,trino-server-375/lib/trino-main-375.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
375,trino-server-375/lib/trino-main-375.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
375,trino-server-375/lib/trino-main-375.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
375,trino-server-375/lib/trino-main-375.jar,,task.http-response-threads,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.ignore-downstream-preferences,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.schedule-split-batch-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
375,trino-server-375/lib/trino-main-375.jar,,sink.max-buffer-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-cpu-time,"",false
375,trino-server-375/lib/trino-main-375.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.skip-redundant-sort,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.min-drivers,"",false
375,trino-server-375/lib/trino-main-375.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.include-coordinator,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.enable-intermediate-aggregations,"",false
375,trino-server-375/lib/trino-main-375.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-total-memory,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.max-planning-time,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.network-topology.type,"",false
375,trino-server-375/lib/trino-main-375.jar,,query-results.compression-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,discovery-server.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,adaptive-partial-aggregation.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,use-preferred-write-partitioning,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.jwt.key-file,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.max-fraction-full-nodes-per-query,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
375,trino-server-375/lib/trino-main-375.jar,,query.low-memory-killer.policy,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
375,trino-server-375/lib/trino-main-375.jar,,task.writer-count,"Number of writers per task",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.deduplication-buffer-size,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.status-refresh-max-wait,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.push-partial-aggregation-through-join,"",false
375,trino-server-375/lib/trino-main-375.jar,,parse-decimal-literals-as-double,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.http-timeout-threads,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.network-topology.refresh-period,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.allocator-type,"",false
375,trino-server-375/lib/trino-main-375.jar,,filter-and-project-min-output-page-row-count,"",false
375,trino-server-375/lib/trino-main-375.jar,,exchange.client-threads,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.statistics-cpu-timer-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
375,trino-server-375/lib/trino-main-375.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
375,trino-server-375/lib/trino-main-375.jar,,query.info-url-template,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,web-ui.session-timeout,"",false
375,trino-server-375/lib/trino-main-375.jar,,experimental.late-materialization.enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.insecure.user-mapping.file,"",false
375,trino-server-375/lib/trino-main-375.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
375,trino-server-375/lib/trino-main-375.jar,,cpu-cost-weight,"",false
375,trino-server-375/lib/trino-main-375.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
375,trino-server-375/lib/trino-main-375.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
375,trino-server-375/lib/trino-main-375.jar,,scale-writers,"",false
375,trino-server-375/lib/trino-main-375.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.krb5.principal-hostname,"",false
375,trino-server-375/lib/trino-main-375.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
375,trino-server-375/lib/trino-main-375.jar,,spiller-threads,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.max-absolute-full-nodes-per-query,"",false
375,trino-server-375/lib/trino-main-375.jar,,re2j.dfa-retries,"",false
375,trino-server-375/lib/trino-main-375.jar,,access-control.config-files,"",false
375,trino-server-375/lib/trino-main-375.jar,,catalog.config-dir,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.default-filter-factor-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,task.initial-splits-per-node,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
375,trino-server-375/lib/trino-main-375.jar,,redistribute-writes,"",false
375,trino-server-375/lib/trino-main-375.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.max-splits-per-node,"",false
375,trino-server-375/lib/trino-main-375.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
375,trino-server-375/lib/trino-main-375.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
375,trino-server-375/lib/trino-main-375.jar,,network-cost-weight,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
375,trino-server-375/lib/trino-main-375.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
375,trino-server-375/lib/trino-main-375.jar,,catalog.disabled-catalogs,"",false
375,trino-server-375/lib/trino-main-375.jar,,distributed-index-joins-enabled,"",false
375,trino-server-375/lib/trino-main-375.jar,,node-scheduler.network-topology.file,"",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
375,trino-server-375/lib/trino-main-375.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
375,trino-server-375/lib/trino-main-375.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
375,trino-server-375/lib/trino-main-375.jar,,http-server.authentication.krb5.service-name,"",false
375,trino-server-375/lib/trino-main-375.jar,,task-retry-attempts-per-task,"",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
376,trino-server-376/plugin/kinesis/trino-kinesis-376.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
376,trino-server-376/plugin/kinesis/trino-plugin-toolkit-376.jar,kinesis,security.config-file,"",false
376,trino-server-376/plugin/kinesis/trino-plugin-toolkit-376.jar,kinesis,security.refresh-period,"",false
376,trino-server-376/plugin/kinesis/trino-plugin-toolkit-376.jar,kinesis,jmx.base-name,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,password-credential-name,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,credential-provider.type,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,statistics.enabled,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,join-pushdown.strategy,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,keystore-password,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,keystore-user-credential-password,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,complex-expression-pushdown.enabled,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,keystore-password-credential-password,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,keystore-file-path,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,connection-user,"user name for JDBC client",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,connection-password,"Password for JDBC client",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,connection-url,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,case-insensitive-name-matching,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,keystore-type,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,keystore-password-credential-name,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,keystore-user-credential-name,"",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
376,trino-server-376/plugin/clickhouse/trino-base-jdbc-376.jar,clickhouse,user-credential-name,"",false
376,trino-server-376/plugin/clickhouse/trino-clickhouse-376.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
376,trino-server-376/plugin/clickhouse/trino-clickhouse-376.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
376,trino-server-376/plugin/postgresql/trino-postgresql-376.jar,postgresql,postgresql.array-mapping,"",false
376,trino-server-376/plugin/postgresql/trino-postgresql-376.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
376,trino-server-376/plugin/postgresql/trino-postgresql-376.jar,postgresql,postgresql.include-system-tables,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.max-error-retries,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.async-client-concurrency,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.aws-secret-key,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.region,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.base-directory,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.storage-class,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.endpoint,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.source-concurrent-readers,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.sink-buffers-per-partition,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.aws-access-key,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.encryption-enabled,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.s3.use-web-identity-token-credentials,"",false
376,trino-server-376/plugin/exchange/trino-exchange-376.jar,exchange,exchange.sink-buffer-pool-min-size,"",false
376,trino-server-376/plugin/atop/trino-atop-376.jar,atop,atop.max-history-days,"",false
376,trino-server-376/plugin/atop/trino-atop-376.jar,atop,atop.concurrent-readers-per-node,"",false
376,trino-server-376/plugin/atop/trino-atop-376.jar,atop,atop.security,"",false
376,trino-server-376/plugin/atop/trino-atop-376.jar,atop,atop.executable-path,"",false
376,trino-server-376/plugin/atop/trino-atop-376.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
376,trino-server-376/plugin/atop/trino-atop-376.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
376,trino-server-376/plugin/memory/trino-memory-376.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
376,trino-server-376/plugin/memory/trino-memory-376.jar,memory,memory.splits-per-node,"",false
376,trino-server-376/plugin/memory/trino-memory-376.jar,memory,memory.max-data-per-node,"",false
376,trino-server-376/plugin/accumulo/trino-accumulo-376.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
376,trino-server-376/plugin/accumulo/trino-accumulo-376.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
376,trino-server-376/plugin/accumulo/trino-accumulo-376.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
376,trino-server-376/plugin/accumulo/trino-accumulo-376.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
376,trino-server-376/plugin/accumulo/trino-accumulo-376.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
376,trino-server-376/plugin/accumulo/trino-accumulo-376.jar,accumulo,accumulo.instance,"Accumulo instance name",false
376,trino-server-376/plugin/accumulo/trino-accumulo-376.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.forbid-segment-queries,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.fetch-retry-count,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.controller.authentication.type,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.broker.authentication.password,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.max-rows-for-broker-queries,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.controller.authentication.user,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.idle-timeout,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.broker.authentication.type,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.request-timeout,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.thread-pool-size,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.controller-urls,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.broker.authentication.user,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.max-connections-per-server,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.metadata-expiry,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.min-connections-per-server,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.prefer-broker-queries,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.segments-per-split,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.controller.authentication.password,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.connection-timeout,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.max-backlog-per-server,"",false
376,trino-server-376/plugin/pinot/trino-pinot-376.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
376,trino-server-376/plugin/resource-group-managers/trino-resource-group-managers-376.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
376,trino-server-376/plugin/resource-group-managers/trino-resource-group-managers-376.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
376,trino-server-376/plugin/resource-group-managers/trino-resource-group-managers-376.jar,resource-group-managers,resource-groups.config-db-url,"",false
376,trino-server-376/plugin/resource-group-managers/trino-resource-group-managers-376.jar,resource-group-managers,resource-groups.config-file,"",false
376,trino-server-376/plugin/resource-group-managers/trino-resource-group-managers-376.jar,resource-group-managers,jmx.base-name,"",false
376,trino-server-376/plugin/resource-group-managers/trino-resource-group-managers-376.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
376,trino-server-376/plugin/resource-group-managers/trino-resource-group-managers-376.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.table-names,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.connect-timeout,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.hide-internal-columns,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.default-schema,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.key-delimiter,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.key-prefix-schema-table,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.nodes,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.password,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.scan-count,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.table-description-dir,"",false
376,trino-server-376/plugin/redis/trino-redis-376.jar,redis,redis.database-index,"",false
376,trino-server-376/plugin/example-http/trino-example-http-376.jar,example-http,metadata-uri,"",false
376,trino-server-376/plugin/local-file/trino-local-file-376.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
376,trino-server-376/plugin/local-file/trino-local-file-376.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
376,trino-server-376/plugin/jmx/trino-jmx-376.jar,jmx,jmx.dump-tables,"",false
376,trino-server-376/plugin/jmx/trino-jmx-376.jar,jmx,jmx.max-entries,"",false
376,trino-server-376/plugin/jmx/trino-jmx-376.jar,jmx,jmx.dump-period,"",false
376,trino-server-376/plugin/phoenix/trino-phoenix-376.jar,phoenix,phoenix.config.resources,"",false
376,trino-server-376/plugin/phoenix/trino-phoenix-376.jar,phoenix,phoenix.connection-url,"",false
376,trino-server-376/plugin/phoenix/trino-phoenix-376.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.connection-pool.min-size,"",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.connection-pool.enabled,"",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.remarks-reporting.enabled,"",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.synonyms.enabled,"",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.connection-pool.max-size,"",false
376,trino-server-376/plugin/oracle/trino-oracle-376.jar,oracle,oracle.number.rounding-mode,"",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.max-initial-split-size,"",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.max-initial-splits,"",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.max-split-size,"",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
376,trino-server-376/plugin/delta-lake/trino-delta-lake-376.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.ssl.enabled,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-initial-splits,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.adl-proxy-host,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.security,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs.connect.max-retries,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.file-status-cache-expire-time,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.split-loader-concurrency,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.sts.region,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.writer.block-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.adl-refresh-url,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.compression-codec,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.max-merge-distance,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.abfs-access-key,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.aws-secret-key,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore-recording-path,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.max-buffer-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore-cache-ttl,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.config.resources,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.wasb-storage-account,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.signer-type,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore-timeout,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.endpoint,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.max-error-retries,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.adl-credential,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.proxy.protocol,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.bookkeeper-port,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.file-status-cache-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.writer.page-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.writer-sort-buffer-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.writer-identification,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.location,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-register-partition-procedure,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.sts.endpoint,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs-timeout,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-concurrent-file-renames,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs.verify-checksum,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.hdfs.socks-proxy,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.storage-format,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.proxy.port,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.abfs-storage-account,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.ignore-absent-partitions,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-split-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.replay-metastore-recording,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.force-local-scheduling,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.aws-access-key,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.max-buffer-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.max-merge-distance,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.max-read-block-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.socket-timeout,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.max-backoff-time,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.proxy.username,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.adl-client-id,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-split-iterator-threads,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.recursive-directories,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.streaming.enabled,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.stream-buffer-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.data-transfer-port,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.connect-timeout,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.max-connections,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.max-retry-time,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-initial-split-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.version-compatibility,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.azure.wasb-access-key,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore-recording-duration,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore-refresh-interval,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs.domain-socket-path,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.file-status-cache-tables,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,parquet.max-read-block-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.proxy.host,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.dfs.connect.timeout,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.signer-class,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.max-client-retries,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3.proxy.password,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.s3-file-system-type,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.cache.read-mode,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
376,trino-server-376/plugin/delta-lake/trino-hive-376.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
376,trino-server-376/plugin/session-property-managers/trino-session-property-managers-376.jar,session-property-managers,session-property-manager.db.password,"",false
376,trino-server-376/plugin/session-property-managers/trino-session-property-managers-376.jar,session-property-managers,session-property-manager.db.username,"",false
376,trino-server-376/plugin/session-property-managers/trino-session-property-managers-376.jar,session-property-managers,session-property-manager.db.url,"",false
376,trino-server-376/plugin/session-property-managers/trino-session-property-managers-376.jar,session-property-managers,session-property-manager.config-file,"",false
376,trino-server-376/plugin/session-property-managers/trino-session-property-managers-376.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.view-expire-duration,"",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
376,trino-server-376/plugin/bigquery/trino-bigquery-376.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.write-concern,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.connections-per-host,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.credentials,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.max-connection-idle-time,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.connection-url,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.schema-collection,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.socket-timeout,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.read-preference,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.min-connections-per-host,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.ssl.enabled,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.cursor-batch-size,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.max-wait-time,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.required-replica-set,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.seeds,"",false
376,trino-server-376/plugin/mongodb/trino-mongodb-376.jar,mongodb,mongodb.connection-timeout,"",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.catalog.type,"",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.file-format,"",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.security,"",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
376,trino-server-376/plugin/iceberg/trino-iceberg-376.jar,iceberg,iceberg.compression-codec,"",false
376,trino-server-376/plugin/phoenix5/trino-phoenix5-376.jar,phoenix5,phoenix.config.resources,"",false
376,trino-server-376/plugin/phoenix5/trino-phoenix5-376.jar,phoenix5,phoenix.connection-url,"",false
376,trino-server-376/plugin/phoenix5/trino-phoenix5-376.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
376,trino-server-376/plugin/thrift/trino-thrift-376.jar,thrift,trino-thrift.max-response-size,"",false
376,trino-server-376/plugin/thrift/trino-thrift-376.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
376,trino-server-376/plugin/thrift/trino-thrift-376.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.orc.nested-lazy,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,metadata.db.url,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.compaction-enabled,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.security,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.orc.max-read-size,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.balancer-enabled,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,storage.organization-enabled,"",false
376,trino-server-376/plugin/raptor-legacy/trino-raptor-legacy-376.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
376,trino-server-376/plugin/google-sheets/trino-google-sheets-376.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
376,trino-server-376/plugin/google-sheets/trino-google-sheets-376.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
376,trino-server-376/plugin/google-sheets/trino-google-sheets-376.jar,google-sheets,credentials-path,"Credential file path to google service account",false
376,trino-server-376/plugin/google-sheets/trino-google-sheets-376.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
376,trino-server-376/plugin/kafka/trino-kafka-376.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.client.read-timeout,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.fetch-size,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.tls.enabled,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.client.connect-timeout,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.retry-policy,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.client.so-linger,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.tls.truststore-path,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.splits-per-node,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.username,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.password,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.contact-points,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.speculative-execution.limit,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.speculative-execution.delay,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.split-size,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.tls.keystore-path,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.batch-size,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.native-protocol-port,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.tls.truststore-password,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.consistency-level,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.tls.keystore-password,"",false
376,trino-server-376/plugin/cassandra/trino-cassandra-376.jar,cassandra,cassandra.protocol-version,"",false
376,trino-server-376/plugin/mysql/trino-mysql-376.jar,mysql,mysql.max-reconnects,"",false
376,trino-server-376/plugin/mysql/trino-mysql-376.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
376,trino-server-376/plugin/mysql/trino-mysql-376.jar,mysql,mysql.connection-timeout,"",false
376,trino-server-376/plugin/mysql/trino-mysql-376.jar,mysql,mysql.auto-reconnect,"",false
376,trino-server-376/plugin/sqlserver/trino-sqlserver-376.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
376,trino-server-376/plugin/http-event-listener/trino-http-event-listener-376.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.schema-emulation.prefix,"",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.client.master-addresses,"",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.schema-emulation.enabled,"",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.client.disable-statistics,"",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.grouped-execution.enabled,"",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.client.default-operation-timeout,"",false
376,trino-server-376/plugin/kudu/trino-kudu-376.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.ssl.keystore.password,"Password for the key store",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.cache-ttl,"",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.ssl.truststore.password,"Password for the trust store",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.url,"URL of the LDAP server",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.timeout.connect,"Timeout for establishing a connection",false
376,trino-server-376/plugin/password-authenticators/trino-password-authenticators-376.jar,password-authenticators,ldap.timeout.read,"Timeout for reading data from LDAP",false
376,trino-server-376/plugin/prometheus/trino-prometheus-376.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
376,trino-server-376/plugin/prometheus/trino-prometheus-376.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
376,trino-server-376/plugin/prometheus/trino-prometheus-376.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
376,trino-server-376/plugin/prometheus/trino-prometheus-376.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
376,trino-server-376/plugin/prometheus/trino-prometheus-376.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
376,trino-server-376/plugin/prometheus/trino-prometheus-376.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.auth.user,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.tls.enabled,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.security,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.port,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.aws.access-key,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.host,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.aws.region,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.auth.password,"",false
376,trino-server-376/plugin/elasticsearch/trino-elasticsearch-376.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
376,trino-server-376/plugin/singlestore/trino-singlestore-376.jar,singlestore,singlestore.auto-reconnect,"",false
376,trino-server-376/plugin/singlestore/trino-singlestore-376.jar,singlestore,singlestore.connection-timeout,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.max-partial-aggregation-memory,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.concurrent-request-multiplier,"",false
376,trino-server-376/lib/trino-main-376.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,internal-communication.https.required,"",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.min-error-duration,"",false
376,trino-server-376/lib/trino-main-376.jar,,internal-communication.shared-secret,"",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.max-response-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,max-spill-per-node,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.krb5.name-type,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
376,trino-server-376/lib/trino-main-376.jar,,plugin.dir,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.acknowledge-pages,"",false
376,trino-server-376/lib/trino-main-376.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
376,trino-server-376/lib/trino-main-376.jar,,query.remote-task.max-callback-threads,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
376,trino-server-376/lib/trino-main-376.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.merge-project-with-values,"",false
376,trino-server-376/lib/trino-main-376.jar,,enable-large-dynamic-filters,"",false
376,trino-server-376/lib/trino-main-376.jar,,internal-communication.https.keystore.path,"",false
376,trino-server-376/lib/trino-main-376.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.jwt.required-audience,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
376,trino-server-376/lib/trino-main-376.jar,,task.max-index-memory,"",false
376,trino-server-376/lib/trino-main-376.jar,,sql.default-schema,"",false
376,trino-server-376/lib/trino-main-376.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-scan-physical-bytes,"",false
376,trino-server-376/lib/trino-main-376.jar,,join-distribution-type,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.max-local-exchange-buffer-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,web-ui.user,"",false
376,trino-server-376/lib/trino-main-376.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
376,trino-server-376/lib/trino-main-376.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
376,trino-server-376/lib/trino-main-376.jar,,task.client.timeout,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.max-partial-top-n-memory,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.complex-expression-pushdown.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-memory,"",false
376,trino-server-376/lib/trino-main-376.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
376,trino-server-376/lib/trino-main-376.jar,,enable-stats-calculator,"",false
376,trino-server-376/lib/trino-main-376.jar,,task-retry-attempts-overall,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-run-time,"",false
376,trino-server-376/lib/trino-main-376.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
376,trino-server-376/lib/trino-main-376.jar,,regex-library,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-memory-per-node,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.password.user-mapping.pattern,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.push-table-write-through-union,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.min-candidates,"",false
376,trino-server-376/lib/trino-main-376.jar,,failure-detector.threshold,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.share-index-loading,"",false
376,trino-server-376/lib/trino-main-376.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.certificate.user-mapping.file,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.max-pending-splits-per-task,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
376,trino-server-376/lib/trino-main-376.jar,,internal-communication.https.truststore.key,"",false
376,trino-server-376/lib/trino-main-376.jar,,enable-dynamic-filtering,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.optimize-hash-generation,"",false
376,trino-server-376/lib/trino-main-376.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
376,trino-server-376/lib/trino-main-376.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
376,trino-server-376/lib/trino-main-376.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.force-single-node-output,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.split-concurrency-adjustment-interval,"",false
376,trino-server-376/lib/trino-main-376.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.max-buffer-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,sql.default-catalog,"",false
376,trino-server-376/lib/trino-main-376.jar,,spill-compression-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.password.user-mapping.file,"",false
376,trino-server-376/lib/trino-main-376.jar,,spill-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.https.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.jwt.principal-field,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
376,trino-server-376/lib/trino-main-376.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
376,trino-server-376/lib/trino-main-376.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,web-ui.shared-secret,"",false
376,trino-server-376/lib/trino-main-376.jar,,deprecated.legacy-row-to-json-cast,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.optimize-top-n-ranking,"",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.compression-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
376,trino-server-376/lib/trino-main-376.jar,,query.remote-task.min-error-duration,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-execution-time,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.prefer-partial-aggregation,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
376,trino-server-376/lib/trino-main-376.jar,,spiller-spill-path,"",false
376,trino-server-376/lib/trino-main-376.jar,,memory-cost-weight,"",false
376,trino-server-376/lib/trino-main-376.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
376,trino-server-376/lib/trino-main-376.jar,,enable-forced-exchange-below-group-id,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
376,trino-server-376/lib/trino-main-376.jar,,failure-detector.heartbeat-interval,"",false
376,trino-server-376/lib/trino-main-376.jar,,aggregation-operator-unspill-memory-limit,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.min-expire-age,"",false
376,trino-server-376/lib/trino-main-376.jar,,spiller-max-used-space-threshold,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.use-mark-distinct,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,event.max-output-stage-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.jwt.required-issuer,"",false
376,trino-server-376/lib/trino-main-376.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.optimized-local-scheduling,"",false
376,trino-server-376/lib/trino-main-376.jar,,distributed-sort,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.client.timeout,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
376,trino-server-376/lib/trino-main-376.jar,,task-retry-attempts-per-task,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.krb5.service-name,"",false
376,trino-server-376/lib/trino-main-376.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.network-topology.file,"",false
376,trino-server-376/lib/trino-main-376.jar,,distributed-index-joins-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,catalog.disabled-catalogs,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
376,trino-server-376/lib/trino-main-376.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
376,trino-server-376/lib/trino-main-376.jar,,network-cost-weight,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
376,trino-server-376/lib/trino-main-376.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
376,trino-server-376/lib/trino-main-376.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.max-splits-per-node,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
376,trino-server-376/lib/trino-main-376.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
376,trino-server-376/lib/trino-main-376.jar,,redistribute-writes,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
376,trino-server-376/lib/trino-main-376.jar,,task.initial-splits-per-node,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.default-filter-factor-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,catalog.config-dir,"",false
376,trino-server-376/lib/trino-main-376.jar,,access-control.config-files,"",false
376,trino-server-376/lib/trino-main-376.jar,,re2j.dfa-retries,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.max-absolute-full-nodes-per-query,"",false
376,trino-server-376/lib/trino-main-376.jar,,spiller-threads,"",false
376,trino-server-376/lib/trino-main-376.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.krb5.principal-hostname,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,scale-writers,"",false
376,trino-server-376/lib/trino-main-376.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
376,trino-server-376/lib/trino-main-376.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
376,trino-server-376/lib/trino-main-376.jar,,cpu-cost-weight,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
376,trino-server-376/lib/trino-main-376.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.insecure.user-mapping.file,"",false
376,trino-server-376/lib/trino-main-376.jar,,experimental.late-materialization.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,web-ui.session-timeout,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.info-url-template,"",false
376,trino-server-376/lib/trino-main-376.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
376,trino-server-376/lib/trino-main-376.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
376,trino-server-376/lib/trino-main-376.jar,,task.statistics-cpu-timer-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.client-threads,"",false
376,trino-server-376/lib/trino-main-376.jar,,filter-and-project-min-output-page-row-count,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.allocator-type,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.network-topology.refresh-period,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.http-timeout-threads,"",false
376,trino-server-376/lib/trino-main-376.jar,,parse-decimal-literals-as-double,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.push-partial-aggregation-through-join,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.status-refresh-max-wait,"",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.deduplication-buffer-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.writer-count,"Number of writers per task",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
376,trino-server-376/lib/trino-main-376.jar,,query.low-memory-killer.policy,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.max-fraction-full-nodes-per-query,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.jwt.key-file,"",false
376,trino-server-376/lib/trino-main-376.jar,,use-preferred-write-partitioning,"",false
376,trino-server-376/lib/trino-main-376.jar,,adaptive-partial-aggregation.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,discovery-server.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,query-results.compression-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.network-topology.type,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-planning-time,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-total-memory,"",false
376,trino-server-376/lib/trino-main-376.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.enable-intermediate-aggregations,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.include-coordinator,"",false
376,trino-server-376/lib/trino-main-376.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
376,trino-server-376/lib/trino-main-376.jar,,task.min-drivers,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.skip-redundant-sort,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-cpu-time,"",false
376,trino-server-376/lib/trino-main-376.jar,,sink.max-buffer-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
376,trino-server-376/lib/trino-main-376.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.schedule-split-batch-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.ignore-downstream-preferences,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.http-response-threads,"",false
376,trino-server-376/lib/trino-main-376.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
376,trino-server-376/lib/trino-main-376.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
376,trino-server-376/lib/trino-main-376.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
376,trino-server-376/lib/trino-main-376.jar,,query.min-schedule-split-batch-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.per-operator-cpu-timer-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-history,"",false
376,trino-server-376/lib/trino-main-376.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
376,trino-server-376/lib/trino-main-376.jar,,jmx.base-name,"",false
376,trino-server-376/lib/trino-main-376.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.krb5.keytab,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-stage-count,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.remote-task.max-error-duration,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
376,trino-server-376/lib/trino-main-376.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.page-buffer-client.max-callback-threads,"",false
376,trino-server-376/lib/trino-main-376.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.dictionary-aggregation,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.execution-policy,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.service-thread-count,"",false
376,trino-server-376/lib/trino-main-376.jar,,driver.max-page-partitioning-buffer-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
376,trino-server-376/lib/trino-main-376.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
376,trino-server-376/lib/trino-main-376.jar,,re2j.dfa-states-limit,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.optimize-metadata-queries,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-queued-queries,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,query-retry-attempts,"",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.jwt.user-mapping.file,"",false
376,trino-server-376/lib/trino-main-376.jar,,http.include-exception-in-response,"",false
376,trino-server-376/lib/trino-main-376.jar,,compiler.expression-cache-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,pages-index.eager-compaction-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.krb5.user-mapping.file,"",false
376,trino-server-376/lib/trino-main-376.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
376,trino-server-376/lib/trino-main-376.jar,,sink.max-broadcast-buffer-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,internal-communication.https.truststore.path,"",false
376,trino-server-376/lib/trino-main-376.jar,,statistics-precalculation-for-pushdown.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-length,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
376,trino-server-376/lib/trino-main-376.jar,,spill-encryption-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
376,trino-server-376/lib/trino-main-376.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
376,trino-server-376/lib/trino-main-376.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
376,trino-server-376/lib/trino-main-376.jar,,web-ui.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,shutdown.grace-period,"",false
376,trino-server-376/lib/trino-main-376.jar,,filter-and-project-min-output-page-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.info.max-age,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.push-aggregation-through-outer-join,"",false
376,trino-server-376/lib/trino-main-376.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
376,trino-server-376/lib/trino-main-376.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
376,trino-server-376/lib/trino-main-376.jar,,query.manager-executor-pool-size,"",false
376,trino-server-376/lib/trino-main-376.jar,,query.max-concurrent-queries,"",false
376,trino-server-376/lib/trino-main-376.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
376,trino-server-376/lib/trino-main-376.jar,,http.authentication.krb5.config,"",false
376,trino-server-376/lib/trino-main-376.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
376,trino-server-376/lib/trino-main-376.jar,,retry-policy,"",false
376,trino-server-376/lib/trino-main-376.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
376,trino-server-376/lib/trino-main-376.jar,,failure-detector.enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.cpu-timer-enabled,"",false
376,trino-server-376/lib/trino-main-376.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
376,trino-server-376/lib/trino-main-376.jar,,analyzer.max-grouping-sets,"",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.data-integrity-verification,"",false
376,trino-server-376/lib/trino-main-376.jar,,warning-collector.max-warnings,"",false
376,trino-server-376/lib/trino-main-376.jar,,internal-communication.https.keystore.key,"",false
376,trino-server-376/lib/trino-main-376.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
376,trino-server-376/lib/trino-main-376.jar,,query-max-spill-per-node,"",false
376,trino-server-376/lib/trino-main-376.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
376,trino-server-376/lib/trino-main-376.jar,,node-scheduler.policy,"",false
376,trino-server-376/lib/trino-main-376.jar,,exchange.max-error-duration,"",false
376,trino-server-376/lib/trino-main-376.jar,,task.max-worker-threads,"",false
376,trino-server-376/lib/trino-main-376.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
376,trino-server-376/lib/trino-main-376.jar,,task.info-update-interval,"Interval between updating task data",false
376,trino-server-376/lib/trino-main-376.jar,,iterative-optimizer-timeout,"",false
376,trino-server-376/lib/trino-main-376.jar,,event-listener.config-files,"",false
376,trino-server-376/lib/trino-main-376.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
376,trino-server-376/lib/trino-main-376.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
377,trino-server-377/plugin/kinesis/trino-kinesis-377.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
377,trino-server-377/plugin/kinesis/trino-plugin-toolkit-377.jar,kinesis,jmx.base-name,"",false
377,trino-server-377/plugin/kinesis/trino-plugin-toolkit-377.jar,kinesis,security.config-file,"",false
377,trino-server-377/plugin/kinesis/trino-plugin-toolkit-377.jar,kinesis,security.refresh-period,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,keystore-password-credential-password,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,keystore-file-path,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,connection-user,"user name for JDBC client",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,connection-password,"Password for JDBC client",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,connection-url,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,case-insensitive-name-matching,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,keystore-type,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,keystore-password-credential-name,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,keystore-user-credential-name,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,user-credential-name,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,password-credential-name,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,credential-provider.type,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,statistics.enabled,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,join-pushdown.strategy,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,keystore-password,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,keystore-user-credential-password,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
377,trino-server-377/plugin/clickhouse/trino-base-jdbc-377.jar,clickhouse,complex-expression-pushdown.enabled,"",false
377,trino-server-377/plugin/clickhouse/trino-clickhouse-377.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
377,trino-server-377/plugin/clickhouse/trino-clickhouse-377.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
377,trino-server-377/plugin/postgresql/trino-postgresql-377.jar,postgresql,postgresql.include-system-tables,"",false
377,trino-server-377/plugin/postgresql/trino-postgresql-377.jar,postgresql,postgresql.array-mapping,"",false
377,trino-server-377/plugin/postgresql/trino-postgresql-377.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.endpoint,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.source-concurrent-readers,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.sink-buffers-per-partition,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.aws-access-key,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.encryption-enabled,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.use-web-identity-token-credentials,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.sink-buffer-pool-min-size,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.max-error-retries,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.async-client-concurrency,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.aws-secret-key,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.region,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.base-directory,"",false
377,trino-server-377/plugin/exchange/trino-exchange-377.jar,exchange,exchange.s3.storage-class,"",false
377,trino-server-377/plugin/atop/trino-atop-377.jar,atop,atop.executable-path,"",false
377,trino-server-377/plugin/atop/trino-atop-377.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
377,trino-server-377/plugin/atop/trino-atop-377.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
377,trino-server-377/plugin/atop/trino-atop-377.jar,atop,atop.max-history-days,"",false
377,trino-server-377/plugin/atop/trino-atop-377.jar,atop,atop.concurrent-readers-per-node,"",false
377,trino-server-377/plugin/atop/trino-atop-377.jar,atop,atop.security,"",false
377,trino-server-377/plugin/memory/trino-memory-377.jar,memory,memory.max-data-per-node,"",false
377,trino-server-377/plugin/memory/trino-memory-377.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
377,trino-server-377/plugin/memory/trino-memory-377.jar,memory,memory.splits-per-node,"",false
377,trino-server-377/plugin/accumulo/trino-accumulo-377.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
377,trino-server-377/plugin/accumulo/trino-accumulo-377.jar,accumulo,accumulo.instance,"Accumulo instance name",false
377,trino-server-377/plugin/accumulo/trino-accumulo-377.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
377,trino-server-377/plugin/accumulo/trino-accumulo-377.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
377,trino-server-377/plugin/accumulo/trino-accumulo-377.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
377,trino-server-377/plugin/accumulo/trino-accumulo-377.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
377,trino-server-377/plugin/accumulo/trino-accumulo-377.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.max-connections-per-server,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.metadata-expiry,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.min-connections-per-server,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.prefer-broker-queries,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.segments-per-split,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.controller.authentication.password,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.connection-timeout,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.max-backlog-per-server,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.forbid-segment-queries,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.fetch-retry-count,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.controller.authentication.type,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.broker.authentication.password,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.max-rows-for-broker-queries,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.controller.authentication.user,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.idle-timeout,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.broker.authentication.type,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.request-timeout,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.thread-pool-size,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.controller-urls,"",false
377,trino-server-377/plugin/pinot/trino-pinot-377.jar,pinot,pinot.broker.authentication.user,"",false
377,trino-server-377/plugin/resource-group-managers/trino-resource-group-managers-377.jar,resource-group-managers,jmx.base-name,"",false
377,trino-server-377/plugin/resource-group-managers/trino-resource-group-managers-377.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
377,trino-server-377/plugin/resource-group-managers/trino-resource-group-managers-377.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
377,trino-server-377/plugin/resource-group-managers/trino-resource-group-managers-377.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
377,trino-server-377/plugin/resource-group-managers/trino-resource-group-managers-377.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
377,trino-server-377/plugin/resource-group-managers/trino-resource-group-managers-377.jar,resource-group-managers,resource-groups.config-db-url,"",false
377,trino-server-377/plugin/resource-group-managers/trino-resource-group-managers-377.jar,resource-group-managers,resource-groups.config-file,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.key-prefix-schema-table,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.nodes,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.password,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.scan-count,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.table-description-dir,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.database-index,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.table-names,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.connect-timeout,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.hide-internal-columns,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.default-schema,"",false
377,trino-server-377/plugin/redis/trino-redis-377.jar,redis,redis.key-delimiter,"",false
377,trino-server-377/plugin/example-http/trino-example-http-377.jar,example-http,metadata-uri,"",false
377,trino-server-377/plugin/local-file/trino-local-file-377.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
377,trino-server-377/plugin/local-file/trino-local-file-377.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
377,trino-server-377/plugin/jmx/trino-jmx-377.jar,jmx,jmx.max-entries,"",false
377,trino-server-377/plugin/jmx/trino-jmx-377.jar,jmx,jmx.dump-period,"",false
377,trino-server-377/plugin/jmx/trino-jmx-377.jar,jmx,jmx.dump-tables,"",false
377,trino-server-377/plugin/phoenix/trino-phoenix-377.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
377,trino-server-377/plugin/phoenix/trino-phoenix-377.jar,phoenix,phoenix.config.resources,"",false
377,trino-server-377/plugin/phoenix/trino-phoenix-377.jar,phoenix,phoenix.connection-url,"",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.remarks-reporting.enabled,"",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.synonyms.enabled,"",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.connection-pool.max-size,"",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.number.rounding-mode,"",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.connection-pool.min-size,"",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
377,trino-server-377/plugin/oracle/trino-oracle-377.jar,oracle,oracle.connection-pool.enabled,"",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.max-split-size,"",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.max-initial-split-size,"",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.max-initial-splits,"",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
377,trino-server-377/plugin/delta-lake/trino-delta-lake-377.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.aws-access-key,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.max-buffer-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.max-merge-distance,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.max-read-block-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.socket-timeout,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.max-backoff-time,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.proxy.username,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.adl-client-id,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-split-iterator-threads,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.recursive-directories,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.streaming.enabled,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.stream-buffer-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.data-transfer-port,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.connect-timeout,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.max-connections,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.max-retry-time,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-initial-split-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.version-compatibility,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.wasb-access-key,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore-recording-duration,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore-refresh-interval,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs.domain-socket-path,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.file-status-cache-tables,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.max-read-block-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.proxy.host,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs.connect.timeout,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.signer-class,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.max-client-retries,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.proxy.password,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3-file-system-type,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.read-mode,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.ssl.enabled,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-initial-splits,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.adl-proxy-host,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.security,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs.connect.max-retries,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.file-status-cache-expire-time,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.split-loader-concurrency,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.sts.region,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.writer.block-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.adl-refresh-url,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.compression-codec,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.max-merge-distance,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.abfs-access-key,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.aws-secret-key,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore-recording-path,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.max-buffer-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore-cache-ttl,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.config.resources,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.wasb-storage-account,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.signer-type,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore-timeout,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.endpoint,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.max-error-retries,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.adl-credential,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.proxy.protocol,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.bookkeeper-port,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.file-status-cache-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.writer.page-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.writer-sort-buffer-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.writer-identification,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.cache.location,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-register-partition-procedure,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.sts.endpoint,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs-timeout,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-concurrent-file-renames,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.dfs.verify-checksum,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.hdfs.socks-proxy,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.storage-format,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.proxy.port,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.abfs-storage-account,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.ignore-absent-partitions,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.max-split-size,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.replay-metastore-recording,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.force-local-scheduling,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
377,trino-server-377/plugin/delta-lake/trino-hive-377.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
377,trino-server-377/plugin/session-property-managers/trino-session-property-managers-377.jar,session-property-managers,session-property-manager.db.username,"",false
377,trino-server-377/plugin/session-property-managers/trino-session-property-managers-377.jar,session-property-managers,session-property-manager.db.url,"",false
377,trino-server-377/plugin/session-property-managers/trino-session-property-managers-377.jar,session-property-managers,session-property-manager.config-file,"",false
377,trino-server-377/plugin/session-property-managers/trino-session-property-managers-377.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
377,trino-server-377/plugin/session-property-managers/trino-session-property-managers-377.jar,session-property-managers,session-property-manager.db.password,"",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.view-expire-duration,"",false
377,trino-server-377/plugin/bigquery/trino-bigquery-377.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.read-preference,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.min-connections-per-host,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.ssl.enabled,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.cursor-batch-size,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.max-wait-time,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.required-replica-set,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.seeds,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.connection-timeout,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.write-concern,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.connections-per-host,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.credentials,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.max-connection-idle-time,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.connection-url,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.schema-collection,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.socket-timeout,"",false
377,trino-server-377/plugin/mongodb/trino-mongodb-377.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.compression-codec,"",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.catalog.type,"",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.file-format,"",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.security,"",false
377,trino-server-377/plugin/iceberg/trino-iceberg-377.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
377,trino-server-377/plugin/phoenix5/trino-phoenix5-377.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
377,trino-server-377/plugin/phoenix5/trino-phoenix5-377.jar,phoenix5,phoenix.config.resources,"",false
377,trino-server-377/plugin/phoenix5/trino-phoenix5-377.jar,phoenix5,phoenix.connection-url,"",false
377,trino-server-377/plugin/thrift/trino-thrift-377.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
377,trino-server-377/plugin/thrift/trino-thrift-377.jar,thrift,trino-thrift.max-response-size,"",false
377,trino-server-377/plugin/thrift/trino-thrift-377.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.security,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.orc.max-read-size,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.balancer-enabled,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.organization-enabled,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.orc.nested-lazy,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,metadata.db.url,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,storage.compaction-enabled,"",false
377,trino-server-377/plugin/raptor-legacy/trino-raptor-legacy-377.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
377,trino-server-377/plugin/google-sheets/trino-google-sheets-377.jar,google-sheets,credentials-path,"Credential file path to google service account",false
377,trino-server-377/plugin/google-sheets/trino-google-sheets-377.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
377,trino-server-377/plugin/google-sheets/trino-google-sheets-377.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
377,trino-server-377/plugin/google-sheets/trino-google-sheets-377.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.config.resources,"Optional config files",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
377,trino-server-377/plugin/kafka/trino-kafka-377.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.tls.truststore-path,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.splits-per-node,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.username,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.password,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.contact-points,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.speculative-execution.limit,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.speculative-execution.delay,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.split-size,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.tls.keystore-path,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.batch-size,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.native-protocol-port,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.tls.truststore-password,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.consistency-level,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.tls.keystore-password,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.protocol-version,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.client.read-timeout,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.fetch-size,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.tls.enabled,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.client.connect-timeout,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.retry-policy,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.client.so-linger,"",false
377,trino-server-377/plugin/cassandra/trino-cassandra-377.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
377,trino-server-377/plugin/mysql/trino-mysql-377.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
377,trino-server-377/plugin/mysql/trino-mysql-377.jar,mysql,mysql.connection-timeout,"",false
377,trino-server-377/plugin/mysql/trino-mysql-377.jar,mysql,mysql.auto-reconnect,"",false
377,trino-server-377/plugin/mysql/trino-mysql-377.jar,mysql,mysql.max-reconnects,"",false
377,trino-server-377/plugin/sqlserver/trino-sqlserver-377.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
377,trino-server-377/plugin/http-event-listener/trino-http-event-listener-377.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.client.default-operation-timeout,"",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.schema-emulation.prefix,"",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.client.master-addresses,"",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.schema-emulation.enabled,"",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.client.disable-statistics,"",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.grouped-execution.enabled,"",false
377,trino-server-377/plugin/kudu/trino-kudu-377.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.ssl.truststore.password,"Password for the trust store",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.url,"URL of the LDAP server",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.timeout.connect,"Timeout for establishing a connection",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.timeout.read,"Timeout for reading data from LDAP",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.ssl.keystore.password,"Password for the key store",false
377,trino-server-377/plugin/password-authenticators/trino-password-authenticators-377.jar,password-authenticators,ldap.cache-ttl,"",false
377,trino-server-377/plugin/prometheus/trino-prometheus-377.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
377,trino-server-377/plugin/prometheus/trino-prometheus-377.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
377,trino-server-377/plugin/prometheus/trino-prometheus-377.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
377,trino-server-377/plugin/prometheus/trino-prometheus-377.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
377,trino-server-377/plugin/prometheus/trino-prometheus-377.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
377,trino-server-377/plugin/prometheus/trino-prometheus-377.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.aws.access-key,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.host,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.aws.region,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.auth.password,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.auth.user,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.tls.enabled,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.security,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.port,"",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
377,trino-server-377/plugin/elasticsearch/trino-elasticsearch-377.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
377,trino-server-377/plugin/singlestore/trino-singlestore-377.jar,singlestore,singlestore.auto-reconnect,"",false
377,trino-server-377/plugin/singlestore/trino-singlestore-377.jar,singlestore,singlestore.connection-timeout,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.compression-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
377,trino-server-377/lib/trino-main-377.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-run-time,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.skip-redundant-sort,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.optimize-metadata-queries,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
377,trino-server-377/lib/trino-main-377.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
377,trino-server-377/lib/trino-main-377.jar,,redistribute-writes,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.http-response-threads,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
377,trino-server-377/lib/trino-main-377.jar,,shutdown.grace-period,"",false
377,trino-server-377/lib/trino-main-377.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
377,trino-server-377/lib/trino-main-377.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
377,trino-server-377/lib/trino-main-377.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.min-error-duration,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.remote-task.max-error-duration,"",false
377,trino-server-377/lib/trino-main-377.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
377,trino-server-377/lib/trino-main-377.jar,,event.max-output-stage-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.jwt.user-mapping.file,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.min-schedule-split-batch-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
377,trino-server-377/lib/trino-main-377.jar,,memory-cost-weight,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.share-index-loading,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.optimize-top-n-ranking,"",false
377,trino-server-377/lib/trino-main-377.jar,,internal-communication.https.truststore.path,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.statistics-cpu-timer-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
377,trino-server-377/lib/trino-main-377.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
377,trino-server-377/lib/trino-main-377.jar,,filter-and-project-min-output-page-row-count,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.info-update-interval,"Interval between updating task data",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.prefer-partial-aggregation,"",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.client-threads,"",false
377,trino-server-377/lib/trino-main-377.jar,,driver.max-page-partitioning-buffer-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-cpu-time,"",false
377,trino-server-377/lib/trino-main-377.jar,,query-results.compression-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,spiller-max-used-space-threshold,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.per-operator-cpu-timer-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.jwt.required-issuer,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.complex-expression-pushdown.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-concurrent-queries,"",false
377,trino-server-377/lib/trino-main-377.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.certificate.user-mapping.file,"",false
377,trino-server-377/lib/trino-main-377.jar,,task-retry-attempts-overall,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
377,trino-server-377/lib/trino-main-377.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
377,trino-server-377/lib/trino-main-377.jar,,sink.max-buffer-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.info-url-template,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.max-error-duration,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.deduplication-buffer-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,discovery-server.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,distributed-index-joins-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
377,trino-server-377/lib/trino-main-377.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-total-memory,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.push-aggregation-through-outer-join,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.initial-splits-per-node,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.policy,"",false
377,trino-server-377/lib/trino-main-377.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
377,trino-server-377/lib/trino-main-377.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
377,trino-server-377/lib/trino-main-377.jar,,task.client.timeout,"",false
377,trino-server-377/lib/trino-main-377.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
377,trino-server-377/lib/trino-main-377.jar,,query-retry-attempts,"",false
377,trino-server-377/lib/trino-main-377.jar,,analyzer.max-grouping-sets,"",false
377,trino-server-377/lib/trino-main-377.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,internal-communication.https.keystore.key,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
377,trino-server-377/lib/trino-main-377.jar,,query.schedule-split-batch-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.data-integrity-verification,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.low-memory-killer.policy,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.max-response-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.dictionary-aggregation,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.krb5.principal-hostname,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.jwt.key-file,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.include-coordinator,"",false
377,trino-server-377/lib/trino-main-377.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.krb5.name-type,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-memory-per-node,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
377,trino-server-377/lib/trino-main-377.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-scan-physical-bytes,"",false
377,trino-server-377/lib/trino-main-377.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
377,trino-server-377/lib/trino-main-377.jar,,access-control.config-files,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
377,trino-server-377/lib/trino-main-377.jar,,web-ui.session-timeout,"",false
377,trino-server-377/lib/trino-main-377.jar,,sql.default-schema,"",false
377,trino-server-377/lib/trino-main-377.jar,,spill-encryption-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
377,trino-server-377/lib/trino-main-377.jar,,adaptive-partial-aggregation.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,spiller-threads,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-queued-queries,"",false
377,trino-server-377/lib/trino-main-377.jar,,use-preferred-write-partitioning,"",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
377,trino-server-377/lib/trino-main-377.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
377,trino-server-377/lib/trino-main-377.jar,,deprecated.legacy-row-to-json-cast,"",false
377,trino-server-377/lib/trino-main-377.jar,,network-cost-weight,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-length,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.network-topology.file,"",false
377,trino-server-377/lib/trino-main-377.jar,,enable-dynamic-filtering,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
377,trino-server-377/lib/trino-main-377.jar,,spill-compression-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
377,trino-server-377/lib/trino-main-377.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
377,trino-server-377/lib/trino-main-377.jar,,task.max-local-exchange-buffer-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.jwt.principal-field,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.split-concurrency-adjustment-interval,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.allocator-type,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.max-worker-threads,"",false
377,trino-server-377/lib/trino-main-377.jar,,parse-decimal-literals-as-double,"",false
377,trino-server-377/lib/trino-main-377.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
377,trino-server-377/lib/trino-main-377.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,catalog.disabled-catalogs,"",false
377,trino-server-377/lib/trino-main-377.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
377,trino-server-377/lib/trino-main-377.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-history,"",false
377,trino-server-377/lib/trino-main-377.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.max-pending-splits-per-task,"",false
377,trino-server-377/lib/trino-main-377.jar,,cpu-cost-weight,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.status-refresh-max-wait,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.krb5.keytab,"",false
377,trino-server-377/lib/trino-main-377.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.jwt.required-audience,"",false
377,trino-server-377/lib/trino-main-377.jar,,iterative-optimizer-timeout,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,event-listener.config-files,"",false
377,trino-server-377/lib/trino-main-377.jar,,scale-writers,"",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
377,trino-server-377/lib/trino-main-377.jar,,internal-communication.https.keystore.path,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.krb5.user-mapping.file,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.min-candidates,"",false
377,trino-server-377/lib/trino-main-377.jar,,spill-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.execution-policy,"",false
377,trino-server-377/lib/trino-main-377.jar,,max-spill-per-node,"",false
377,trino-server-377/lib/trino-main-377.jar,,aggregation-operator-unspill-memory-limit,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.push-partial-aggregation-through-join,"",false
377,trino-server-377/lib/trino-main-377.jar,,compiler.expression-cache-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.ignore-downstream-preferences,"",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.max-fraction-full-nodes-per-query,"",false
377,trino-server-377/lib/trino-main-377.jar,,regex-library,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.use-mark-distinct,"",false
377,trino-server-377/lib/trino-main-377.jar,,re2j.dfa-states-limit,"",false
377,trino-server-377/lib/trino-main-377.jar,,spiller-spill-path,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.network-topology.refresh-period,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.page-buffer-client.max-callback-threads,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.https.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.optimize-hash-generation,"",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
377,trino-server-377/lib/trino-main-377.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
377,trino-server-377/lib/trino-main-377.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
377,trino-server-377/lib/trino-main-377.jar,,http.authentication.krb5.config,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
377,trino-server-377/lib/trino-main-377.jar,,query.client.timeout,"",false
377,trino-server-377/lib/trino-main-377.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
377,trino-server-377/lib/trino-main-377.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
377,trino-server-377/lib/trino-main-377.jar,,enable-forced-exchange-below-group-id,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.concurrent-request-multiplier,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.http-timeout-threads,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.min-drivers,"",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.max-buffer-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
377,trino-server-377/lib/trino-main-377.jar,,failure-detector.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.info.max-age,"",false
377,trino-server-377/lib/trino-main-377.jar,,internal-communication.https.required,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.max-splits-per-node,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.password.user-mapping.file,"",false
377,trino-server-377/lib/trino-main-377.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
377,trino-server-377/lib/trino-main-377.jar,,http.include-exception-in-response,"",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.service-thread-count,"",false
377,trino-server-377/lib/trino-main-377.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
377,trino-server-377/lib/trino-main-377.jar,,task.max-partial-aggregation-memory,"",false
377,trino-server-377/lib/trino-main-377.jar,,join-distribution-type,"",false
377,trino-server-377/lib/trino-main-377.jar,,web-ui.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.max-partial-top-n-memory,"",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
377,trino-server-377/lib/trino-main-377.jar,,query.remote-task.max-callback-threads,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
377,trino-server-377/lib/trino-main-377.jar,,query-max-spill-per-node,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.remote-task.min-error-duration,"",false
377,trino-server-377/lib/trino-main-377.jar,,internal-communication.shared-secret,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
377,trino-server-377/lib/trino-main-377.jar,,pages-index.eager-compaction-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.merge-project-with-values,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.krb5.service-name,"",false
377,trino-server-377/lib/trino-main-377.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
377,trino-server-377/lib/trino-main-377.jar,,exchange.acknowledge-pages,"",false
377,trino-server-377/lib/trino-main-377.jar,,re2j.dfa-retries,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.max-absolute-full-nodes-per-query,"",false
377,trino-server-377/lib/trino-main-377.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
377,trino-server-377/lib/trino-main-377.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
377,trino-server-377/lib/trino-main-377.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
377,trino-server-377/lib/trino-main-377.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
377,trino-server-377/lib/trino-main-377.jar,,warning-collector.max-warnings,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.password.user-mapping.pattern,"",false
377,trino-server-377/lib/trino-main-377.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
377,trino-server-377/lib/trino-main-377.jar,,task.cpu-timer-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,sink.max-broadcast-buffer-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-planning-time,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-stage-count,"",false
377,trino-server-377/lib/trino-main-377.jar,,failure-detector.threshold,"",false
377,trino-server-377/lib/trino-main-377.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,web-ui.shared-secret,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
377,trino-server-377/lib/trino-main-377.jar,,experimental.late-materialization.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,distributed-sort,"",false
377,trino-server-377/lib/trino-main-377.jar,,internal-communication.https.truststore.key,"",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,task-retry-attempts-per-task,"",false
377,trino-server-377/lib/trino-main-377.jar,,sql.default-catalog,"",false
377,trino-server-377/lib/trino-main-377.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
377,trino-server-377/lib/trino-main-377.jar,,web-ui.user,"",false
377,trino-server-377/lib/trino-main-377.jar,,jmx.base-name,"",false
377,trino-server-377/lib/trino-main-377.jar,,statistics-precalculation-for-pushdown.enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.manager-executor-pool-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,catalog.config-dir,"",false
377,trino-server-377/lib/trino-main-377.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
377,trino-server-377/lib/trino-main-377.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.insecure.user-mapping.file,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.network-topology.type,"",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.push-table-write-through-union,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.default-filter-factor-enabled,"",false
377,trino-server-377/lib/trino-main-377.jar,,node-scheduler.optimized-local-scheduling,"",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.enable-intermediate-aggregations,"",false
377,trino-server-377/lib/trino-main-377.jar,,filter-and-project-min-output-page-size,"",false
377,trino-server-377/lib/trino-main-377.jar,,enable-large-dynamic-filters,"",false
377,trino-server-377/lib/trino-main-377.jar,,task.max-index-memory,"",false
377,trino-server-377/lib/trino-main-377.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.force-single-node-output,"",false
377,trino-server-377/lib/trino-main-377.jar,,retry-policy,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-memory,"",false
377,trino-server-377/lib/trino-main-377.jar,,plugin.dir,"",false
377,trino-server-377/lib/trino-main-377.jar,,failure-detector.heartbeat-interval,"",false
377,trino-server-377/lib/trino-main-377.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
377,trino-server-377/lib/trino-main-377.jar,,task.writer-count,"Number of writers per task",false
377,trino-server-377/lib/trino-main-377.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
377,trino-server-377/lib/trino-main-377.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
377,trino-server-377/lib/trino-main-377.jar,,query.min-expire-age,"",false
377,trino-server-377/lib/trino-main-377.jar,,enable-stats-calculator,"",false
377,trino-server-377/lib/trino-main-377.jar,,query.max-execution-time,"",false
377,trino-server-377/lib/trino-main-377.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
378,trino-server-378/plugin/kinesis/trino-plugin-toolkit-378.jar,kinesis,security.config-file,"",false
378,trino-server-378/plugin/kinesis/trino-plugin-toolkit-378.jar,kinesis,security.refresh-period,"",false
378,trino-server-378/plugin/kinesis/trino-plugin-toolkit-378.jar,kinesis,jmx.base-name,"",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
378,trino-server-378/plugin/kinesis/trino-kinesis-378.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
378,trino-server-378/plugin/clickhouse/trino-clickhouse-378.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
378,trino-server-378/plugin/clickhouse/trino-clickhouse-378.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,keystore-user-credential-name,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,user-credential-name,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,password-credential-name,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,credential-provider.type,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,statistics.enabled,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,join-pushdown.strategy,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,keystore-password,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,keystore-user-credential-password,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,complex-expression-pushdown.enabled,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,keystore-password-credential-password,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,keystore-file-path,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,connection-user,"user name for JDBC client",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,connection-password,"Password for JDBC client",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,connection-url,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,case-insensitive-name-matching,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,keystore-type,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,keystore-password-credential-name,"",false
378,trino-server-378/plugin/clickhouse/trino-base-jdbc-378.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
378,trino-server-378/plugin/postgresql/trino-postgresql-378.jar,postgresql,postgresql.array-mapping,"",false
378,trino-server-378/plugin/postgresql/trino-postgresql-378.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
378,trino-server-378/plugin/postgresql/trino-postgresql-378.jar,postgresql,postgresql.include-system-tables,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.aws-access-key,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.encryption-enabled,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.sink-buffer-pool-min-size,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.source-concurrent-readers,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.use-web-identity-token-credentials,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.region,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.base-directories,"List of base directories separated by commas",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.async-client-concurrency,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.endpoint,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.retry-mode,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.async-client-connection-acquisition-timeout,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.max-error-retries,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.aws-secret-key,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.sink-buffers-per-partition,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.async-client-max-pending-connection-acquires,"",false
378,trino-server-378/plugin/exchange/trino-exchange-378.jar,exchange,exchange.s3.storage-class,"",false
378,trino-server-378/plugin/atop/trino-atop-378.jar,atop,atop.max-history-days,"",false
378,trino-server-378/plugin/atop/trino-atop-378.jar,atop,atop.concurrent-readers-per-node,"",false
378,trino-server-378/plugin/atop/trino-atop-378.jar,atop,atop.security,"",false
378,trino-server-378/plugin/atop/trino-atop-378.jar,atop,atop.executable-path,"",false
378,trino-server-378/plugin/atop/trino-atop-378.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
378,trino-server-378/plugin/atop/trino-atop-378.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
378,trino-server-378/plugin/memory/trino-memory-378.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
378,trino-server-378/plugin/memory/trino-memory-378.jar,memory,memory.splits-per-node,"",false
378,trino-server-378/plugin/memory/trino-memory-378.jar,memory,memory.max-data-per-node,"",false
378,trino-server-378/plugin/accumulo/trino-accumulo-378.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
378,trino-server-378/plugin/accumulo/trino-accumulo-378.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
378,trino-server-378/plugin/accumulo/trino-accumulo-378.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
378,trino-server-378/plugin/accumulo/trino-accumulo-378.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
378,trino-server-378/plugin/accumulo/trino-accumulo-378.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
378,trino-server-378/plugin/accumulo/trino-accumulo-378.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
378,trino-server-378/plugin/accumulo/trino-accumulo-378.jar,accumulo,accumulo.instance,"Accumulo instance name",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.max-backlog-per-server,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.forbid-segment-queries,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.fetch-retry-count,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.controller.authentication.type,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.broker.authentication.password,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.max-rows-for-broker-queries,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.controller.authentication.user,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.idle-timeout,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.broker.authentication.type,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.request-timeout,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.thread-pool-size,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.controller-urls,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.broker.authentication.user,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.max-connections-per-server,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.metadata-expiry,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.min-connections-per-server,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.prefer-broker-queries,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.segments-per-split,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.controller.authentication.password,"",false
378,trino-server-378/plugin/pinot/trino-pinot-378.jar,pinot,pinot.connection-timeout,"",false
378,trino-server-378/plugin/resource-group-managers/trino-resource-group-managers-378.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
378,trino-server-378/plugin/resource-group-managers/trino-resource-group-managers-378.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
378,trino-server-378/plugin/resource-group-managers/trino-resource-group-managers-378.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
378,trino-server-378/plugin/resource-group-managers/trino-resource-group-managers-378.jar,resource-group-managers,resource-groups.config-db-url,"",false
378,trino-server-378/plugin/resource-group-managers/trino-resource-group-managers-378.jar,resource-group-managers,resource-groups.config-file,"",false
378,trino-server-378/plugin/resource-group-managers/trino-resource-group-managers-378.jar,resource-group-managers,jmx.base-name,"",false
378,trino-server-378/plugin/resource-group-managers/trino-resource-group-managers-378.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.table-description-dir,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.database-index,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.table-names,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.connect-timeout,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.hide-internal-columns,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.default-schema,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.key-delimiter,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.key-prefix-schema-table,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.nodes,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.password,"",false
378,trino-server-378/plugin/redis/trino-redis-378.jar,redis,redis.scan-count,"",false
378,trino-server-378/plugin/example-http/trino-example-http-378.jar,example-http,metadata-uri,"",false
378,trino-server-378/plugin/local-file/trino-local-file-378.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
378,trino-server-378/plugin/local-file/trino-local-file-378.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
378,trino-server-378/plugin/jmx/trino-jmx-378.jar,jmx,jmx.dump-tables,"",false
378,trino-server-378/plugin/jmx/trino-jmx-378.jar,jmx,jmx.max-entries,"",false
378,trino-server-378/plugin/jmx/trino-jmx-378.jar,jmx,jmx.dump-period,"",false
378,trino-server-378/plugin/phoenix/trino-phoenix-378.jar,phoenix,phoenix.config.resources,"",false
378,trino-server-378/plugin/phoenix/trino-phoenix-378.jar,phoenix,phoenix.connection-url,"",false
378,trino-server-378/plugin/phoenix/trino-phoenix-378.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.connection-pool.max-size,"",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.number.rounding-mode,"",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.connection-pool.min-size,"",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.connection-pool.enabled,"",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.remarks-reporting.enabled,"",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.synonyms.enabled,"",false
378,trino-server-378/plugin/oracle/trino-oracle-378.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.signer-class,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.max-client-retries,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.proxy.password,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3-file-system-type,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.read-mode,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.ssl.enabled,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-initial-splits,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.adl-proxy-host,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.security,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs.connect.max-retries,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.file-status-cache-expire-time,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.split-loader-concurrency,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.sts.region,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.writer.block-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.adl-refresh-url,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.compression-codec,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.max-merge-distance,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.abfs-access-key,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.aws-secret-key,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore-recording-path,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.max-buffer-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore-cache-ttl,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.config.resources,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.wasb-storage-account,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.signer-type,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore-timeout,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.endpoint,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.max-error-retries,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.adl-credential,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.proxy.protocol,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.bookkeeper-port,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.file-status-cache-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.writer.page-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.writer-sort-buffer-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.writer-identification,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.location,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-register-partition-procedure,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.sts.endpoint,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs-timeout,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-concurrent-file-renames,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs.verify-checksum,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.hdfs.socks-proxy,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.storage-format,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.proxy.port,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.abfs-storage-account,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.ignore-absent-partitions,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-split-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.replay-metastore-recording,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.force-local-scheduling,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.aws-access-key,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.max-buffer-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.max-merge-distance,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.max-read-block-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.socket-timeout,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.max-backoff-time,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.proxy.username,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.adl-client-id,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-split-iterator-threads,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.recursive-directories,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.streaming.enabled,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.stream-buffer-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.data-transfer-port,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.connect-timeout,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.max-connections,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.max-retry-time,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.max-initial-split-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.version-compatibility,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.azure.wasb-access-key,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore-recording-duration,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore-refresh-interval,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs.domain-socket-path,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.file-status-cache-tables,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,parquet.max-read-block-size,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.s3.proxy.host,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.dfs.connect.timeout,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
378,trino-server-378/plugin/delta-lake/trino-hive-378.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.max-initial-split-size,"",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.max-initial-splits,"",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.max-split-size,"",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
378,trino-server-378/plugin/delta-lake/trino-delta-lake-378.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
378,trino-server-378/plugin/session-property-managers/trino-session-property-managers-378.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
378,trino-server-378/plugin/session-property-managers/trino-session-property-managers-378.jar,session-property-managers,session-property-manager.db.password,"",false
378,trino-server-378/plugin/session-property-managers/trino-session-property-managers-378.jar,session-property-managers,session-property-manager.db.username,"",false
378,trino-server-378/plugin/session-property-managers/trino-session-property-managers-378.jar,session-property-managers,session-property-manager.db.url,"",false
378,trino-server-378/plugin/session-property-managers/trino-session-property-managers-378.jar,session-property-managers,session-property-manager.config-file,"",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.view-expire-duration,"",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
378,trino-server-378/plugin/bigquery/trino-bigquery-378.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.write-concern,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.connections-per-host,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.credentials,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.max-connection-idle-time,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.connection-url,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.schema-collection,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.socket-timeout,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.read-preference,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.min-connections-per-host,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.ssl.enabled,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.cursor-batch-size,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.max-wait-time,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.required-replica-set,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.seeds,"",false
378,trino-server-378/plugin/mongodb/trino-mongodb-378.jar,mongodb,mongodb.connection-timeout,"",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.delete_orphan_files.min-retention,"Minimal retention period for delete_orphan_files procedure",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.file-format,"",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.catalog.type,"",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.security,"",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
378,trino-server-378/plugin/iceberg/trino-iceberg-378.jar,iceberg,iceberg.compression-codec,"",false
378,trino-server-378/plugin/phoenix5/trino-phoenix5-378.jar,phoenix5,phoenix.config.resources,"",false
378,trino-server-378/plugin/phoenix5/trino-phoenix5-378.jar,phoenix5,phoenix.connection-url,"",false
378,trino-server-378/plugin/phoenix5/trino-phoenix5-378.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
378,trino-server-378/plugin/thrift/trino-thrift-378.jar,thrift,trino-thrift.max-response-size,"",false
378,trino-server-378/plugin/thrift/trino-thrift-378.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
378,trino-server-378/plugin/thrift/trino-thrift-378.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.organization-enabled,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.orc.nested-lazy,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,metadata.db.url,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.compaction-enabled,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.security,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.orc.max-read-size,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.balancer-enabled,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
378,trino-server-378/plugin/raptor-legacy/trino-raptor-legacy-378.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
378,trino-server-378/plugin/google-sheets/trino-google-sheets-378.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
378,trino-server-378/plugin/google-sheets/trino-google-sheets-378.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
378,trino-server-378/plugin/google-sheets/trino-google-sheets-378.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
378,trino-server-378/plugin/google-sheets/trino-google-sheets-378.jar,google-sheets,credentials-path,"Credential file path to google service account",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.config.resources,"Optional config files",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
378,trino-server-378/plugin/kafka/trino-kafka-378.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.tls.truststore-password,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.consistency-level,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.tls.keystore-password,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.protocol-version,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.client.read-timeout,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.fetch-size,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.tls.enabled,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.client.connect-timeout,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.retry-policy,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.client.so-linger,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.tls.truststore-path,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.splits-per-node,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.username,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.password,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.contact-points,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.speculative-execution.limit,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.speculative-execution.delay,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.split-size,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.tls.keystore-path,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.batch-size,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
378,trino-server-378/plugin/cassandra/trino-cassandra-378.jar,cassandra,cassandra.native-protocol-port,"",false
378,trino-server-378/plugin/mysql/trino-mysql-378.jar,mysql,mysql.auto-reconnect,"",false
378,trino-server-378/plugin/mysql/trino-mysql-378.jar,mysql,mysql.max-reconnects,"",false
378,trino-server-378/plugin/mysql/trino-mysql-378.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
378,trino-server-378/plugin/mysql/trino-mysql-378.jar,mysql,mysql.connection-timeout,"",false
378,trino-server-378/plugin/sqlserver/trino-sqlserver-378.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
378,trino-server-378/plugin/http-event-listener/trino-http-event-listener-378.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.schema-emulation.prefix,"",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.client.master-addresses,"",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.schema-emulation.enabled,"",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.client.disable-statistics,"",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.grouped-execution.enabled,"",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.client.default-operation-timeout,"",false
378,trino-server-378/plugin/kudu/trino-kudu-378.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.timeout.connect,"Timeout for establishing a connection",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.timeout.read,"Timeout for reading data from LDAP",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.ssl.keystore.password,"Password for the key store",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.cache-ttl,"",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.ssl.truststore.password,"Password for the trust store",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,ldap.url,"URL of the LDAP server",false
378,trino-server-378/plugin/password-authenticators/trino-password-authenticators-378.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
378,trino-server-378/plugin/prometheus/trino-prometheus-378.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
378,trino-server-378/plugin/prometheus/trino-prometheus-378.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
378,trino-server-378/plugin/prometheus/trino-prometheus-378.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
378,trino-server-378/plugin/prometheus/trino-prometheus-378.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
378,trino-server-378/plugin/prometheus/trino-prometheus-378.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
378,trino-server-378/plugin/prometheus/trino-prometheus-378.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.auth.password,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.auth.user,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.tls.enabled,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.security,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.port,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.aws.access-key,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.host,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.aws.region,"",false
378,trino-server-378/plugin/elasticsearch/trino-elasticsearch-378.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
378,trino-server-378/plugin/singlestore/trino-singlestore-378.jar,singlestore,singlestore.auto-reconnect,"",false
378,trino-server-378/plugin/singlestore/trino-singlestore-378.jar,singlestore,singlestore.connection-timeout,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.allocator-type,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.acknowledge-pages,"",false
378,trino-server-378/lib/trino-main-378.jar,,shutdown.grace-period,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.optimize-hash-generation,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
378,trino-server-378/lib/trino-main-378.jar,,sink.max-buffer-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.krb5.principal-hostname,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.push-aggregation-through-outer-join,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.max-error-duration,"",false
378,trino-server-378/lib/trino-main-378.jar,,event-listener.config-files,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
378,trino-server-378/lib/trino-main-378.jar,,enable-stats-calculator,"",false
378,trino-server-378/lib/trino-main-378.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
378,trino-server-378/lib/trino-main-378.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
378,trino-server-378/lib/trino-main-378.jar,,analyzer.max-grouping-sets,"",false
378,trino-server-378/lib/trino-main-378.jar,,redistribute-writes,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.statistics-cpu-timer-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
378,trino-server-378/lib/trino-main-378.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
378,trino-server-378/lib/trino-main-378.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
378,trino-server-378/lib/trino-main-378.jar,,enable-large-dynamic-filters,"",false
378,trino-server-378/lib/trino-main-378.jar,,scale-writers,"",false
378,trino-server-378/lib/trino-main-378.jar,,web-ui.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,filter-and-project-min-output-page-row-count,"",false
378,trino-server-378/lib/trino-main-378.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
378,trino-server-378/lib/trino-main-378.jar,,query.remote-task.max-error-duration,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.complex-expression-pushdown.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
378,trino-server-378/lib/trino-main-378.jar,,filter-and-project-min-output-page-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.cpu-timer-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.client-threads,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.min-error-duration,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.certificate.user-mapping.file,"",false
378,trino-server-378/lib/trino-main-378.jar,,spiller-threads,"",false
378,trino-server-378/lib/trino-main-378.jar,,failure-detector.heartbeat-interval,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.ignore-downstream-preferences,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.merge-project-with-values,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.dictionary-aggregation,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.min-drivers,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.krb5.keytab,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-concurrent-queries,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-planning-time,"",false
378,trino-server-378/lib/trino-main-378.jar,,warning-collector.max-warnings,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.max-response-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
378,trino-server-378/lib/trino-main-378.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
378,trino-server-378/lib/trino-main-378.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.krb5.user-mapping.file,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.remote-task.max-callback-threads,"",false
378,trino-server-378/lib/trino-main-378.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
378,trino-server-378/lib/trino-main-378.jar,,task.http-response-threads,"",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
378,trino-server-378/lib/trino-main-378.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
378,trino-server-378/lib/trino-main-378.jar,,use-preferred-write-partitioning,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.max-pending-splits-per-task,"",false
378,trino-server-378/lib/trino-main-378.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
378,trino-server-378/lib/trino-main-378.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
378,trino-server-378/lib/trino-main-378.jar,,query-max-spill-per-node,"",false
378,trino-server-378/lib/trino-main-378.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
378,trino-server-378/lib/trino-main-378.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
378,trino-server-378/lib/trino-main-378.jar,,query.manager-executor-pool-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.network-topology.type,"",false
378,trino-server-378/lib/trino-main-378.jar,,spill-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.push-table-write-through-union,"",false
378,trino-server-378/lib/trino-main-378.jar,,web-ui.shared-secret,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.password.user-mapping.file,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.max-splits-per-node,"",false
378,trino-server-378/lib/trino-main-378.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
378,trino-server-378/lib/trino-main-378.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
378,trino-server-378/lib/trino-main-378.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
378,trino-server-378/lib/trino-main-378.jar,,failure-detector.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,retry-policy,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,internal-communication.https.truststore.key,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
378,trino-server-378/lib/trino-main-378.jar,,event.max-output-stage-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
378,trino-server-378/lib/trino-main-378.jar,,internal-communication.https.required,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.max-absolute-full-nodes-per-query,"",false
378,trino-server-378/lib/trino-main-378.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
378,trino-server-378/lib/trino-main-378.jar,,discovery-server.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.client.timeout,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.min-schedule-split-batch-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.https.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.concurrent-request-multiplier,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
378,trino-server-378/lib/trino-main-378.jar,,catalog.disabled-catalogs,"",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-cpu-time,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.remote-task.min-error-duration,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.deduplication-buffer-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.min-expire-age,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.optimized-local-scheduling,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
378,trino-server-378/lib/trino-main-378.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
378,trino-server-378/lib/trino-main-378.jar,,task.info.max-age,"",false
378,trino-server-378/lib/trino-main-378.jar,,distributed-index-joins-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-stage-count,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.per-operator-cpu-timer-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,access-control.config-files,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
378,trino-server-378/lib/trino-main-378.jar,,jmx.base-name,"",false
378,trino-server-378/lib/trino-main-378.jar,,re2j.dfa-states-limit,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.share-index-loading,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-memory-per-node,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.max-partial-top-n-memory,"",false
378,trino-server-378/lib/trino-main-378.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
378,trino-server-378/lib/trino-main-378.jar,,query.info-url-template,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
378,trino-server-378/lib/trino-main-378.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.push-partial-aggregation-through-join,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.optimize-metadata-queries,"",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-memory,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
378,trino-server-378/lib/trino-main-378.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-length,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-history,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.jwt.principal-field,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.jwt.user-mapping.file,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.page-buffer-client.max-callback-threads,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.optimize-top-n-ranking,"",false
378,trino-server-378/lib/trino-main-378.jar,,network-cost-weight,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.max-partial-aggregation-memory,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
378,trino-server-378/lib/trino-main-378.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.service-thread-count,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.writer-count,"Number of writers per task",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.jwt.required-issuer,"",false
378,trino-server-378/lib/trino-main-378.jar,,iterative-optimizer-timeout,"",false
378,trino-server-378/lib/trino-main-378.jar,,compiler.expression-cache-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.use-mark-distinct,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,task-retry-attempts-overall,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-total-memory,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.include-coordinator,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.low-memory-killer.policy,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
378,trino-server-378/lib/trino-main-378.jar,,sql.default-catalog,"",false
378,trino-server-378/lib/trino-main-378.jar,,internal-communication.https.keystore.path,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.max-fraction-full-nodes-per-query,"",false
378,trino-server-378/lib/trino-main-378.jar,,http.authentication.krb5.config,"",false
378,trino-server-378/lib/trino-main-378.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
378,trino-server-378/lib/trino-main-378.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
378,trino-server-378/lib/trino-main-378.jar,,query.schedule-split-batch-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.max-worker-threads,"",false
378,trino-server-378/lib/trino-main-378.jar,,aggregation-operator-unspill-memory-limit,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.insecure.user-mapping.file,"",false
378,trino-server-378/lib/trino-main-378.jar,,join-distribution-type,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
378,trino-server-378/lib/trino-main-378.jar,,failure-detector.threshold,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
378,trino-server-378/lib/trino-main-378.jar,,spiller-spill-path,"",false
378,trino-server-378/lib/trino-main-378.jar,,sink.max-broadcast-buffer-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.status-refresh-max-wait,"",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
378,trino-server-378/lib/trino-main-378.jar,,web-ui.session-timeout,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.min-candidates,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.password.user-mapping.pattern,"",false
378,trino-server-378/lib/trino-main-378.jar,,cpu-cost-weight,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-scan-physical-bytes,"",false
378,trino-server-378/lib/trino-main-378.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
378,trino-server-378/lib/trino-main-378.jar,,sql.default-schema,"",false
378,trino-server-378/lib/trino-main-378.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
378,trino-server-378/lib/trino-main-378.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
378,trino-server-378/lib/trino-main-378.jar,,catalog.config-dir,"",false
378,trino-server-378/lib/trino-main-378.jar,,pages-index.eager-compaction-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.krb5.service-name,"",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.data-integrity-verification,"",false
378,trino-server-378/lib/trino-main-378.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,plugin.dir,"",false
378,trino-server-378/lib/trino-main-378.jar,,parse-decimal-literals-as-double,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
378,trino-server-378/lib/trino-main-378.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
378,trino-server-378/lib/trino-main-378.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
378,trino-server-378/lib/trino-main-378.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
378,trino-server-378/lib/trino-main-378.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.force-single-node-output,"",false
378,trino-server-378/lib/trino-main-378.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
378,trino-server-378/lib/trino-main-378.jar,,query-retry-attempts,"",false
378,trino-server-378/lib/trino-main-378.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
378,trino-server-378/lib/trino-main-378.jar,,max-spill-per-node,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-execution-time,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
378,trino-server-378/lib/trino-main-378.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.jwt.required-audience,"",false
378,trino-server-378/lib/trino-main-378.jar,,enable-forced-exchange-below-group-id,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
378,trino-server-378/lib/trino-main-378.jar,,driver.max-page-partitioning-buffer-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.policy,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.jwt.key-file,"",false
378,trino-server-378/lib/trino-main-378.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.enable-intermediate-aggregations,"",false
378,trino-server-378/lib/trino-main-378.jar,,spill-compression-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,internal-communication.shared-secret,"",false
378,trino-server-378/lib/trino-main-378.jar,,spiller-max-used-space-threshold,"",false
378,trino-server-378/lib/trino-main-378.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.network-topology.refresh-period,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.max-buffer-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.split-concurrency-adjustment-interval,"",false
378,trino-server-378/lib/trino-main-378.jar,,deprecated.legacy-row-to-json-cast,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.krb5.name-type,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.max-local-exchange-buffer-size,"",false
378,trino-server-378/lib/trino-main-378.jar,,enable-dynamic-filtering,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
378,trino-server-378/lib/trino-main-378.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
378,trino-server-378/lib/trino-main-378.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
378,trino-server-378/lib/trino-main-378.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.http-timeout-threads,"",false
378,trino-server-378/lib/trino-main-378.jar,,node-scheduler.network-topology.file,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
378,trino-server-378/lib/trino-main-378.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
378,trino-server-378/lib/trino-main-378.jar,,re2j.dfa-retries,"",false
378,trino-server-378/lib/trino-main-378.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
378,trino-server-378/lib/trino-main-378.jar,,http.include-exception-in-response,"",false
378,trino-server-378/lib/trino-main-378.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
378,trino-server-378/lib/trino-main-378.jar,,task.max-index-memory,"",false
378,trino-server-378/lib/trino-main-378.jar,,distributed-sort,"",false
378,trino-server-378/lib/trino-main-378.jar,,query.execution-policy,"",false
378,trino-server-378/lib/trino-main-378.jar,,statistics-precalculation-for-pushdown.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.initial-splits-per-node,"",false
378,trino-server-378/lib/trino-main-378.jar,,exchange.compression-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.prefer-partial-aggregation,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.info-update-interval,"Interval between updating task data",false
378,trino-server-378/lib/trino-main-378.jar,,query-results.compression-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,memory-cost-weight,"",false
378,trino-server-378/lib/trino-main-378.jar,,internal-communication.https.keystore.key,"",false
378,trino-server-378/lib/trino-main-378.jar,,web-ui.user,"",false
378,trino-server-378/lib/trino-main-378.jar,,experimental.late-materialization.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,internal-communication.https.truststore.path,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.client.timeout,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
378,trino-server-378/lib/trino-main-378.jar,,spill-encryption-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
378,trino-server-378/lib/trino-main-378.jar,,task-retry-attempts-per-task,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.default-filter-factor-enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
378,trino-server-378/lib/trino-main-378.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-queued-queries,"",false
378,trino-server-378/lib/trino-main-378.jar,,optimizer.skip-redundant-sort,"",false
378,trino-server-378/lib/trino-main-378.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
378,trino-server-378/lib/trino-main-378.jar,,regex-library,"",false
378,trino-server-378/lib/trino-main-378.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
378,trino-server-378/lib/trino-main-378.jar,,adaptive-partial-aggregation.enabled,"",false
378,trino-server-378/lib/trino-main-378.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
378,trino-server-378/lib/trino-main-378.jar,,query.max-run-time,"",false
378,trino-server-378/lib/trino-main-378.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
378,trino-server-378/lib/trino-main-378.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
378,trino-server-378/lib/trino-main-378.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
378,trino-server-378/lib/trino-main-378.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,security.refresh-period,"",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,jmx.base-name,"",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,security.config-file,"",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.url,"URL of the LDAP server",false
379,trino-server-379/plugin/kinesis/trino-plugin-toolkit-379.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
379,trino-server-379/plugin/kinesis/trino-kinesis-379.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
379,trino-server-379/plugin/clickhouse/trino-clickhouse-379.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
379,trino-server-379/plugin/clickhouse/trino-clickhouse-379.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,keystore-file-path,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,connection-user,"user name for JDBC client",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,connection-password,"Password for JDBC client",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,connection-url,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,case-insensitive-name-matching,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,keystore-type,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,keystore-password-credential-name,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,keystore-user-credential-name,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,user-credential-name,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,password-credential-name,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,credential-provider.type,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,statistics.enabled,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,join-pushdown.strategy,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,keystore-password,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,keystore-user-credential-password,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,complex-expression-pushdown.enabled,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,keystore-password-credential-password,"",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
379,trino-server-379/plugin/clickhouse/trino-base-jdbc-379.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
379,trino-server-379/plugin/postgresql/trino-postgresql-379.jar,postgresql,postgresql.include-system-tables,"",false
379,trino-server-379/plugin/postgresql/trino-postgresql-379.jar,postgresql,postgresql.array-mapping,"",false
379,trino-server-379/plugin/postgresql/trino-postgresql-379.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
379,trino-server-379/plugin/atop/trino-atop-379.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
379,trino-server-379/plugin/atop/trino-atop-379.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
379,trino-server-379/plugin/atop/trino-atop-379.jar,atop,atop.max-history-days,"",false
379,trino-server-379/plugin/atop/trino-atop-379.jar,atop,atop.concurrent-readers-per-node,"",false
379,trino-server-379/plugin/atop/trino-atop-379.jar,atop,atop.security,"",false
379,trino-server-379/plugin/atop/trino-atop-379.jar,atop,atop.executable-path,"",false
379,trino-server-379/plugin/memory/trino-memory-379.jar,memory,memory.max-data-per-node,"",false
379,trino-server-379/plugin/memory/trino-memory-379.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
379,trino-server-379/plugin/memory/trino-memory-379.jar,memory,memory.splits-per-node,"",false
379,trino-server-379/plugin/accumulo/trino-accumulo-379.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
379,trino-server-379/plugin/accumulo/trino-accumulo-379.jar,accumulo,accumulo.instance,"Accumulo instance name",false
379,trino-server-379/plugin/accumulo/trino-accumulo-379.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
379,trino-server-379/plugin/accumulo/trino-accumulo-379.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
379,trino-server-379/plugin/accumulo/trino-accumulo-379.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
379,trino-server-379/plugin/accumulo/trino-accumulo-379.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
379,trino-server-379/plugin/accumulo/trino-accumulo-379.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.metadata-expiry,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.min-connections-per-server,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.prefer-broker-queries,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.segments-per-split,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.controller.authentication.password,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.connection-timeout,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.max-backlog-per-server,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.forbid-segment-queries,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.fetch-retry-count,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.controller.authentication.type,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.broker.authentication.password,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.max-rows-for-broker-queries,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.controller.authentication.user,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.idle-timeout,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.broker.authentication.type,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.request-timeout,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.thread-pool-size,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.controller-urls,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.broker.authentication.user,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
379,trino-server-379/plugin/pinot/trino-pinot-379.jar,pinot,pinot.max-connections-per-server,"",false
379,trino-server-379/plugin/resource-group-managers/trino-resource-group-managers-379.jar,resource-group-managers,jmx.base-name,"",false
379,trino-server-379/plugin/resource-group-managers/trino-resource-group-managers-379.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
379,trino-server-379/plugin/resource-group-managers/trino-resource-group-managers-379.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
379,trino-server-379/plugin/resource-group-managers/trino-resource-group-managers-379.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
379,trino-server-379/plugin/resource-group-managers/trino-resource-group-managers-379.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
379,trino-server-379/plugin/resource-group-managers/trino-resource-group-managers-379.jar,resource-group-managers,resource-groups.config-db-url,"",false
379,trino-server-379/plugin/resource-group-managers/trino-resource-group-managers-379.jar,resource-group-managers,resource-groups.config-file,"",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.default-schema,"The schema name to use in the connector",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.password,"Password for a password-protected Redis server",false
379,trino-server-379/plugin/redis/trino-redis-379.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
379,trino-server-379/plugin/example-http/trino-example-http-379.jar,example-http,metadata-uri,"",false
379,trino-server-379/plugin/local-file/trino-local-file-379.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
379,trino-server-379/plugin/local-file/trino-local-file-379.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
379,trino-server-379/plugin/jmx/trino-jmx-379.jar,jmx,jmx.max-entries,"",false
379,trino-server-379/plugin/jmx/trino-jmx-379.jar,jmx,jmx.dump-period,"",false
379,trino-server-379/plugin/jmx/trino-jmx-379.jar,jmx,jmx.dump-tables,"",false
379,trino-server-379/plugin/phoenix/trino-phoenix-379.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
379,trino-server-379/plugin/phoenix/trino-phoenix-379.jar,phoenix,phoenix.config.resources,"",false
379,trino-server-379/plugin/phoenix/trino-phoenix-379.jar,phoenix,phoenix.connection-url,"",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.remarks-reporting.enabled,"",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.synonyms.enabled,"",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.connection-pool.max-size,"",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.number.rounding-mode,"",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.connection-pool.min-size,"",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
379,trino-server-379/plugin/oracle/trino-oracle-379.jar,oracle,oracle.connection-pool.enabled,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.recursive-directories,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.streaming.enabled,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.stream-buffer-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.data-transfer-port,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.connect-timeout,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.max-connections,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.max-retry-time,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-initial-split-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.version-compatibility,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.wasb-access-key,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore-recording-duration,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore-refresh-interval,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs.domain-socket-path,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.file-status-cache-tables,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.max-read-block-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.proxy.host,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs.connect.timeout,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.signer-class,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.max-client-retries,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.proxy.password,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3-file-system-type,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.read-mode,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.ssl.enabled,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-initial-splits,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.adl-proxy-host,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.security,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs.connect.max-retries,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.file-status-cache-expire-time,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.split-loader-concurrency,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.sts.region,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.writer.block-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.adl-refresh-url,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.compression-codec,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.max-merge-distance,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.abfs-access-key,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.aws-secret-key,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore-recording-path,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.max-buffer-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore-cache-ttl,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.config.resources,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.wasb-storage-account,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.signer-type,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore-timeout,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.endpoint,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.max-error-retries,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.adl-credential,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.proxy.protocol,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.bookkeeper-port,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.file-status-cache-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.writer.page-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.writer-sort-buffer-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.writer-identification,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.cache.location,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.legacy-hive-view-translation,"Use legacy Hive view translation mechanism",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-register-partition-procedure,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.translate-hive-views,"Experimental: Allow translation of Hive views into Trino views",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.sts.endpoint,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs-timeout,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-concurrent-file-renames,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.dfs.verify-checksum,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.hdfs.socks-proxy,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.storage-format,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.proxy.port,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.abfs-storage-account,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.ignore-absent-partitions,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-split-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.replay-metastore-recording,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.force-local-scheduling,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.aws-access-key,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.max-buffer-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.max-merge-distance,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.max-read-block-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.socket-timeout,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.max-backoff-time,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.s3.proxy.username,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.azure.adl-client-id,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.max-split-iterator-threads,"",false
379,trino-server-379/plugin/delta-lake/trino-hive-379.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.max-split-size,"",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.max-initial-split-size,"",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.max-initial-splits,"",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
379,trino-server-379/plugin/delta-lake/trino-delta-lake-379.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
379,trino-server-379/plugin/session-property-managers/trino-session-property-managers-379.jar,session-property-managers,session-property-manager.db.url,"",false
379,trino-server-379/plugin/session-property-managers/trino-session-property-managers-379.jar,session-property-managers,session-property-manager.config-file,"",false
379,trino-server-379/plugin/session-property-managers/trino-session-property-managers-379.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
379,trino-server-379/plugin/session-property-managers/trino-session-property-managers-379.jar,session-property-managers,session-property-manager.db.password,"",false
379,trino-server-379/plugin/session-property-managers/trino-session-property-managers-379.jar,session-property-managers,session-property-manager.db.username,"",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.view-expire-duration,"",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
379,trino-server-379/plugin/bigquery/trino-bigquery-379.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.ssl.enabled,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.cursor-batch-size,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.max-wait-time,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.required-replica-set,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.seeds,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.connection-timeout,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.write-concern,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.connections-per-host,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.credentials,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.max-connection-idle-time,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.connection-url,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.schema-collection,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.socket-timeout,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.read-preference,"",false
379,trino-server-379/plugin/mongodb/trino-mongodb-379.jar,mongodb,mongodb.min-connections-per-host,"",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.security,"",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.compression-codec,"",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.delete_orphan_files.min-retention,"Minimal retention period for delete_orphan_files procedure",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.file-format,"",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
379,trino-server-379/plugin/iceberg/trino-iceberg-379.jar,iceberg,iceberg.catalog.type,"",false
379,trino-server-379/plugin/phoenix5/trino-phoenix5-379.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
379,trino-server-379/plugin/phoenix5/trino-phoenix5-379.jar,phoenix5,phoenix.config.resources,"",false
379,trino-server-379/plugin/phoenix5/trino-phoenix5-379.jar,phoenix5,phoenix.connection-url,"",false
379,trino-server-379/plugin/thrift/trino-thrift-379.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
379,trino-server-379/plugin/thrift/trino-thrift-379.jar,thrift,trino-thrift.max-response-size,"",false
379,trino-server-379/plugin/thrift/trino-thrift-379.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.balancer-enabled,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.organization-enabled,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.orc.nested-lazy,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,metadata.db.url,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.compaction-enabled,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,raptor.security,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.orc.max-read-size,"",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
379,trino-server-379/plugin/raptor-legacy/trino-raptor-legacy-379.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
379,trino-server-379/plugin/google-sheets/trino-google-sheets-379.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
379,trino-server-379/plugin/google-sheets/trino-google-sheets-379.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
379,trino-server-379/plugin/google-sheets/trino-google-sheets-379.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
379,trino-server-379/plugin/google-sheets/trino-google-sheets-379.jar,google-sheets,credentials-path,"Credential file path to google service account",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.config.resources,"Optional config files",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
379,trino-server-379/plugin/kafka/trino-kafka-379.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.password,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.contact-points,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.speculative-execution.limit,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.speculative-execution.delay,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.split-size,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.tls.keystore-path,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.batch-size,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.native-protocol-port,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.tls.truststore-password,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.consistency-level,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.tls.keystore-password,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.protocol-version,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.client.read-timeout,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.fetch-size,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.tls.enabled,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.client.connect-timeout,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.retry-policy,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.client.so-linger,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.tls.truststore-path,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.splits-per-node,"",false
379,trino-server-379/plugin/cassandra/trino-cassandra-379.jar,cassandra,cassandra.username,"",false
379,trino-server-379/plugin/mysql/trino-mysql-379.jar,mysql,mysql.connection-timeout,"",false
379,trino-server-379/plugin/mysql/trino-mysql-379.jar,mysql,mysql.auto-reconnect,"",false
379,trino-server-379/plugin/mysql/trino-mysql-379.jar,mysql,mysql.max-reconnects,"",false
379,trino-server-379/plugin/mysql/trino-mysql-379.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
379,trino-server-379/plugin/sqlserver/trino-sqlserver-379.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
379,trino-server-379/plugin/http-event-listener/trino-http-event-listener-379.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.schema-emulation.prefix,"",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.client.master-addresses,"",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.schema-emulation.enabled,"",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.client.disable-statistics,"",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.grouped-execution.enabled,"",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
379,trino-server-379/plugin/kudu/trino-kudu-379.jar,kudu,kudu.client.default-operation-timeout,"",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
379,trino-server-379/plugin/password-authenticators/trino-password-authenticators-379.jar,password-authenticators,ldap.cache-ttl,"",false
379,trino-server-379/plugin/prometheus/trino-prometheus-379.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
379,trino-server-379/plugin/prometheus/trino-prometheus-379.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
379,trino-server-379/plugin/prometheus/trino-prometheus-379.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
379,trino-server-379/plugin/prometheus/trino-prometheus-379.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
379,trino-server-379/plugin/prometheus/trino-prometheus-379.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
379,trino-server-379/plugin/prometheus/trino-prometheus-379.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.storage-class,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.encryption-enabled,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.use-web-identity-token-credentials,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.region,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.endpoint,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
379,trino-server-379/plugin/exchange-filesystem/trino-exchange-filesystem-379.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.host,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.aws.region,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.auth.password,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.auth.user,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.tls.enabled,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.security,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.port,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.aws.access-key,"",false
379,trino-server-379/plugin/elasticsearch/trino-elasticsearch-379.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
379,trino-server-379/plugin/singlestore/trino-singlestore-379.jar,singlestore,singlestore.auto-reconnect,"",false
379,trino-server-379/plugin/singlestore/trino-singlestore-379.jar,singlestore,singlestore.connection-timeout,"",false
379,trino-server-379/lib/trino-main-379.jar,,parse-decimal-literals-as-double,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
379,trino-server-379/lib/trino-main-379.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
379,trino-server-379/lib/trino-main-379.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
379,trino-server-379/lib/trino-main-379.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
379,trino-server-379/lib/trino-main-379.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.force-single-node-output,"",false
379,trino-server-379/lib/trino-main-379.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
379,trino-server-379/lib/trino-main-379.jar,,query-retry-attempts,"",false
379,trino-server-379/lib/trino-main-379.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
379,trino-server-379/lib/trino-main-379.jar,,max-spill-per-node,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-execution-time,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
379,trino-server-379/lib/trino-main-379.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.jwt.required-audience,"",false
379,trino-server-379/lib/trino-main-379.jar,,enable-forced-exchange-below-group-id,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
379,trino-server-379/lib/trino-main-379.jar,,driver.max-page-partitioning-buffer-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.policy,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.jwt.key-file,"",false
379,trino-server-379/lib/trino-main-379.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.enable-intermediate-aggregations,"",false
379,trino-server-379/lib/trino-main-379.jar,,spill-compression-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,internal-communication.shared-secret,"",false
379,trino-server-379/lib/trino-main-379.jar,,spiller-max-used-space-threshold,"",false
379,trino-server-379/lib/trino-main-379.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.network-topology.refresh-period,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.max-buffer-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.split-concurrency-adjustment-interval,"",false
379,trino-server-379/lib/trino-main-379.jar,,deprecated.legacy-row-to-json-cast,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.krb5.name-type,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.max-local-exchange-buffer-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,enable-dynamic-filtering,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
379,trino-server-379/lib/trino-main-379.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
379,trino-server-379/lib/trino-main-379.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
379,trino-server-379/lib/trino-main-379.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.http-timeout-threads,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.network-topology.file,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
379,trino-server-379/lib/trino-main-379.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
379,trino-server-379/lib/trino-main-379.jar,,re2j.dfa-retries,"",false
379,trino-server-379/lib/trino-main-379.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
379,trino-server-379/lib/trino-main-379.jar,,http.include-exception-in-response,"",false
379,trino-server-379/lib/trino-main-379.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
379,trino-server-379/lib/trino-main-379.jar,,task.max-index-memory,"",false
379,trino-server-379/lib/trino-main-379.jar,,distributed-sort,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.execution-policy,"",false
379,trino-server-379/lib/trino-main-379.jar,,statistics-precalculation-for-pushdown.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.initial-splits-per-node,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.compression-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.prefer-partial-aggregation,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.info-update-interval,"Interval between updating task data",false
379,trino-server-379/lib/trino-main-379.jar,,query-results.compression-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,memory-cost-weight,"",false
379,trino-server-379/lib/trino-main-379.jar,,internal-communication.https.keystore.key,"",false
379,trino-server-379/lib/trino-main-379.jar,,web-ui.user,"",false
379,trino-server-379/lib/trino-main-379.jar,,experimental.late-materialization.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,internal-communication.https.truststore.path,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.client.timeout,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
379,trino-server-379/lib/trino-main-379.jar,,spill-encryption-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
379,trino-server-379/lib/trino-main-379.jar,,task-retry-attempts-per-task,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.default-filter-factor-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-queued-queries,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.skip-redundant-sort,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
379,trino-server-379/lib/trino-main-379.jar,,regex-library,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,adaptive-partial-aggregation.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-run-time,"",false
379,trino-server-379/lib/trino-main-379.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
379,trino-server-379/lib/trino-main-379.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
379,trino-server-379/lib/trino-main-379.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.allocator-type,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.acknowledge-pages,"",false
379,trino-server-379/lib/trino-main-379.jar,,shutdown.grace-period,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.optimize-hash-generation,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
379,trino-server-379/lib/trino-main-379.jar,,sink.max-buffer-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.krb5.principal-hostname,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.push-aggregation-through-outer-join,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.max-error-duration,"",false
379,trino-server-379/lib/trino-main-379.jar,,event-listener.config-files,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
379,trino-server-379/lib/trino-main-379.jar,,enable-stats-calculator,"",false
379,trino-server-379/lib/trino-main-379.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
379,trino-server-379/lib/trino-main-379.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
379,trino-server-379/lib/trino-main-379.jar,,analyzer.max-grouping-sets,"",false
379,trino-server-379/lib/trino-main-379.jar,,redistribute-writes,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.statistics-cpu-timer-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
379,trino-server-379/lib/trino-main-379.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
379,trino-server-379/lib/trino-main-379.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
379,trino-server-379/lib/trino-main-379.jar,,enable-large-dynamic-filters,"",false
379,trino-server-379/lib/trino-main-379.jar,,scale-writers,"",false
379,trino-server-379/lib/trino-main-379.jar,,web-ui.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,filter-and-project-min-output-page-row-count,"",false
379,trino-server-379/lib/trino-main-379.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
379,trino-server-379/lib/trino-main-379.jar,,query.remote-task.max-error-duration,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.complex-expression-pushdown.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
379,trino-server-379/lib/trino-main-379.jar,,filter-and-project-min-output-page-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.cpu-timer-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.client-threads,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.min-error-duration,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.certificate.user-mapping.file,"",false
379,trino-server-379/lib/trino-main-379.jar,,spiller-threads,"",false
379,trino-server-379/lib/trino-main-379.jar,,failure-detector.heartbeat-interval,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.ignore-downstream-preferences,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.merge-project-with-values,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.dictionary-aggregation,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.min-drivers,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.krb5.keytab,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-concurrent-queries,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-planning-time,"",false
379,trino-server-379/lib/trino-main-379.jar,,warning-collector.max-warnings,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.max-response-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
379,trino-server-379/lib/trino-main-379.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
379,trino-server-379/lib/trino-main-379.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.krb5.user-mapping.file,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.remote-task.max-callback-threads,"",false
379,trino-server-379/lib/trino-main-379.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
379,trino-server-379/lib/trino-main-379.jar,,task.http-response-threads,"",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
379,trino-server-379/lib/trino-main-379.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
379,trino-server-379/lib/trino-main-379.jar,,use-preferred-write-partitioning,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.max-pending-splits-per-task,"",false
379,trino-server-379/lib/trino-main-379.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
379,trino-server-379/lib/trino-main-379.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
379,trino-server-379/lib/trino-main-379.jar,,query-max-spill-per-node,"",false
379,trino-server-379/lib/trino-main-379.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
379,trino-server-379/lib/trino-main-379.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
379,trino-server-379/lib/trino-main-379.jar,,query.manager-executor-pool-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.network-topology.type,"",false
379,trino-server-379/lib/trino-main-379.jar,,spill-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.push-table-write-through-union,"",false
379,trino-server-379/lib/trino-main-379.jar,,web-ui.shared-secret,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.password.user-mapping.file,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.max-splits-per-node,"",false
379,trino-server-379/lib/trino-main-379.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
379,trino-server-379/lib/trino-main-379.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
379,trino-server-379/lib/trino-main-379.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
379,trino-server-379/lib/trino-main-379.jar,,failure-detector.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,retry-policy,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,internal-communication.https.truststore.key,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
379,trino-server-379/lib/trino-main-379.jar,,event.max-output-stage-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
379,trino-server-379/lib/trino-main-379.jar,,internal-communication.https.required,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.max-absolute-full-nodes-per-query,"",false
379,trino-server-379/lib/trino-main-379.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
379,trino-server-379/lib/trino-main-379.jar,,discovery-server.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.client.timeout,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.min-schedule-split-batch-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.https.enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.concurrent-request-multiplier,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
379,trino-server-379/lib/trino-main-379.jar,,catalog.disabled-catalogs,"",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-cpu-time,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.remote-task.min-error-duration,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.deduplication-buffer-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.min-expire-age,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.optimized-local-scheduling,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
379,trino-server-379/lib/trino-main-379.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
379,trino-server-379/lib/trino-main-379.jar,,task.info.max-age,"",false
379,trino-server-379/lib/trino-main-379.jar,,distributed-index-joins-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-stage-count,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.per-operator-cpu-timer-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,access-control.config-files,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
379,trino-server-379/lib/trino-main-379.jar,,jmx.base-name,"",false
379,trino-server-379/lib/trino-main-379.jar,,re2j.dfa-states-limit,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.share-index-loading,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-memory-per-node,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.max-partial-top-n-memory,"",false
379,trino-server-379/lib/trino-main-379.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
379,trino-server-379/lib/trino-main-379.jar,,query.info-url-template,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
379,trino-server-379/lib/trino-main-379.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.push-partial-aggregation-through-join,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.optimize-metadata-queries,"",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-memory,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
379,trino-server-379/lib/trino-main-379.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-length,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-history,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.jwt.principal-field,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.jwt.user-mapping.file,"",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.page-buffer-client.max-callback-threads,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.optimize-top-n-ranking,"",false
379,trino-server-379/lib/trino-main-379.jar,,network-cost-weight,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.max-partial-aggregation-memory,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
379,trino-server-379/lib/trino-main-379.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.service-thread-count,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.writer-count,"Number of writers per task",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.jwt.required-issuer,"",false
379,trino-server-379/lib/trino-main-379.jar,,iterative-optimizer-timeout,"",false
379,trino-server-379/lib/trino-main-379.jar,,compiler.expression-cache-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.use-mark-distinct,"",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,task-retry-attempts-overall,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-total-memory,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.include-coordinator,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.low-memory-killer.policy,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
379,trino-server-379/lib/trino-main-379.jar,,sql.default-catalog,"",false
379,trino-server-379/lib/trino-main-379.jar,,internal-communication.https.keystore.path,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.max-fraction-full-nodes-per-query,"",false
379,trino-server-379/lib/trino-main-379.jar,,http.authentication.krb5.config,"",false
379,trino-server-379/lib/trino-main-379.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
379,trino-server-379/lib/trino-main-379.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
379,trino-server-379/lib/trino-main-379.jar,,query.schedule-split-batch-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.max-worker-threads,"",false
379,trino-server-379/lib/trino-main-379.jar,,aggregation-operator-unspill-memory-limit,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.insecure.user-mapping.file,"",false
379,trino-server-379/lib/trino-main-379.jar,,join-distribution-type,"",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
379,trino-server-379/lib/trino-main-379.jar,,failure-detector.threshold,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
379,trino-server-379/lib/trino-main-379.jar,,spiller-spill-path,"",false
379,trino-server-379/lib/trino-main-379.jar,,sink.max-broadcast-buffer-size,"",false
379,trino-server-379/lib/trino-main-379.jar,,task.status-refresh-max-wait,"",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
379,trino-server-379/lib/trino-main-379.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
379,trino-server-379/lib/trino-main-379.jar,,web-ui.session-timeout,"",false
379,trino-server-379/lib/trino-main-379.jar,,node-scheduler.min-candidates,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.password.user-mapping.pattern,"",false
379,trino-server-379/lib/trino-main-379.jar,,cpu-cost-weight,"",false
379,trino-server-379/lib/trino-main-379.jar,,query.max-scan-physical-bytes,"",false
379,trino-server-379/lib/trino-main-379.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
379,trino-server-379/lib/trino-main-379.jar,,sql.default-schema,"",false
379,trino-server-379/lib/trino-main-379.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
379,trino-server-379/lib/trino-main-379.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
379,trino-server-379/lib/trino-main-379.jar,,catalog.config-dir,"",false
379,trino-server-379/lib/trino-main-379.jar,,pages-index.eager-compaction-enabled,"",false
379,trino-server-379/lib/trino-main-379.jar,,http-server.authentication.krb5.service-name,"",false
379,trino-server-379/lib/trino-main-379.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
379,trino-server-379/lib/trino-main-379.jar,,exchange.data-integrity-verification,"",false
379,trino-server-379/lib/trino-main-379.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
379,trino-server-379/lib/trino-main-379.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
379,trino-server-379/lib/trino-main-379.jar,,plugin.dir,"",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.url,"URL of the LDAP server",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,security.config-file,"",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,jmx.base-name,"",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,security.refresh-period,"",false
380,trino-server-380/plugin/kinesis/trino-plugin-toolkit-380.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
380,trino-server-380/plugin/kinesis/trino-kinesis-380.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
380,trino-server-380/plugin/clickhouse/trino-clickhouse-380.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
380,trino-server-380/plugin/clickhouse/trino-clickhouse-380.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,keystore-user-credential-password,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,keystore-password,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,join-pushdown.strategy,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,statistics.enabled,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,credential-provider.type,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,password-credential-name,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,user-credential-name,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,keystore-user-credential-name,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,keystore-password-credential-name,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,keystore-type,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,case-insensitive-name-matching,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,connection-url,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,connection-password,"Password for JDBC client",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,connection-user,"user name for JDBC client",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,keystore-file-path,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,keystore-password-credential-password,"",false
380,trino-server-380/plugin/clickhouse/trino-base-jdbc-380.jar,clickhouse,complex-expression-pushdown.enabled,"",false
380,trino-server-380/plugin/postgresql/trino-postgresql-380.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
380,trino-server-380/plugin/postgresql/trino-postgresql-380.jar,postgresql,postgresql.array-mapping,"",false
380,trino-server-380/plugin/postgresql/trino-postgresql-380.jar,postgresql,postgresql.include-system-tables,"",false
380,trino-server-380/plugin/atop/trino-atop-380.jar,atop,atop.concurrent-readers-per-node,"",false
380,trino-server-380/plugin/atop/trino-atop-380.jar,atop,atop.max-history-days,"",false
380,trino-server-380/plugin/atop/trino-atop-380.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
380,trino-server-380/plugin/atop/trino-atop-380.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
380,trino-server-380/plugin/atop/trino-atop-380.jar,atop,atop.executable-path,"",false
380,trino-server-380/plugin/atop/trino-atop-380.jar,atop,atop.security,"",false
380,trino-server-380/plugin/memory/trino-memory-380.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
380,trino-server-380/plugin/memory/trino-memory-380.jar,memory,memory.max-data-per-node,"",false
380,trino-server-380/plugin/memory/trino-memory-380.jar,memory,memory.splits-per-node,"",false
380,trino-server-380/plugin/accumulo/trino-accumulo-380.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
380,trino-server-380/plugin/accumulo/trino-accumulo-380.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
380,trino-server-380/plugin/accumulo/trino-accumulo-380.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
380,trino-server-380/plugin/accumulo/trino-accumulo-380.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
380,trino-server-380/plugin/accumulo/trino-accumulo-380.jar,accumulo,accumulo.instance,"Accumulo instance name",false
380,trino-server-380/plugin/accumulo/trino-accumulo-380.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
380,trino-server-380/plugin/accumulo/trino-accumulo-380.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.thread-pool-size,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.request-timeout,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.broker.authentication.type,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.idle-timeout,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.controller.authentication.user,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.max-rows-for-broker-queries,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.broker.authentication.password,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.controller.authentication.type,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.fetch-retry-count,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.forbid-segment-queries,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.max-backlog-per-server,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.connection-timeout,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.controller.authentication.password,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.segments-per-split,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.prefer-broker-queries,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.min-connections-per-server,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.metadata-expiry,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.max-connections-per-server,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.broker.authentication.user,"",false
380,trino-server-380/plugin/pinot/trino-pinot-380.jar,pinot,pinot.controller-urls,"",false
380,trino-server-380/plugin/resource-group-managers/trino-resource-group-managers-380.jar,resource-group-managers,resource-groups.config-db-url,"",false
380,trino-server-380/plugin/resource-group-managers/trino-resource-group-managers-380.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
380,trino-server-380/plugin/resource-group-managers/trino-resource-group-managers-380.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
380,trino-server-380/plugin/resource-group-managers/trino-resource-group-managers-380.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
380,trino-server-380/plugin/resource-group-managers/trino-resource-group-managers-380.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
380,trino-server-380/plugin/resource-group-managers/trino-resource-group-managers-380.jar,resource-group-managers,jmx.base-name,"",false
380,trino-server-380/plugin/resource-group-managers/trino-resource-group-managers-380.jar,resource-group-managers,resource-groups.config-file,"",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.default-schema,"The schema name to use in the connector",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
380,trino-server-380/plugin/redis/trino-redis-380.jar,redis,redis.password,"Password for a password-protected Redis server",false
380,trino-server-380/plugin/example-http/trino-example-http-380.jar,example-http,metadata-uri,"",false
380,trino-server-380/plugin/local-file/trino-local-file-380.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
380,trino-server-380/plugin/local-file/trino-local-file-380.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
380,trino-server-380/plugin/jmx/trino-jmx-380.jar,jmx,jmx.dump-period,"",false
380,trino-server-380/plugin/jmx/trino-jmx-380.jar,jmx,jmx.max-entries,"",false
380,trino-server-380/plugin/jmx/trino-jmx-380.jar,jmx,jmx.dump-tables,"",false
380,trino-server-380/plugin/phoenix/trino-phoenix-380.jar,phoenix,phoenix.config.resources,"",false
380,trino-server-380/plugin/phoenix/trino-phoenix-380.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
380,trino-server-380/plugin/phoenix/trino-phoenix-380.jar,phoenix,phoenix.connection-url,"",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.connection-pool.enabled,"",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.connection-pool.min-size,"",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.number.rounding-mode,"",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.connection-pool.max-size,"",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.synonyms.enabled,"",false
380,trino-server-380/plugin/oracle/trino-oracle-380.jar,oracle,oracle.remarks-reporting.enabled,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.replay-metastore-recording,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.auto-purge,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.read-mode,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs.domain-socket-path,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.adl-refresh-url,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.storage-format,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.proxy.host,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.security,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.aws-secret-key,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.location,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.compression-codec,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.writer-identification,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3-file-system-type,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.file-status-cache-tables,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs.verify-checksum,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.abfs-access-key,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.adl-client-id,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hdfs.socks-proxy,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.signer-type,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.max-buffer-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.split-loader-concurrency,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.proxy.protocol,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.config.resources,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.streaming.enabled,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.proxy.username,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.ignore-absent-partitions,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-concurrent-file-renames,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.writer-sort-buffer-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.max-backoff-time,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.adl-proxy-host,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.stream-buffer-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.sts.region,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.force-local-scheduling,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs.connect.timeout,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.adl-credential,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.version-compatibility,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.max-merge-distance,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.max-merge-distance,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.abfs-storage-account,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs-timeout,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.connect-timeout,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore-recording-duration,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.max-read-block-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.file-status-cache-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.bookkeeper-port,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.writer.block-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore-timeout,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-split-iterator-threads,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.data-transfer-port,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.signer-class,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.wasb-storage-account,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-register-partition-procedure,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.proxy.password,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.max-retry-time,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs.connect.max-retries,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.endpoint,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.recursive-directories,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.aws-access-key,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.file-status-cache-expire-time,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.max-error-retries,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.wasb-access-key,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-initial-split-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.writer.page-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore-refresh-interval,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore-recording-path,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.sts.endpoint,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.proxy.port,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.ssl.enabled,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.max-read-block-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-initial-splits,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore-cache-ttl,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.max-client-retries,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.max-split-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.socket-timeout,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.max-buffer-size,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.s3.max-connections,"",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
380,trino-server-380/plugin/delta-lake/trino-hive-380.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.max-initial-split-size,"",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.max-split-size,"",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
380,trino-server-380/plugin/delta-lake/trino-delta-lake-380.jar,delta-lake,delta.max-initial-splits,"",false
380,trino-server-380/plugin/session-property-managers/trino-session-property-managers-380.jar,session-property-managers,session-property-manager.db.password,"",false
380,trino-server-380/plugin/session-property-managers/trino-session-property-managers-380.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
380,trino-server-380/plugin/session-property-managers/trino-session-property-managers-380.jar,session-property-managers,session-property-manager.config-file,"",false
380,trino-server-380/plugin/session-property-managers/trino-session-property-managers-380.jar,session-property-managers,session-property-manager.db.url,"",false
380,trino-server-380/plugin/session-property-managers/trino-session-property-managers-380.jar,session-property-managers,session-property-manager.db.username,"",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.view-expire-duration,"",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
380,trino-server-380/plugin/bigquery/trino-bigquery-380.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.socket-timeout,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.schema-collection,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.connection-url,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.max-connection-idle-time,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.credentials,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.connections-per-host,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.write-concern,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.connection-timeout,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.seeds,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.required-replica-set,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.max-wait-time,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.cursor-batch-size,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.ssl.enabled,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.min-connections-per-host,"",false
380,trino-server-380/plugin/mongodb/trino-mongodb-380.jar,mongodb,mongodb.read-preference,"",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.file-format,"",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.delete_orphan_files.min-retention,"Minimal retention period for delete_orphan_files procedure",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.compression-codec,"",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.security,"",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.catalog.type,"",false
380,trino-server-380/plugin/iceberg/trino-iceberg-380.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
380,trino-server-380/plugin/phoenix5/trino-phoenix5-380.jar,phoenix5,phoenix.config.resources,"",false
380,trino-server-380/plugin/phoenix5/trino-phoenix5-380.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
380,trino-server-380/plugin/phoenix5/trino-phoenix5-380.jar,phoenix5,phoenix.connection-url,"",false
380,trino-server-380/plugin/thrift/trino-thrift-380.jar,thrift,trino-thrift.max-response-size,"",false
380,trino-server-380/plugin/thrift/trino-thrift-380.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
380,trino-server-380/plugin/thrift/trino-thrift-380.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,metadata.db.url,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.orc.nested-lazy,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.organization-enabled,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.balancer-enabled,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.orc.max-read-size,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,raptor.security,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.compaction-enabled,"",false
380,trino-server-380/plugin/raptor-legacy/trino-raptor-legacy-380.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
380,trino-server-380/plugin/google-sheets/trino-google-sheets-380.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
380,trino-server-380/plugin/google-sheets/trino-google-sheets-380.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
380,trino-server-380/plugin/google-sheets/trino-google-sheets-380.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
380,trino-server-380/plugin/google-sheets/trino-google-sheets-380.jar,google-sheets,credentials-path,"Credential file path to google service account",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.config.resources,"Optional config files",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
380,trino-server-380/plugin/kafka/trino-kafka-380.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.retry-policy,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.client.connect-timeout,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.tls.enabled,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.fetch-size,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.client.read-timeout,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.protocol-version,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.tls.keystore-password,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.consistency-level,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.tls.truststore-password,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.native-protocol-port,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.batch-size,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.tls.keystore-path,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.split-size,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.speculative-execution.delay,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.speculative-execution.limit,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.contact-points,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.password,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.username,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.splits-per-node,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.tls.truststore-path,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
380,trino-server-380/plugin/cassandra/trino-cassandra-380.jar,cassandra,cassandra.client.so-linger,"",false
380,trino-server-380/plugin/mysql/trino-mysql-380.jar,mysql,mysql.max-reconnects,"",false
380,trino-server-380/plugin/mysql/trino-mysql-380.jar,mysql,mysql.auto-reconnect,"",false
380,trino-server-380/plugin/mysql/trino-mysql-380.jar,mysql,mysql.connection-timeout,"",false
380,trino-server-380/plugin/mysql/trino-mysql-380.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
380,trino-server-380/plugin/sqlserver/trino-sqlserver-380.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
380,trino-server-380/plugin/sqlserver/trino-sqlserver-380.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
380,trino-server-380/plugin/sqlserver/trino-sqlserver-380.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
380,trino-server-380/plugin/http-event-listener/trino-http-event-listener-380.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.client.disable-statistics,"",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.schema-emulation.enabled,"",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.client.master-addresses,"",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.schema-emulation.prefix,"",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.client.default-operation-timeout,"",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
380,trino-server-380/plugin/kudu/trino-kudu-380.jar,kudu,kudu.grouped-execution.enabled,"",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,ldap.cache-ttl,"",false
380,trino-server-380/plugin/password-authenticators/trino-password-authenticators-380.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
380,trino-server-380/plugin/prometheus/trino-prometheus-380.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
380,trino-server-380/plugin/prometheus/trino-prometheus-380.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
380,trino-server-380/plugin/prometheus/trino-prometheus-380.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
380,trino-server-380/plugin/prometheus/trino-prometheus-380.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
380,trino-server-380/plugin/prometheus/trino-prometheus-380.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
380,trino-server-380/plugin/prometheus/trino-prometheus-380.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.region,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.storage-class,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.endpoint,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.use-web-identity-token-credentials,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.encryption-enabled,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
380,trino-server-380/plugin/exchange-filesystem/trino-exchange-filesystem-380.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.port,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.security,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.tls.enabled,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.auth.user,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.auth.password,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.aws.region,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.host,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.aws.access-key,"",false
380,trino-server-380/plugin/elasticsearch/trino-elasticsearch-380.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
380,trino-server-380/plugin/singlestore/trino-singlestore-380.jar,singlestore,singlestore.connection-timeout,"",false
380,trino-server-380/plugin/singlestore/trino-singlestore-380.jar,singlestore,singlestore.auto-reconnect,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.optimized-local-scheduling,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.default-filter-factor-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.push-table-write-through-union,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.network-topology.type,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.insecure.user-mapping.file,"",false
380,trino-server-380/lib/trino-main-380.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
380,trino-server-380/lib/trino-main-380.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
380,trino-server-380/lib/trino-main-380.jar,,catalog.config-dir,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.manager-executor-pool-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,statistics-precalculation-for-pushdown.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,jmx.base-name,"",false
380,trino-server-380/lib/trino-main-380.jar,,web-ui.user,"",false
380,trino-server-380/lib/trino-main-380.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
380,trino-server-380/lib/trino-main-380.jar,,sql.default-catalog,"",false
380,trino-server-380/lib/trino-main-380.jar,,task-retry-attempts-per-task,"",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,internal-communication.https.truststore.key,"",false
380,trino-server-380/lib/trino-main-380.jar,,distributed-sort,"",false
380,trino-server-380/lib/trino-main-380.jar,,experimental.late-materialization.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
380,trino-server-380/lib/trino-main-380.jar,,web-ui.shared-secret,"",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
380,trino-server-380/lib/trino-main-380.jar,,failure-detector.threshold,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-stage-count,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-planning-time,"",false
380,trino-server-380/lib/trino-main-380.jar,,sink.max-broadcast-buffer-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.cpu-timer-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.password.user-mapping.pattern,"",false
380,trino-server-380/lib/trino-main-380.jar,,warning-collector.max-warnings,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
380,trino-server-380/lib/trino-main-380.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
380,trino-server-380/lib/trino-main-380.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
380,trino-server-380/lib/trino-main-380.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
380,trino-server-380/lib/trino-main-380.jar,,re2j.dfa-retries,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.acknowledge-pages,"",false
380,trino-server-380/lib/trino-main-380.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.krb5.service-name,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.merge-project-with-values,"",false
380,trino-server-380/lib/trino-main-380.jar,,pages-index.eager-compaction-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
380,trino-server-380/lib/trino-main-380.jar,,internal-communication.shared-secret,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.remote-task.min-error-duration,"",false
380,trino-server-380/lib/trino-main-380.jar,,query-max-spill-per-node,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
380,trino-server-380/lib/trino-main-380.jar,,query.remote-task.max-callback-threads,"",false
380,trino-server-380/lib/trino-main-380.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.max-partial-top-n-memory,"",false
380,trino-server-380/lib/trino-main-380.jar,,web-ui.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,join-distribution-type,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.max-partial-aggregation-memory,"",false
380,trino-server-380/lib/trino-main-380.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.service-thread-count,"",false
380,trino-server-380/lib/trino-main-380.jar,,http.include-exception-in-response,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
380,trino-server-380/lib/trino-main-380.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.password.user-mapping.file,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.max-splits-per-node,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
380,trino-server-380/lib/trino-main-380.jar,,internal-communication.https.required,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.info.max-age,"",false
380,trino-server-380/lib/trino-main-380.jar,,failure-detector.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.max-buffer-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.min-drivers,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.http-timeout-threads,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.concurrent-request-multiplier,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
380,trino-server-380/lib/trino-main-380.jar,,enable-forced-exchange-below-group-id,"",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
380,trino-server-380/lib/trino-main-380.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
380,trino-server-380/lib/trino-main-380.jar,,query.client.timeout,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
380,trino-server-380/lib/trino-main-380.jar,,http.authentication.krb5.config,"",false
380,trino-server-380/lib/trino-main-380.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
380,trino-server-380/lib/trino-main-380.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.optimize-hash-generation,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.https.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.page-buffer-client.max-callback-threads,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.network-topology.refresh-period,"",false
380,trino-server-380/lib/trino-main-380.jar,,spiller-spill-path,"",false
380,trino-server-380/lib/trino-main-380.jar,,re2j.dfa-states-limit,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.use-mark-distinct,"",false
380,trino-server-380/lib/trino-main-380.jar,,regex-library,"",false
380,trino-server-380/lib/trino-main-380.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.ignore-downstream-preferences,"",false
380,trino-server-380/lib/trino-main-380.jar,,compiler.expression-cache-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.push-partial-aggregation-through-join,"",false
380,trino-server-380/lib/trino-main-380.jar,,aggregation-operator-unspill-memory-limit,"",false
380,trino-server-380/lib/trino-main-380.jar,,max-spill-per-node,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.execution-policy,"",false
380,trino-server-380/lib/trino-main-380.jar,,spill-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.min-candidates,"",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.krb5.user-mapping.file,"",false
380,trino-server-380/lib/trino-main-380.jar,,internal-communication.https.keystore.path,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
380,trino-server-380/lib/trino-main-380.jar,,scale-writers,"",false
380,trino-server-380/lib/trino-main-380.jar,,event-listener.config-files,"",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
380,trino-server-380/lib/trino-main-380.jar,,iterative-optimizer-timeout,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.jwt.required-audience,"",false
380,trino-server-380/lib/trino-main-380.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.krb5.keytab,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.status-refresh-max-wait,"",false
380,trino-server-380/lib/trino-main-380.jar,,cpu-cost-weight,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.max-pending-splits-per-task,"",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
380,trino-server-380/lib/trino-main-380.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-history,"",false
380,trino-server-380/lib/trino-main-380.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
380,trino-server-380/lib/trino-main-380.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
380,trino-server-380/lib/trino-main-380.jar,,catalog.disabled-catalogs,"",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
380,trino-server-380/lib/trino-main-380.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
380,trino-server-380/lib/trino-main-380.jar,,parse-decimal-literals-as-double,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.max-worker-threads,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.allocator-type,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.split-concurrency-adjustment-interval,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.jwt.principal-field,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
380,trino-server-380/lib/trino-main-380.jar,,task.max-local-exchange-buffer-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
380,trino-server-380/lib/trino-main-380.jar,,spill-compression-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
380,trino-server-380/lib/trino-main-380.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
380,trino-server-380/lib/trino-main-380.jar,,enable-dynamic-filtering,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.network-topology.file,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-length,"",false
380,trino-server-380/lib/trino-main-380.jar,,network-cost-weight,"",false
380,trino-server-380/lib/trino-main-380.jar,,deprecated.legacy-row-to-json-cast,"",false
380,trino-server-380/lib/trino-main-380.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
380,trino-server-380/lib/trino-main-380.jar,,use-preferred-write-partitioning,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-queued-queries,"",false
380,trino-server-380/lib/trino-main-380.jar,,spiller-threads,"",false
380,trino-server-380/lib/trino-main-380.jar,,adaptive-partial-aggregation.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
380,trino-server-380/lib/trino-main-380.jar,,spill-encryption-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,sql.default-schema,"",false
380,trino-server-380/lib/trino-main-380.jar,,web-ui.session-timeout,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
380,trino-server-380/lib/trino-main-380.jar,,access-control.config-files,"",false
380,trino-server-380/lib/trino-main-380.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-scan-physical-bytes,"",false
380,trino-server-380/lib/trino-main-380.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
380,trino-server-380/lib/trino-main-380.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-memory-per-node,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.krb5.name-type,"",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
380,trino-server-380/lib/trino-main-380.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.include-coordinator,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.jwt.key-file,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.krb5.principal-hostname,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.dictionary-aggregation,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.max-response-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.low-memory-killer.policy,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.data-integrity-verification,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.schedule-split-batch-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
380,trino-server-380/lib/trino-main-380.jar,,internal-communication.https.keystore.key,"",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
380,trino-server-380/lib/trino-main-380.jar,,analyzer.max-grouping-sets,"",false
380,trino-server-380/lib/trino-main-380.jar,,query-retry-attempts,"",false
380,trino-server-380/lib/trino-main-380.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
380,trino-server-380/lib/trino-main-380.jar,,task.client.timeout,"",false
380,trino-server-380/lib/trino-main-380.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
380,trino-server-380/lib/trino-main-380.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.policy,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.initial-splits-per-node,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.push-aggregation-through-outer-join,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-total-memory,"",false
380,trino-server-380/lib/trino-main-380.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
380,trino-server-380/lib/trino-main-380.jar,,distributed-index-joins-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,discovery-server.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.deduplication-buffer-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.max-error-duration,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.info-url-template,"",false
380,trino-server-380/lib/trino-main-380.jar,,sink.max-buffer-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
380,trino-server-380/lib/trino-main-380.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
380,trino-server-380/lib/trino-main-380.jar,,task-retry-attempts-overall,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.certificate.user-mapping.file,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
380,trino-server-380/lib/trino-main-380.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-concurrent-queries,"",false
380,trino-server-380/lib/trino-main-380.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.complex-expression-pushdown.enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.jwt.required-issuer,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
380,trino-server-380/lib/trino-main-380.jar,,task.per-operator-cpu-timer-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,spiller-max-used-space-threshold,"",false
380,trino-server-380/lib/trino-main-380.jar,,query-results.compression-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-cpu-time,"",false
380,trino-server-380/lib/trino-main-380.jar,,driver.max-page-partitioning-buffer-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.client-threads,"",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.prefer-partial-aggregation,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.info-update-interval,"Interval between updating task data",false
380,trino-server-380/lib/trino-main-380.jar,,filter-and-project-min-output-page-row-count,"",false
380,trino-server-380/lib/trino-main-380.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
380,trino-server-380/lib/trino-main-380.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
380,trino-server-380/lib/trino-main-380.jar,,task.statistics-cpu-timer-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,internal-communication.https.truststore.path,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.optimize-top-n-ranking,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.share-index-loading,"",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
380,trino-server-380/lib/trino-main-380.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
380,trino-server-380/lib/trino-main-380.jar,,memory-cost-weight,"",false
380,trino-server-380/lib/trino-main-380.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
380,trino-server-380/lib/trino-main-380.jar,,query.min-schedule-split-batch-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.jwt.user-mapping.file,"",false
380,trino-server-380/lib/trino-main-380.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
380,trino-server-380/lib/trino-main-380.jar,,event.max-output-stage-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
380,trino-server-380/lib/trino-main-380.jar,,query.remote-task.max-error-duration,"",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.min-error-duration,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
380,trino-server-380/lib/trino-main-380.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
380,trino-server-380/lib/trino-main-380.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
380,trino-server-380/lib/trino-main-380.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
380,trino-server-380/lib/trino-main-380.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
380,trino-server-380/lib/trino-main-380.jar,,shutdown.grace-period,"",false
380,trino-server-380/lib/trino-main-380.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
380,trino-server-380/lib/trino-main-380.jar,,task.http-response-threads,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
380,trino-server-380/lib/trino-main-380.jar,,redistribute-writes,"",false
380,trino-server-380/lib/trino-main-380.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.optimize-metadata-queries,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.skip-redundant-sort,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-run-time,"",false
380,trino-server-380/lib/trino-main-380.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
380,trino-server-380/lib/trino-main-380.jar,,exchange.compression-enabled,"",false
380,trino-server-380/lib/trino-main-380.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-execution-time,"",false
380,trino-server-380/lib/trino-main-380.jar,,enable-stats-calculator,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.min-expire-age,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
380,trino-server-380/lib/trino-main-380.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
380,trino-server-380/lib/trino-main-380.jar,,task.writer-count,"Number of writers per task",false
380,trino-server-380/lib/trino-main-380.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
380,trino-server-380/lib/trino-main-380.jar,,failure-detector.heartbeat-interval,"",false
380,trino-server-380/lib/trino-main-380.jar,,plugin.dir,"",false
380,trino-server-380/lib/trino-main-380.jar,,query.max-memory,"",false
380,trino-server-380/lib/trino-main-380.jar,,retry-policy,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.force-single-node-output,"",false
380,trino-server-380/lib/trino-main-380.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
380,trino-server-380/lib/trino-main-380.jar,,task.max-index-memory,"",false
380,trino-server-380/lib/trino-main-380.jar,,enable-large-dynamic-filters,"",false
380,trino-server-380/lib/trino-main-380.jar,,filter-and-project-min-output-page-size,"",false
380,trino-server-380/lib/trino-main-380.jar,,optimizer.enable-intermediate-aggregations,"",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.url,"URL of the LDAP server",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,security.refresh-period,"",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,jmx.base-name,"",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,security.config-file,"",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
381,trino-server-381/plugin/kinesis/trino-plugin-toolkit-381.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
381,trino-server-381/plugin/kinesis/trino-kinesis-381.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
381,trino-server-381/plugin/clickhouse/trino-clickhouse-381.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
381,trino-server-381/plugin/clickhouse/trino-clickhouse-381.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,keystore-user-credential-password,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,complex-expression-pushdown.enabled,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,keystore-password-credential-password,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,keystore-file-path,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,connection-user,"user name for JDBC client",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,connection-password,"Password for JDBC client",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,connection-url,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,case-insensitive-name-matching,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,keystore-type,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,keystore-password-credential-name,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,keystore-user-credential-name,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,user-credential-name,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,password-credential-name,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,credential-provider.type,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,statistics.enabled,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,join-pushdown.strategy,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,keystore-password,"",false
381,trino-server-381/plugin/clickhouse/trino-base-jdbc-381.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
381,trino-server-381/plugin/postgresql/trino-postgresql-381.jar,postgresql,postgresql.include-system-tables,"",false
381,trino-server-381/plugin/postgresql/trino-postgresql-381.jar,postgresql,postgresql.array-mapping,"",false
381,trino-server-381/plugin/postgresql/trino-postgresql-381.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
381,trino-server-381/plugin/atop/trino-atop-381.jar,atop,atop.security,"",false
381,trino-server-381/plugin/atop/trino-atop-381.jar,atop,atop.executable-path,"",false
381,trino-server-381/plugin/atop/trino-atop-381.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
381,trino-server-381/plugin/atop/trino-atop-381.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
381,trino-server-381/plugin/atop/trino-atop-381.jar,atop,atop.max-history-days,"",false
381,trino-server-381/plugin/atop/trino-atop-381.jar,atop,atop.concurrent-readers-per-node,"",false
381,trino-server-381/plugin/memory/trino-memory-381.jar,memory,memory.splits-per-node,"",false
381,trino-server-381/plugin/memory/trino-memory-381.jar,memory,memory.max-data-per-node,"",false
381,trino-server-381/plugin/memory/trino-memory-381.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
381,trino-server-381/plugin/accumulo/trino-accumulo-381.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
381,trino-server-381/plugin/accumulo/trino-accumulo-381.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
381,trino-server-381/plugin/accumulo/trino-accumulo-381.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
381,trino-server-381/plugin/accumulo/trino-accumulo-381.jar,accumulo,accumulo.instance,"Accumulo instance name",false
381,trino-server-381/plugin/accumulo/trino-accumulo-381.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
381,trino-server-381/plugin/accumulo/trino-accumulo-381.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
381,trino-server-381/plugin/accumulo/trino-accumulo-381.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.idle-timeout,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.broker.authentication.type,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.request-timeout,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.thread-pool-size,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.controller-urls,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.broker.authentication.user,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.max-connections-per-server,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.metadata-expiry,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.min-connections-per-server,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.prefer-broker-queries,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.segments-per-split,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.controller.authentication.password,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.connection-timeout,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.max-backlog-per-server,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.forbid-segment-queries,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.fetch-retry-count,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.controller.authentication.type,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.broker.authentication.password,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.max-rows-for-broker-queries,"",false
381,trino-server-381/plugin/pinot/trino-pinot-381.jar,pinot,pinot.controller.authentication.user,"",false
381,trino-server-381/plugin/resource-group-managers/trino-resource-group-managers-381.jar,resource-group-managers,resource-groups.config-file,"",false
381,trino-server-381/plugin/resource-group-managers/trino-resource-group-managers-381.jar,resource-group-managers,jmx.base-name,"",false
381,trino-server-381/plugin/resource-group-managers/trino-resource-group-managers-381.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
381,trino-server-381/plugin/resource-group-managers/trino-resource-group-managers-381.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
381,trino-server-381/plugin/resource-group-managers/trino-resource-group-managers-381.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
381,trino-server-381/plugin/resource-group-managers/trino-resource-group-managers-381.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
381,trino-server-381/plugin/resource-group-managers/trino-resource-group-managers-381.jar,resource-group-managers,resource-groups.config-db-url,"",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.user,"Username for a Redis server",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.password,"Password for a password-protected Redis server",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.default-schema,"The schema name to use in the connector",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
381,trino-server-381/plugin/redis/trino-redis-381.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
381,trino-server-381/plugin/example-http/trino-example-http-381.jar,example-http,metadata-uri,"",false
381,trino-server-381/plugin/local-file/trino-local-file-381.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
381,trino-server-381/plugin/local-file/trino-local-file-381.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
381,trino-server-381/plugin/jmx/trino-jmx-381.jar,jmx,jmx.dump-tables,"",false
381,trino-server-381/plugin/jmx/trino-jmx-381.jar,jmx,jmx.max-entries,"",false
381,trino-server-381/plugin/jmx/trino-jmx-381.jar,jmx,jmx.dump-period,"",false
381,trino-server-381/plugin/phoenix/trino-phoenix-381.jar,phoenix,phoenix.connection-url,"",false
381,trino-server-381/plugin/phoenix/trino-phoenix-381.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
381,trino-server-381/plugin/phoenix/trino-phoenix-381.jar,phoenix,phoenix.config.resources,"",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.remarks-reporting.enabled,"",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.synonyms.enabled,"",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.connection-pool.max-size,"",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.number.rounding-mode,"",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.connection-pool.min-size,"",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
381,trino-server-381/plugin/oracle/trino-oracle-381.jar,oracle,oracle.connection-pool.enabled,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.split-loader-concurrency,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.max-buffer-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.signer-type,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hdfs.socks-proxy,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.adl-client-id,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.abfs-access-key,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs.verify-checksum,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.file-status-cache-tables,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3-file-system-type,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.writer-identification,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.compression-codec,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.location,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.aws-secret-key,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.security,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.proxy.host,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.storage-format,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.adl-refresh-url,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs.domain-socket-path,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.read-mode,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.auto-purge,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.replay-metastore-recording,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.max-connections,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.max-buffer-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.socket-timeout,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-split-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.max-client-retries,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore-cache-ttl,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-initial-splits,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.max-read-block-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.ssl.enabled,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.proxy.port,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.sts.endpoint,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore-recording-path,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore-refresh-interval,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.writer.page-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-initial-split-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.wasb-access-key,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.max-error-retries,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.file-status-cache-expire-time,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.aws-access-key,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.recursive-directories,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.endpoint,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs.connect.max-retries,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.max-retry-time,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.proxy.password,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-register-partition-procedure,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.wasb-storage-account,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.signer-class,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.data-transfer-port,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-split-iterator-threads,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore-timeout,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.writer.block-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.cache.bookkeeper-port,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.file-status-cache-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.max-read-block-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore-recording-duration,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.connect-timeout,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs-timeout,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.abfs-storage-account,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.max-merge-distance,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.max-merge-distance,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.version-compatibility,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.adl-credential,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs.connect.timeout,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.force-local-scheduling,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.sts.region,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.stream-buffer-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.adl-proxy-host,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.max-backoff-time,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.writer-sort-buffer-size,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-concurrent-file-renames,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.ignore-absent-partitions,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.proxy.username,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.streaming.enabled,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.config.resources,"",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
381,trino-server-381/plugin/delta-lake/trino-hive-381.jar,delta-lake,hive.s3.proxy.protocol,"",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.max-initial-splits,"",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.max-split-size,"",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.max-initial-split-size,"",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
381,trino-server-381/plugin/delta-lake/trino-delta-lake-381.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
381,trino-server-381/plugin/session-property-managers/trino-session-property-managers-381.jar,session-property-managers,session-property-manager.db.username,"",false
381,trino-server-381/plugin/session-property-managers/trino-session-property-managers-381.jar,session-property-managers,session-property-manager.db.url,"",false
381,trino-server-381/plugin/session-property-managers/trino-session-property-managers-381.jar,session-property-managers,session-property-manager.config-file,"",false
381,trino-server-381/plugin/session-property-managers/trino-session-property-managers-381.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
381,trino-server-381/plugin/session-property-managers/trino-session-property-managers-381.jar,session-property-managers,session-property-manager.db.password,"",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.view-expire-duration,"",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
381,trino-server-381/plugin/bigquery/trino-bigquery-381.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.schema-collection,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.socket-timeout,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.read-preference,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.min-connections-per-host,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.ssl.enabled,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.cursor-batch-size,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.max-wait-time,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.required-replica-set,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.seeds,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.connection-timeout,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.write-concern,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.connections-per-host,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.credentials,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.max-connection-idle-time,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.connection-url,"",false
381,trino-server-381/plugin/mongodb/trino-mongodb-381.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.catalog.type,"",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.security,"",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.compression-codec,"",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.delete_orphan_files.min-retention,"Minimal retention period for delete_orphan_files procedure",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
381,trino-server-381/plugin/iceberg/trino-iceberg-381.jar,iceberg,iceberg.file-format,"",false
381,trino-server-381/plugin/phoenix5/trino-phoenix5-381.jar,phoenix5,phoenix.connection-url,"",false
381,trino-server-381/plugin/phoenix5/trino-phoenix5-381.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
381,trino-server-381/plugin/phoenix5/trino-phoenix5-381.jar,phoenix5,phoenix.config.resources,"",false
381,trino-server-381/plugin/thrift/trino-thrift-381.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
381,trino-server-381/plugin/thrift/trino-thrift-381.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
381,trino-server-381/plugin/thrift/trino-thrift-381.jar,thrift,trino-thrift.max-response-size,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.orc.nested-lazy,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,metadata.db.url,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.compaction-enabled,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.security,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.orc.max-read-size,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.balancer-enabled,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.organization-enabled,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
381,trino-server-381/plugin/raptor-legacy/trino-raptor-legacy-381.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
381,trino-server-381/plugin/google-sheets/trino-google-sheets-381.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
381,trino-server-381/plugin/google-sheets/trino-google-sheets-381.jar,google-sheets,credentials-path,"Credential file path to google service account",false
381,trino-server-381/plugin/google-sheets/trino-google-sheets-381.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
381,trino-server-381/plugin/google-sheets/trino-google-sheets-381.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.config.resources,"Optional config files",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
381,trino-server-381/plugin/kafka/trino-kafka-381.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.client.connect-timeout,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.retry-policy,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.client.so-linger,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.tls.truststore-path,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.splits-per-node,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.username,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.password,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.contact-points,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.speculative-execution.limit,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.speculative-execution.delay,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.split-size,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.tls.keystore-path,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.batch-size,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.native-protocol-port,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.tls.truststore-password,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.consistency-level,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.tls.keystore-password,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.protocol-version,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.client.read-timeout,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.fetch-size,"",false
381,trino-server-381/plugin/cassandra/trino-cassandra-381.jar,cassandra,cassandra.tls.enabled,"",false
381,trino-server-381/plugin/mysql/trino-mysql-381.jar,mysql,mysql.max-reconnects,"",false
381,trino-server-381/plugin/mysql/trino-mysql-381.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
381,trino-server-381/plugin/mysql/trino-mysql-381.jar,mysql,mysql.connection-timeout,"",false
381,trino-server-381/plugin/mysql/trino-mysql-381.jar,mysql,mysql.auto-reconnect,"",false
381,trino-server-381/plugin/sqlserver/trino-sqlserver-381.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
381,trino-server-381/plugin/sqlserver/trino-sqlserver-381.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
381,trino-server-381/plugin/sqlserver/trino-sqlserver-381.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
381,trino-server-381/plugin/http-event-listener/trino-http-event-listener-381.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.client.disable-statistics,"",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.grouped-execution.enabled,"",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.client.default-operation-timeout,"",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.schema-emulation.prefix,"",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.client.master-addresses,"",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.schema-emulation.enabled,"",false
381,trino-server-381/plugin/kudu/trino-kudu-381.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,ldap.cache-ttl,"",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
381,trino-server-381/plugin/password-authenticators/trino-password-authenticators-381.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
381,trino-server-381/plugin/prometheus/trino-prometheus-381.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
381,trino-server-381/plugin/prometheus/trino-prometheus-381.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
381,trino-server-381/plugin/prometheus/trino-prometheus-381.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
381,trino-server-381/plugin/prometheus/trino-prometheus-381.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
381,trino-server-381/plugin/prometheus/trino-prometheus-381.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
381,trino-server-381/plugin/prometheus/trino-prometheus-381.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.encryption-enabled,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.azure.connection-string,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.storage-class,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.endpoint,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.use-web-identity-token-credentials,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.region,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
381,trino-server-381/plugin/exchange-filesystem/trino-exchange-filesystem-381.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.security,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.port,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.aws.access-key,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.host,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.aws.region,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.auth.password,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.auth.user,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.tls.enabled,"",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
381,trino-server-381/plugin/elasticsearch/trino-elasticsearch-381.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
381,trino-server-381/plugin/singlestore/trino-singlestore-381.jar,singlestore,singlestore.auto-reconnect,"",false
381,trino-server-381/plugin/singlestore/trino-singlestore-381.jar,singlestore,singlestore.connection-timeout,"",false
381,trino-server-381/lib/trino-main-381.jar,,enable-forced-exchange-below-group-id,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.info-url-template,"",false
381,trino-server-381/lib/trino-main-381.jar,,use-preferred-write-partitioning,"",false
381,trino-server-381/lib/trino-main-381.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.prefer-partial-aggregation,"",false
381,trino-server-381/lib/trino-main-381.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.jwt.required-audience,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
381,trino-server-381/lib/trino-main-381.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-execution-time,"",false
381,trino-server-381/lib/trino-main-381.jar,,spiller-max-used-space-threshold,"",false
381,trino-server-381/lib/trino-main-381.jar,,sql.default-schema,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.client-threads,"",false
381,trino-server-381/lib/trino-main-381.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
381,trino-server-381/lib/trino-main-381.jar,,query.client.timeout,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.low-memory-killer.policy,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-length,"",false
381,trino-server-381/lib/trino-main-381.jar,,max-spill-per-node,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.min-candidates,"",false
381,trino-server-381/lib/trino-main-381.jar,,deprecated.legacy-row-to-json-cast,"",false
381,trino-server-381/lib/trino-main-381.jar,,catalog.disabled-catalogs,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.include-coordinator,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.max-worker-threads,"",false
381,trino-server-381/lib/trino-main-381.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
381,trino-server-381/lib/trino-main-381.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.krb5.service-name,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
381,trino-server-381/lib/trino-main-381.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
381,trino-server-381/lib/trino-main-381.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.push-partial-aggregation-through-join,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
381,trino-server-381/lib/trino-main-381.jar,,web-ui.user,"",false
381,trino-server-381/lib/trino-main-381.jar,,join-distribution-type,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.max-local-exchange-buffer-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.password.user-mapping.file,"",false
381,trino-server-381/lib/trino-main-381.jar,,enable-stats-calculator,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
381,trino-server-381/lib/trino-main-381.jar,,parse-decimal-literals-as-double,"",false
381,trino-server-381/lib/trino-main-381.jar,,web-ui.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,http.include-exception-in-response,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
381,trino-server-381/lib/trino-main-381.jar,,catalog.config-dir,"",false
381,trino-server-381/lib/trino-main-381.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.max-splits-per-node,"",false
381,trino-server-381/lib/trino-main-381.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
381,trino-server-381/lib/trino-main-381.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,spill-encryption-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.skip-redundant-sort,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-planning-time,"",false
381,trino-server-381/lib/trino-main-381.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
381,trino-server-381/lib/trino-main-381.jar,,task.split-concurrency-adjustment-interval,"",false
381,trino-server-381/lib/trino-main-381.jar,,spiller-threads,"",false
381,trino-server-381/lib/trino-main-381.jar,,spill-compression-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.concurrent-request-multiplier,"",false
381,trino-server-381/lib/trino-main-381.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
381,trino-server-381/lib/trino-main-381.jar,,statistics-precalculation-for-pushdown.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.dictionary-aggregation,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.cpu-timer-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,failure-detector.threshold,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-memory-per-node,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.max-response-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
381,trino-server-381/lib/trino-main-381.jar,,cpu-cost-weight,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.min-schedule-split-batch-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-total-memory,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.jwt.required-issuer,"",false
381,trino-server-381/lib/trino-main-381.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
381,trino-server-381/lib/trino-main-381.jar,,enable-large-dynamic-filters,"",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.max-error-duration,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.share-index-loading,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.deduplication-buffer-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,shutdown.grace-period,"",false
381,trino-server-381/lib/trino-main-381.jar,,query-retry-attempts,"",false
381,trino-server-381/lib/trino-main-381.jar,,failure-detector.heartbeat-interval,"",false
381,trino-server-381/lib/trino-main-381.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
381,trino-server-381/lib/trino-main-381.jar,,adaptive-partial-aggregation.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-run-time,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.jwt.key-file,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.manager-executor-pool-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,aggregation-operator-unspill-memory-limit,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
381,trino-server-381/lib/trino-main-381.jar,,failure-detector.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
381,trino-server-381/lib/trino-main-381.jar,,spiller-spill-path,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.info.max-age,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.krb5.name-type,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.info-update-interval,"Interval between updating task data",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.policy,"",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
381,trino-server-381/lib/trino-main-381.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.ignore-downstream-preferences,"",false
381,trino-server-381/lib/trino-main-381.jar,,sql.default-catalog,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
381,trino-server-381/lib/trino-main-381.jar,,task.low-memory-killer.policy,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
381,trino-server-381/lib/trino-main-381.jar,,query.execution-policy,"",false
381,trino-server-381/lib/trino-main-381.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
381,trino-server-381/lib/trino-main-381.jar,,task.min-drivers,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.page-buffer-client.max-callback-threads,"",false
381,trino-server-381/lib/trino-main-381.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
381,trino-server-381/lib/trino-main-381.jar,,internal-communication.https.truststore.path,"",false
381,trino-server-381/lib/trino-main-381.jar,,internal-communication.https.keystore.path,"",false
381,trino-server-381/lib/trino-main-381.jar,,enable-dynamic-filtering,"",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.service-thread-count,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.remote-task.max-callback-threads,"",false
381,trino-server-381/lib/trino-main-381.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
381,trino-server-381/lib/trino-main-381.jar,,query-max-spill-per-node,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.min-error-duration,"",false
381,trino-server-381/lib/trino-main-381.jar,,redistribute-writes,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.enable-intermediate-aggregations,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.network-topology.file,"",false
381,trino-server-381/lib/trino-main-381.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.allocator-type,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-stage-count,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.use-mark-distinct,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.acknowledge-pages,"",false
381,trino-server-381/lib/trino-main-381.jar,,retry-policy,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.krb5.keytab,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
381,trino-server-381/lib/trino-main-381.jar,,filter-and-project-min-output-page-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.optimize-metadata-queries,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.optimize-top-n-ranking,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.min-expire-age,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
381,trino-server-381/lib/trino-main-381.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
381,trino-server-381/lib/trino-main-381.jar,,regex-library,"",false
381,trino-server-381/lib/trino-main-381.jar,,internal-communication.https.keystore.key,"",false
381,trino-server-381/lib/trino-main-381.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
381,trino-server-381/lib/trino-main-381.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
381,trino-server-381/lib/trino-main-381.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
381,trino-server-381/lib/trino-main-381.jar,,jmx.base-name,"",false
381,trino-server-381/lib/trino-main-381.jar,,re2j.dfa-states-limit,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-memory,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.max-buffer-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.complex-expression-pushdown.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
381,trino-server-381/lib/trino-main-381.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,task.max-partial-top-n-memory,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.per-operator-cpu-timer-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
381,trino-server-381/lib/trino-main-381.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
381,trino-server-381/lib/trino-main-381.jar,,http.authentication.krb5.config,"",false
381,trino-server-381/lib/trino-main-381.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
381,trino-server-381/lib/trino-main-381.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
381,trino-server-381/lib/trino-main-381.jar,,event-listener.config-files,"",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-queued-queries,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.http-response-threads,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,task-retry-attempts-overall,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.compression-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
381,trino-server-381/lib/trino-main-381.jar,,task-retry-attempts-per-task,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.push-aggregation-through-outer-join,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.https.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
381,trino-server-381/lib/trino-main-381.jar,,discovery-server.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
381,trino-server-381/lib/trino-main-381.jar,,compiler.expression-cache-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
381,trino-server-381/lib/trino-main-381.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
381,trino-server-381/lib/trino-main-381.jar,,spill-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,sink.max-buffer-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.network-topology.refresh-period,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,internal-communication.https.required,"",false
381,trino-server-381/lib/trino-main-381.jar,,filter-and-project-min-output-page-row-count,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-history,"",false
381,trino-server-381/lib/trino-main-381.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
381,trino-server-381/lib/trino-main-381.jar,,task.max-partial-aggregation-memory,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.status-refresh-max-wait,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
381,trino-server-381/lib/trino-main-381.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.jwt.user-mapping.file,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.force-single-node-output,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
381,trino-server-381/lib/trino-main-381.jar,,scale-writers,"",false
381,trino-server-381/lib/trino-main-381.jar,,experimental.late-materialization.enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.merge-project-with-values,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.schedule-split-batch-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.krb5.user-mapping.file,"",false
381,trino-server-381/lib/trino-main-381.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
381,trino-server-381/lib/trino-main-381.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
381,trino-server-381/lib/trino-main-381.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-scan-physical-bytes,"",false
381,trino-server-381/lib/trino-main-381.jar,,internal-communication.https.truststore.key,"",false
381,trino-server-381/lib/trino-main-381.jar,,re2j.dfa-retries,"",false
381,trino-server-381/lib/trino-main-381.jar,,query-results.compression-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.client.timeout,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.http-timeout-threads,"",false
381,trino-server-381/lib/trino-main-381.jar,,memory-cost-weight,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.default-filter-factor-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.remote-task.max-error-duration,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-cpu-time,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.push-table-write-through-union,"",false
381,trino-server-381/lib/trino-main-381.jar,,web-ui.session-timeout,"",false
381,trino-server-381/lib/trino-main-381.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
381,trino-server-381/lib/trino-main-381.jar,,task.max-index-memory,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.writer-count,"Number of writers per task",false
381,trino-server-381/lib/trino-main-381.jar,,plugin.dir,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.statistics-cpu-timer-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.certificate.user-mapping.file,"",false
381,trino-server-381/lib/trino-main-381.jar,,warning-collector.max-warnings,"",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.password.user-mapping.pattern,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.network-topology.type,"",false
381,trino-server-381/lib/trino-main-381.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
381,trino-server-381/lib/trino-main-381.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
381,trino-server-381/lib/trino-main-381.jar,,access-control.config-files,"",false
381,trino-server-381/lib/trino-main-381.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.krb5.principal-hostname,"",false
381,trino-server-381/lib/trino-main-381.jar,,driver.max-page-partitioning-buffer-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,iterative-optimizer-timeout,"",false
381,trino-server-381/lib/trino-main-381.jar,,exchange.data-integrity-verification,"",false
381,trino-server-381/lib/trino-main-381.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
381,trino-server-381/lib/trino-main-381.jar,,query.remote-task.min-error-duration,"",false
381,trino-server-381/lib/trino-main-381.jar,,sink.max-broadcast-buffer-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
381,trino-server-381/lib/trino-main-381.jar,,web-ui.shared-secret,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
381,trino-server-381/lib/trino-main-381.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
381,trino-server-381/lib/trino-main-381.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
381,trino-server-381/lib/trino-main-381.jar,,network-cost-weight,"",false
381,trino-server-381/lib/trino-main-381.jar,,analyzer.max-grouping-sets,"",false
381,trino-server-381/lib/trino-main-381.jar,,event.max-output-stage-size,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.max-pending-splits-per-task,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
381,trino-server-381/lib/trino-main-381.jar,,distributed-index-joins-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,query.max-concurrent-queries,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.insecure.user-mapping.file,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
381,trino-server-381/lib/trino-main-381.jar,,distributed-sort,"",false
381,trino-server-381/lib/trino-main-381.jar,,internal-communication.shared-secret,"",false
381,trino-server-381/lib/trino-main-381.jar,,optimizer.optimize-hash-generation,"",false
381,trino-server-381/lib/trino-main-381.jar,,pages-index.eager-compaction-enabled,"",false
381,trino-server-381/lib/trino-main-381.jar,,task.initial-splits-per-node,"",false
381,trino-server-381/lib/trino-main-381.jar,,node-scheduler.optimized-local-scheduling,"",false
381,trino-server-381/lib/trino-main-381.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
381,trino-server-381/lib/trino-main-381.jar,,http-server.authentication.jwt.principal-field,"",false
381,trino-server-381/lib/trino-main-381.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,jmx.base-name,"",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,security.refresh-period,"",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.url,"URL of the LDAP server",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,security.config-file,"",false
382,trino-server-382/plugin/kinesis/trino-plugin-toolkit-382.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
382,trino-server-382/plugin/kinesis/trino-kinesis-382.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
382,trino-server-382/plugin/clickhouse/trino-clickhouse-382.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
382,trino-server-382/plugin/clickhouse/trino-clickhouse-382.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,user-credential-name,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,keystore-user-credential-name,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,keystore-password-credential-name,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,keystore-type,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,case-insensitive-name-matching,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,connection-url,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,connection-password,"Password for JDBC client",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,connection-user,"user name for JDBC client",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,keystore-file-path,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,keystore-password-credential-password,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,complex-expression-pushdown.enabled,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,keystore-user-credential-password,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,keystore-password,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,join-pushdown.strategy,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,statistics.enabled,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,credential-provider.type,"",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
382,trino-server-382/plugin/clickhouse/trino-base-jdbc-382.jar,clickhouse,password-credential-name,"",false
382,trino-server-382/plugin/postgresql/trino-postgresql-382.jar,postgresql,postgresql.include-system-tables,"",false
382,trino-server-382/plugin/postgresql/trino-postgresql-382.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
382,trino-server-382/plugin/postgresql/trino-postgresql-382.jar,postgresql,postgresql.array-mapping,"",false
382,trino-server-382/plugin/atop/trino-atop-382.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
382,trino-server-382/plugin/atop/trino-atop-382.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
382,trino-server-382/plugin/atop/trino-atop-382.jar,atop,atop.executable-path,"",false
382,trino-server-382/plugin/atop/trino-atop-382.jar,atop,atop.security,"",false
382,trino-server-382/plugin/atop/trino-atop-382.jar,atop,atop.concurrent-readers-per-node,"",false
382,trino-server-382/plugin/atop/trino-atop-382.jar,atop,atop.max-history-days,"",false
382,trino-server-382/plugin/memory/trino-memory-382.jar,memory,memory.max-data-per-node,"",false
382,trino-server-382/plugin/memory/trino-memory-382.jar,memory,memory.splits-per-node,"",false
382,trino-server-382/plugin/memory/trino-memory-382.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
382,trino-server-382/plugin/accumulo/trino-accumulo-382.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
382,trino-server-382/plugin/accumulo/trino-accumulo-382.jar,accumulo,accumulo.instance,"Accumulo instance name",false
382,trino-server-382/plugin/accumulo/trino-accumulo-382.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
382,trino-server-382/plugin/accumulo/trino-accumulo-382.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
382,trino-server-382/plugin/accumulo/trino-accumulo-382.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
382,trino-server-382/plugin/accumulo/trino-accumulo-382.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
382,trino-server-382/plugin/accumulo/trino-accumulo-382.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.controller.authentication.type,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.fetch-retry-count,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.forbid-segment-queries,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.max-backlog-per-server,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.connection-timeout,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.controller.authentication.password,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.segments-per-split,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.prefer-broker-queries,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.min-connections-per-server,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.metadata-expiry,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.max-connections-per-server,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.broker.authentication.user,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.controller-urls,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.thread-pool-size,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.request-timeout,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.broker.authentication.type,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.idle-timeout,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.controller.authentication.user,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.max-rows-for-broker-queries,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.broker.authentication.password,"",false
382,trino-server-382/plugin/pinot/trino-pinot-382.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
382,trino-server-382/plugin/resource-group-managers/trino-resource-group-managers-382.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
382,trino-server-382/plugin/resource-group-managers/trino-resource-group-managers-382.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
382,trino-server-382/plugin/resource-group-managers/trino-resource-group-managers-382.jar,resource-group-managers,jmx.base-name,"",false
382,trino-server-382/plugin/resource-group-managers/trino-resource-group-managers-382.jar,resource-group-managers,resource-groups.config-file,"",false
382,trino-server-382/plugin/resource-group-managers/trino-resource-group-managers-382.jar,resource-group-managers,resource-groups.config-db-url,"",false
382,trino-server-382/plugin/resource-group-managers/trino-resource-group-managers-382.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
382,trino-server-382/plugin/resource-group-managers/trino-resource-group-managers-382.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.default-schema,"The schema name to use in the connector",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.password,"Password for a password-protected Redis server",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.user,"Username for a Redis server",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
382,trino-server-382/plugin/redis/trino-redis-382.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
382,trino-server-382/plugin/example-http/trino-example-http-382.jar,example-http,metadata-uri,"",false
382,trino-server-382/plugin/local-file/trino-local-file-382.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
382,trino-server-382/plugin/local-file/trino-local-file-382.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
382,trino-server-382/plugin/jmx/trino-jmx-382.jar,jmx,jmx.dump-period,"",false
382,trino-server-382/plugin/jmx/trino-jmx-382.jar,jmx,jmx.max-entries,"",false
382,trino-server-382/plugin/jmx/trino-jmx-382.jar,jmx,jmx.dump-tables,"",false
382,trino-server-382/plugin/phoenix/trino-phoenix-382.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
382,trino-server-382/plugin/phoenix/trino-phoenix-382.jar,phoenix,phoenix.connection-url,"",false
382,trino-server-382/plugin/phoenix/trino-phoenix-382.jar,phoenix,phoenix.config.resources,"",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.number.rounding-mode,"",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.connection-pool.max-size,"",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.synonyms.enabled,"",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.remarks-reporting.enabled,"",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.connection-pool.enabled,"",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
382,trino-server-382/plugin/oracle/trino-oracle-382.jar,oracle,oracle.connection-pool.min-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-cache-ttl,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.max-client-retries,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.auto-purge,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.aws-secret-key,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.data-transfer-port,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.proxy.port,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.file-status-cache-expire-time,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.abfs-access-key,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.version-compatibility,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hdfs.socks-proxy,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.adl-refresh-url,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.read-mode,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-timeout,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.force-local-scheduling,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.wasb-access-key,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.max-error-retries,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.file-status-cache-tables,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.split-loader-concurrency,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs.connect.max-retries,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.proxy.protocol,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.adl-credential,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.adl-proxy-host,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.max-buffer-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-recording-path,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.max-merge-distance,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.max-buffer-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.signer-type,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.socket-timeout,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.max-read-block-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.sts.region,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.compression-codec,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3-file-system-type,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.max-connections,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs.verify-checksum,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs-timeout,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.writer.page-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.signer-class,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.sts.endpoint,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.security,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.file-status-cache-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-split-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.bookkeeper-port,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.stream-buffer-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.proxy.password,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-split-iterator-threads,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-initial-splits,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.writer.block-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.ignore-absent-partitions,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.replay-metastore-recording,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.config.resources,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.connect-timeout,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.streaming.enabled,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.wasb-storage-account,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.proxy.host,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.aws-access-key,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-register-partition-procedure,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.max-read-block-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-concurrent-file-renames,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-initial-split-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.max-merge-distance,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.max-retry-time,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs.connect.timeout,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.writer-sort-buffer-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.ssl.enabled,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.cache.location,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.dfs.domain-socket-path,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.endpoint,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.adl-client-id,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.writer.writer-identification,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-refresh-interval,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.storage-format,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.metastore-recording-duration,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.max-backoff-time,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.azure.abfs-storage-account,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.recursive-directories,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.s3.proxy.username,"",false
382,trino-server-382/plugin/delta-lake/trino-hive-382.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.max-split-size,"",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.max-initial-splits,"",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.max-initial-split-size,"",false
382,trino-server-382/plugin/delta-lake/trino-delta-lake-382.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
382,trino-server-382/plugin/session-property-managers/trino-session-property-managers-382.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
382,trino-server-382/plugin/session-property-managers/trino-session-property-managers-382.jar,session-property-managers,session-property-manager.config-file,"",false
382,trino-server-382/plugin/session-property-managers/trino-session-property-managers-382.jar,session-property-managers,session-property-manager.db.url,"",false
382,trino-server-382/plugin/session-property-managers/trino-session-property-managers-382.jar,session-property-managers,session-property-manager.db.username,"",false
382,trino-server-382/plugin/session-property-managers/trino-session-property-managers-382.jar,session-property-managers,session-property-manager.db.password,"",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.query-results-cache.enabled,"",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.view-expire-duration,"",false
382,trino-server-382/plugin/bigquery/trino-bigquery-382.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.write-concern,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.connection-timeout,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.seeds,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.required-replica-set,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.max-wait-time,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.cursor-batch-size,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.ssl.enabled,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.min-connections-per-host,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.read-preference,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.socket-timeout,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.schema-collection,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.connection-url,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.max-connection-idle-time,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.credentials,"",false
382,trino-server-382/plugin/mongodb/trino-mongodb-382.jar,mongodb,mongodb.connections-per-host,"",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.compression-codec,"",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.security,"",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.catalog.type,"",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.file-format,"",false
382,trino-server-382/plugin/iceberg/trino-iceberg-382.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
382,trino-server-382/plugin/phoenix5/trino-phoenix5-382.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
382,trino-server-382/plugin/phoenix5/trino-phoenix5-382.jar,phoenix5,phoenix.connection-url,"",false
382,trino-server-382/plugin/phoenix5/trino-phoenix5-382.jar,phoenix5,phoenix.config.resources,"",false
382,trino-server-382/plugin/thrift/trino-thrift-382.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
382,trino-server-382/plugin/thrift/trino-thrift-382.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
382,trino-server-382/plugin/thrift/trino-thrift-382.jar,thrift,trino-thrift.max-response-size,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.organization-enabled,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.balancer-enabled,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.orc.max-read-size,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.security,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.compaction-enabled,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,metadata.db.url,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.orc.nested-lazy,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
382,trino-server-382/plugin/raptor-legacy/trino-raptor-legacy-382.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
382,trino-server-382/plugin/google-sheets/trino-google-sheets-382.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
382,trino-server-382/plugin/google-sheets/trino-google-sheets-382.jar,google-sheets,credentials-path,"Credential file path to google service account",false
382,trino-server-382/plugin/google-sheets/trino-google-sheets-382.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
382,trino-server-382/plugin/google-sheets/trino-google-sheets-382.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.config.resources,"Optional config files",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
382,trino-server-382/plugin/kafka/trino-kafka-382.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.client.read-timeout,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.protocol-version,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.tls.keystore-password,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.consistency-level,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.tls.truststore-password,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.native-protocol-port,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.batch-size,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.tls.keystore-path,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.split-size,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.speculative-execution.delay,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.speculative-execution.limit,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.contact-points,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.password,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.username,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.splits-per-node,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.tls.truststore-path,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.client.so-linger,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.retry-policy,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.client.connect-timeout,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.tls.enabled,"",false
382,trino-server-382/plugin/cassandra/trino-cassandra-382.jar,cassandra,cassandra.fetch-size,"",false
382,trino-server-382/plugin/mysql/trino-mysql-382.jar,mysql,mysql.auto-reconnect,"",false
382,trino-server-382/plugin/mysql/trino-mysql-382.jar,mysql,mysql.connection-timeout,"",false
382,trino-server-382/plugin/mysql/trino-mysql-382.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
382,trino-server-382/plugin/mysql/trino-mysql-382.jar,mysql,mysql.max-reconnects,"",false
382,trino-server-382/plugin/sqlserver/trino-sqlserver-382.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
382,trino-server-382/plugin/sqlserver/trino-sqlserver-382.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
382,trino-server-382/plugin/sqlserver/trino-sqlserver-382.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
382,trino-server-382/plugin/http-event-listener/trino-http-event-listener-382.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.client.default-operation-timeout,"",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.grouped-execution.enabled,"",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.client.disable-statistics,"",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.schema-emulation.enabled,"",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.client.master-addresses,"",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
382,trino-server-382/plugin/kudu/trino-kudu-382.jar,kudu,kudu.schema-emulation.prefix,"",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,ldap.cache-ttl,"",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
382,trino-server-382/plugin/password-authenticators/trino-password-authenticators-382.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.auth.password,"",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.auth.user,"",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
382,trino-server-382/plugin/prometheus/trino-prometheus-382.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.region,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.use-web-identity-token-credentials,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.encryption-enabled,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.storage-class,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.endpoint,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.azure.connection-string,"",false
382,trino-server-382/plugin/exchange-filesystem/trino-exchange-filesystem-382.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.auth.password,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.aws.region,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.host,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.aws.access-key,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.port,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.security,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.tls.enabled,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.auth.user,"",false
382,trino-server-382/plugin/elasticsearch/trino-elasticsearch-382.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
382,trino-server-382/plugin/singlestore/trino-singlestore-382.jar,singlestore,singlestore.connection-timeout,"",false
382,trino-server-382/plugin/singlestore/trino-singlestore-382.jar,singlestore,singlestore.auto-reconnect,"",false
382,trino-server-382/lib/trino-main-382.jar,,use-preferred-write-partitioning,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.ignore-downstream-preferences,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.max-buffer-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.krb5.user-mapping.file,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
382,trino-server-382/lib/trino-main-382.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.max-splits-per-node,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.remote-task.max-callback-threads,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.compression-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,shutdown.grace-period,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.jwt.user-mapping.file,"",false
382,trino-server-382/lib/trino-main-382.jar,,cpu-cost-weight,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.data-integrity-verification,"",false
382,trino-server-382/lib/trino-main-382.jar,,distributed-sort,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.low-memory-killer.policy,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.push-partial-aggregation-through-join,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.prefer-partial-aggregation,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.acknowledge-pages,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
382,trino-server-382/lib/trino-main-382.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
382,trino-server-382/lib/trino-main-382.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
382,trino-server-382/lib/trino-main-382.jar,,http.authentication.krb5.config,"",false
382,trino-server-382/lib/trino-main-382.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
382,trino-server-382/lib/trino-main-382.jar,,task-retry-attempts-per-task,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.optimize-metadata-queries,"",false
382,trino-server-382/lib/trino-main-382.jar,,query-max-spill-per-node,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.policy,"",false
382,trino-server-382/lib/trino-main-382.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
382,trino-server-382/lib/trino-main-382.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
382,trino-server-382/lib/trino-main-382.jar,,failure-detector.threshold,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.merge-project-with-values,"",false
382,trino-server-382/lib/trino-main-382.jar,,http.include-exception-in-response,"",false
382,trino-server-382/lib/trino-main-382.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
382,trino-server-382/lib/trino-main-382.jar,,query-retry-attempts,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.max-response-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.enable-intermediate-aggregations,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.min-expire-age,"",false
382,trino-server-382/lib/trino-main-382.jar,,access-control.config-files,"",false
382,trino-server-382/lib/trino-main-382.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
382,trino-server-382/lib/trino-main-382.jar,,enable-forced-exchange-below-group-id,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
382,trino-server-382/lib/trino-main-382.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-cpu-time,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.max-error-duration,"",false
382,trino-server-382/lib/trino-main-382.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
382,trino-server-382/lib/trino-main-382.jar,,network-cost-weight,"",false
382,trino-server-382/lib/trino-main-382.jar,,filter-and-project-min-output-page-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-queued-queries,"",false
382,trino-server-382/lib/trino-main-382.jar,,sink.max-buffer-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.krb5.name-type,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
382,trino-server-382/lib/trino-main-382.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
382,trino-server-382/lib/trino-main-382.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
382,trino-server-382/lib/trino-main-382.jar,,task.info-update-interval,"Interval between updating task data",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
382,trino-server-382/lib/trino-main-382.jar,,pages-index.eager-compaction-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.optimize-top-n-ranking,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.max-partial-aggregation-memory,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.jwt.required-issuer,"",false
382,trino-server-382/lib/trino-main-382.jar,,scale-writers,"",false
382,trino-server-382/lib/trino-main-382.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
382,trino-server-382/lib/trino-main-382.jar,,enable-large-dynamic-filters,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
382,trino-server-382/lib/trino-main-382.jar,,spiller-spill-path,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.max-pending-splits-per-task,"",false
382,trino-server-382/lib/trino-main-382.jar,,experimental.late-materialization.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-history,"",false
382,trino-server-382/lib/trino-main-382.jar,,enable-stats-calculator,"",false
382,trino-server-382/lib/trino-main-382.jar,,jmx.base-name,"",false
382,trino-server-382/lib/trino-main-382.jar,,task-retry-attempts-overall,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.force-single-node-output,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.low-memory-killer.policy,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.jwt.key-file,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
382,trino-server-382/lib/trino-main-382.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.allocator-type,"",false
382,trino-server-382/lib/trino-main-382.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.status-refresh-max-wait,"",false
382,trino-server-382/lib/trino-main-382.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
382,trino-server-382/lib/trino-main-382.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.default-filter-factor-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-run-time,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.use-mark-distinct,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
382,trino-server-382/lib/trino-main-382.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
382,trino-server-382/lib/trino-main-382.jar,,join-distribution-type,"",false
382,trino-server-382/lib/trino-main-382.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
382,trino-server-382/lib/trino-main-382.jar,,aggregation-operator-unspill-memory-limit,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-concurrent-queries,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.max-local-exchange-buffer-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,internal-communication.https.truststore.key,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.cpu-timer-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-scan-physical-bytes,"",false
382,trino-server-382/lib/trino-main-382.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-length,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.info.max-age,"",false
382,trino-server-382/lib/trino-main-382.jar,,warning-collector.max-warnings,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.insecure.user-mapping.file,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.min-schedule-split-batch-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,sql.default-catalog,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.max-partial-top-n-memory,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.password.user-mapping.pattern,"",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
382,trino-server-382/lib/trino-main-382.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
382,trino-server-382/lib/trino-main-382.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
382,trino-server-382/lib/trino-main-382.jar,,web-ui.session-timeout,"",false
382,trino-server-382/lib/trino-main-382.jar,,internal-communication.https.keystore.path,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
382,trino-server-382/lib/trino-main-382.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.deduplication-buffer-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.min-drivers,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.network-topology.refresh-period,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.password.user-mapping.file,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-memory,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.service-thread-count,"",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
382,trino-server-382/lib/trino-main-382.jar,,event.max-output-stage-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.krb5.keytab,"",false
382,trino-server-382/lib/trino-main-382.jar,,filter-and-project-min-output-page-row-count,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.writer-count,"Number of writers per task",false
382,trino-server-382/lib/trino-main-382.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
382,trino-server-382/lib/trino-main-382.jar,,spiller-threads,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.push-aggregation-through-outer-join,"",false
382,trino-server-382/lib/trino-main-382.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.page-buffer-client.max-callback-threads,"",false
382,trino-server-382/lib/trino-main-382.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-memory-per-node,"",false
382,trino-server-382/lib/trino-main-382.jar,,internal-communication.shared-secret,"",false
382,trino-server-382/lib/trino-main-382.jar,,re2j.dfa-states-limit,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.complex-expression-pushdown.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-planning-time,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.certificate.user-mapping.file,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
382,trino-server-382/lib/trino-main-382.jar,,query.info-url-template,"",false
382,trino-server-382/lib/trino-main-382.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.include-coordinator,"",false
382,trino-server-382/lib/trino-main-382.jar,,web-ui.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.push-table-write-through-union,"",false
382,trino-server-382/lib/trino-main-382.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.krb5.service-name,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.network-topology.file,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.client.timeout,"",false
382,trino-server-382/lib/trino-main-382.jar,,statistics-precalculation-for-pushdown.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
382,trino-server-382/lib/trino-main-382.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
382,trino-server-382/lib/trino-main-382.jar,,discovery-server.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
382,trino-server-382/lib/trino-main-382.jar,,retry-policy,"",false
382,trino-server-382/lib/trino-main-382.jar,,web-ui.user,"",false
382,trino-server-382/lib/trino-main-382.jar,,sql.default-schema,"",false
382,trino-server-382/lib/trino-main-382.jar,,distributed-index-joins-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,spiller-max-used-space-threshold,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-execution-time,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
382,trino-server-382/lib/trino-main-382.jar,,catalog.disabled-catalogs,"",false
382,trino-server-382/lib/trino-main-382.jar,,spill-compression-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.share-index-loading,"",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
382,trino-server-382/lib/trino-main-382.jar,,spill-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.krb5.principal-hostname,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
382,trino-server-382/lib/trino-main-382.jar,,query.execution-policy,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
382,trino-server-382/lib/trino-main-382.jar,,internal-communication.https.keystore.key,"",false
382,trino-server-382/lib/trino-main-382.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.min-candidates,"",false
382,trino-server-382/lib/trino-main-382.jar,,web-ui.shared-secret,"",false
382,trino-server-382/lib/trino-main-382.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.network-topology.type,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,enable-dynamic-filtering,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
382,trino-server-382/lib/trino-main-382.jar,,internal-communication.https.truststore.path,"",false
382,trino-server-382/lib/trino-main-382.jar,,deprecated.legacy-row-to-json-cast,"",false
382,trino-server-382/lib/trino-main-382.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
382,trino-server-382/lib/trino-main-382.jar,,query.schedule-split-batch-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
382,trino-server-382/lib/trino-main-382.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
382,trino-server-382/lib/trino-main-382.jar,,failure-detector.heartbeat-interval,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.max-worker-threads,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.https.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,spill-encryption-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
382,trino-server-382/lib/trino-main-382.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
382,trino-server-382/lib/trino-main-382.jar,,task.client.timeout,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.client-threads,"",false
382,trino-server-382/lib/trino-main-382.jar,,compiler.expression-cache-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
382,trino-server-382/lib/trino-main-382.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
382,trino-server-382/lib/trino-main-382.jar,,parse-decimal-literals-as-double,"",false
382,trino-server-382/lib/trino-main-382.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
382,trino-server-382/lib/trino-main-382.jar,,memory-cost-weight,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.max-index-memory,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
382,trino-server-382/lib/trino-main-382.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.optimize-hash-generation,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.per-operator-cpu-timer-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,iterative-optimizer-timeout,"",false
382,trino-server-382/lib/trino-main-382.jar,,adaptive-partial-aggregation.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-stage-count,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.dictionary-aggregation,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.jwt.principal-field,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
382,trino-server-382/lib/trino-main-382.jar,,re2j.dfa-retries,"",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
382,trino-server-382/lib/trino-main-382.jar,,redistribute-writes,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.http-timeout-threads,"",false
382,trino-server-382/lib/trino-main-382.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.remote-task.max-error-duration,"",false
382,trino-server-382/lib/trino-main-382.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
382,trino-server-382/lib/trino-main-382.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
382,trino-server-382/lib/trino-main-382.jar,,regex-library,"",false
382,trino-server-382/lib/trino-main-382.jar,,failure-detector.enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
382,trino-server-382/lib/trino-main-382.jar,,plugin.dir,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.max-total-memory,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
382,trino-server-382/lib/trino-main-382.jar,,internal-communication.https.required,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.concurrent-request-multiplier,"",false
382,trino-server-382/lib/trino-main-382.jar,,node-scheduler.optimized-local-scheduling,"",false
382,trino-server-382/lib/trino-main-382.jar,,sink.max-broadcast-buffer-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
382,trino-server-382/lib/trino-main-382.jar,,analyzer.max-grouping-sets,"",false
382,trino-server-382/lib/trino-main-382.jar,,query-results.compression-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
382,trino-server-382/lib/trino-main-382.jar,,task.split-concurrency-adjustment-interval,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.http-response-threads,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
382,trino-server-382/lib/trino-main-382.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
382,trino-server-382/lib/trino-main-382.jar,,task.statistics-cpu-timer-enabled,"",false
382,trino-server-382/lib/trino-main-382.jar,,exchange.min-error-duration,"",false
382,trino-server-382/lib/trino-main-382.jar,,catalog.config-dir,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
382,trino-server-382/lib/trino-main-382.jar,,driver.max-page-partitioning-buffer-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,task.initial-splits-per-node,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.jwt.required-audience,"",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.skip-redundant-sort,"",false
382,trino-server-382/lib/trino-main-382.jar,,max-spill-per-node,"",false
382,trino-server-382/lib/trino-main-382.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
382,trino-server-382/lib/trino-main-382.jar,,event-listener.config-files,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.manager-executor-pool-size,"",false
382,trino-server-382/lib/trino-main-382.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
382,trino-server-382/lib/trino-main-382.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
382,trino-server-382/lib/trino-main-382.jar,,query.remote-task.min-error-duration,"",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.url,"URL of the LDAP server",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,security.refresh-period,"",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,jmx.base-name,"",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,security.config-file,"",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
383,trino-server-383/plugin/kinesis/trino-plugin-toolkit-383.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
383,trino-server-383/plugin/kinesis/trino-kinesis-383.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
383,trino-server-383/plugin/clickhouse/trino-clickhouse-383.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
383,trino-server-383/plugin/clickhouse/trino-clickhouse-383.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,keystore-user-credential-password,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,complex-expression-pushdown.enabled,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,keystore-password-credential-password,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,keystore-file-path,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,connection-user,"user name for JDBC client",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,connection-password,"Password for JDBC client",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,connection-url,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,case-insensitive-name-matching,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,keystore-type,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,keystore-password-credential-name,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,keystore-user-credential-name,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,user-credential-name,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,password-credential-name,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,credential-provider.type,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,statistics.enabled,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,join-pushdown.strategy,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,keystore-password,"",false
383,trino-server-383/plugin/clickhouse/trino-base-jdbc-383.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
383,trino-server-383/plugin/postgresql/trino-postgresql-383.jar,postgresql,postgresql.include-system-tables,"",false
383,trino-server-383/plugin/postgresql/trino-postgresql-383.jar,postgresql,postgresql.array-mapping,"",false
383,trino-server-383/plugin/postgresql/trino-postgresql-383.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
383,trino-server-383/plugin/atop/trino-atop-383.jar,atop,atop.security,"",false
383,trino-server-383/plugin/atop/trino-atop-383.jar,atop,atop.executable-path,"",false
383,trino-server-383/plugin/atop/trino-atop-383.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
383,trino-server-383/plugin/atop/trino-atop-383.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
383,trino-server-383/plugin/atop/trino-atop-383.jar,atop,atop.max-history-days,"",false
383,trino-server-383/plugin/atop/trino-atop-383.jar,atop,atop.concurrent-readers-per-node,"",false
383,trino-server-383/plugin/memory/trino-memory-383.jar,memory,memory.splits-per-node,"",false
383,trino-server-383/plugin/memory/trino-memory-383.jar,memory,memory.max-data-per-node,"",false
383,trino-server-383/plugin/memory/trino-memory-383.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
383,trino-server-383/plugin/accumulo/trino-accumulo-383.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
383,trino-server-383/plugin/accumulo/trino-accumulo-383.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
383,trino-server-383/plugin/accumulo/trino-accumulo-383.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
383,trino-server-383/plugin/accumulo/trino-accumulo-383.jar,accumulo,accumulo.instance,"Accumulo instance name",false
383,trino-server-383/plugin/accumulo/trino-accumulo-383.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
383,trino-server-383/plugin/accumulo/trino-accumulo-383.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
383,trino-server-383/plugin/accumulo/trino-accumulo-383.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.idle-timeout,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.broker.authentication.type,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.request-timeout,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.thread-pool-size,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.controller-urls,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.broker.authentication.user,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.max-connections-per-server,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.metadata-expiry,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.min-connections-per-server,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.prefer-broker-queries,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.segments-per-split,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.controller.authentication.password,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.connection-timeout,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.max-backlog-per-server,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.forbid-segment-queries,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.fetch-retry-count,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.controller.authentication.type,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.broker.authentication.password,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.max-rows-for-broker-queries,"",false
383,trino-server-383/plugin/pinot/trino-pinot-383.jar,pinot,pinot.controller.authentication.user,"",false
383,trino-server-383/plugin/resource-group-managers/trino-resource-group-managers-383.jar,resource-group-managers,resource-groups.config-file,"",false
383,trino-server-383/plugin/resource-group-managers/trino-resource-group-managers-383.jar,resource-group-managers,jmx.base-name,"",false
383,trino-server-383/plugin/resource-group-managers/trino-resource-group-managers-383.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
383,trino-server-383/plugin/resource-group-managers/trino-resource-group-managers-383.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
383,trino-server-383/plugin/resource-group-managers/trino-resource-group-managers-383.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
383,trino-server-383/plugin/resource-group-managers/trino-resource-group-managers-383.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
383,trino-server-383/plugin/resource-group-managers/trino-resource-group-managers-383.jar,resource-group-managers,resource-groups.config-db-url,"",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.user,"Username for a Redis server",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.password,"Password for a password-protected Redis server",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.default-schema,"The schema name to use in the connector",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
383,trino-server-383/plugin/redis/trino-redis-383.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
383,trino-server-383/plugin/example-http/trino-example-http-383.jar,example-http,metadata-uri,"",false
383,trino-server-383/plugin/local-file/trino-local-file-383.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
383,trino-server-383/plugin/local-file/trino-local-file-383.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
383,trino-server-383/plugin/jmx/trino-jmx-383.jar,jmx,jmx.dump-tables,"",false
383,trino-server-383/plugin/jmx/trino-jmx-383.jar,jmx,jmx.max-entries,"",false
383,trino-server-383/plugin/jmx/trino-jmx-383.jar,jmx,jmx.dump-period,"",false
383,trino-server-383/plugin/phoenix/trino-phoenix-383.jar,phoenix,phoenix.connection-url,"",false
383,trino-server-383/plugin/phoenix/trino-phoenix-383.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
383,trino-server-383/plugin/phoenix/trino-phoenix-383.jar,phoenix,phoenix.config.resources,"",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.remarks-reporting.enabled,"",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.synonyms.enabled,"",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.connection-pool.max-size,"",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.number.rounding-mode,"",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.connection-pool.min-size,"",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
383,trino-server-383/plugin/oracle/trino-oracle-383.jar,oracle,oracle.connection-pool.enabled,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.proxy.host,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.wasb-storage-account,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.streaming.enabled,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.connect-timeout,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.config.resources,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.replay-metastore-recording,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.ignore-absent-partitions,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.writer.block-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-initial-splits,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-split-iterator-threads,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.proxy.password,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.stream-buffer-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.bookkeeper-port,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-split-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.file-status-cache-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.security,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.sts.endpoint,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.signer-class,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.writer.page-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs-timeout,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs.verify-checksum,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.max-connections,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3-file-system-type,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.compression-codec,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.sts.region,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.max-read-block-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.socket-timeout,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.signer-type,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.max-buffer-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.max-merge-distance,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-recording-path,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.max-buffer-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.adl-proxy-host,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.adl-credential,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.proxy.protocol,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs.connect.max-retries,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.split-loader-concurrency,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.file-status-cache-tables,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.max-error-retries,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.wasb-access-key,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.force-local-scheduling,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-timeout,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.read-mode,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.adl-refresh-url,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hdfs.socks-proxy,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.version-compatibility,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.abfs-access-key,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.file-status-cache-expire-time,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.proxy.port,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.data-transfer-port,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.aws-secret-key,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.auto-purge,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.max-client-retries,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-cache-ttl,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.proxy.username,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.recursive-directories,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.abfs-storage-account,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.max-backoff-time,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-recording-duration,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.storage-format,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-refresh-interval,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.writer-identification,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.azure.adl-client-id,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.endpoint,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs.domain-socket-path,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.location,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.ssl.enabled,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.writer-sort-buffer-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs.connect.timeout,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.max-retry-time,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.max-merge-distance,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-initial-split-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.max-concurrent-file-renames,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.orc.max-read-block-size,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.allow-register-partition-procedure,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.s3.aws-access-key,"",false
383,trino-server-383/plugin/delta-lake/trino-hive-383.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.max-initial-splits,"",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.max-split-size,"",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.max-initial-split-size,"",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
383,trino-server-383/plugin/delta-lake/trino-delta-lake-383.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
383,trino-server-383/plugin/session-property-managers/trino-session-property-managers-383.jar,session-property-managers,session-property-manager.db.username,"",false
383,trino-server-383/plugin/session-property-managers/trino-session-property-managers-383.jar,session-property-managers,session-property-manager.db.url,"",false
383,trino-server-383/plugin/session-property-managers/trino-session-property-managers-383.jar,session-property-managers,session-property-manager.config-file,"",false
383,trino-server-383/plugin/session-property-managers/trino-session-property-managers-383.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
383,trino-server-383/plugin/session-property-managers/trino-session-property-managers-383.jar,session-property-managers,session-property-manager.db.password,"",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.query-results-cache.enabled,"",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.view-expire-duration,"",false
383,trino-server-383/plugin/bigquery/trino-bigquery-383.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.schema-collection,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.socket-timeout,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.read-preference,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.min-connections-per-host,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.ssl.enabled,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.cursor-batch-size,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.max-wait-time,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.required-replica-set,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.seeds,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.connection-timeout,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.write-concern,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.connections-per-host,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.credentials,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.max-connection-idle-time,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.connection-url,"",false
383,trino-server-383/plugin/mongodb/trino-mongodb-383.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.file-format,"",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.catalog.type,"",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.compression-codec,"",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
383,trino-server-383/plugin/iceberg/trino-iceberg-383.jar,iceberg,iceberg.security,"",false
383,trino-server-383/plugin/phoenix5/trino-phoenix5-383.jar,phoenix5,phoenix.connection-url,"",false
383,trino-server-383/plugin/phoenix5/trino-phoenix5-383.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
383,trino-server-383/plugin/phoenix5/trino-phoenix5-383.jar,phoenix5,phoenix.config.resources,"",false
383,trino-server-383/plugin/thrift/trino-thrift-383.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
383,trino-server-383/plugin/thrift/trino-thrift-383.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
383,trino-server-383/plugin/thrift/trino-thrift-383.jar,thrift,trino-thrift.max-response-size,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.orc.nested-lazy,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,metadata.db.url,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.compaction-enabled,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.security,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.orc.max-read-size,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.balancer-enabled,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.organization-enabled,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
383,trino-server-383/plugin/raptor-legacy/trino-raptor-legacy-383.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
383,trino-server-383/plugin/google-sheets/trino-google-sheets-383.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
383,trino-server-383/plugin/google-sheets/trino-google-sheets-383.jar,google-sheets,credentials-path,"Credential file path to google service account",false
383,trino-server-383/plugin/google-sheets/trino-google-sheets-383.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
383,trino-server-383/plugin/google-sheets/trino-google-sheets-383.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.config.resources,"Optional config files",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
383,trino-server-383/plugin/kafka/trino-kafka-383.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.client.connect-timeout,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.retry-policy,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.client.so-linger,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.tls.truststore-path,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.splits-per-node,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.username,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.password,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.contact-points,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.speculative-execution.limit,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.speculative-execution.delay,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.split-size,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.tls.keystore-path,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.batch-size,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.native-protocol-port,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.tls.truststore-password,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.consistency-level,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.tls.keystore-password,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.protocol-version,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.client.read-timeout,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.fetch-size,"",false
383,trino-server-383/plugin/cassandra/trino-cassandra-383.jar,cassandra,cassandra.tls.enabled,"",false
383,trino-server-383/plugin/mysql/trino-mysql-383.jar,mysql,mysql.max-reconnects,"",false
383,trino-server-383/plugin/mysql/trino-mysql-383.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
383,trino-server-383/plugin/mysql/trino-mysql-383.jar,mysql,mysql.connection-timeout,"",false
383,trino-server-383/plugin/mysql/trino-mysql-383.jar,mysql,mysql.auto-reconnect,"",false
383,trino-server-383/plugin/sqlserver/trino-sqlserver-383.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
383,trino-server-383/plugin/sqlserver/trino-sqlserver-383.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
383,trino-server-383/plugin/sqlserver/trino-sqlserver-383.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
383,trino-server-383/plugin/http-event-listener/trino-http-event-listener-383.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.client.disable-statistics,"",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.grouped-execution.enabled,"",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.client.default-operation-timeout,"",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.schema-emulation.prefix,"",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.client.master-addresses,"",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.schema-emulation.enabled,"",false
383,trino-server-383/plugin/kudu/trino-kudu-383.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,ldap.cache-ttl,"",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
383,trino-server-383/plugin/password-authenticators/trino-password-authenticators-383.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.auth.user,"",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.auth.password,"",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
383,trino-server-383/plugin/prometheus/trino-prometheus-383.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.endpoint,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.storage-class,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.azure.connection-string,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.region,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.encryption-enabled,"",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
383,trino-server-383/plugin/exchange-filesystem/trino-exchange-filesystem-383.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.security,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.port,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.aws.access-key,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.host,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.aws.region,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.auth.password,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.auth.user,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.tls.enabled,"",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
383,trino-server-383/plugin/elasticsearch/trino-elasticsearch-383.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
383,trino-server-383/plugin/singlestore/trino-singlestore-383.jar,singlestore,singlestore.auto-reconnect,"",false
383,trino-server-383/plugin/singlestore/trino-singlestore-383.jar,singlestore,singlestore.connection-timeout,"",false
383,trino-server-383/lib/trino-main-383.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
383,trino-server-383/lib/trino-main-383.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
383,trino-server-383/lib/trino-main-383.jar,,query.schedule-split-batch-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
383,trino-server-383/lib/trino-main-383.jar,,deprecated.legacy-row-to-json-cast,"",false
383,trino-server-383/lib/trino-main-383.jar,,internal-communication.https.truststore.path,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
383,trino-server-383/lib/trino-main-383.jar,,enable-dynamic-filtering,"",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.network-topology.type,"",false
383,trino-server-383/lib/trino-main-383.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
383,trino-server-383/lib/trino-main-383.jar,,web-ui.shared-secret,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.min-candidates,"",false
383,trino-server-383/lib/trino-main-383.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
383,trino-server-383/lib/trino-main-383.jar,,internal-communication.https.keystore.key,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
383,trino-server-383/lib/trino-main-383.jar,,query.execution-policy,"",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.krb5.principal-hostname,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
383,trino-server-383/lib/trino-main-383.jar,,spill-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
383,trino-server-383/lib/trino-main-383.jar,,task.share-index-loading,"",false
383,trino-server-383/lib/trino-main-383.jar,,spill-compression-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,catalog.disabled-catalogs,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-execution-time,"",false
383,trino-server-383/lib/trino-main-383.jar,,spiller-max-used-space-threshold,"",false
383,trino-server-383/lib/trino-main-383.jar,,distributed-index-joins-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,sql.default-schema,"",false
383,trino-server-383/lib/trino-main-383.jar,,web-ui.user,"",false
383,trino-server-383/lib/trino-main-383.jar,,retry-policy,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
383,trino-server-383/lib/trino-main-383.jar,,discovery-server.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
383,trino-server-383/lib/trino-main-383.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
383,trino-server-383/lib/trino-main-383.jar,,statistics-precalculation-for-pushdown.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.client.timeout,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.network-topology.file,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.krb5.service-name,"",false
383,trino-server-383/lib/trino-main-383.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.push-table-write-through-union,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
383,trino-server-383/lib/trino-main-383.jar,,web-ui.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.include-coordinator,"",false
383,trino-server-383/lib/trino-main-383.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
383,trino-server-383/lib/trino-main-383.jar,,query.info-url-template,"",false
383,trino-server-383/lib/trino-main-383.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.certificate.user-mapping.file,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-planning-time,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.complex-expression-pushdown.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,re2j.dfa-states-limit,"",false
383,trino-server-383/lib/trino-main-383.jar,,internal-communication.shared-secret,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-memory-per-node,"",false
383,trino-server-383/lib/trino-main-383.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.page-buffer-client.max-callback-threads,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
383,trino-server-383/lib/trino-main-383.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.push-aggregation-through-outer-join,"",false
383,trino-server-383/lib/trino-main-383.jar,,spiller-threads,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
383,trino-server-383/lib/trino-main-383.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
383,trino-server-383/lib/trino-main-383.jar,,task.writer-count,"Number of writers per task",false
383,trino-server-383/lib/trino-main-383.jar,,filter-and-project-min-output-page-row-count,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.krb5.keytab,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,event.max-output-stage-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.service-thread-count,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-memory,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.password.user-mapping.file,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.network-topology.refresh-period,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.min-drivers,"",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.deduplication-buffer-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
383,trino-server-383/lib/trino-main-383.jar,,internal-communication.https.keystore.path,"",false
383,trino-server-383/lib/trino-main-383.jar,,web-ui.session-timeout,"",false
383,trino-server-383/lib/trino-main-383.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
383,trino-server-383/lib/trino-main-383.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.password.user-mapping.pattern,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.max-partial-top-n-memory,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
383,trino-server-383/lib/trino-main-383.jar,,sql.default-catalog,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.min-schedule-split-batch-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.insecure.user-mapping.file,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
383,trino-server-383/lib/trino-main-383.jar,,warning-collector.max-warnings,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.info.max-age,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-length,"",false
383,trino-server-383/lib/trino-main-383.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-scan-physical-bytes,"",false
383,trino-server-383/lib/trino-main-383.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
383,trino-server-383/lib/trino-main-383.jar,,task.cpu-timer-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,internal-communication.https.truststore.key,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.max-local-exchange-buffer-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-concurrent-queries,"",false
383,trino-server-383/lib/trino-main-383.jar,,aggregation-operator-unspill-memory-limit,"",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
383,trino-server-383/lib/trino-main-383.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
383,trino-server-383/lib/trino-main-383.jar,,join-distribution-type,"",false
383,trino-server-383/lib/trino-main-383.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.use-mark-distinct,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-run-time,"",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.default-filter-factor-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
383,trino-server-383/lib/trino-main-383.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
383,trino-server-383/lib/trino-main-383.jar,,task.status-refresh-max-wait,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
383,trino-server-383/lib/trino-main-383.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.allocator-type,"",false
383,trino-server-383/lib/trino-main-383.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
383,trino-server-383/lib/trino-main-383.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.jwt.key-file,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.low-memory-killer.policy,"",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.force-single-node-output,"",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,task-retry-attempts-overall,"",false
383,trino-server-383/lib/trino-main-383.jar,,jmx.base-name,"",false
383,trino-server-383/lib/trino-main-383.jar,,enable-stats-calculator,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-history,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
383,trino-server-383/lib/trino-main-383.jar,,experimental.late-materialization.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.max-pending-splits-per-task,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
383,trino-server-383/lib/trino-main-383.jar,,spiller-spill-path,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
383,trino-server-383/lib/trino-main-383.jar,,enable-large-dynamic-filters,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
383,trino-server-383/lib/trino-main-383.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
383,trino-server-383/lib/trino-main-383.jar,,scale-writers,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.jwt.required-issuer,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.max-partial-aggregation-memory,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.optimize-top-n-ranking,"",false
383,trino-server-383/lib/trino-main-383.jar,,pages-index.eager-compaction-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
383,trino-server-383/lib/trino-main-383.jar,,task.info-update-interval,"Interval between updating task data",false
383,trino-server-383/lib/trino-main-383.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
383,trino-server-383/lib/trino-main-383.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.krb5.name-type,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
383,trino-server-383/lib/trino-main-383.jar,,sink.max-buffer-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-queued-queries,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,filter-and-project-min-output-page-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,network-cost-weight,"",false
383,trino-server-383/lib/trino-main-383.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.max-error-duration,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-cpu-time,"",false
383,trino-server-383/lib/trino-main-383.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
383,trino-server-383/lib/trino-main-383.jar,,enable-forced-exchange-below-group-id,"",false
383,trino-server-383/lib/trino-main-383.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
383,trino-server-383/lib/trino-main-383.jar,,access-control.config-files,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.min-expire-age,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.enable-intermediate-aggregations,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.max-response-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,query-retry-attempts,"",false
383,trino-server-383/lib/trino-main-383.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
383,trino-server-383/lib/trino-main-383.jar,,http.include-exception-in-response,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.merge-project-with-values,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
383,trino-server-383/lib/trino-main-383.jar,,failure-detector.threshold,"",false
383,trino-server-383/lib/trino-main-383.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
383,trino-server-383/lib/trino-main-383.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.policy,"",false
383,trino-server-383/lib/trino-main-383.jar,,query-max-spill-per-node,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.optimize-metadata-queries,"",false
383,trino-server-383/lib/trino-main-383.jar,,task-retry-attempts-per-task,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
383,trino-server-383/lib/trino-main-383.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
383,trino-server-383/lib/trino-main-383.jar,,http.authentication.krb5.config,"",false
383,trino-server-383/lib/trino-main-383.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
383,trino-server-383/lib/trino-main-383.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
383,trino-server-383/lib/trino-main-383.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.acknowledge-pages,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.prefer-partial-aggregation,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.push-partial-aggregation-through-join,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.low-memory-killer.policy,"",false
383,trino-server-383/lib/trino-main-383.jar,,distributed-sort,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.data-integrity-verification,"",false
383,trino-server-383/lib/trino-main-383.jar,,cpu-cost-weight,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.jwt.user-mapping.file,"",false
383,trino-server-383/lib/trino-main-383.jar,,shutdown.grace-period,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.compression-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.remote-task.max-callback-threads,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.max-splits-per-node,"",false
383,trino-server-383/lib/trino-main-383.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.krb5.user-mapping.file,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.max-buffer-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.ignore-downstream-preferences,"",false
383,trino-server-383/lib/trino-main-383.jar,,use-preferred-write-partitioning,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.remote-task.min-error-duration,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
383,trino-server-383/lib/trino-main-383.jar,,query.manager-executor-pool-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
383,trino-server-383/lib/trino-main-383.jar,,event-listener.config-files,"",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
383,trino-server-383/lib/trino-main-383.jar,,max-spill-per-node,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.skip-redundant-sort,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.jwt.required-audience,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.initial-splits-per-node,"",false
383,trino-server-383/lib/trino-main-383.jar,,driver.max-page-partitioning-buffer-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
383,trino-server-383/lib/trino-main-383.jar,,catalog.config-dir,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.min-error-duration,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.statistics-cpu-timer-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
383,trino-server-383/lib/trino-main-383.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
383,trino-server-383/lib/trino-main-383.jar,,task.http-response-threads,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.split-concurrency-adjustment-interval,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
383,trino-server-383/lib/trino-main-383.jar,,query-results.compression-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,analyzer.max-grouping-sets,"",false
383,trino-server-383/lib/trino-main-383.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
383,trino-server-383/lib/trino-main-383.jar,,sink.max-broadcast-buffer-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.optimized-local-scheduling,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.concurrent-request-multiplier,"",false
383,trino-server-383/lib/trino-main-383.jar,,internal-communication.https.required,"",false
383,trino-server-383/lib/trino-main-383.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-total-memory,"",false
383,trino-server-383/lib/trino-main-383.jar,,plugin.dir,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
383,trino-server-383/lib/trino-main-383.jar,,failure-detector.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,regex-library,"",false
383,trino-server-383/lib/trino-main-383.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
383,trino-server-383/lib/trino-main-383.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
383,trino-server-383/lib/trino-main-383.jar,,query.remote-task.max-error-duration,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
383,trino-server-383/lib/trino-main-383.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
383,trino-server-383/lib/trino-main-383.jar,,task.http-timeout-threads,"",false
383,trino-server-383/lib/trino-main-383.jar,,redistribute-writes,"",false
383,trino-server-383/lib/trino-main-383.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
383,trino-server-383/lib/trino-main-383.jar,,re2j.dfa-retries,"",false
383,trino-server-383/lib/trino-main-383.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.jwt.principal-field,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.dictionary-aggregation,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.max-stage-count,"",false
383,trino-server-383/lib/trino-main-383.jar,,adaptive-partial-aggregation.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,iterative-optimizer-timeout,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.per-operator-cpu-timer-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,optimizer.optimize-hash-generation,"",false
383,trino-server-383/lib/trino-main-383.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
383,trino-server-383/lib/trino-main-383.jar,,task.max-index-memory,"",false
383,trino-server-383/lib/trino-main-383.jar,,memory-cost-weight,"",false
383,trino-server-383/lib/trino-main-383.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
383,trino-server-383/lib/trino-main-383.jar,,parse-decimal-literals-as-double,"",false
383,trino-server-383/lib/trino-main-383.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
383,trino-server-383/lib/trino-main-383.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
383,trino-server-383/lib/trino-main-383.jar,,compiler.expression-cache-size,"",false
383,trino-server-383/lib/trino-main-383.jar,,exchange.client-threads,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.client.timeout,"",false
383,trino-server-383/lib/trino-main-383.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
383,trino-server-383/lib/trino-main-383.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
383,trino-server-383/lib/trino-main-383.jar,,spill-encryption-enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,http-server.https.enabled,"",false
383,trino-server-383/lib/trino-main-383.jar,,task.max-worker-threads,"",false
383,trino-server-383/lib/trino-main-383.jar,,failure-detector.heartbeat-interval,"",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,security.config-file,"",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,jmx.base-name,"",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,security.refresh-period,"",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.url,"URL of the LDAP server",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
384,trino-server-384/plugin/kinesis/trino-plugin-toolkit-384.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
384,trino-server-384/plugin/kinesis/trino-kinesis-384.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
384,trino-server-384/plugin/clickhouse/trino-clickhouse-384.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
384,trino-server-384/plugin/clickhouse/trino-clickhouse-384.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,keystore-password,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,join-pushdown.strategy,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,statistics.enabled,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,credential-provider.type,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,password-credential-name,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,user-credential-name,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,keystore-user-credential-name,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,keystore-password-credential-name,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,keystore-type,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,case-insensitive-name-matching,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,connection-url,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,connection-password,"Password for JDBC client",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,connection-user,"user name for JDBC client",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,keystore-file-path,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,keystore-password-credential-password,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,complex-expression-pushdown.enabled,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,keystore-user-credential-password,"",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
384,trino-server-384/plugin/clickhouse/trino-base-jdbc-384.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
384,trino-server-384/plugin/postgresql/trino-postgresql-384.jar,postgresql,postgresql.array-mapping,"",false
384,trino-server-384/plugin/postgresql/trino-postgresql-384.jar,postgresql,postgresql.include-system-tables,"",false
384,trino-server-384/plugin/postgresql/trino-postgresql-384.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
384,trino-server-384/plugin/atop/trino-atop-384.jar,atop,atop.max-history-days,"",false
384,trino-server-384/plugin/atop/trino-atop-384.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
384,trino-server-384/plugin/atop/trino-atop-384.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
384,trino-server-384/plugin/atop/trino-atop-384.jar,atop,atop.executable-path,"",false
384,trino-server-384/plugin/atop/trino-atop-384.jar,atop,atop.security,"",false
384,trino-server-384/plugin/atop/trino-atop-384.jar,atop,atop.concurrent-readers-per-node,"",false
384,trino-server-384/plugin/memory/trino-memory-384.jar,memory,memory.max-data-per-node,"",false
384,trino-server-384/plugin/memory/trino-memory-384.jar,memory,memory.splits-per-node,"",false
384,trino-server-384/plugin/memory/trino-memory-384.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
384,trino-server-384/plugin/accumulo/trino-accumulo-384.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
384,trino-server-384/plugin/accumulo/trino-accumulo-384.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
384,trino-server-384/plugin/accumulo/trino-accumulo-384.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
384,trino-server-384/plugin/accumulo/trino-accumulo-384.jar,accumulo,accumulo.instance,"Accumulo instance name",false
384,trino-server-384/plugin/accumulo/trino-accumulo-384.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
384,trino-server-384/plugin/accumulo/trino-accumulo-384.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
384,trino-server-384/plugin/accumulo/trino-accumulo-384.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.controller.authentication.user,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.max-rows-for-broker-queries,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.broker.authentication.password,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.controller.authentication.type,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.fetch-retry-count,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.forbid-segment-queries,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.max-backlog-per-server,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.connection-timeout,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.controller.authentication.password,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.segments-per-split,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.prefer-broker-queries,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.min-connections-per-server,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.metadata-expiry,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.max-connections-per-server,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.broker.authentication.user,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.controller-urls,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.thread-pool-size,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.request-timeout,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.broker.authentication.type,"",false
384,trino-server-384/plugin/pinot/trino-pinot-384.jar,pinot,pinot.idle-timeout,"",false
384,trino-server-384/plugin/resource-group-managers/trino-resource-group-managers-384.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
384,trino-server-384/plugin/resource-group-managers/trino-resource-group-managers-384.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
384,trino-server-384/plugin/resource-group-managers/trino-resource-group-managers-384.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
384,trino-server-384/plugin/resource-group-managers/trino-resource-group-managers-384.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
384,trino-server-384/plugin/resource-group-managers/trino-resource-group-managers-384.jar,resource-group-managers,jmx.base-name,"",false
384,trino-server-384/plugin/resource-group-managers/trino-resource-group-managers-384.jar,resource-group-managers,resource-groups.config-file,"",false
384,trino-server-384/plugin/resource-group-managers/trino-resource-group-managers-384.jar,resource-group-managers,resource-groups.config-db-url,"",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.default-schema,"The schema name to use in the connector",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.password,"Password for a password-protected Redis server",false
384,trino-server-384/plugin/redis/trino-redis-384.jar,redis,redis.user,"Username for a Redis server",false
384,trino-server-384/plugin/example-http/trino-example-http-384.jar,example-http,metadata-uri,"",false
384,trino-server-384/plugin/local-file/trino-local-file-384.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
384,trino-server-384/plugin/local-file/trino-local-file-384.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
384,trino-server-384/plugin/jmx/trino-jmx-384.jar,jmx,jmx.dump-period,"",false
384,trino-server-384/plugin/jmx/trino-jmx-384.jar,jmx,jmx.max-entries,"",false
384,trino-server-384/plugin/jmx/trino-jmx-384.jar,jmx,jmx.dump-tables,"",false
384,trino-server-384/plugin/phoenix/trino-phoenix-384.jar,phoenix,phoenix.config.resources,"",false
384,trino-server-384/plugin/phoenix/trino-phoenix-384.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
384,trino-server-384/plugin/phoenix/trino-phoenix-384.jar,phoenix,phoenix.connection-url,"",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.connection-pool.min-size,"",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.number.rounding-mode,"",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.connection-pool.max-size,"",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.synonyms.enabled,"",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.remarks-reporting.enabled,"",false
384,trino-server-384/plugin/oracle/trino-oracle-384.jar,oracle,oracle.connection-pool.enabled,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.aws-access-key,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-register-partition-procedure,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.max-read-block-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-concurrent-file-renames,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-initial-split-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.max-merge-distance,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.max-retry-time,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs.connect.timeout,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.writer-sort-buffer-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.ssl.enabled,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.location,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs.domain-socket-path,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.endpoint,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.adl-client-id,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.writer-identification,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-refresh-interval,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.storage-format,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-recording-duration,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.max-backoff-time,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.abfs-storage-account,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.recursive-directories,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.proxy.username,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-cache-ttl,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.max-client-retries,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.auto-purge,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.aws-secret-key,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.data-transfer-port,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.proxy.port,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.file-status-cache-expire-time,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.abfs-access-key,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.version-compatibility,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hdfs.socks-proxy,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.adl-refresh-url,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.read-mode,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-timeout,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.force-local-scheduling,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.wasb-access-key,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.max-error-retries,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.file-status-cache-tables,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.split-loader-concurrency,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs.connect.max-retries,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.proxy.protocol,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.adl-credential,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.adl-proxy-host,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.max-buffer-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-recording-path,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.max-merge-distance,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.max-buffer-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.signer-type,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.socket-timeout,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.max-read-block-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.sts.region,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.compression-codec,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3-file-system-type,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.max-connections,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs.verify-checksum,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs-timeout,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.writer.page-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.signer-class,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.sts.endpoint,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.security,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.file-status-cache-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-split-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.cache.bookkeeper-port,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.orc.stream-buffer-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.proxy.password,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-split-iterator-threads,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-initial-splits,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,parquet.writer.block-size,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.ignore-absent-partitions,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.replay-metastore-recording,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.config.resources,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.connect-timeout,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.streaming.enabled,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.azure.wasb-storage-account,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.metastore,"",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
384,trino-server-384/plugin/delta-lake/trino-hive-384.jar,delta-lake,hive.s3.proxy.host,"",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.max-initial-split-size,"",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.max-split-size,"",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.max-initial-splits,"",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
384,trino-server-384/plugin/delta-lake/trino-delta-lake-384.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
384,trino-server-384/plugin/session-property-managers/trino-session-property-managers-384.jar,session-property-managers,session-property-manager.db.password,"",false
384,trino-server-384/plugin/session-property-managers/trino-session-property-managers-384.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
384,trino-server-384/plugin/session-property-managers/trino-session-property-managers-384.jar,session-property-managers,session-property-manager.config-file,"",false
384,trino-server-384/plugin/session-property-managers/trino-session-property-managers-384.jar,session-property-managers,session-property-manager.db.url,"",false
384,trino-server-384/plugin/session-property-managers/trino-session-property-managers-384.jar,session-property-managers,session-property-manager.db.username,"",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.view-expire-duration,"",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.query-results-cache.enabled,"",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
384,trino-server-384/plugin/bigquery/trino-bigquery-384.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.connection-url,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.max-connection-idle-time,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.credentials,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.connections-per-host,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.write-concern,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.connection-timeout,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.seeds,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.required-replica-set,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.max-wait-time,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.cursor-batch-size,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.ssl.enabled,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.min-connections-per-host,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.read-preference,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.socket-timeout,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.schema-collection,"",false
384,trino-server-384/plugin/mongodb/trino-mongodb-384.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.security,"",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.compression-codec,"",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.catalog.type,"",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.file-format,"",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
384,trino-server-384/plugin/iceberg/trino-iceberg-384.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
384,trino-server-384/plugin/phoenix5/trino-phoenix5-384.jar,phoenix5,phoenix.config.resources,"",false
384,trino-server-384/plugin/phoenix5/trino-phoenix5-384.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
384,trino-server-384/plugin/phoenix5/trino-phoenix5-384.jar,phoenix5,phoenix.connection-url,"",false
384,trino-server-384/plugin/thrift/trino-thrift-384.jar,thrift,trino-thrift.max-response-size,"",false
384,trino-server-384/plugin/thrift/trino-thrift-384.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
384,trino-server-384/plugin/thrift/trino-thrift-384.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.organization-enabled,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.balancer-enabled,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.orc.max-read-size,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.security,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.compaction-enabled,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,metadata.db.url,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.orc.nested-lazy,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
384,trino-server-384/plugin/raptor-legacy/trino-raptor-legacy-384.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
384,trino-server-384/plugin/google-sheets/trino-google-sheets-384.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
384,trino-server-384/plugin/google-sheets/trino-google-sheets-384.jar,google-sheets,credentials-path,"Credential file path to google service account",false
384,trino-server-384/plugin/google-sheets/trino-google-sheets-384.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
384,trino-server-384/plugin/google-sheets/trino-google-sheets-384.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.config.resources,"Optional config files",false
384,trino-server-384/plugin/kafka/trino-kafka-384.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.tls.enabled,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.fetch-size,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.client.read-timeout,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.protocol-version,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.tls.keystore-password,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.consistency-level,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.tls.truststore-password,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.native-protocol-port,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.batch-size,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.tls.keystore-path,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.split-size,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.speculative-execution.delay,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.speculative-execution.limit,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.contact-points,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.password,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.username,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.splits-per-node,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.tls.truststore-path,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.client.so-linger,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.retry-policy,"",false
384,trino-server-384/plugin/cassandra/trino-cassandra-384.jar,cassandra,cassandra.client.connect-timeout,"",false
384,trino-server-384/plugin/mysql/trino-mysql-384.jar,mysql,mysql.auto-reconnect,"",false
384,trino-server-384/plugin/mysql/trino-mysql-384.jar,mysql,mysql.connection-timeout,"",false
384,trino-server-384/plugin/mysql/trino-mysql-384.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
384,trino-server-384/plugin/mysql/trino-mysql-384.jar,mysql,mysql.max-reconnects,"",false
384,trino-server-384/plugin/sqlserver/trino-sqlserver-384.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
384,trino-server-384/plugin/sqlserver/trino-sqlserver-384.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
384,trino-server-384/plugin/sqlserver/trino-sqlserver-384.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
384,trino-server-384/plugin/http-event-listener/trino-http-event-listener-384.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.schema-emulation.enabled,"",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.client.master-addresses,"",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.schema-emulation.prefix,"",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.client.default-operation-timeout,"",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.grouped-execution.enabled,"",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
384,trino-server-384/plugin/kudu/trino-kudu-384.jar,kudu,kudu.client.disable-statistics,"",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,ldap.cache-ttl,"",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
384,trino-server-384/plugin/password-authenticators/trino-password-authenticators-384.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.auth.password,"",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.auth.user,"",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
384,trino-server-384/plugin/prometheus/trino-prometheus-384.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.encryption-enabled,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.region,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.azure.connection-string,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.storage-class,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.endpoint,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
384,trino-server-384/plugin/exchange-filesystem/trino-exchange-filesystem-384.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.tls.enabled,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.auth.user,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.auth.password,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.aws.region,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.host,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.aws.access-key,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.port,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.security,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
384,trino-server-384/plugin/elasticsearch/trino-elasticsearch-384.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
384,trino-server-384/plugin/singlestore/trino-singlestore-384.jar,singlestore,singlestore.connection-timeout,"",false
384,trino-server-384/plugin/singlestore/trino-singlestore-384.jar,singlestore,singlestore.auto-reconnect,"",false
384,trino-server-384/lib/trino-main-384.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
384,trino-server-384/lib/trino-main-384.jar,,failure-detector.heartbeat-interval,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.max-worker-threads,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.https.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,spill-encryption-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
384,trino-server-384/lib/trino-main-384.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
384,trino-server-384/lib/trino-main-384.jar,,task.client.timeout,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.client-threads,"",false
384,trino-server-384/lib/trino-main-384.jar,,compiler.expression-cache-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
384,trino-server-384/lib/trino-main-384.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
384,trino-server-384/lib/trino-main-384.jar,,parse-decimal-literals-as-double,"",false
384,trino-server-384/lib/trino-main-384.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
384,trino-server-384/lib/trino-main-384.jar,,memory-cost-weight,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.max-index-memory,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
384,trino-server-384/lib/trino-main-384.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.optimize-hash-generation,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.per-operator-cpu-timer-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,iterative-optimizer-timeout,"",false
384,trino-server-384/lib/trino-main-384.jar,,adaptive-partial-aggregation.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-stage-count,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.dictionary-aggregation,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.jwt.principal-field,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
384,trino-server-384/lib/trino-main-384.jar,,re2j.dfa-retries,"",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
384,trino-server-384/lib/trino-main-384.jar,,redistribute-writes,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.http-timeout-threads,"",false
384,trino-server-384/lib/trino-main-384.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.remote-task.max-error-duration,"",false
384,trino-server-384/lib/trino-main-384.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
384,trino-server-384/lib/trino-main-384.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
384,trino-server-384/lib/trino-main-384.jar,,regex-library,"",false
384,trino-server-384/lib/trino-main-384.jar,,failure-detector.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
384,trino-server-384/lib/trino-main-384.jar,,plugin.dir,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-total-memory,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,internal-communication.https.required,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.concurrent-request-multiplier,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.optimized-local-scheduling,"",false
384,trino-server-384/lib/trino-main-384.jar,,sink.max-broadcast-buffer-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
384,trino-server-384/lib/trino-main-384.jar,,analyzer.max-grouping-sets,"",false
384,trino-server-384/lib/trino-main-384.jar,,query-results.compression-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
384,trino-server-384/lib/trino-main-384.jar,,task.split-concurrency-adjustment-interval,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.http-response-threads,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
384,trino-server-384/lib/trino-main-384.jar,,task.statistics-cpu-timer-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.min-error-duration,"",false
384,trino-server-384/lib/trino-main-384.jar,,catalog.config-dir,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
384,trino-server-384/lib/trino-main-384.jar,,driver.max-page-partitioning-buffer-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.initial-splits-per-node,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.jwt.required-audience,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.skip-redundant-sort,"",false
384,trino-server-384/lib/trino-main-384.jar,,max-spill-per-node,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
384,trino-server-384/lib/trino-main-384.jar,,event-listener.config-files,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.manager-executor-pool-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.remote-task.min-error-duration,"",false
384,trino-server-384/lib/trino-main-384.jar,,use-preferred-write-partitioning,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.ignore-downstream-preferences,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.max-buffer-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.krb5.user-mapping.file,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
384,trino-server-384/lib/trino-main-384.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.max-splits-per-node,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.remote-task.max-callback-threads,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.compression-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,shutdown.grace-period,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.jwt.user-mapping.file,"",false
384,trino-server-384/lib/trino-main-384.jar,,cpu-cost-weight,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.data-integrity-verification,"",false
384,trino-server-384/lib/trino-main-384.jar,,distributed-sort,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.low-memory-killer.policy,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.push-partial-aggregation-through-join,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.prefer-partial-aggregation,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.acknowledge-pages,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
384,trino-server-384/lib/trino-main-384.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
384,trino-server-384/lib/trino-main-384.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
384,trino-server-384/lib/trino-main-384.jar,,http.authentication.krb5.config,"",false
384,trino-server-384/lib/trino-main-384.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
384,trino-server-384/lib/trino-main-384.jar,,task-retry-attempts-per-task,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.optimize-metadata-queries,"",false
384,trino-server-384/lib/trino-main-384.jar,,query-max-spill-per-node,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.policy,"",false
384,trino-server-384/lib/trino-main-384.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
384,trino-server-384/lib/trino-main-384.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
384,trino-server-384/lib/trino-main-384.jar,,failure-detector.threshold,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.merge-project-with-values,"",false
384,trino-server-384/lib/trino-main-384.jar,,http.include-exception-in-response,"",false
384,trino-server-384/lib/trino-main-384.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
384,trino-server-384/lib/trino-main-384.jar,,query-retry-attempts,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.max-response-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.enable-intermediate-aggregations,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.min-expire-age,"",false
384,trino-server-384/lib/trino-main-384.jar,,access-control.config-files,"",false
384,trino-server-384/lib/trino-main-384.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
384,trino-server-384/lib/trino-main-384.jar,,enable-forced-exchange-below-group-id,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
384,trino-server-384/lib/trino-main-384.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-cpu-time,"",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.max-error-duration,"",false
384,trino-server-384/lib/trino-main-384.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
384,trino-server-384/lib/trino-main-384.jar,,network-cost-weight,"",false
384,trino-server-384/lib/trino-main-384.jar,,filter-and-project-min-output-page-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-queued-queries,"",false
384,trino-server-384/lib/trino-main-384.jar,,sink.max-buffer-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.krb5.name-type,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
384,trino-server-384/lib/trino-main-384.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
384,trino-server-384/lib/trino-main-384.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
384,trino-server-384/lib/trino-main-384.jar,,task.info-update-interval,"Interval between updating task data",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
384,trino-server-384/lib/trino-main-384.jar,,pages-index.eager-compaction-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.optimize-top-n-ranking,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.max-partial-aggregation-memory,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.jwt.required-issuer,"",false
384,trino-server-384/lib/trino-main-384.jar,,scale-writers,"",false
384,trino-server-384/lib/trino-main-384.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
384,trino-server-384/lib/trino-main-384.jar,,enable-large-dynamic-filters,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
384,trino-server-384/lib/trino-main-384.jar,,spiller-spill-path,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.max-pending-splits-per-task,"",false
384,trino-server-384/lib/trino-main-384.jar,,experimental.late-materialization.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-history,"",false
384,trino-server-384/lib/trino-main-384.jar,,enable-stats-calculator,"",false
384,trino-server-384/lib/trino-main-384.jar,,jmx.base-name,"",false
384,trino-server-384/lib/trino-main-384.jar,,task-retry-attempts-overall,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.force-single-node-output,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.low-memory-killer.policy,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.jwt.key-file,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
384,trino-server-384/lib/trino-main-384.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.allocator-type,"",false
384,trino-server-384/lib/trino-main-384.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.status-refresh-max-wait,"",false
384,trino-server-384/lib/trino-main-384.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
384,trino-server-384/lib/trino-main-384.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.default-filter-factor-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-run-time,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.use-mark-distinct,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
384,trino-server-384/lib/trino-main-384.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
384,trino-server-384/lib/trino-main-384.jar,,join-distribution-type,"",false
384,trino-server-384/lib/trino-main-384.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
384,trino-server-384/lib/trino-main-384.jar,,aggregation-operator-unspill-memory-limit,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-concurrent-queries,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.max-local-exchange-buffer-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,internal-communication.https.truststore.key,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.cpu-timer-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-scan-physical-bytes,"",false
384,trino-server-384/lib/trino-main-384.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-length,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.info.max-age,"",false
384,trino-server-384/lib/trino-main-384.jar,,warning-collector.max-warnings,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.insecure.user-mapping.file,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.min-schedule-split-batch-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,sql.default-catalog,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.max-partial-top-n-memory,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.password.user-mapping.pattern,"",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
384,trino-server-384/lib/trino-main-384.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
384,trino-server-384/lib/trino-main-384.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
384,trino-server-384/lib/trino-main-384.jar,,web-ui.session-timeout,"",false
384,trino-server-384/lib/trino-main-384.jar,,internal-communication.https.keystore.path,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
384,trino-server-384/lib/trino-main-384.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.deduplication-buffer-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.min-drivers,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.network-topology.refresh-period,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.password.user-mapping.file,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-memory,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.service-thread-count,"",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
384,trino-server-384/lib/trino-main-384.jar,,event.max-output-stage-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.krb5.keytab,"",false
384,trino-server-384/lib/trino-main-384.jar,,filter-and-project-min-output-page-row-count,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.writer-count,"Number of writers per task",false
384,trino-server-384/lib/trino-main-384.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
384,trino-server-384/lib/trino-main-384.jar,,spiller-threads,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.push-aggregation-through-outer-join,"",false
384,trino-server-384/lib/trino-main-384.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
384,trino-server-384/lib/trino-main-384.jar,,exchange.page-buffer-client.max-callback-threads,"",false
384,trino-server-384/lib/trino-main-384.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-memory-per-node,"",false
384,trino-server-384/lib/trino-main-384.jar,,internal-communication.shared-secret,"",false
384,trino-server-384/lib/trino-main-384.jar,,re2j.dfa-states-limit,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.complex-expression-pushdown.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-planning-time,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.certificate.user-mapping.file,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
384,trino-server-384/lib/trino-main-384.jar,,query.info-url-template,"",false
384,trino-server-384/lib/trino-main-384.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.include-coordinator,"",false
384,trino-server-384/lib/trino-main-384.jar,,web-ui.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.push-table-write-through-union,"",false
384,trino-server-384/lib/trino-main-384.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.krb5.service-name,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.network-topology.file,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.client.timeout,"",false
384,trino-server-384/lib/trino-main-384.jar,,statistics-precalculation-for-pushdown.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
384,trino-server-384/lib/trino-main-384.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
384,trino-server-384/lib/trino-main-384.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
384,trino-server-384/lib/trino-main-384.jar,,discovery-server.enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
384,trino-server-384/lib/trino-main-384.jar,,retry-policy,"",false
384,trino-server-384/lib/trino-main-384.jar,,web-ui.user,"",false
384,trino-server-384/lib/trino-main-384.jar,,sql.default-schema,"",false
384,trino-server-384/lib/trino-main-384.jar,,distributed-index-joins-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,spiller-max-used-space-threshold,"",false
384,trino-server-384/lib/trino-main-384.jar,,query.max-execution-time,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
384,trino-server-384/lib/trino-main-384.jar,,catalog.disabled-catalogs,"",false
384,trino-server-384/lib/trino-main-384.jar,,spill-compression-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.share-index-loading,"",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
384,trino-server-384/lib/trino-main-384.jar,,spill-enabled,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.krb5.principal-hostname,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
384,trino-server-384/lib/trino-main-384.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
384,trino-server-384/lib/trino-main-384.jar,,query.execution-policy,"",false
384,trino-server-384/lib/trino-main-384.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
384,trino-server-384/lib/trino-main-384.jar,,internal-communication.https.keystore.key,"",false
384,trino-server-384/lib/trino-main-384.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.min-candidates,"",false
384,trino-server-384/lib/trino-main-384.jar,,web-ui.shared-secret,"",false
384,trino-server-384/lib/trino-main-384.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
384,trino-server-384/lib/trino-main-384.jar,,node-scheduler.network-topology.type,"",false
384,trino-server-384/lib/trino-main-384.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
384,trino-server-384/lib/trino-main-384.jar,,enable-dynamic-filtering,"",false
384,trino-server-384/lib/trino-main-384.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
384,trino-server-384/lib/trino-main-384.jar,,internal-communication.https.truststore.path,"",false
384,trino-server-384/lib/trino-main-384.jar,,deprecated.legacy-row-to-json-cast,"",false
384,trino-server-384/lib/trino-main-384.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
384,trino-server-384/lib/trino-main-384.jar,,query.schedule-split-batch-size,"",false
384,trino-server-384/lib/trino-main-384.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,jmx.base-name,"",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,security.config-file,"",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.url,"URL of the LDAP server",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
385,trino-server-385/plugin/kinesis/trino-plugin-toolkit-385.jar,kinesis,security.refresh-period,"",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
385,trino-server-385/plugin/kinesis/trino-kinesis-385.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
385,trino-server-385/plugin/clickhouse/trino-clickhouse-385.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
385,trino-server-385/plugin/clickhouse/trino-clickhouse-385.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,connection-password,"Password for JDBC client",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,connection-url,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,case-insensitive-name-matching,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,keystore-type,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,keystore-password-credential-name,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,keystore-user-credential-name,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,user-credential-name,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,password-credential-name,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,credential-provider.type,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,statistics.enabled,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,join-pushdown.strategy,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,keystore-password,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,keystore-user-credential-password,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,complex-expression-pushdown.enabled,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,keystore-password-credential-password,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,keystore-file-path,"",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
385,trino-server-385/plugin/clickhouse/trino-base-jdbc-385.jar,clickhouse,connection-user,"user name for JDBC client",false
385,trino-server-385/plugin/postgresql/trino-postgresql-385.jar,postgresql,postgresql.include-system-tables,"",false
385,trino-server-385/plugin/postgresql/trino-postgresql-385.jar,postgresql,postgresql.array-mapping,"",false
385,trino-server-385/plugin/postgresql/trino-postgresql-385.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
385,trino-server-385/plugin/atop/trino-atop-385.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
385,trino-server-385/plugin/atop/trino-atop-385.jar,atop,atop.max-history-days,"",false
385,trino-server-385/plugin/atop/trino-atop-385.jar,atop,atop.concurrent-readers-per-node,"",false
385,trino-server-385/plugin/atop/trino-atop-385.jar,atop,atop.security,"",false
385,trino-server-385/plugin/atop/trino-atop-385.jar,atop,atop.executable-path,"",false
385,trino-server-385/plugin/atop/trino-atop-385.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
385,trino-server-385/plugin/memory/trino-memory-385.jar,memory,memory.max-data-per-node,"",false
385,trino-server-385/plugin/memory/trino-memory-385.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
385,trino-server-385/plugin/memory/trino-memory-385.jar,memory,memory.splits-per-node,"",false
385,trino-server-385/plugin/accumulo/trino-accumulo-385.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
385,trino-server-385/plugin/accumulo/trino-accumulo-385.jar,accumulo,accumulo.instance,"Accumulo instance name",false
385,trino-server-385/plugin/accumulo/trino-accumulo-385.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
385,trino-server-385/plugin/accumulo/trino-accumulo-385.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
385,trino-server-385/plugin/accumulo/trino-accumulo-385.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
385,trino-server-385/plugin/accumulo/trino-accumulo-385.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
385,trino-server-385/plugin/accumulo/trino-accumulo-385.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.prefer-broker-queries,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.segments-per-split,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.controller.authentication.password,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.connection-timeout,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.max-backlog-per-server,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.forbid-segment-queries,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.fetch-retry-count,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.controller.authentication.type,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.broker.authentication.password,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.max-rows-for-broker-queries,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.controller.authentication.user,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.idle-timeout,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.broker.authentication.type,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.request-timeout,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.thread-pool-size,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.controller-urls,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.broker.authentication.user,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.max-connections-per-server,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.metadata-expiry,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.min-connections-per-server,"",false
385,trino-server-385/plugin/pinot/trino-pinot-385.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
385,trino-server-385/plugin/resource-group-managers/trino-resource-group-managers-385.jar,resource-group-managers,jmx.base-name,"",false
385,trino-server-385/plugin/resource-group-managers/trino-resource-group-managers-385.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
385,trino-server-385/plugin/resource-group-managers/trino-resource-group-managers-385.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
385,trino-server-385/plugin/resource-group-managers/trino-resource-group-managers-385.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
385,trino-server-385/plugin/resource-group-managers/trino-resource-group-managers-385.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
385,trino-server-385/plugin/resource-group-managers/trino-resource-group-managers-385.jar,resource-group-managers,resource-groups.config-db-url,"",false
385,trino-server-385/plugin/resource-group-managers/trino-resource-group-managers-385.jar,resource-group-managers,resource-groups.config-file,"",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.user,"Username for a Redis server",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.password,"Password for a password-protected Redis server",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
385,trino-server-385/plugin/redis/trino-redis-385.jar,redis,redis.default-schema,"The schema name to use in the connector",false
385,trino-server-385/plugin/example-http/trino-example-http-385.jar,example-http,metadata-uri,"",false
385,trino-server-385/plugin/local-file/trino-local-file-385.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
385,trino-server-385/plugin/local-file/trino-local-file-385.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
385,trino-server-385/plugin/jmx/trino-jmx-385.jar,jmx,jmx.dump-period,"",false
385,trino-server-385/plugin/jmx/trino-jmx-385.jar,jmx,jmx.dump-tables,"",false
385,trino-server-385/plugin/jmx/trino-jmx-385.jar,jmx,jmx.max-entries,"",false
385,trino-server-385/plugin/phoenix/trino-phoenix-385.jar,phoenix,phoenix.config.resources,"",false
385,trino-server-385/plugin/phoenix/trino-phoenix-385.jar,phoenix,phoenix.connection-url,"",false
385,trino-server-385/plugin/phoenix/trino-phoenix-385.jar,phoenix,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.remarks-reporting.enabled,"",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.synonyms.enabled,"",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.connection-pool.max-size,"",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.number.rounding-mode,"",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.connection-pool.min-size,"",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
385,trino-server-385/plugin/oracle/trino-oracle-385.jar,oracle,oracle.connection-pool.enabled,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.adl-credential,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.proxy.protocol,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs.connect.max-retries,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.split-loader-concurrency,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.file-status-cache-tables,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.max-error-retries,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.wasb-access-key,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.force-local-scheduling,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-timeout,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.read-mode,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.adl-refresh-url,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hdfs.socks-proxy,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.version-compatibility,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.abfs-access-key,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.file-status-cache-expire-time,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.proxy.port,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.data-transfer-port,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.aws-secret-key,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.auto-purge,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.max-client-retries,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-cache-ttl,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.proxy.username,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.recursive-directories,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.abfs-storage-account,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.max-backoff-time,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-recording-duration,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.storage-format,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-refresh-interval,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.writer-identification,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.adl-client-id,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.endpoint,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs.domain-socket-path,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.location,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.ssl.enabled,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.writer-sort-buffer-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs.connect.timeout,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.max-retry-time,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.max-merge-distance,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-initial-split-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-concurrent-file-renames,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.max-read-block-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-register-partition-procedure,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.aws-access-key,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.proxy.host,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.wasb-storage-account,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.streaming.enabled,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.connect-timeout,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.config.resources,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.replay-metastore-recording,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.ignore-absent-partitions,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.writer.block-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-initial-splits,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-split-iterator-threads,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.proxy.password,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.stream-buffer-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.bookkeeper-port,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-split-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.file-status-cache-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.security,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.sts.endpoint,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.signer-class,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.writer.page-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs-timeout,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.dfs.verify-checksum,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.max-connections,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3-file-system-type,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.compression-codec,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.sts.region,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.max-read-block-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.socket-timeout,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.s3.signer-type,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.max-buffer-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.max-merge-distance,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore-recording-path,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,parquet.max-buffer-size,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.azure.adl-proxy-host,"",false
385,trino-server-385/plugin/delta-lake/trino-hive-385.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.max-initial-split-size,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.max-initial-splits,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.max-split-size,"",false
385,trino-server-385/plugin/delta-lake/trino-delta-lake-385.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
385,trino-server-385/plugin/session-property-managers/trino-session-property-managers-385.jar,session-property-managers,session-property-manager.config-file,"",false
385,trino-server-385/plugin/session-property-managers/trino-session-property-managers-385.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
385,trino-server-385/plugin/session-property-managers/trino-session-property-managers-385.jar,session-property-managers,session-property-manager.db.password,"",false
385,trino-server-385/plugin/session-property-managers/trino-session-property-managers-385.jar,session-property-managers,session-property-manager.db.username,"",false
385,trino-server-385/plugin/session-property-managers/trino-session-property-managers-385.jar,session-property-managers,session-property-manager.db.url,"",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.view-expire-duration,"",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.query-results-cache.enabled,"",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
385,trino-server-385/plugin/bigquery/trino-bigquery-385.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.max-wait-time,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.required-replica-set,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.seeds,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.connection-timeout,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.write-concern,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.connections-per-host,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.credentials,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.max-connection-idle-time,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.connection-url,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.schema-collection,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.socket-timeout,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.read-preference,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.min-connections-per-host,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.ssl.enabled,"",false
385,trino-server-385/plugin/mongodb/trino-mongodb-385.jar,mongodb,mongodb.cursor-batch-size,"",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.security,"",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.catalog.type,"",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.file-format,"",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.compression-codec,"",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
385,trino-server-385/plugin/iceberg/trino-iceberg-385.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
385,trino-server-385/plugin/phoenix5/trino-phoenix5-385.jar,phoenix5,phoenix.config.resources,"",false
385,trino-server-385/plugin/phoenix5/trino-phoenix5-385.jar,phoenix5,phoenix.connection-url,"",false
385,trino-server-385/plugin/phoenix5/trino-phoenix5-385.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
385,trino-server-385/plugin/thrift/trino-thrift-385.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
385,trino-server-385/plugin/thrift/trino-thrift-385.jar,thrift,trino-thrift.max-response-size,"",false
385,trino-server-385/plugin/thrift/trino-thrift-385.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.balancer-enabled,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.orc.nested-lazy,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.orc.max-read-size,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.security,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.organization-enabled,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,metadata.db.filename,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,metadata.db.url,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.compaction-enabled,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
385,trino-server-385/plugin/raptor-legacy/trino-raptor-legacy-385.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
385,trino-server-385/plugin/google-sheets/trino-google-sheets-385.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
385,trino-server-385/plugin/google-sheets/trino-google-sheets-385.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
385,trino-server-385/plugin/google-sheets/trino-google-sheets-385.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
385,trino-server-385/plugin/google-sheets/trino-google-sheets-385.jar,google-sheets,credentials-path,"Credential file path to google service account",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.config.resources,"Optional config files",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
385,trino-server-385/plugin/kafka/trino-kafka-385.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.tls.keystore-path,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.batch-size,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.native-protocol-port,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.tls.truststore-password,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.consistency-level,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.tls.keystore-password,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.protocol-version,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.client.read-timeout,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.fetch-size,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.tls.enabled,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.client.connect-timeout,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.retry-policy,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.client.so-linger,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.tls.truststore-path,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.splits-per-node,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.username,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.password,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.contact-points,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.speculative-execution.limit,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.speculative-execution.delay,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
385,trino-server-385/plugin/cassandra/trino-cassandra-385.jar,cassandra,cassandra.split-size,"",false
385,trino-server-385/plugin/mysql/trino-mysql-385.jar,mysql,mysql.connection-timeout,"",false
385,trino-server-385/plugin/mysql/trino-mysql-385.jar,mysql,mysql.auto-reconnect,"",false
385,trino-server-385/plugin/mysql/trino-mysql-385.jar,mysql,mysql.max-reconnects,"",false
385,trino-server-385/plugin/mysql/trino-mysql-385.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
385,trino-server-385/plugin/sqlserver/trino-sqlserver-385.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
385,trino-server-385/plugin/sqlserver/trino-sqlserver-385.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
385,trino-server-385/plugin/sqlserver/trino-sqlserver-385.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
385,trino-server-385/plugin/http-event-listener/trino-http-event-listener-385.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.schema-emulation.prefix,"",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.client.master-addresses,"",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.schema-emulation.enabled,"",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.client.disable-statistics,"",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.grouped-execution.enabled,"",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
385,trino-server-385/plugin/kudu/trino-kudu-385.jar,kudu,kudu.client.default-operation-timeout,"",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,ldap.cache-ttl,"",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
385,trino-server-385/plugin/password-authenticators/trino-password-authenticators-385.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.auth.password,"",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
385,trino-server-385/plugin/prometheus/trino-prometheus-385.jar,prometheus,prometheus.auth.user,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.region,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.encryption-enabled,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.endpoint,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.storage-class,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.azure.connection-string,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
385,trino-server-385/plugin/exchange-filesystem/trino-exchange-filesystem-385.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.aws.region,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.auth.password,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.auth.user,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.tls.enabled,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.security,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.port,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.aws.access-key,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.host,"",false
385,trino-server-385/plugin/elasticsearch/trino-elasticsearch-385.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
385,trino-server-385/plugin/singlestore/trino-singlestore-385.jar,singlestore,singlestore.auto-reconnect,"",false
385,trino-server-385/plugin/singlestore/trino-singlestore-385.jar,singlestore,singlestore.connection-timeout,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.optimized-local-scheduling,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.low-memory-killer.policy,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.max-buffer-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.krb5.name-type,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.page-buffer-client.max-callback-threads,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.info-url-template,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
385,trino-server-385/lib/trino-main-385.jar,,task.info-update-interval,"Interval between updating task data",false
385,trino-server-385/lib/trino-main-385.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
385,trino-server-385/lib/trino-main-385.jar,,sink.max-buffer-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
385,trino-server-385/lib/trino-main-385.jar,,warning-collector.max-warnings,"",false
385,trino-server-385/lib/trino-main-385.jar,,statistics-precalculation-for-pushdown.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,regex-library,"",false
385,trino-server-385/lib/trino-main-385.jar,,spill-compression-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
385,trino-server-385/lib/trino-main-385.jar,,internal-communication.shared-secret,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.policy,"",false
385,trino-server-385/lib/trino-main-385.jar,,query-results.compression-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.max-local-exchange-buffer-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.max-worker-threads,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.min-schedule-split-batch-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,driver.max-page-partitioning-buffer-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-scan-physical-bytes,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.insecure.user-mapping.file,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.jwt.required-issuer,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.jwt.principal-field,"",false
385,trino-server-385/lib/trino-main-385.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
385,trino-server-385/lib/trino-main-385.jar,,task.client.timeout,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.use-mark-distinct,"",false
385,trino-server-385/lib/trino-main-385.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.network-topology.type,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
385,trino-server-385/lib/trino-main-385.jar,,catalog.disabled-catalogs,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.acknowledge-pages,"",false
385,trino-server-385/lib/trino-main-385.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-cpu-time,"",false
385,trino-server-385/lib/trino-main-385.jar,,sql.default-catalog,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
385,trino-server-385/lib/trino-main-385.jar,,task-retry-attempts-per-task,"",false
385,trino-server-385/lib/trino-main-385.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
385,trino-server-385/lib/trino-main-385.jar,,web-ui.user,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.push-aggregation-through-outer-join,"",false
385,trino-server-385/lib/trino-main-385.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
385,trino-server-385/lib/trino-main-385.jar,,task.cpu-timer-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.writer-count,"Number of writers per task",false
385,trino-server-385/lib/trino-main-385.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
385,trino-server-385/lib/trino-main-385.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
385,trino-server-385/lib/trino-main-385.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
385,trino-server-385/lib/trino-main-385.jar,,iterative-optimizer-timeout,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-total-memory,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.network-topology.refresh-period,"",false
385,trino-server-385/lib/trino-main-385.jar,,enable-large-dynamic-filters,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.max-partial-top-n-memory,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
385,trino-server-385/lib/trino-main-385.jar,,experimental.late-materialization.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,enable-stats-calculator,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
385,trino-server-385/lib/trino-main-385.jar,,spill-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.network-topology.file,"",false
385,trino-server-385/lib/trino-main-385.jar,,task-retry-attempts-overall,"",false
385,trino-server-385/lib/trino-main-385.jar,,re2j.dfa-states-limit,"",false
385,trino-server-385/lib/trino-main-385.jar,,parse-decimal-literals-as-double,"",false
385,trino-server-385/lib/trino-main-385.jar,,failure-detector.heartbeat-interval,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.merge-project-with-values,"",false
385,trino-server-385/lib/trino-main-385.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
385,trino-server-385/lib/trino-main-385.jar,,query.execution-policy,"",false
385,trino-server-385/lib/trino-main-385.jar,,sql.default-schema,"",false
385,trino-server-385/lib/trino-main-385.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.force-single-node-output,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.ignore-downstream-preferences,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.min-candidates,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
385,trino-server-385/lib/trino-main-385.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,deprecated.legacy-row-to-json-cast,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.optimize-metadata-queries,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-run-time,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
385,trino-server-385/lib/trino-main-385.jar,,query.client.timeout,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
385,trino-server-385/lib/trino-main-385.jar,,filter-and-project-min-output-page-row-count,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-queued-queries,"",false
385,trino-server-385/lib/trino-main-385.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
385,trino-server-385/lib/trino-main-385.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
385,trino-server-385/lib/trino-main-385.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
385,trino-server-385/lib/trino-main-385.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
385,trino-server-385/lib/trino-main-385.jar,,http.authentication.krb5.config,"",false
385,trino-server-385/lib/trino-main-385.jar,,discovery-server.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.include-coordinator,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
385,trino-server-385/lib/trino-main-385.jar,,retry-policy,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,network-cost-weight,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,failure-detector.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
385,trino-server-385/lib/trino-main-385.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
385,trino-server-385/lib/trino-main-385.jar,,task.http-timeout-threads,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.schedule-split-batch-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,web-ui.session-timeout,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.service-thread-count,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.compression-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,spiller-max-used-space-threshold,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-history,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
385,trino-server-385/lib/trino-main-385.jar,,query.remote-task.max-callback-threads,"",false
385,trino-server-385/lib/trino-main-385.jar,,plugin.dir,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.http-response-threads,"",false
385,trino-server-385/lib/trino-main-385.jar,,scale-writers,"",false
385,trino-server-385/lib/trino-main-385.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
385,trino-server-385/lib/trino-main-385.jar,,task.max-partial-aggregation-memory,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-concurrent-queries,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.password.user-mapping.file,"",false
385,trino-server-385/lib/trino-main-385.jar,,sink.max-broadcast-buffer-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
385,trino-server-385/lib/trino-main-385.jar,,jmx.base-name,"",false
385,trino-server-385/lib/trino-main-385.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
385,trino-server-385/lib/trino-main-385.jar,,redistribute-writes,"",false
385,trino-server-385/lib/trino-main-385.jar,,access-control.config-files,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.max-splits-per-node,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.default-filter-factor-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-memory-per-node,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,internal-communication.https.required,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.min-error-duration,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.min-drivers,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.allocator-type,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.krb5.user-mapping.file,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.certificate.user-mapping.file,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-planning-time,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.per-operator-cpu-timer-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
385,trino-server-385/lib/trino-main-385.jar,,enable-forced-exchange-below-group-id,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.remote-task.min-error-duration,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.skip-redundant-sort,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.krb5.keytab,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.krb5.principal-hostname,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.jwt.key-file,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.share-index-loading,"",false
385,trino-server-385/lib/trino-main-385.jar,,spiller-spill-path,"",false
385,trino-server-385/lib/trino-main-385.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
385,trino-server-385/lib/trino-main-385.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
385,trino-server-385/lib/trino-main-385.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
385,trino-server-385/lib/trino-main-385.jar,,http.include-exception-in-response,"",false
385,trino-server-385/lib/trino-main-385.jar,,web-ui.shared-secret,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.password.user-mapping.pattern,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.push-partial-aggregation-through-join,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.krb5.service-name,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.low-memory-killer.policy,"",false
385,trino-server-385/lib/trino-main-385.jar,,spiller-threads,"",false
385,trino-server-385/lib/trino-main-385.jar,,query-retry-attempts,"",false
385,trino-server-385/lib/trino-main-385.jar,,failure-detector.threshold,"",false
385,trino-server-385/lib/trino-main-385.jar,,event.max-output-stage-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-stage-count,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.client-threads,"",false
385,trino-server-385/lib/trino-main-385.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,task.split-concurrency-adjustment-interval,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.complex-expression-pushdown.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
385,trino-server-385/lib/trino-main-385.jar,,task.info.max-age,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-length,"",false
385,trino-server-385/lib/trino-main-385.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
385,trino-server-385/lib/trino-main-385.jar,,analyzer.max-grouping-sets,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.enable-intermediate-aggregations,"",false
385,trino-server-385/lib/trino-main-385.jar,,internal-communication.https.truststore.path,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.prefer-partial-aggregation,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
385,trino-server-385/lib/trino-main-385.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-execution-time,"",false
385,trino-server-385/lib/trino-main-385.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
385,trino-server-385/lib/trino-main-385.jar,,compiler.expression-cache-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.https.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.jwt.required-audience,"",false
385,trino-server-385/lib/trino-main-385.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.dictionary-aggregation,"",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
385,trino-server-385/lib/trino-main-385.jar,,query.max-memory,"",false
385,trino-server-385/lib/trino-main-385.jar,,internal-communication.https.keystore.key,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.remote-task.max-error-duration,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.manager-executor-pool-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
385,trino-server-385/lib/trino-main-385.jar,,use-preferred-write-partitioning,"",false
385,trino-server-385/lib/trino-main-385.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
385,trino-server-385/lib/trino-main-385.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
385,trino-server-385/lib/trino-main-385.jar,,spill-encryption-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,enable-dynamic-filtering,"",false
385,trino-server-385/lib/trino-main-385.jar,,distributed-sort,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
385,trino-server-385/lib/trino-main-385.jar,,query-max-spill-per-node,"",false
385,trino-server-385/lib/trino-main-385.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
385,trino-server-385/lib/trino-main-385.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
385,trino-server-385/lib/trino-main-385.jar,,max-spill-per-node,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.statistics-cpu-timer-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,aggregation-operator-unspill-memory-limit,"",false
385,trino-server-385/lib/trino-main-385.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
385,trino-server-385/lib/trino-main-385.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
385,trino-server-385/lib/trino-main-385.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
385,trino-server-385/lib/trino-main-385.jar,,task.max-index-memory,"",false
385,trino-server-385/lib/trino-main-385.jar,,event-listener.config-files,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.deduplication-buffer-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,internal-communication.https.truststore.key,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
385,trino-server-385/lib/trino-main-385.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.max-pending-splits-per-task,"",false
385,trino-server-385/lib/trino-main-385.jar,,join-distribution-type,"",false
385,trino-server-385/lib/trino-main-385.jar,,shutdown.grace-period,"",false
385,trino-server-385/lib/trino-main-385.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.optimize-top-n-ranking,"",false
385,trino-server-385/lib/trino-main-385.jar,,catalog.config-dir,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.initial-splits-per-node,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.optimize-hash-generation,"",false
385,trino-server-385/lib/trino-main-385.jar,,web-ui.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.min-expire-age,"",false
385,trino-server-385/lib/trino-main-385.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
385,trino-server-385/lib/trino-main-385.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
385,trino-server-385/lib/trino-main-385.jar,,pages-index.eager-compaction-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.data-integrity-verification,"",false
385,trino-server-385/lib/trino-main-385.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.jwt.user-mapping.file,"",false
385,trino-server-385/lib/trino-main-385.jar,,memory-cost-weight,"",false
385,trino-server-385/lib/trino-main-385.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
385,trino-server-385/lib/trino-main-385.jar,,task.status-refresh-max-wait,"",false
385,trino-server-385/lib/trino-main-385.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
385,trino-server-385/lib/trino-main-385.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.max-response-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,internal-communication.https.keystore.path,"",false
385,trino-server-385/lib/trino-main-385.jar,,cpu-cost-weight,"",false
385,trino-server-385/lib/trino-main-385.jar,,re2j.dfa-retries,"",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
385,trino-server-385/lib/trino-main-385.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
385,trino-server-385/lib/trino-main-385.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.concurrent-request-multiplier,"",false
385,trino-server-385/lib/trino-main-385.jar,,adaptive-partial-aggregation.enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,exchange.max-error-duration,"",false
385,trino-server-385/lib/trino-main-385.jar,,filter-and-project-min-output-page-size,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
385,trino-server-385/lib/trino-main-385.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
385,trino-server-385/lib/trino-main-385.jar,,distributed-index-joins-enabled,"",false
385,trino-server-385/lib/trino-main-385.jar,,optimizer.push-table-write-through-union,"",false
385,trino-server-385/lib/trino-main-385.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
385,trino-server-385/lib/trino-main-385.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,jmx.base-name,"",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,security.refresh-period,"",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.url,"URL of the LDAP server",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,security.config-file,"",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
386,trino-server-386/plugin/kinesis/trino-plugin-toolkit-386.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
386,trino-server-386/plugin/kinesis/trino-kinesis-386.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
386,trino-server-386/plugin/clickhouse/trino-clickhouse-386.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
386,trino-server-386/plugin/clickhouse/trino-clickhouse-386.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,keystore-type,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,case-insensitive-name-matching,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,connection-url,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,connection-password,"Password for JDBC client",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,connection-user,"user name for JDBC client",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,keystore-file-path,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,keystore-password-credential-password,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,complex-expression-pushdown.enabled,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,keystore-user-credential-password,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,keystore-password,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,join-pushdown.strategy,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,statistics.enabled,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,credential-provider.type,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,password-credential-name,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,user-credential-name,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,keystore-user-credential-name,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,keystore-password-credential-name,"",false
386,trino-server-386/plugin/clickhouse/trino-base-jdbc-386.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
386,trino-server-386/plugin/postgresql/trino-postgresql-386.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
386,trino-server-386/plugin/postgresql/trino-postgresql-386.jar,postgresql,postgresql.array-mapping,"",false
386,trino-server-386/plugin/postgresql/trino-postgresql-386.jar,postgresql,postgresql.include-system-tables,"",false
386,trino-server-386/plugin/atop/trino-atop-386.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
386,trino-server-386/plugin/atop/trino-atop-386.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
386,trino-server-386/plugin/atop/trino-atop-386.jar,atop,atop.executable-path,"",false
386,trino-server-386/plugin/atop/trino-atop-386.jar,atop,atop.security,"",false
386,trino-server-386/plugin/atop/trino-atop-386.jar,atop,atop.concurrent-readers-per-node,"",false
386,trino-server-386/plugin/atop/trino-atop-386.jar,atop,atop.max-history-days,"",false
386,trino-server-386/plugin/memory/trino-memory-386.jar,memory,memory.splits-per-node,"",false
386,trino-server-386/plugin/memory/trino-memory-386.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
386,trino-server-386/plugin/memory/trino-memory-386.jar,memory,memory.max-data-per-node,"",false
386,trino-server-386/plugin/accumulo/trino-accumulo-386.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
386,trino-server-386/plugin/accumulo/trino-accumulo-386.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
386,trino-server-386/plugin/accumulo/trino-accumulo-386.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
386,trino-server-386/plugin/accumulo/trino-accumulo-386.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
386,trino-server-386/plugin/accumulo/trino-accumulo-386.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
386,trino-server-386/plugin/accumulo/trino-accumulo-386.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
386,trino-server-386/plugin/accumulo/trino-accumulo-386.jar,accumulo,accumulo.instance,"Accumulo instance name",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.controller.authentication.password,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.segments-per-split,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.prefer-broker-queries,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.min-connections-per-server,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.metadata-expiry,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.max-connections-per-server,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.broker.authentication.user,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.controller-urls,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.thread-pool-size,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.request-timeout,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.broker.authentication.type,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.idle-timeout,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.controller.authentication.user,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.max-rows-for-broker-queries,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.broker.authentication.password,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.controller.authentication.type,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.fetch-retry-count,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.forbid-segment-queries,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.max-backlog-per-server,"",false
386,trino-server-386/plugin/pinot/trino-pinot-386.jar,pinot,pinot.connection-timeout,"",false
386,trino-server-386/plugin/resource-group-managers/trino-resource-group-managers-386.jar,resource-group-managers,jmx.base-name,"",false
386,trino-server-386/plugin/resource-group-managers/trino-resource-group-managers-386.jar,resource-group-managers,resource-groups.config-file,"",false
386,trino-server-386/plugin/resource-group-managers/trino-resource-group-managers-386.jar,resource-group-managers,resource-groups.config-db-url,"",false
386,trino-server-386/plugin/resource-group-managers/trino-resource-group-managers-386.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
386,trino-server-386/plugin/resource-group-managers/trino-resource-group-managers-386.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
386,trino-server-386/plugin/resource-group-managers/trino-resource-group-managers-386.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
386,trino-server-386/plugin/resource-group-managers/trino-resource-group-managers-386.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.default-schema,"The schema name to use in the connector",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.password,"Password for a password-protected Redis server",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.user,"Username for a Redis server",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
386,trino-server-386/plugin/redis/trino-redis-386.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
386,trino-server-386/plugin/example-http/trino-example-http-386.jar,example-http,metadata-uri,"",false
386,trino-server-386/plugin/local-file/trino-local-file-386.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
386,trino-server-386/plugin/local-file/trino-local-file-386.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
386,trino-server-386/plugin/jmx/trino-jmx-386.jar,jmx,jmx.max-entries,"",false
386,trino-server-386/plugin/jmx/trino-jmx-386.jar,jmx,jmx.dump-tables,"",false
386,trino-server-386/plugin/jmx/trino-jmx-386.jar,jmx,jmx.dump-period,"",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.synonyms.enabled,"",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.remarks-reporting.enabled,"",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.connection-pool.enabled,"",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.connection-pool.min-size,"",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.number.rounding-mode,"",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.connection-pool.max-size,"",false
386,trino-server-386/plugin/oracle/trino-oracle-386.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hdfs.socks-proxy,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.adl-refresh-url,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.read-mode,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-timeout,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.force-local-scheduling,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.wasb-access-key,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.max-error-retries,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.file-status-cache-tables,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.split-loader-concurrency,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs.connect.max-retries,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.proxy.protocol,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.adl-credential,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.adl-proxy-host,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.max-buffer-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-recording-path,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.max-merge-distance,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.max-buffer-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.signer-type,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.socket-timeout,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.max-read-block-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.sts.region,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.compression-codec,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3-file-system-type,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.max-connections,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs.verify-checksum,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs-timeout,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.writer.page-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.signer-class,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.sts.endpoint,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.security,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.file-status-cache-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-split-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.bookkeeper-port,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.stream-buffer-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.proxy.password,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-split-iterator-threads,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-initial-splits,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.writer.block-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.ignore-absent-partitions,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.replay-metastore-recording,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.config.resources,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.connect-timeout,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.streaming.enabled,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.wasb-storage-account,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.proxy.host,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.aws-access-key,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-register-partition-procedure,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.max-read-block-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-concurrent-file-renames,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-initial-split-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.max-merge-distance,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.max-retry-time,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs.connect.timeout,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.writer-sort-buffer-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.ssl.enabled,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.location,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs.domain-socket-path,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.endpoint,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.adl-client-id,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.writer-identification,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-refresh-interval,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.storage-format,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-recording-duration,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.max-backoff-time,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.abfs-storage-account,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.recursive-directories,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.proxy.username,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore-cache-ttl,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.max-client-retries,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.auto-purge,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.aws-secret-key,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.cache.data-transfer-port,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.proxy.port,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.file-status-cache-expire-time,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.azure.abfs-access-key,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.metastore.version-compatibility,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
386,trino-server-386/plugin/delta-lake/trino-hive-386.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.max-initial-split-size,"",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.max-split-size,"",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.max-initial-splits,"",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
386,trino-server-386/plugin/delta-lake/trino-delta-lake-386.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
386,trino-server-386/plugin/session-property-managers/trino-session-property-managers-386.jar,session-property-managers,session-property-manager.db.url,"",false
386,trino-server-386/plugin/session-property-managers/trino-session-property-managers-386.jar,session-property-managers,session-property-manager.db.username,"",false
386,trino-server-386/plugin/session-property-managers/trino-session-property-managers-386.jar,session-property-managers,session-property-manager.db.password,"",false
386,trino-server-386/plugin/session-property-managers/trino-session-property-managers-386.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
386,trino-server-386/plugin/session-property-managers/trino-session-property-managers-386.jar,session-property-managers,session-property-manager.config-file,"",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.query-results-cache.enabled,"",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.view-expire-duration,"",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
386,trino-server-386/plugin/bigquery/trino-bigquery-386.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.required-replica-set,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.max-wait-time,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.cursor-batch-size,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.ssl.enabled,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.min-connections-per-host,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.read-preference,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.socket-timeout,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.schema-collection,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.connection-url,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.max-connection-idle-time,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.credentials,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.connections-per-host,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.write-concern,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.connection-timeout,"",false
386,trino-server-386/plugin/mongodb/trino-mongodb-386.jar,mongodb,mongodb.seeds,"",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.file-format,"",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.catalog.type,"",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.security,"",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.compression-codec,"",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
386,trino-server-386/plugin/iceberg/trino-iceberg-386.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
386,trino-server-386/plugin/phoenix5/trino-phoenix5-386.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
386,trino-server-386/plugin/phoenix5/trino-phoenix5-386.jar,phoenix5,phoenix.connection-url,"",false
386,trino-server-386/plugin/phoenix5/trino-phoenix5-386.jar,phoenix5,phoenix.config.resources,"",false
386,trino-server-386/plugin/thrift/trino-thrift-386.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
386,trino-server-386/plugin/thrift/trino-thrift-386.jar,thrift,trino-thrift.max-response-size,"",false
386,trino-server-386/plugin/thrift/trino-thrift-386.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.orc.max-read-size,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.orc.nested-lazy,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.balancer-enabled,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.compaction-enabled,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,metadata.db.url,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,metadata.db.filename,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.organization-enabled,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,raptor.security,"",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
386,trino-server-386/plugin/raptor-legacy/trino-raptor-legacy-386.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
386,trino-server-386/plugin/google-sheets/trino-google-sheets-386.jar,google-sheets,credentials-path,"Credential file path to google service account",false
386,trino-server-386/plugin/google-sheets/trino-google-sheets-386.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
386,trino-server-386/plugin/google-sheets/trino-google-sheets-386.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
386,trino-server-386/plugin/google-sheets/trino-google-sheets-386.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.config.resources,"Optional config files",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
386,trino-server-386/plugin/kafka/trino-kafka-386.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.batch-size,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.tls.keystore-path,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.split-size,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.speculative-execution.delay,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.speculative-execution.limit,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.contact-points,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.password,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.username,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.splits-per-node,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.tls.truststore-path,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.client.so-linger,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.retry-policy,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.client.connect-timeout,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.tls.enabled,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.fetch-size,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.client.read-timeout,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.protocol-version,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.tls.keystore-password,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.consistency-level,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.tls.truststore-password,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
386,trino-server-386/plugin/cassandra/trino-cassandra-386.jar,cassandra,cassandra.native-protocol-port,"",false
386,trino-server-386/plugin/mysql/trino-mysql-386.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
386,trino-server-386/plugin/mysql/trino-mysql-386.jar,mysql,mysql.max-reconnects,"",false
386,trino-server-386/plugin/mysql/trino-mysql-386.jar,mysql,mysql.auto-reconnect,"",false
386,trino-server-386/plugin/mysql/trino-mysql-386.jar,mysql,mysql.connection-timeout,"",false
386,trino-server-386/plugin/sqlserver/trino-sqlserver-386.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
386,trino-server-386/plugin/sqlserver/trino-sqlserver-386.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
386,trino-server-386/plugin/sqlserver/trino-sqlserver-386.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
386,trino-server-386/plugin/http-event-listener/trino-http-event-listener-386.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.client.default-operation-timeout,"",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.grouped-execution.enabled,"",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.client.disable-statistics,"",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.schema-emulation.enabled,"",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.client.master-addresses,"",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.schema-emulation.prefix,"",false
386,trino-server-386/plugin/kudu/trino-kudu-386.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,ldap.cache-ttl,"",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
386,trino-server-386/plugin/password-authenticators/trino-password-authenticators-386.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.auth.password,"",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.auth.user,"",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
386,trino-server-386/plugin/prometheus/trino-prometheus-386.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.encryption-enabled,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.endpoint,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.azure.connection-string,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.storage-class,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.region,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
386,trino-server-386/plugin/exchange-filesystem/trino-exchange-filesystem-386.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.aws.region,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.host,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.aws.access-key,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.port,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.security,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.tls.enabled,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.auth.user,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.auth.password,"",false
386,trino-server-386/plugin/elasticsearch/trino-elasticsearch-386.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
386,trino-server-386/plugin/singlestore/trino-singlestore-386.jar,singlestore,singlestore.connection-timeout,"",false
386,trino-server-386/plugin/singlestore/trino-singlestore-386.jar,singlestore,singlestore.auto-reconnect,"",false
386,trino-server-386/lib/trino-main-386.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
386,trino-server-386/lib/trino-main-386.jar,,task-retry-attempts-per-task,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
386,trino-server-386/lib/trino-main-386.jar,,sql.default-catalog,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-cpu-time,"",false
386,trino-server-386/lib/trino-main-386.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.acknowledge-pages,"",false
386,trino-server-386/lib/trino-main-386.jar,,catalog.disabled-catalogs,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.network-topology.type,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
386,trino-server-386/lib/trino-main-386.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.use-mark-distinct,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.client.timeout,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
386,trino-server-386/lib/trino-main-386.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.jwt.principal-field,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.jwt.required-issuer,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.insecure.user-mapping.file,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-scan-physical-bytes,"",false
386,trino-server-386/lib/trino-main-386.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
386,trino-server-386/lib/trino-main-386.jar,,driver.max-page-partitioning-buffer-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.min-schedule-split-batch-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.max-worker-threads,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.max-local-exchange-buffer-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,query-results.compression-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.policy,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
386,trino-server-386/lib/trino-main-386.jar,,internal-communication.shared-secret,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
386,trino-server-386/lib/trino-main-386.jar,,spill-compression-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,regex-library,"",false
386,trino-server-386/lib/trino-main-386.jar,,statistics-precalculation-for-pushdown.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,warning-collector.max-warnings,"",false
386,trino-server-386/lib/trino-main-386.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
386,trino-server-386/lib/trino-main-386.jar,,sink.max-buffer-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
386,trino-server-386/lib/trino-main-386.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
386,trino-server-386/lib/trino-main-386.jar,,task.info-update-interval,"Interval between updating task data",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
386,trino-server-386/lib/trino-main-386.jar,,query.info-url-template,"",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.page-buffer-client.max-callback-threads,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.krb5.name-type,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.max-buffer-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.low-memory-killer.policy,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.optimized-local-scheduling,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
386,trino-server-386/lib/trino-main-386.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
386,trino-server-386/lib/trino-main-386.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.push-table-write-through-union,"",false
386,trino-server-386/lib/trino-main-386.jar,,distributed-index-joins-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
386,trino-server-386/lib/trino-main-386.jar,,filter-and-project-min-output-page-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.max-error-duration,"",false
386,trino-server-386/lib/trino-main-386.jar,,adaptive-partial-aggregation.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.concurrent-request-multiplier,"",false
386,trino-server-386/lib/trino-main-386.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
386,trino-server-386/lib/trino-main-386.jar,,re2j.dfa-retries,"",false
386,trino-server-386/lib/trino-main-386.jar,,cpu-cost-weight,"",false
386,trino-server-386/lib/trino-main-386.jar,,internal-communication.https.keystore.path,"",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.max-response-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
386,trino-server-386/lib/trino-main-386.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
386,trino-server-386/lib/trino-main-386.jar,,task.status-refresh-max-wait,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,memory-cost-weight,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.jwt.user-mapping.file,"",false
386,trino-server-386/lib/trino-main-386.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.data-integrity-verification,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
386,trino-server-386/lib/trino-main-386.jar,,pages-index.eager-compaction-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
386,trino-server-386/lib/trino-main-386.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
386,trino-server-386/lib/trino-main-386.jar,,query.min-expire-age,"",false
386,trino-server-386/lib/trino-main-386.jar,,web-ui.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.optimize-hash-generation,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
386,trino-server-386/lib/trino-main-386.jar,,task.initial-splits-per-node,"",false
386,trino-server-386/lib/trino-main-386.jar,,catalog.config-dir,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.optimize-top-n-ranking,"",false
386,trino-server-386/lib/trino-main-386.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
386,trino-server-386/lib/trino-main-386.jar,,shutdown.grace-period,"",false
386,trino-server-386/lib/trino-main-386.jar,,join-distribution-type,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.max-pending-splits-per-task,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
386,trino-server-386/lib/trino-main-386.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
386,trino-server-386/lib/trino-main-386.jar,,internal-communication.https.truststore.key,"",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.deduplication-buffer-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,event-listener.config-files,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.max-index-memory,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
386,trino-server-386/lib/trino-main-386.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
386,trino-server-386/lib/trino-main-386.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
386,trino-server-386/lib/trino-main-386.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
386,trino-server-386/lib/trino-main-386.jar,,aggregation-operator-unspill-memory-limit,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.statistics-cpu-timer-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,max-spill-per-node,"",false
386,trino-server-386/lib/trino-main-386.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
386,trino-server-386/lib/trino-main-386.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
386,trino-server-386/lib/trino-main-386.jar,,query-max-spill-per-node,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
386,trino-server-386/lib/trino-main-386.jar,,distributed-sort,"",false
386,trino-server-386/lib/trino-main-386.jar,,enable-dynamic-filtering,"",false
386,trino-server-386/lib/trino-main-386.jar,,spill-encryption-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
386,trino-server-386/lib/trino-main-386.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
386,trino-server-386/lib/trino-main-386.jar,,use-preferred-write-partitioning,"",false
386,trino-server-386/lib/trino-main-386.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
386,trino-server-386/lib/trino-main-386.jar,,query.manager-executor-pool-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.remote-task.max-error-duration,"",false
386,trino-server-386/lib/trino-main-386.jar,,internal-communication.https.keystore.key,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-memory,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.dictionary-aggregation,"",false
386,trino-server-386/lib/trino-main-386.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.jwt.required-audience,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.https.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,compiler.expression-cache-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-execution-time,"",false
386,trino-server-386/lib/trino-main-386.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.prefer-partial-aggregation,"",false
386,trino-server-386/lib/trino-main-386.jar,,internal-communication.https.truststore.path,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.enable-intermediate-aggregations,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
386,trino-server-386/lib/trino-main-386.jar,,analyzer.max-grouping-sets,"",false
386,trino-server-386/lib/trino-main-386.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-length,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.info.max-age,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.complex-expression-pushdown.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.split-concurrency-adjustment-interval,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.client-threads,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-stage-count,"",false
386,trino-server-386/lib/trino-main-386.jar,,event.max-output-stage-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,failure-detector.threshold,"",false
386,trino-server-386/lib/trino-main-386.jar,,query-retry-attempts,"",false
386,trino-server-386/lib/trino-main-386.jar,,spiller-threads,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.low-memory-killer.policy,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.krb5.service-name,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.push-partial-aggregation-through-join,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.password.user-mapping.pattern,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,web-ui.shared-secret,"",false
386,trino-server-386/lib/trino-main-386.jar,,http.include-exception-in-response,"",false
386,trino-server-386/lib/trino-main-386.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
386,trino-server-386/lib/trino-main-386.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
386,trino-server-386/lib/trino-main-386.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
386,trino-server-386/lib/trino-main-386.jar,,spiller-spill-path,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.share-index-loading,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.jwt.key-file,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.krb5.principal-hostname,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.krb5.keytab,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.skip-redundant-sort,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.remote-task.min-error-duration,"",false
386,trino-server-386/lib/trino-main-386.jar,,enable-forced-exchange-below-group-id,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.per-operator-cpu-timer-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-planning-time,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.certificate.user-mapping.file,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.krb5.user-mapping.file,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.allocator-type,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.min-drivers,"",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.min-error-duration,"",false
386,trino-server-386/lib/trino-main-386.jar,,internal-communication.https.required,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-memory-per-node,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.default-filter-factor-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.max-splits-per-node,"",false
386,trino-server-386/lib/trino-main-386.jar,,access-control.config-files,"",false
386,trino-server-386/lib/trino-main-386.jar,,redistribute-writes,"",false
386,trino-server-386/lib/trino-main-386.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
386,trino-server-386/lib/trino-main-386.jar,,jmx.base-name,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
386,trino-server-386/lib/trino-main-386.jar,,sink.max-broadcast-buffer-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.password.user-mapping.file,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-concurrent-queries,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.max-partial-aggregation-memory,"",false
386,trino-server-386/lib/trino-main-386.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
386,trino-server-386/lib/trino-main-386.jar,,scale-writers,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.http-response-threads,"",false
386,trino-server-386/lib/trino-main-386.jar,,plugin.dir,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.remote-task.max-callback-threads,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-history,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
386,trino-server-386/lib/trino-main-386.jar,,spiller-max-used-space-threshold,"",false
386,trino-server-386/lib/trino-main-386.jar,,exchange.compression-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.service-thread-count,"",false
386,trino-server-386/lib/trino-main-386.jar,,web-ui.session-timeout,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.schedule-split-batch-size,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.http-timeout-threads,"",false
386,trino-server-386/lib/trino-main-386.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
386,trino-server-386/lib/trino-main-386.jar,,failure-detector.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,network-cost-weight,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,retry-policy,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
386,trino-server-386/lib/trino-main-386.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.include-coordinator,"",false
386,trino-server-386/lib/trino-main-386.jar,,discovery-server.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,http.authentication.krb5.config,"",false
386,trino-server-386/lib/trino-main-386.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
386,trino-server-386/lib/trino-main-386.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
386,trino-server-386/lib/trino-main-386.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
386,trino-server-386/lib/trino-main-386.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-queued-queries,"",false
386,trino-server-386/lib/trino-main-386.jar,,filter-and-project-min-output-page-row-count,"",false
386,trino-server-386/lib/trino-main-386.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.client.timeout,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-run-time,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.optimize-metadata-queries,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,deprecated.legacy-row-to-json-cast,"",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.min-candidates,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.ignore-downstream-preferences,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.force-single-node-output,"",false
386,trino-server-386/lib/trino-main-386.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
386,trino-server-386/lib/trino-main-386.jar,,sql.default-schema,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.execution-policy,"",false
386,trino-server-386/lib/trino-main-386.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.merge-project-with-values,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,failure-detector.heartbeat-interval,"",false
386,trino-server-386/lib/trino-main-386.jar,,parse-decimal-literals-as-double,"",false
386,trino-server-386/lib/trino-main-386.jar,,re2j.dfa-states-limit,"",false
386,trino-server-386/lib/trino-main-386.jar,,task-retry-attempts-overall,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.network-topology.file,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
386,trino-server-386/lib/trino-main-386.jar,,spill-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
386,trino-server-386/lib/trino-main-386.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
386,trino-server-386/lib/trino-main-386.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
386,trino-server-386/lib/trino-main-386.jar,,enable-stats-calculator,"",false
386,trino-server-386/lib/trino-main-386.jar,,experimental.late-materialization.enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
386,trino-server-386/lib/trino-main-386.jar,,task.max-partial-top-n-memory,"",false
386,trino-server-386/lib/trino-main-386.jar,,enable-large-dynamic-filters,"",false
386,trino-server-386/lib/trino-main-386.jar,,node-scheduler.network-topology.refresh-period,"",false
386,trino-server-386/lib/trino-main-386.jar,,query.max-total-memory,"",false
386,trino-server-386/lib/trino-main-386.jar,,iterative-optimizer-timeout,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
386,trino-server-386/lib/trino-main-386.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
386,trino-server-386/lib/trino-main-386.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
386,trino-server-386/lib/trino-main-386.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
386,trino-server-386/lib/trino-main-386.jar,,task.writer-count,"Number of writers per task",false
386,trino-server-386/lib/trino-main-386.jar,,task.cpu-timer-enabled,"",false
386,trino-server-386/lib/trino-main-386.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.push-aggregation-through-outer-join,"",false
386,trino-server-386/lib/trino-main-386.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
386,trino-server-386/lib/trino-main-386.jar,,web-ui.user,"",false
386,trino-server-386/lib/trino-main-386.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,jmx.base-name,"",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,security.refresh-period,"",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.url,"URL of the LDAP server",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,security.config-file,"",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
387,trino-server-387/plugin/kinesis/trino-plugin-toolkit-387.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
387,trino-server-387/plugin/kinesis/trino-kinesis-387.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
387,trino-server-387/plugin/clickhouse/trino-clickhouse-387.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
387,trino-server-387/plugin/clickhouse/trino-clickhouse-387.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,keystore-password-credential-name,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,keystore-type,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,case-insensitive-name-matching,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,connection-url,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,connection-password,"Password for JDBC client",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,connection-user,"user name for JDBC client",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,keystore-file-path,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,keystore-password-credential-password,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,complex-expression-pushdown.enabled,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,keystore-user-credential-password,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,keystore-password,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,join-pushdown.strategy,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,statistics.enabled,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,credential-provider.type,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,password-credential-name,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,user-credential-name,"",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
387,trino-server-387/plugin/clickhouse/trino-base-jdbc-387.jar,clickhouse,keystore-user-credential-name,"",false
387,trino-server-387/plugin/postgresql/trino-postgresql-387.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
387,trino-server-387/plugin/postgresql/trino-postgresql-387.jar,postgresql,postgresql.array-mapping,"",false
387,trino-server-387/plugin/postgresql/trino-postgresql-387.jar,postgresql,postgresql.include-system-tables,"",false
387,trino-server-387/plugin/atop/trino-atop-387.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
387,trino-server-387/plugin/atop/trino-atop-387.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
387,trino-server-387/plugin/atop/trino-atop-387.jar,atop,atop.executable-path,"",false
387,trino-server-387/plugin/atop/trino-atop-387.jar,atop,atop.security,"",false
387,trino-server-387/plugin/atop/trino-atop-387.jar,atop,atop.concurrent-readers-per-node,"",false
387,trino-server-387/plugin/atop/trino-atop-387.jar,atop,atop.max-history-days,"",false
387,trino-server-387/plugin/memory/trino-memory-387.jar,memory,memory.splits-per-node,"",false
387,trino-server-387/plugin/memory/trino-memory-387.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
387,trino-server-387/plugin/memory/trino-memory-387.jar,memory,memory.max-data-per-node,"",false
387,trino-server-387/plugin/accumulo/trino-accumulo-387.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
387,trino-server-387/plugin/accumulo/trino-accumulo-387.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
387,trino-server-387/plugin/accumulo/trino-accumulo-387.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
387,trino-server-387/plugin/accumulo/trino-accumulo-387.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
387,trino-server-387/plugin/accumulo/trino-accumulo-387.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
387,trino-server-387/plugin/accumulo/trino-accumulo-387.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
387,trino-server-387/plugin/accumulo/trino-accumulo-387.jar,accumulo,accumulo.instance,"Accumulo instance name",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.enabled,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.use-plain-text,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.prefer-broker-queries,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.forbid-segment-queries,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.tls.keystore-password,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.controller.authentication.user,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.broker.authentication.user,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.segments-per-split,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.tls.truststore-path,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.max-rows-for-broker-queries,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.tls.truststore-password,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.tls.truststore-type,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.connection-timeout,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.controller.authentication.type,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.fetch-retry-count,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.broker.authentication.type,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.controller-urls,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.port,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.tls.keystore-type,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.metadata-expiry,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.grpc.tls.keystore-path,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.controller.authentication.password,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.broker.authentication.password,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.target-segment-page-size,"",false
387,trino-server-387/plugin/pinot/trino-pinot-387.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
387,trino-server-387/plugin/resource-group-managers/trino-resource-group-managers-387.jar,resource-group-managers,jmx.base-name,"",false
387,trino-server-387/plugin/resource-group-managers/trino-resource-group-managers-387.jar,resource-group-managers,resource-groups.config-file,"",false
387,trino-server-387/plugin/resource-group-managers/trino-resource-group-managers-387.jar,resource-group-managers,resource-groups.config-db-url,"",false
387,trino-server-387/plugin/resource-group-managers/trino-resource-group-managers-387.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
387,trino-server-387/plugin/resource-group-managers/trino-resource-group-managers-387.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
387,trino-server-387/plugin/resource-group-managers/trino-resource-group-managers-387.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
387,trino-server-387/plugin/resource-group-managers/trino-resource-group-managers-387.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.default-schema,"The schema name to use in the connector",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.password,"Password for a password-protected Redis server",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.user,"Username for a Redis server",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
387,trino-server-387/plugin/redis/trino-redis-387.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
387,trino-server-387/plugin/example-http/trino-example-http-387.jar,example-http,metadata-uri,"",false
387,trino-server-387/plugin/local-file/trino-local-file-387.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
387,trino-server-387/plugin/local-file/trino-local-file-387.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
387,trino-server-387/plugin/jmx/trino-jmx-387.jar,jmx,jmx.max-entries,"",false
387,trino-server-387/plugin/jmx/trino-jmx-387.jar,jmx,jmx.dump-tables,"",false
387,trino-server-387/plugin/jmx/trino-jmx-387.jar,jmx,jmx.dump-period,"",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.synonyms.enabled,"",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.remarks-reporting.enabled,"",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.connection-pool.enabled,"",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.connection-pool.min-size,"",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.number.rounding-mode,"",false
387,trino-server-387/plugin/oracle/trino-oracle-387.jar,oracle,oracle.connection-pool.max-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.file-status-cache-expire-time,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.abfs-access-key,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.version-compatibility,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hdfs.socks-proxy,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.adl-refresh-url,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.read-mode,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-timeout,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.force-local-scheduling,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.wasb-access-key,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.max-error-retries,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.file-status-cache-tables,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.split-loader-concurrency,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs.connect.max-retries,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.proxy.protocol,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.adl-credential,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.adl-proxy-host,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.max-buffer-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-recording-path,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.max-merge-distance,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.max-buffer-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.signer-type,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.socket-timeout,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.max-read-block-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.sts.region,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.compression-codec,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3-file-system-type,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.max-connections,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs.verify-checksum,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs-timeout,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.writer.page-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.signer-class,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.sts.endpoint,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.security,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.file-status-cache-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-split-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.bookkeeper-port,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.stream-buffer-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.proxy.password,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-split-iterator-threads,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-initial-splits,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.writer.block-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.ignore-absent-partitions,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.replay-metastore-recording,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.config.resources,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.connect-timeout,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.streaming.enabled,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.wasb-storage-account,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.proxy.host,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.aws-access-key,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-register-partition-procedure,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.max-read-block-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-concurrent-file-renames,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-initial-split-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.max-merge-distance,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.max-retry-time,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs.connect.timeout,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.writer-sort-buffer-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.ssl.enabled,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.location,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dfs.domain-socket-path,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.endpoint,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.adl-client-id,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.writer-identification,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-refresh-interval,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.storage-format,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-recording-duration,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.max-backoff-time,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.abfs-storage-account,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.recursive-directories,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.proxy.username,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore-cache-ttl,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.max-client-retries,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.auto-purge,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.aws-secret-key,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.cache.data-transfer-port,"",false
387,trino-server-387/plugin/delta-lake/trino-hive-387.jar,delta-lake,hive.s3.proxy.port,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.max-initial-split-size,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.max-split-size,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.max-initial-splits,"",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
387,trino-server-387/plugin/delta-lake/trino-delta-lake-387.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
387,trino-server-387/plugin/session-property-managers/trino-session-property-managers-387.jar,session-property-managers,session-property-manager.db.url,"",false
387,trino-server-387/plugin/session-property-managers/trino-session-property-managers-387.jar,session-property-managers,session-property-manager.db.username,"",false
387,trino-server-387/plugin/session-property-managers/trino-session-property-managers-387.jar,session-property-managers,session-property-manager.db.password,"",false
387,trino-server-387/plugin/session-property-managers/trino-session-property-managers-387.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
387,trino-server-387/plugin/session-property-managers/trino-session-property-managers-387.jar,session-property-managers,session-property-manager.config-file,"",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.query-results-cache.enabled,"",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.view-expire-duration,"",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
387,trino-server-387/plugin/bigquery/trino-bigquery-387.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.seeds,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.required-replica-set,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.max-wait-time,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.cursor-batch-size,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.ssl.enabled,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.min-connections-per-host,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.read-preference,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.socket-timeout,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.schema-collection,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.connection-url,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.max-connection-idle-time,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.credentials,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.connections-per-host,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.write-concern,"",false
387,trino-server-387/plugin/mongodb/trino-mongodb-387.jar,mongodb,mongodb.connection-timeout,"",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.catalog.type,"",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.file-format,"",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.compression-codec,"",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.security,"",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
387,trino-server-387/plugin/iceberg/trino-iceberg-387.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
387,trino-server-387/plugin/phoenix5/trino-phoenix5-387.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
387,trino-server-387/plugin/phoenix5/trino-phoenix5-387.jar,phoenix5,phoenix.connection-url,"",false
387,trino-server-387/plugin/phoenix5/trino-phoenix5-387.jar,phoenix5,phoenix.config.resources,"",false
387,trino-server-387/plugin/thrift/trino-thrift-387.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
387,trino-server-387/plugin/thrift/trino-thrift-387.jar,thrift,trino-thrift.max-response-size,"",false
387,trino-server-387/plugin/thrift/trino-thrift-387.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.orc.max-read-size,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.orc.nested-lazy,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.balancer-enabled,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.compaction-enabled,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,metadata.db.url,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,metadata.db.filename,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.organization-enabled,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,raptor.security,"",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
387,trino-server-387/plugin/raptor-legacy/trino-raptor-legacy-387.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
387,trino-server-387/plugin/google-sheets/trino-google-sheets-387.jar,google-sheets,credentials-path,"Credential file path to google service account",false
387,trino-server-387/plugin/google-sheets/trino-google-sheets-387.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
387,trino-server-387/plugin/google-sheets/trino-google-sheets-387.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
387,trino-server-387/plugin/google-sheets/trino-google-sheets-387.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.config.resources,"Optional config files",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
387,trino-server-387/plugin/kafka/trino-kafka-387.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.native-protocol-port,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.batch-size,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.tls.keystore-path,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.split-size,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.speculative-execution.delay,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.speculative-execution.limit,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.contact-points,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.password,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.username,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.splits-per-node,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.tls.truststore-path,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.client.so-linger,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.retry-policy,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.client.connect-timeout,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.tls.enabled,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.fetch-size,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.client.read-timeout,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.protocol-version,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.tls.keystore-password,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.consistency-level,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.tls.truststore-password,"",false
387,trino-server-387/plugin/cassandra/trino-cassandra-387.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
387,trino-server-387/plugin/mysql/trino-mysql-387.jar,mysql,mysql.connection-timeout,"",false
387,trino-server-387/plugin/mysql/trino-mysql-387.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
387,trino-server-387/plugin/mysql/trino-mysql-387.jar,mysql,mysql.max-reconnects,"",false
387,trino-server-387/plugin/mysql/trino-mysql-387.jar,mysql,mysql.auto-reconnect,"",false
387,trino-server-387/plugin/sqlserver/trino-sqlserver-387.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
387,trino-server-387/plugin/sqlserver/trino-sqlserver-387.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
387,trino-server-387/plugin/sqlserver/trino-sqlserver-387.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
387,trino-server-387/plugin/http-event-listener/trino-http-event-listener-387.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.client.default-operation-timeout,"",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.grouped-execution.enabled,"",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.client.disable-statistics,"",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.schema-emulation.enabled,"",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.client.master-addresses,"",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.schema-emulation.prefix,"",false
387,trino-server-387/plugin/kudu/trino-kudu-387.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,ldap.cache-ttl,"",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
387,trino-server-387/plugin/password-authenticators/trino-password-authenticators-387.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.auth.password,"",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.auth.user,"",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
387,trino-server-387/plugin/prometheus/trino-prometheus-387.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.encryption-enabled,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.endpoint,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.azure.connection-string,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.storage-class,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.region,"",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
387,trino-server-387/plugin/exchange-filesystem/trino-exchange-filesystem-387.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.aws.region,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.host,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.aws.access-key,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.port,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.security,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.tls.enabled,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.auth.user,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.auth.password,"",false
387,trino-server-387/plugin/elasticsearch/trino-elasticsearch-387.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
387,trino-server-387/plugin/singlestore/trino-singlestore-387.jar,singlestore,singlestore.connection-timeout,"",false
387,trino-server-387/plugin/singlestore/trino-singlestore-387.jar,singlestore,singlestore.auto-reconnect,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.network-topology.refresh-period,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-total-memory,"",false
387,trino-server-387/lib/trino-main-387.jar,,iterative-optimizer-timeout,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
387,trino-server-387/lib/trino-main-387.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
387,trino-server-387/lib/trino-main-387.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
387,trino-server-387/lib/trino-main-387.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
387,trino-server-387/lib/trino-main-387.jar,,task.writer-count,"Number of writers per task",false
387,trino-server-387/lib/trino-main-387.jar,,task.cpu-timer-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.push-aggregation-through-outer-join,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
387,trino-server-387/lib/trino-main-387.jar,,web-ui.user,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
387,trino-server-387/lib/trino-main-387.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
387,trino-server-387/lib/trino-main-387.jar,,task-retry-attempts-per-task,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
387,trino-server-387/lib/trino-main-387.jar,,sql.default-catalog,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-cpu-time,"",false
387,trino-server-387/lib/trino-main-387.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.acknowledge-pages,"",false
387,trino-server-387/lib/trino-main-387.jar,,catalog.disabled-catalogs,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.network-topology.type,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
387,trino-server-387/lib/trino-main-387.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.use-mark-distinct,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.client.timeout,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
387,trino-server-387/lib/trino-main-387.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.jwt.principal-field,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.jwt.required-issuer,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.insecure.user-mapping.file,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-scan-physical-bytes,"",false
387,trino-server-387/lib/trino-main-387.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
387,trino-server-387/lib/trino-main-387.jar,,driver.max-page-partitioning-buffer-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.min-schedule-split-batch-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.max-worker-threads,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.max-local-exchange-buffer-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,query-results.compression-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.policy,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
387,trino-server-387/lib/trino-main-387.jar,,internal-communication.shared-secret,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
387,trino-server-387/lib/trino-main-387.jar,,spill-compression-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,regex-library,"",false
387,trino-server-387/lib/trino-main-387.jar,,statistics-precalculation-for-pushdown.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,warning-collector.max-warnings,"",false
387,trino-server-387/lib/trino-main-387.jar,,concurrent-lifespans-per-task,"Experimental: Default number of lifespans that run in parallel on each task when grouped execution is enabled",false
387,trino-server-387/lib/trino-main-387.jar,,sink.max-buffer-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
387,trino-server-387/lib/trino-main-387.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
387,trino-server-387/lib/trino-main-387.jar,,task.info-update-interval,"Interval between updating task data",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
387,trino-server-387/lib/trino-main-387.jar,,query.info-url-template,"",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.page-buffer-client.max-callback-threads,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.krb5.name-type,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.max-buffer-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.low-memory-killer.policy,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.optimized-local-scheduling,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
387,trino-server-387/lib/trino-main-387.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
387,trino-server-387/lib/trino-main-387.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.push-table-write-through-union,"",false
387,trino-server-387/lib/trino-main-387.jar,,distributed-index-joins-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
387,trino-server-387/lib/trino-main-387.jar,,filter-and-project-min-output-page-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.max-error-duration,"",false
387,trino-server-387/lib/trino-main-387.jar,,adaptive-partial-aggregation.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.concurrent-request-multiplier,"",false
387,trino-server-387/lib/trino-main-387.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
387,trino-server-387/lib/trino-main-387.jar,,re2j.dfa-retries,"",false
387,trino-server-387/lib/trino-main-387.jar,,cpu-cost-weight,"",false
387,trino-server-387/lib/trino-main-387.jar,,internal-communication.https.keystore.path,"",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.max-response-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
387,trino-server-387/lib/trino-main-387.jar,,grouped-execution-enabled,"Experimental: Use grouped execution when possible",false
387,trino-server-387/lib/trino-main-387.jar,,task.status-refresh-max-wait,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,memory-cost-weight,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.jwt.user-mapping.file,"",false
387,trino-server-387/lib/trino-main-387.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.data-integrity-verification,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
387,trino-server-387/lib/trino-main-387.jar,,pages-index.eager-compaction-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
387,trino-server-387/lib/trino-main-387.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
387,trino-server-387/lib/trino-main-387.jar,,query.min-expire-age,"",false
387,trino-server-387/lib/trino-main-387.jar,,web-ui.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.optimize-hash-generation,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
387,trino-server-387/lib/trino-main-387.jar,,task.initial-splits-per-node,"",false
387,trino-server-387/lib/trino-main-387.jar,,catalog.config-dir,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.optimize-top-n-ranking,"",false
387,trino-server-387/lib/trino-main-387.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
387,trino-server-387/lib/trino-main-387.jar,,shutdown.grace-period,"",false
387,trino-server-387/lib/trino-main-387.jar,,join-distribution-type,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.max-pending-splits-per-task,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
387,trino-server-387/lib/trino-main-387.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
387,trino-server-387/lib/trino-main-387.jar,,internal-communication.https.truststore.key,"",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.deduplication-buffer-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,event-listener.config-files,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.max-index-memory,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
387,trino-server-387/lib/trino-main-387.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
387,trino-server-387/lib/trino-main-387.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
387,trino-server-387/lib/trino-main-387.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
387,trino-server-387/lib/trino-main-387.jar,,aggregation-operator-unspill-memory-limit,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.statistics-cpu-timer-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,max-spill-per-node,"",false
387,trino-server-387/lib/trino-main-387.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
387,trino-server-387/lib/trino-main-387.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
387,trino-server-387/lib/trino-main-387.jar,,query-max-spill-per-node,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
387,trino-server-387/lib/trino-main-387.jar,,distributed-sort,"",false
387,trino-server-387/lib/trino-main-387.jar,,enable-dynamic-filtering,"",false
387,trino-server-387/lib/trino-main-387.jar,,spill-encryption-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
387,trino-server-387/lib/trino-main-387.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
387,trino-server-387/lib/trino-main-387.jar,,use-preferred-write-partitioning,"",false
387,trino-server-387/lib/trino-main-387.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
387,trino-server-387/lib/trino-main-387.jar,,query.manager-executor-pool-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.remote-task.max-error-duration,"",false
387,trino-server-387/lib/trino-main-387.jar,,internal-communication.https.keystore.key,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-memory,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.dictionary-aggregation,"",false
387,trino-server-387/lib/trino-main-387.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.jwt.required-audience,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.https.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,compiler.expression-cache-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-execution-time,"",false
387,trino-server-387/lib/trino-main-387.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.prefer-partial-aggregation,"",false
387,trino-server-387/lib/trino-main-387.jar,,internal-communication.https.truststore.path,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.enable-intermediate-aggregations,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
387,trino-server-387/lib/trino-main-387.jar,,analyzer.max-grouping-sets,"",false
387,trino-server-387/lib/trino-main-387.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-length,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.info.max-age,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.complex-expression-pushdown.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.split-concurrency-adjustment-interval,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.client-threads,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-stage-count,"",false
387,trino-server-387/lib/trino-main-387.jar,,event.max-output-stage-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,failure-detector.threshold,"",false
387,trino-server-387/lib/trino-main-387.jar,,query-retry-attempts,"",false
387,trino-server-387/lib/trino-main-387.jar,,spiller-threads,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.low-memory-killer.policy,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.krb5.service-name,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.push-partial-aggregation-through-join,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.password.user-mapping.pattern,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,web-ui.shared-secret,"",false
387,trino-server-387/lib/trino-main-387.jar,,http.include-exception-in-response,"",false
387,trino-server-387/lib/trino-main-387.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
387,trino-server-387/lib/trino-main-387.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
387,trino-server-387/lib/trino-main-387.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
387,trino-server-387/lib/trino-main-387.jar,,spiller-spill-path,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.share-index-loading,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.jwt.key-file,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.krb5.principal-hostname,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.krb5.keytab,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.skip-redundant-sort,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.remote-task.min-error-duration,"",false
387,trino-server-387/lib/trino-main-387.jar,,enable-forced-exchange-below-group-id,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.per-operator-cpu-timer-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-planning-time,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.certificate.user-mapping.file,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.krb5.user-mapping.file,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.allocator-type,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.min-drivers,"",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.min-error-duration,"",false
387,trino-server-387/lib/trino-main-387.jar,,internal-communication.https.required,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-memory-per-node,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.default-filter-factor-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.max-splits-per-node,"",false
387,trino-server-387/lib/trino-main-387.jar,,access-control.config-files,"",false
387,trino-server-387/lib/trino-main-387.jar,,redistribute-writes,"",false
387,trino-server-387/lib/trino-main-387.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
387,trino-server-387/lib/trino-main-387.jar,,jmx.base-name,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
387,trino-server-387/lib/trino-main-387.jar,,sink.max-broadcast-buffer-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.password.user-mapping.file,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-concurrent-queries,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.max-partial-aggregation-memory,"",false
387,trino-server-387/lib/trino-main-387.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
387,trino-server-387/lib/trino-main-387.jar,,scale-writers,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.http-response-threads,"",false
387,trino-server-387/lib/trino-main-387.jar,,plugin.dir,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.remote-task.max-callback-threads,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-schedule-for-grouped-execution,"Experimental: Use dynamic schedule for grouped execution when possible",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-history,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
387,trino-server-387/lib/trino-main-387.jar,,spiller-max-used-space-threshold,"",false
387,trino-server-387/lib/trino-main-387.jar,,exchange.compression-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.service-thread-count,"",false
387,trino-server-387/lib/trino-main-387.jar,,web-ui.session-timeout,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.schedule-split-batch-size,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.http-timeout-threads,"",false
387,trino-server-387/lib/trino-main-387.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
387,trino-server-387/lib/trino-main-387.jar,,failure-detector.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,network-cost-weight,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,retry-policy,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
387,trino-server-387/lib/trino-main-387.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.include-coordinator,"",false
387,trino-server-387/lib/trino-main-387.jar,,discovery-server.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,http.authentication.krb5.config,"",false
387,trino-server-387/lib/trino-main-387.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
387,trino-server-387/lib/trino-main-387.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
387,trino-server-387/lib/trino-main-387.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
387,trino-server-387/lib/trino-main-387.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-queued-queries,"",false
387,trino-server-387/lib/trino-main-387.jar,,filter-and-project-min-output-page-row-count,"",false
387,trino-server-387/lib/trino-main-387.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.client.timeout,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
387,trino-server-387/lib/trino-main-387.jar,,query.max-run-time,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.optimize-metadata-queries,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,deprecated.legacy-row-to-json-cast,"",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.min-candidates,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.ignore-downstream-preferences,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.force-single-node-output,"",false
387,trino-server-387/lib/trino-main-387.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
387,trino-server-387/lib/trino-main-387.jar,,sql.default-schema,"",false
387,trino-server-387/lib/trino-main-387.jar,,query.execution-policy,"",false
387,trino-server-387/lib/trino-main-387.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.merge-project-with-values,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,failure-detector.heartbeat-interval,"",false
387,trino-server-387/lib/trino-main-387.jar,,parse-decimal-literals-as-double,"",false
387,trino-server-387/lib/trino-main-387.jar,,re2j.dfa-states-limit,"",false
387,trino-server-387/lib/trino-main-387.jar,,task-retry-attempts-overall,"",false
387,trino-server-387/lib/trino-main-387.jar,,node-scheduler.network-topology.file,"",false
387,trino-server-387/lib/trino-main-387.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
387,trino-server-387/lib/trino-main-387.jar,,spill-enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
387,trino-server-387/lib/trino-main-387.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
387,trino-server-387/lib/trino-main-387.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
387,trino-server-387/lib/trino-main-387.jar,,enable-stats-calculator,"",false
387,trino-server-387/lib/trino-main-387.jar,,experimental.late-materialization.enabled,"",false
387,trino-server-387/lib/trino-main-387.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
387,trino-server-387/lib/trino-main-387.jar,,task.max-partial-top-n-memory,"",false
387,trino-server-387/lib/trino-main-387.jar,,enable-large-dynamic-filters,"",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
388,trino-server-388/plugin/kinesis/trino-kinesis-388.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.url,"URL of the LDAP server",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,security.refresh-period,"",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,jmx.base-name,"",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,security.config-file,"",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
388,trino-server-388/plugin/kinesis/trino-plugin-toolkit-388.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,keystore-user-credential-password,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,complex-expression-pushdown.enabled,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,keystore-password-credential-password,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,keystore-file-path,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,connection-user,"user name for JDBC client",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,connection-password,"Password for JDBC client",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,connection-url,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,case-insensitive-name-matching,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,keystore-type,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,keystore-password-credential-name,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,keystore-user-credential-name,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,user-credential-name,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,password-credential-name,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,credential-provider.type,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,statistics.enabled,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,join-pushdown.strategy,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,keystore-password,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
388,trino-server-388/plugin/clickhouse/trino-base-jdbc-388.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
388,trino-server-388/plugin/clickhouse/trino-clickhouse-388.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
388,trino-server-388/plugin/clickhouse/trino-clickhouse-388.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
388,trino-server-388/plugin/postgresql/trino-postgresql-388.jar,postgresql,postgresql.include-system-tables,"",false
388,trino-server-388/plugin/postgresql/trino-postgresql-388.jar,postgresql,postgresql.array-mapping,"",false
388,trino-server-388/plugin/postgresql/trino-postgresql-388.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
388,trino-server-388/plugin/atop/trino-atop-388.jar,atop,atop.security,"",false
388,trino-server-388/plugin/atop/trino-atop-388.jar,atop,atop.executable-path,"",false
388,trino-server-388/plugin/atop/trino-atop-388.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
388,trino-server-388/plugin/atop/trino-atop-388.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
388,trino-server-388/plugin/atop/trino-atop-388.jar,atop,atop.max-history-days,"",false
388,trino-server-388/plugin/atop/trino-atop-388.jar,atop,atop.concurrent-readers-per-node,"",false
388,trino-server-388/plugin/memory/trino-memory-388.jar,memory,memory.max-data-per-node,"",false
388,trino-server-388/plugin/memory/trino-memory-388.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
388,trino-server-388/plugin/memory/trino-memory-388.jar,memory,memory.splits-per-node,"",false
388,trino-server-388/plugin/accumulo/trino-accumulo-388.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
388,trino-server-388/plugin/accumulo/trino-accumulo-388.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
388,trino-server-388/plugin/accumulo/trino-accumulo-388.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
388,trino-server-388/plugin/accumulo/trino-accumulo-388.jar,accumulo,accumulo.instance,"Accumulo instance name",false
388,trino-server-388/plugin/accumulo/trino-accumulo-388.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
388,trino-server-388/plugin/accumulo/trino-accumulo-388.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
388,trino-server-388/plugin/accumulo/trino-accumulo-388.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.connection-timeout,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.tls.truststore-type,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.tls.truststore-password,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.max-rows-for-broker-queries,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.tls.truststore-path,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.segments-per-split,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.broker.authentication.user,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.controller.authentication.user,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.tls.keystore-password,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.forbid-segment-queries,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.prefer-broker-queries,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.use-plain-text,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.enabled,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.target-segment-page-size,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.broker.authentication.password,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.controller.authentication.password,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.tls.keystore-path,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.metadata-expiry,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.tls.keystore-type,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.grpc.port,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.controller-urls,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.broker.authentication.type,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.fetch-retry-count,"",false
388,trino-server-388/plugin/pinot/trino-pinot-388.jar,pinot,pinot.controller.authentication.type,"",false
388,trino-server-388/plugin/resource-group-managers/trino-resource-group-managers-388.jar,resource-group-managers,resource-groups.config-file,"",false
388,trino-server-388/plugin/resource-group-managers/trino-resource-group-managers-388.jar,resource-group-managers,jmx.base-name,"",false
388,trino-server-388/plugin/resource-group-managers/trino-resource-group-managers-388.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
388,trino-server-388/plugin/resource-group-managers/trino-resource-group-managers-388.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
388,trino-server-388/plugin/resource-group-managers/trino-resource-group-managers-388.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
388,trino-server-388/plugin/resource-group-managers/trino-resource-group-managers-388.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
388,trino-server-388/plugin/resource-group-managers/trino-resource-group-managers-388.jar,resource-group-managers,resource-groups.config-db-url,"",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.user,"Username for a Redis server",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.password,"Password for a password-protected Redis server",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.default-schema,"The schema name to use in the connector",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
388,trino-server-388/plugin/redis/trino-redis-388.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
388,trino-server-388/plugin/example-http/trino-example-http-388.jar,example-http,metadata-uri,"",false
388,trino-server-388/plugin/local-file/trino-local-file-388.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
388,trino-server-388/plugin/local-file/trino-local-file-388.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
388,trino-server-388/plugin/jmx/trino-jmx-388.jar,jmx,jmx.dump-tables,"",false
388,trino-server-388/plugin/jmx/trino-jmx-388.jar,jmx,jmx.max-entries,"",false
388,trino-server-388/plugin/jmx/trino-jmx-388.jar,jmx,jmx.dump-period,"",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.remarks-reporting.enabled,"",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.synonyms.enabled,"",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.connection-pool.max-size,"",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.number.rounding-mode,"",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.connection-pool.min-size,"",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
388,trino-server-388/plugin/oracle/trino-oracle-388.jar,oracle,oracle.connection-pool.enabled,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.max-initial-split-size,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.max-initial-splits,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.max-split-size,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
388,trino-server-388/plugin/delta-lake/trino-delta-lake-388.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-split-iterator-threads,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.proxy.password,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.stream-buffer-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.bookkeeper-port,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-split-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.file-status-cache-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.security,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.sts.endpoint,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.signer-class,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.writer.page-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs-timeout,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs.verify-checksum,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.max-connections,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3-file-system-type,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.compression-codec,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.sts.region,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.max-read-block-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.socket-timeout,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.signer-type,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.max-buffer-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.max-merge-distance,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-recording-path,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.max-buffer-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.adl-proxy-host,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.adl-credential,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.proxy.protocol,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs.connect.max-retries,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.split-loader-concurrency,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.file-status-cache-tables,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.max-error-retries,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.wasb-access-key,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.force-local-scheduling,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-timeout,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.read-mode,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.adl-refresh-url,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hdfs.socks-proxy,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.version-compatibility,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.abfs-access-key,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.file-status-cache-expire-time,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.proxy.port,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.data-transfer-port,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.aws-secret-key,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.auto-purge,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.max-client-retries,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-cache-ttl,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.proxy.username,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.recursive-directories,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.abfs-storage-account,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.max-backoff-time,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-recording-duration,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.storage-format,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-refresh-interval,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.writer-identification,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.adl-client-id,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.endpoint,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs.domain-socket-path,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.location,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.ssl.enabled,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.writer-sort-buffer-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs.connect.timeout,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.max-retry-time,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.max-merge-distance,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-initial-split-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-concurrent-file-renames,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.orc.max-read-block-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.allow-register-partition-procedure,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.aws-access-key,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.proxy.host,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.azure.wasb-storage-account,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.streaming.enabled,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3.connect-timeout,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.config.resources,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.replay-metastore-recording,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.ignore-absent-partitions,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,parquet.writer.block-size,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.max-initial-splits,"",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
388,trino-server-388/plugin/delta-lake/trino-hive-388.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
388,trino-server-388/plugin/session-property-managers/trino-session-property-managers-388.jar,session-property-managers,session-property-manager.db.username,"",false
388,trino-server-388/plugin/session-property-managers/trino-session-property-managers-388.jar,session-property-managers,session-property-manager.db.url,"",false
388,trino-server-388/plugin/session-property-managers/trino-session-property-managers-388.jar,session-property-managers,session-property-manager.config-file,"",false
388,trino-server-388/plugin/session-property-managers/trino-session-property-managers-388.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
388,trino-server-388/plugin/session-property-managers/trino-session-property-managers-388.jar,session-property-managers,session-property-manager.db.password,"",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.query-results-cache.enabled,"",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.view-expire-duration,"",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
388,trino-server-388/plugin/bigquery/trino-bigquery-388.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.read-preference,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.min-connections-per-host,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.ssl.enabled,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.cursor-batch-size,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.max-wait-time,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.required-replica-set,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.seeds,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.connection-timeout,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.write-concern,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.connections-per-host,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.credentials,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.max-connection-idle-time,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.connection-url,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.schema-collection,"",false
388,trino-server-388/plugin/mongodb/trino-mongodb-388.jar,mongodb,mongodb.socket-timeout,"",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.file-format,"",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.compression-codec,"",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.catalog.type,"",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
388,trino-server-388/plugin/iceberg/trino-iceberg-388.jar,iceberg,iceberg.security,"",false
388,trino-server-388/plugin/phoenix5/trino-phoenix5-388.jar,phoenix5,phoenix.connection-url,"",false
388,trino-server-388/plugin/phoenix5/trino-phoenix5-388.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
388,trino-server-388/plugin/phoenix5/trino-phoenix5-388.jar,phoenix5,phoenix.config.resources,"",false
388,trino-server-388/plugin/thrift/trino-thrift-388.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
388,trino-server-388/plugin/thrift/trino-thrift-388.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
388,trino-server-388/plugin/thrift/trino-thrift-388.jar,thrift,trino-thrift.max-response-size,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.compaction-enabled,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.balancer-enabled,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.orc.nested-lazy,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.orc.max-read-size,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.security,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.organization-enabled,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,metadata.db.filename,"",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
388,trino-server-388/plugin/raptor-legacy/trino-raptor-legacy-388.jar,raptor-legacy,metadata.db.url,"",false
388,trino-server-388/plugin/google-sheets/trino-google-sheets-388.jar,google-sheets,credentials-path,"Credential file path to google service account",false
388,trino-server-388/plugin/google-sheets/trino-google-sheets-388.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
388,trino-server-388/plugin/google-sheets/trino-google-sheets-388.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
388,trino-server-388/plugin/google-sheets/trino-google-sheets-388.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.config.resources,"Optional config files",false
388,trino-server-388/plugin/kafka/trino-kafka-388.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.client.so-linger,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.tls.truststore-path,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.splits-per-node,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.username,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.password,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.contact-points,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.speculative-execution.limit,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.speculative-execution.delay,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.split-size,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.tls.keystore-path,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.batch-size,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.native-protocol-port,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.tls.truststore-password,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.consistency-level,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.tls.keystore-password,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.protocol-version,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.client.read-timeout,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.fetch-size,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.tls.enabled,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.client.connect-timeout,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.retry-policy,"",false
388,trino-server-388/plugin/cassandra/trino-cassandra-388.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
388,trino-server-388/plugin/mysql/trino-mysql-388.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
388,trino-server-388/plugin/mysql/trino-mysql-388.jar,mysql,mysql.connection-timeout,"",false
388,trino-server-388/plugin/mysql/trino-mysql-388.jar,mysql,mysql.auto-reconnect,"",false
388,trino-server-388/plugin/mysql/trino-mysql-388.jar,mysql,mysql.max-reconnects,"",false
388,trino-server-388/plugin/sqlserver/trino-sqlserver-388.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
388,trino-server-388/plugin/sqlserver/trino-sqlserver-388.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
388,trino-server-388/plugin/sqlserver/trino-sqlserver-388.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
388,trino-server-388/plugin/http-event-listener/trino-http-event-listener-388.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.schema-emulation.prefix,"",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.client.disable-statistics,"",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.client.default-operation-timeout,"",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.client.master-addresses,"",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.schema-emulation.enabled,"",false
388,trino-server-388/plugin/kudu/trino-kudu-388.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,ldap.cache-ttl,"",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
388,trino-server-388/plugin/password-authenticators/trino-password-authenticators-388.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.auth.user,"",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.auth.password,"",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
388,trino-server-388/plugin/prometheus/trino-prometheus-388.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.endpoint,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.encryption-enabled,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.region,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.storage-class,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.azure.connection-string,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
388,trino-server-388/plugin/exchange-filesystem/trino-exchange-filesystem-388.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.port,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.aws.access-key,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.host,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.aws.region,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.auth.password,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.auth.user,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.tls.enabled,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
388,trino-server-388/plugin/elasticsearch/trino-elasticsearch-388.jar,elasticsearch,elasticsearch.security,"",false
388,trino-server-388/plugin/singlestore/trino-singlestore-388.jar,singlestore,singlestore.auto-reconnect,"",false
388,trino-server-388/plugin/singlestore/trino-singlestore-388.jar,singlestore,singlestore.connection-timeout,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-concurrent-queries,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.allocator-type,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.status-refresh-max-wait,"",false
388,trino-server-388/lib/trino-main-388.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
388,trino-server-388/lib/trino-main-388.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
388,trino-server-388/lib/trino-main-388.jar,,query.low-memory-killer.policy,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.password.user-mapping.file,"",false
388,trino-server-388/lib/trino-main-388.jar,,enable-dynamic-filtering,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-execution-time,"",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.compression-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.share-index-loading,"",false
388,trino-server-388/lib/trino-main-388.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
388,trino-server-388/lib/trino-main-388.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.page-buffer-client.max-callback-threads,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.optimize-hash-generation,"",false
388,trino-server-388/lib/trino-main-388.jar,,join-distribution-type,"",false
388,trino-server-388/lib/trino-main-388.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
388,trino-server-388/lib/trino-main-388.jar,,plugin.dir,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,query-results.compression-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
388,trino-server-388/lib/trino-main-388.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
388,trino-server-388/lib/trino-main-388.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
388,trino-server-388/lib/trino-main-388.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
388,trino-server-388/lib/trino-main-388.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-run-time,"",false
388,trino-server-388/lib/trino-main-388.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
388,trino-server-388/lib/trino-main-388.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
388,trino-server-388/lib/trino-main-388.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
388,trino-server-388/lib/trino-main-388.jar,,query.min-schedule-split-batch-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,memory-cost-weight,"",false
388,trino-server-388/lib/trino-main-388.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.data-integrity-verification,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.info-url-template,"",false
388,trino-server-388/lib/trino-main-388.jar,,jmx.base-name,"",false
388,trino-server-388/lib/trino-main-388.jar,,internal-communication.https.keystore.key,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
388,trino-server-388/lib/trino-main-388.jar,,task.writer-count,"Number of writers per task",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.krb5.principal-hostname,"",false
388,trino-server-388/lib/trino-main-388.jar,,enable-forced-exchange-below-group-id,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
388,trino-server-388/lib/trino-main-388.jar,,spill-compression-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.optimized-local-scheduling,"",false
388,trino-server-388/lib/trino-main-388.jar,,enable-large-dynamic-filters,"",false
388,trino-server-388/lib/trino-main-388.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
388,trino-server-388/lib/trino-main-388.jar,,scale-writers,"",false
388,trino-server-388/lib/trino-main-388.jar,,spiller-spill-path,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-history,"",false
388,trino-server-388/lib/trino-main-388.jar,,web-ui.user,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.krb5.user-mapping.file,"",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.min-error-duration,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
388,trino-server-388/lib/trino-main-388.jar,,access-control.config-files,"",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.acknowledge-pages,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.jwt.principal-field,"",false
388,trino-server-388/lib/trino-main-388.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
388,trino-server-388/lib/trino-main-388.jar,,task.http-timeout-threads,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.service-thread-count,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.password.user-mapping.pattern,"",false
388,trino-server-388/lib/trino-main-388.jar,,filter-and-project-min-output-page-row-count,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
388,trino-server-388/lib/trino-main-388.jar,,distributed-sort,"",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
388,trino-server-388/lib/trino-main-388.jar,,deprecated.legacy-row-to-json-cast,"",false
388,trino-server-388/lib/trino-main-388.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
388,trino-server-388/lib/trino-main-388.jar,,statistics-precalculation-for-pushdown.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
388,trino-server-388/lib/trino-main-388.jar,,query-retry-attempts,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.split-concurrency-adjustment-interval,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.use-mark-distinct,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.low-memory-killer.policy,"",false
388,trino-server-388/lib/trino-main-388.jar,,http.authentication.krb5.config,"",false
388,trino-server-388/lib/trino-main-388.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.deduplication-buffer-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.max-splits-per-node,"",false
388,trino-server-388/lib/trino-main-388.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
388,trino-server-388/lib/trino-main-388.jar,,spill-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
388,trino-server-388/lib/trino-main-388.jar,,failure-detector.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.jwt.user-mapping.file,"",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.max-buffer-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,http.include-exception-in-response,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.skip-redundant-sort,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
388,trino-server-388/lib/trino-main-388.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
388,trino-server-388/lib/trino-main-388.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
388,trino-server-388/lib/trino-main-388.jar,,internal-communication.https.truststore.key,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
388,trino-server-388/lib/trino-main-388.jar,,max-spill-per-node,"",false
388,trino-server-388/lib/trino-main-388.jar,,query-max-spill-per-node,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.cpu-timer-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,warning-collector.max-warnings,"",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
388,trino-server-388/lib/trino-main-388.jar,,enable-stats-calculator,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.merge-project-with-values,"",false
388,trino-server-388/lib/trino-main-388.jar,,compiler.expression-cache-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,catalog.config-dir,"",false
388,trino-server-388/lib/trino-main-388.jar,,web-ui.shared-secret,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-cpu-time,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.jwt.required-issuer,"",false
388,trino-server-388/lib/trino-main-388.jar,,network-cost-weight,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
388,trino-server-388/lib/trino-main-388.jar,,spiller-max-used-space-threshold,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-scan-physical-bytes,"",false
388,trino-server-388/lib/trino-main-388.jar,,retry-policy,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.client.timeout,"",false
388,trino-server-388/lib/trino-main-388.jar,,use-preferred-write-partitioning,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
388,trino-server-388/lib/trino-main-388.jar,,task-retry-attempts-overall,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.krb5.name-type,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.min-expire-age,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
388,trino-server-388/lib/trino-main-388.jar,,event-listener.config-files,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.initial-splits-per-node,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.max-partial-top-n-memory,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.network-topology.refresh-period,"",false
388,trino-server-388/lib/trino-main-388.jar,,distributed-index-joins-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
388,trino-server-388/lib/trino-main-388.jar,,internal-communication.shared-secret,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
388,trino-server-388/lib/trino-main-388.jar,,internal-communication.https.required,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
388,trino-server-388/lib/trino-main-388.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
388,trino-server-388/lib/trino-main-388.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
388,trino-server-388/lib/trino-main-388.jar,,redistribute-writes,"",false
388,trino-server-388/lib/trino-main-388.jar,,internal-communication.https.truststore.path,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.jwt.required-audience,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.default-filter-factor-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
388,trino-server-388/lib/trino-main-388.jar,,web-ui.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,sink.max-broadcast-buffer-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,re2j.dfa-states-limit,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.max-local-exchange-buffer-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.insecure.user-mapping.file,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.min-candidates,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.optimize-top-n-ranking,"",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.ignore-downstream-preferences,"",false
388,trino-server-388/lib/trino-main-388.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
388,trino-server-388/lib/trino-main-388.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
388,trino-server-388/lib/trino-main-388.jar,,query.remote-task.max-error-duration,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
388,trino-server-388/lib/trino-main-388.jar,,filter-and-project-min-output-page-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.push-table-write-through-union,"",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
388,trino-server-388/lib/trino-main-388.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
388,trino-server-388/lib/trino-main-388.jar,,sql.default-catalog,"",false
388,trino-server-388/lib/trino-main-388.jar,,catalog.disabled-catalogs,"",false
388,trino-server-388/lib/trino-main-388.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
388,trino-server-388/lib/trino-main-388.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.dictionary-aggregation,"",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.jwt.key-file,"",false
388,trino-server-388/lib/trino-main-388.jar,,regex-library,"",false
388,trino-server-388/lib/trino-main-388.jar,,aggregation-operator-unspill-memory-limit,"",false
388,trino-server-388/lib/trino-main-388.jar,,experimental.late-materialization.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-stage-count,"",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
388,trino-server-388/lib/trino-main-388.jar,,task.max-partial-aggregation-memory,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.push-aggregation-through-outer-join,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.https.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.policy,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.max-index-memory,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
388,trino-server-388/lib/trino-main-388.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
388,trino-server-388/lib/trino-main-388.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
388,trino-server-388/lib/trino-main-388.jar,,adaptive-partial-aggregation.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
388,trino-server-388/lib/trino-main-388.jar,,sql.default-schema,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.krb5.service-name,"",false
388,trino-server-388/lib/trino-main-388.jar,,parse-decimal-literals-as-double,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-total-memory,"",false
388,trino-server-388/lib/trino-main-388.jar,,iterative-optimizer-timeout,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-queued-queries,"",false
388,trino-server-388/lib/trino-main-388.jar,,cpu-cost-weight,"",false
388,trino-server-388/lib/trino-main-388.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
388,trino-server-388/lib/trino-main-388.jar,,task.info-update-interval,"Interval between updating task data",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.certificate.user-mapping.file,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-planning-time,"",false
388,trino-server-388/lib/trino-main-388.jar,,driver.max-page-partitioning-buffer-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-memory-per-node,"",false
388,trino-server-388/lib/trino-main-388.jar,,sink.max-buffer-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.remote-task.max-callback-threads,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-memory,"",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.client-threads,"",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.max-error-duration,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.schedule-split-batch-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.include-coordinator,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.max-worker-threads,"",false
388,trino-server-388/lib/trino-main-388.jar,,spiller-threads,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.remote-task.min-error-duration,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.network-topology.type,"",false
388,trino-server-388/lib/trino-main-388.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
388,trino-server-388/lib/trino-main-388.jar,,query.manager-executor-pool-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.concurrent-request-multiplier,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
388,trino-server-388/lib/trino-main-388.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.krb5.keytab,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.client.timeout,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.force-single-node-output,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
388,trino-server-388/lib/trino-main-388.jar,,event.max-output-stage-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,internal-communication.https.keystore.path,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.enable-intermediate-aggregations,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.optimize-metadata-queries,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.prefer-partial-aggregation,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.per-operator-cpu-timer-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
388,trino-server-388/lib/trino-main-388.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.push-partial-aggregation-through-join,"",false
388,trino-server-388/lib/trino-main-388.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,pages-index.eager-compaction-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
388,trino-server-388/lib/trino-main-388.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
388,trino-server-388/lib/trino-main-388.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.complex-expression-pushdown.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,spill-encryption-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,exchange.max-response-size,"",false
388,trino-server-388/lib/trino-main-388.jar,,failure-detector.heartbeat-interval,"",false
388,trino-server-388/lib/trino-main-388.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
388,trino-server-388/lib/trino-main-388.jar,,task.statistics-cpu-timer-enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
388,trino-server-388/lib/trino-main-388.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.execution-policy,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.info.max-age,"",false
388,trino-server-388/lib/trino-main-388.jar,,query.max-length,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.network-topology.file,"",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
388,trino-server-388/lib/trino-main-388.jar,,discovery-server.enabled,"",false
388,trino-server-388/lib/trino-main-388.jar,,re2j.dfa-retries,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.http-response-threads,"",false
388,trino-server-388/lib/trino-main-388.jar,,task-retry-attempts-per-task,"",false
388,trino-server-388/lib/trino-main-388.jar,,analyzer.max-grouping-sets,"",false
388,trino-server-388/lib/trino-main-388.jar,,node-scheduler.max-pending-splits-per-task,"",false
388,trino-server-388/lib/trino-main-388.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
388,trino-server-388/lib/trino-main-388.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
388,trino-server-388/lib/trino-main-388.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
388,trino-server-388/lib/trino-main-388.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
388,trino-server-388/lib/trino-main-388.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
388,trino-server-388/lib/trino-main-388.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
388,trino-server-388/lib/trino-main-388.jar,,web-ui.session-timeout,"",false
388,trino-server-388/lib/trino-main-388.jar,,task.min-drivers,"",false
388,trino-server-388/lib/trino-main-388.jar,,shutdown.grace-period,"",false
388,trino-server-388/lib/trino-main-388.jar,,failure-detector.threshold,"",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
389,trino-server-389/plugin/kinesis/trino-kinesis-389.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,security.config-file,"",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.url,"URL of the LDAP server",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,security.refresh-period,"",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
389,trino-server-389/plugin/kinesis/trino-plugin-toolkit-389.jar,kinesis,jmx.base-name,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,keystore-user-credential-name,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,user-credential-name,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,password-credential-name,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,credential-provider.type,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,statistics.enabled,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,join-pushdown.strategy,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,keystore-password,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,keystore-user-credential-password,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,complex-expression-pushdown.enabled,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,keystore-password-credential-password,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,keystore-file-path,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,connection-user,"user name for JDBC client",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,connection-password,"Password for JDBC client",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,connection-url,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,case-insensitive-name-matching,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,keystore-type,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
389,trino-server-389/plugin/clickhouse/trino-base-jdbc-389.jar,clickhouse,keystore-password-credential-name,"",false
389,trino-server-389/plugin/clickhouse/trino-clickhouse-389.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
389,trino-server-389/plugin/clickhouse/trino-clickhouse-389.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
389,trino-server-389/plugin/postgresql/trino-postgresql-389.jar,postgresql,postgresql.array-mapping,"",false
389,trino-server-389/plugin/postgresql/trino-postgresql-389.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
389,trino-server-389/plugin/postgresql/trino-postgresql-389.jar,postgresql,postgresql.include-system-tables,"",false
389,trino-server-389/plugin/atop/trino-atop-389.jar,atop,atop.max-history-days,"",false
389,trino-server-389/plugin/atop/trino-atop-389.jar,atop,atop.concurrent-readers-per-node,"",false
389,trino-server-389/plugin/atop/trino-atop-389.jar,atop,atop.security,"",false
389,trino-server-389/plugin/atop/trino-atop-389.jar,atop,atop.executable-path,"",false
389,trino-server-389/plugin/atop/trino-atop-389.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
389,trino-server-389/plugin/atop/trino-atop-389.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
389,trino-server-389/plugin/memory/trino-memory-389.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
389,trino-server-389/plugin/memory/trino-memory-389.jar,memory,memory.splits-per-node,"",false
389,trino-server-389/plugin/memory/trino-memory-389.jar,memory,memory.max-data-per-node,"",false
389,trino-server-389/plugin/accumulo/trino-accumulo-389.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
389,trino-server-389/plugin/accumulo/trino-accumulo-389.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
389,trino-server-389/plugin/accumulo/trino-accumulo-389.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
389,trino-server-389/plugin/accumulo/trino-accumulo-389.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
389,trino-server-389/plugin/accumulo/trino-accumulo-389.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
389,trino-server-389/plugin/accumulo/trino-accumulo-389.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
389,trino-server-389/plugin/accumulo/trino-accumulo-389.jar,accumulo,accumulo.instance,"Accumulo instance name",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.target-segment-page-size,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.broker.authentication.password,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.controller.authentication.password,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.tls.keystore-path,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.metadata-expiry,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.tls.keystore-type,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.port,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.controller-urls,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.broker.authentication.type,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.fetch-retry-count,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.controller.authentication.type,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.connection-timeout,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.tls.truststore-type,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.tls.truststore-password,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.max-rows-for-broker-queries,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.tls.truststore-path,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.segments-per-split,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.broker.authentication.user,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.controller.authentication.user,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.tls.keystore-password,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.forbid-segment-queries,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.prefer-broker-queries,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.use-plain-text,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.enabled,"",false
389,trino-server-389/plugin/pinot/trino-pinot-389.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
389,trino-server-389/plugin/resource-group-managers/trino-resource-group-managers-389.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
389,trino-server-389/plugin/resource-group-managers/trino-resource-group-managers-389.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
389,trino-server-389/plugin/resource-group-managers/trino-resource-group-managers-389.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
389,trino-server-389/plugin/resource-group-managers/trino-resource-group-managers-389.jar,resource-group-managers,resource-groups.config-db-url,"",false
389,trino-server-389/plugin/resource-group-managers/trino-resource-group-managers-389.jar,resource-group-managers,resource-groups.config-file,"",false
389,trino-server-389/plugin/resource-group-managers/trino-resource-group-managers-389.jar,resource-group-managers,jmx.base-name,"",false
389,trino-server-389/plugin/resource-group-managers/trino-resource-group-managers-389.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.user,"Username for a Redis server",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.password,"Password for a password-protected Redis server",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.default-schema,"The schema name to use in the connector",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
389,trino-server-389/plugin/redis/trino-redis-389.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
389,trino-server-389/plugin/example-http/trino-example-http-389.jar,example-http,metadata-uri,"",false
389,trino-server-389/plugin/local-file/trino-local-file-389.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
389,trino-server-389/plugin/local-file/trino-local-file-389.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
389,trino-server-389/plugin/jmx/trino-jmx-389.jar,jmx,jmx.dump-tables,"",false
389,trino-server-389/plugin/jmx/trino-jmx-389.jar,jmx,jmx.max-entries,"",false
389,trino-server-389/plugin/jmx/trino-jmx-389.jar,jmx,jmx.dump-period,"",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.connection-pool.max-size,"",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.number.rounding-mode,"",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.connection-pool.min-size,"",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.connection-pool.enabled,"",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.remarks-reporting.enabled,"",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.synonyms.enabled,"",false
389,trino-server-389/plugin/oracle/trino-oracle-389.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.max-initial-splits,"",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.max-split-size,"",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.max-initial-split-size,"",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
389,trino-server-389/plugin/delta-lake/trino-delta-lake-389.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.abfs-access-key,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.file-status-cache-expire-time,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.proxy.port,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.data-transfer-port,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.aws-secret-key,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.auto-purge,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.max-client-retries,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-cache-ttl,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.proxy.username,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.recursive-directories,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.abfs-storage-account,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.max-backoff-time,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-recording-duration,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.storage-format,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-refresh-interval,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.writer-identification,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.adl-client-id,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.endpoint,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs.domain-socket-path,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.location,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.ssl.enabled,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.writer-sort-buffer-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs.connect.timeout,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.max-retry-time,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.max-merge-distance,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-initial-split-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-concurrent-file-renames,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.max-read-block-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-register-partition-procedure,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.aws-access-key,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.proxy.host,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.wasb-storage-account,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.streaming.enabled,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.connect-timeout,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.config.resources,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.replay-metastore-recording,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.ignore-absent-partitions,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.writer.block-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-initial-splits,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-split-iterator-threads,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.proxy.password,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.stream-buffer-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.bookkeeper-port,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-split-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.file-status-cache-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.security,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.sts.endpoint,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.signer-class,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.writer.page-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs-timeout,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs.verify-checksum,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.max-connections,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3-file-system-type,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.compression-codec,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.sts.region,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.max-read-block-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.socket-timeout,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.signer-type,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.max-buffer-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.max-merge-distance,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-recording-path,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,parquet.max-buffer-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.adl-proxy-host,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.adl-credential,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.proxy.protocol,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs.connect.max-retries,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.split-loader-concurrency,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.file-status-cache-tables,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.max-error-retries,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.wasb-access-key,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.force-local-scheduling,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore-timeout,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.cache.read-mode,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.adl-refresh-url,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.hdfs.socks-proxy,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.metastore.version-compatibility,"",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
389,trino-server-389/plugin/delta-lake/trino-hive-389.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
389,trino-server-389/plugin/session-property-managers/trino-session-property-managers-389.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
389,trino-server-389/plugin/session-property-managers/trino-session-property-managers-389.jar,session-property-managers,session-property-manager.db.password,"",false
389,trino-server-389/plugin/session-property-managers/trino-session-property-managers-389.jar,session-property-managers,session-property-manager.db.username,"",false
389,trino-server-389/plugin/session-property-managers/trino-session-property-managers-389.jar,session-property-managers,session-property-manager.db.url,"",false
389,trino-server-389/plugin/session-property-managers/trino-session-property-managers-389.jar,session-property-managers,session-property-manager.config-file,"",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.view-expire-duration,"",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.query-results-cache.enabled,"",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
389,trino-server-389/plugin/bigquery/trino-bigquery-389.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.connection-timeout,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.write-concern,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.connections-per-host,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.credentials,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.max-connection-idle-time,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.connection-url,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.schema-collection,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.socket-timeout,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.read-preference,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.min-connections-per-host,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.ssl.enabled,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.cursor-batch-size,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.max-wait-time,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.required-replica-set,"",false
389,trino-server-389/plugin/mongodb/trino-mongodb-389.jar,mongodb,mongodb.seeds,"",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.catalog.type,"",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.security,"",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.file-format,"",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.compression-codec,"",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
389,trino-server-389/plugin/iceberg/trino-iceberg-389.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
389,trino-server-389/plugin/phoenix5/trino-phoenix5-389.jar,phoenix5,phoenix.config.resources,"",false
389,trino-server-389/plugin/phoenix5/trino-phoenix5-389.jar,phoenix5,phoenix.connection-url,"",false
389,trino-server-389/plugin/phoenix5/trino-phoenix5-389.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
389,trino-server-389/plugin/thrift/trino-thrift-389.jar,thrift,trino-thrift.max-response-size,"",false
389,trino-server-389/plugin/thrift/trino-thrift-389.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
389,trino-server-389/plugin/thrift/trino-thrift-389.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.security,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.organization-enabled,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,metadata.db.filename,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,metadata.db.url,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.compaction-enabled,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.balancer-enabled,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.orc.nested-lazy,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.orc.max-read-size,"",false
389,trino-server-389/plugin/raptor-legacy/trino-raptor-legacy-389.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
389,trino-server-389/plugin/google-sheets/trino-google-sheets-389.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
389,trino-server-389/plugin/google-sheets/trino-google-sheets-389.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
389,trino-server-389/plugin/google-sheets/trino-google-sheets-389.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
389,trino-server-389/plugin/google-sheets/trino-google-sheets-389.jar,google-sheets,credentials-path,"Credential file path to google service account",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.config.resources,"Optional config files",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
389,trino-server-389/plugin/kafka/trino-kafka-389.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.load-policy.token-aware.shuffle-replicas,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.tls.truststore-password,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.consistency-level,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.tls.keystore-password,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.protocol-version,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.client.read-timeout,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.fetch-size,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.tls.enabled,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.client.connect-timeout,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.retry-policy,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.load-policy.allowed-addresses,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.load-policy.use-token-aware,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.client.so-linger,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.tls.truststore-path,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.splits-per-node,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.username,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.password,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.contact-points,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.speculative-execution.limit,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.speculative-execution.delay,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.split-size,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.tls.keystore-path,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.batch-size,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
389,trino-server-389/plugin/cassandra/trino-cassandra-389.jar,cassandra,cassandra.native-protocol-port,"",false
389,trino-server-389/plugin/mysql/trino-mysql-389.jar,mysql,mysql.auto-reconnect,"",false
389,trino-server-389/plugin/mysql/trino-mysql-389.jar,mysql,mysql.max-reconnects,"",false
389,trino-server-389/plugin/mysql/trino-mysql-389.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
389,trino-server-389/plugin/mysql/trino-mysql-389.jar,mysql,mysql.connection-timeout,"",false
389,trino-server-389/plugin/sqlserver/trino-sqlserver-389.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
389,trino-server-389/plugin/sqlserver/trino-sqlserver-389.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
389,trino-server-389/plugin/sqlserver/trino-sqlserver-389.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
389,trino-server-389/plugin/http-event-listener/trino-http-event-listener-389.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.client.default-operation-timeout,"",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.client.master-addresses,"",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.schema-emulation.enabled,"",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.schema-emulation.prefix,"",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.client.disable-statistics,"",false
389,trino-server-389/plugin/kudu/trino-kudu-389.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,ldap.cache-ttl,"",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
389,trino-server-389/plugin/password-authenticators/trino-password-authenticators-389.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.auth.user,"",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.auth.password,"",false
389,trino-server-389/plugin/prometheus/trino-prometheus-389.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.region,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.storage-class,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.azure.connection-string,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.endpoint,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.encryption-enabled,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
389,trino-server-389/plugin/exchange-filesystem/trino-exchange-filesystem-389.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.auth.password,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.auth.user,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.tls.enabled,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.security,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.port,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.aws.access-key,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.host,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.aws.region,"",false
389,trino-server-389/plugin/elasticsearch/trino-elasticsearch-389.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
389,trino-server-389/plugin/singlestore/trino-singlestore-389.jar,singlestore,singlestore.auto-reconnect,"",false
389,trino-server-389/plugin/singlestore/trino-singlestore-389.jar,singlestore,singlestore.connection-timeout,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.low-memory-killer.policy,"",false
389,trino-server-389/lib/trino-main-389.jar,,compiler.expression-cache-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
389,trino-server-389/lib/trino-main-389.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.merge-project-with-values,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.info-url-template,"",false
389,trino-server-389/lib/trino-main-389.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
389,trino-server-389/lib/trino-main-389.jar,,task.max-index-memory,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.max-response-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
389,trino-server-389/lib/trino-main-389.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
389,trino-server-389/lib/trino-main-389.jar,,task.max-partial-aggregation-memory,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.cpu-timer-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.prefer-partial-aggregation,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.compression-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.jwt.principal-field,"",false
389,trino-server-389/lib/trino-main-389.jar,,sink.max-broadcast-buffer-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.remote-task.min-error-duration,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
389,trino-server-389/lib/trino-main-389.jar,,sql.default-catalog,"",false
389,trino-server-389/lib/trino-main-389.jar,,shutdown.grace-period,"",false
389,trino-server-389/lib/trino-main-389.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
389,trino-server-389/lib/trino-main-389.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.max-pending-splits-per-task,"",false
389,trino-server-389/lib/trino-main-389.jar,,enable-forced-exchange-below-group-id,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.deduplication-buffer-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,redistribute-writes,"",false
389,trino-server-389/lib/trino-main-389.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.client-threads,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-execution-time,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-planning-time,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-stage-count,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.remote-task.max-error-duration,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-memory-per-node,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.https.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.krb5.service-name,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.http-response-threads,"",false
389,trino-server-389/lib/trino-main-389.jar,,discovery-server.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.status-refresh-max-wait,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.default-filter-factor-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.execution-policy,"",false
389,trino-server-389/lib/trino-main-389.jar,,jmx.base-name,"",false
389,trino-server-389/lib/trino-main-389.jar,,retry-policy,"",false
389,trino-server-389/lib/trino-main-389.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
389,trino-server-389/lib/trino-main-389.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.min-drivers,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.jwt.required-issuer,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.jwt.required-audience,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
389,trino-server-389/lib/trino-main-389.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.password.user-mapping.file,"",false
389,trino-server-389/lib/trino-main-389.jar,,pages-index.eager-compaction-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.min-error-duration,"",false
389,trino-server-389/lib/trino-main-389.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
389,trino-server-389/lib/trino-main-389.jar,,enable-dynamic-filtering,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
389,trino-server-389/lib/trino-main-389.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
389,trino-server-389/lib/trino-main-389.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
389,trino-server-389/lib/trino-main-389.jar,,spill-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
389,trino-server-389/lib/trino-main-389.jar,,query.schedule-split-batch-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.split-concurrency-adjustment-interval,"",false
389,trino-server-389/lib/trino-main-389.jar,,internal-communication.https.truststore.key,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.krb5.keytab,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,parse-decimal-literals-as-double,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.optimize-hash-generation,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.network-topology.file,"",false
389,trino-server-389/lib/trino-main-389.jar,,spiller-max-used-space-threshold,"",false
389,trino-server-389/lib/trino-main-389.jar,,filter-and-project-min-output-page-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.allocator-type,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.ignore-downstream-preferences,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
389,trino-server-389/lib/trino-main-389.jar,,internal-communication.https.required,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
389,trino-server-389/lib/trino-main-389.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.push-table-write-through-union,"",false
389,trino-server-389/lib/trino-main-389.jar,,aggregation-operator-unspill-memory-limit,"",false
389,trino-server-389/lib/trino-main-389.jar,,event-listener.config-files,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.dictionary-aggregation,"",false
389,trino-server-389/lib/trino-main-389.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
389,trino-server-389/lib/trino-main-389.jar,,join-distribution-type,"",false
389,trino-server-389/lib/trino-main-389.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.push-aggregation-through-outer-join,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
389,trino-server-389/lib/trino-main-389.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.max-error-duration,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
389,trino-server-389/lib/trino-main-389.jar,,failure-detector.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,web-ui.user,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
389,trino-server-389/lib/trino-main-389.jar,,iterative-optimizer-timeout,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
389,trino-server-389/lib/trino-main-389.jar,,http.include-exception-in-response,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.min-schedule-split-batch-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,distributed-index-joins-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.max-buffer-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.network-topology.type,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.http-timeout-threads,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.min-candidates,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-scan-physical-bytes,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.optimize-top-n-ranking,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-memory,"",false
389,trino-server-389/lib/trino-main-389.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
389,trino-server-389/lib/trino-main-389.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.use-mark-distinct,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
389,trino-server-389/lib/trino-main-389.jar,,statistics-precalculation-for-pushdown.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
389,trino-server-389/lib/trino-main-389.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
389,trino-server-389/lib/trino-main-389.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
389,trino-server-389/lib/trino-main-389.jar,,query-max-spill-per-node,"",false
389,trino-server-389/lib/trino-main-389.jar,,catalog.config-dir,"",false
389,trino-server-389/lib/trino-main-389.jar,,web-ui.session-timeout,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.statistics-cpu-timer-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,query-retry-attempts,"",false
389,trino-server-389/lib/trino-main-389.jar,,warning-collector.max-warnings,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
389,trino-server-389/lib/trino-main-389.jar,,use-preferred-write-partitioning,"",false
389,trino-server-389/lib/trino-main-389.jar,,query-results.compression-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.max-partial-top-n-memory,"",false
389,trino-server-389/lib/trino-main-389.jar,,distributed-sort,"",false
389,trino-server-389/lib/trino-main-389.jar,,experimental.late-materialization.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.optimize-metadata-queries,"",false
389,trino-server-389/lib/trino-main-389.jar,,enable-stats-calculator,"",false
389,trino-server-389/lib/trino-main-389.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
389,trino-server-389/lib/trino-main-389.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
389,trino-server-389/lib/trino-main-389.jar,,task.per-operator-cpu-timer-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
389,trino-server-389/lib/trino-main-389.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
389,trino-server-389/lib/trino-main-389.jar,,re2j.dfa-states-limit,"",false
389,trino-server-389/lib/trino-main-389.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-queued-queries,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
389,trino-server-389/lib/trino-main-389.jar,,deprecated.legacy-row-to-json-cast,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.jwt.user-mapping.file,"",false
389,trino-server-389/lib/trino-main-389.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
389,trino-server-389/lib/trino-main-389.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
389,trino-server-389/lib/trino-main-389.jar,,query.low-memory-killer.policy,"",false
389,trino-server-389/lib/trino-main-389.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.complex-expression-pushdown.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,sink.max-buffer-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.concurrent-request-multiplier,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
389,trino-server-389/lib/trino-main-389.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
389,trino-server-389/lib/trino-main-389.jar,,task-retry-attempts-overall,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-history,"",false
389,trino-server-389/lib/trino-main-389.jar,,spiller-threads,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.include-coordinator,"",false
389,trino-server-389/lib/trino-main-389.jar,,internal-communication.shared-secret,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.max-splits-per-node,"",false
389,trino-server-389/lib/trino-main-389.jar,,network-cost-weight,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,failure-detector.heartbeat-interval,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.network-topology.refresh-period,"",false
389,trino-server-389/lib/trino-main-389.jar,,internal-communication.https.keystore.path,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
389,trino-server-389/lib/trino-main-389.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
389,trino-server-389/lib/trino-main-389.jar,,internal-communication.https.truststore.path,"",false
389,trino-server-389/lib/trino-main-389.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.certificate.user-mapping.file,"",false
389,trino-server-389/lib/trino-main-389.jar,,enable-large-dynamic-filters,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
389,trino-server-389/lib/trino-main-389.jar,,spiller-spill-path,"",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.policy,"",false
389,trino-server-389/lib/trino-main-389.jar,,filter-and-project-min-output-page-row-count,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.page-buffer-client.max-callback-threads,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.insecure.user-mapping.file,"",false
389,trino-server-389/lib/trino-main-389.jar,,re2j.dfa-retries,"",false
389,trino-server-389/lib/trino-main-389.jar,,memory-cost-weight,"",false
389,trino-server-389/lib/trino-main-389.jar,,failure-detector.threshold,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-length,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.jwt.key-file,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.client.timeout,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-concurrent-queries,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
389,trino-server-389/lib/trino-main-389.jar,,web-ui.shared-secret,"",false
389,trino-server-389/lib/trino-main-389.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
389,trino-server-389/lib/trino-main-389.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
389,trino-server-389/lib/trino-main-389.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.krb5.name-type,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-run-time,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.krb5.user-mapping.file,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
389,trino-server-389/lib/trino-main-389.jar,,internal-communication.https.keystore.key,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
389,trino-server-389/lib/trino-main-389.jar,,spill-compression-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
389,trino-server-389/lib/trino-main-389.jar,,regex-library,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.password.user-mapping.pattern,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-cpu-time,"",false
389,trino-server-389/lib/trino-main-389.jar,,web-ui.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,event.max-output-stage-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.min-expire-age,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.manager-executor-pool-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.share-index-loading,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.enable-intermediate-aggregations,"",false
389,trino-server-389/lib/trino-main-389.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
389,trino-server-389/lib/trino-main-389.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.skip-redundant-sort,"",false
389,trino-server-389/lib/trino-main-389.jar,,access-control.config-files,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.initial-splits-per-node,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
389,trino-server-389/lib/trino-main-389.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
389,trino-server-389/lib/trino-main-389.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
389,trino-server-389/lib/trino-main-389.jar,,adaptive-partial-aggregation.enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,scale-writers,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.client.timeout,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
389,trino-server-389/lib/trino-main-389.jar,,plugin.dir,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.data-integrity-verification,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.service-thread-count,"",false
389,trino-server-389/lib/trino-main-389.jar,,exchange.acknowledge-pages,"",false
389,trino-server-389/lib/trino-main-389.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
389,trino-server-389/lib/trino-main-389.jar,,node-scheduler.optimized-local-scheduling,"",false
389,trino-server-389/lib/trino-main-389.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
389,trino-server-389/lib/trino-main-389.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
389,trino-server-389/lib/trino-main-389.jar,,query.max-total-memory,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.krb5.principal-hostname,"",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
389,trino-server-389/lib/trino-main-389.jar,,cpu-cost-weight,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.max-worker-threads,"",false
389,trino-server-389/lib/trino-main-389.jar,,catalog.disabled-catalogs,"",false
389,trino-server-389/lib/trino-main-389.jar,,sql.default-schema,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
389,trino-server-389/lib/trino-main-389.jar,,query.remote-task.max-callback-threads,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.info.max-age,"",false
389,trino-server-389/lib/trino-main-389.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
389,trino-server-389/lib/trino-main-389.jar,,driver.max-page-partitioning-buffer-size,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.writer-count,"Number of writers per task",false
389,trino-server-389/lib/trino-main-389.jar,,spill-encryption-enabled,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
389,trino-server-389/lib/trino-main-389.jar,,task.info-update-interval,"Interval between updating task data",false
389,trino-server-389/lib/trino-main-389.jar,,http.authentication.krb5.config,"",false
389,trino-server-389/lib/trino-main-389.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.force-single-node-output,"",false
389,trino-server-389/lib/trino-main-389.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
389,trino-server-389/lib/trino-main-389.jar,,optimizer.push-partial-aggregation-through-join,"",false
389,trino-server-389/lib/trino-main-389.jar,,max-spill-per-node,"",false
389,trino-server-389/lib/trino-main-389.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
389,trino-server-389/lib/trino-main-389.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
389,trino-server-389/lib/trino-main-389.jar,,analyzer.max-grouping-sets,"",false
389,trino-server-389/lib/trino-main-389.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
389,trino-server-389/lib/trino-main-389.jar,,task-retry-attempts-per-task,"",false
389,trino-server-389/lib/trino-main-389.jar,,task.max-local-exchange-buffer-size,"",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,security.config-file,"",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.url,"URL of the LDAP server",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,security.refresh-period,"",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,jmx.base-name,"",false
390,trino-server-390/plugin/kinesis/trino-plugin-toolkit-390.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
390,trino-server-390/plugin/kinesis/trino-kinesis-390.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
390,trino-server-390/plugin/clickhouse/trino-clickhouse-390.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
390,trino-server-390/plugin/clickhouse/trino-clickhouse-390.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,user-credential-name,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,password-credential-name,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,credential-provider.type,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,statistics.enabled,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,join-pushdown.strategy,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,keystore-password,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,keystore-user-credential-password,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,complex-expression-pushdown.enabled,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,keystore-password-credential-password,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,keystore-file-path,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,connection-user,"user name for JDBC client",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,connection-password,"Password for JDBC client",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,connection-url,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,case-insensitive-name-matching,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,keystore-type,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,keystore-password-credential-name,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,keystore-user-credential-name,"",false
390,trino-server-390/plugin/clickhouse/trino-base-jdbc-390.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
390,trino-server-390/plugin/postgresql/trino-postgresql-390.jar,postgresql,postgresql.array-mapping,"",false
390,trino-server-390/plugin/postgresql/trino-postgresql-390.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
390,trino-server-390/plugin/postgresql/trino-postgresql-390.jar,postgresql,postgresql.include-system-tables,"",false
390,trino-server-390/plugin/atop/trino-atop-390.jar,atop,atop.max-history-days,"",false
390,trino-server-390/plugin/atop/trino-atop-390.jar,atop,atop.concurrent-readers-per-node,"",false
390,trino-server-390/plugin/atop/trino-atop-390.jar,atop,atop.security,"",false
390,trino-server-390/plugin/atop/trino-atop-390.jar,atop,atop.executable-path,"",false
390,trino-server-390/plugin/atop/trino-atop-390.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
390,trino-server-390/plugin/atop/trino-atop-390.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
390,trino-server-390/plugin/memory/trino-memory-390.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
390,trino-server-390/plugin/memory/trino-memory-390.jar,memory,memory.splits-per-node,"",false
390,trino-server-390/plugin/memory/trino-memory-390.jar,memory,memory.max-data-per-node,"",false
390,trino-server-390/plugin/accumulo/trino-accumulo-390.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
390,trino-server-390/plugin/accumulo/trino-accumulo-390.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
390,trino-server-390/plugin/accumulo/trino-accumulo-390.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
390,trino-server-390/plugin/accumulo/trino-accumulo-390.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
390,trino-server-390/plugin/accumulo/trino-accumulo-390.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
390,trino-server-390/plugin/accumulo/trino-accumulo-390.jar,accumulo,accumulo.instance,"Accumulo instance name",false
390,trino-server-390/plugin/accumulo/trino-accumulo-390.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.broker.authentication.password,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.controller.authentication.password,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.tls.keystore-path,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.metadata-expiry,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.tls.keystore-type,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.port,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.controller-urls,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.broker.authentication.type,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.fetch-retry-count,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.controller.authentication.type,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.connection-timeout,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.tls.truststore-type,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.tls.truststore-password,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.max-rows-for-broker-queries,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.tls.truststore-path,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.segments-per-split,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.broker.authentication.user,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.controller.authentication.user,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.tls.keystore-password,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.forbid-segment-queries,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.prefer-broker-queries,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.use-plain-text,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.enabled,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
390,trino-server-390/plugin/pinot/trino-pinot-390.jar,pinot,pinot.target-segment-page-size,"",false
390,trino-server-390/plugin/resource-group-managers/trino-resource-group-managers-390.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
390,trino-server-390/plugin/resource-group-managers/trino-resource-group-managers-390.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
390,trino-server-390/plugin/resource-group-managers/trino-resource-group-managers-390.jar,resource-group-managers,resource-groups.config-db-url,"",false
390,trino-server-390/plugin/resource-group-managers/trino-resource-group-managers-390.jar,resource-group-managers,resource-groups.config-file,"",false
390,trino-server-390/plugin/resource-group-managers/trino-resource-group-managers-390.jar,resource-group-managers,jmx.base-name,"",false
390,trino-server-390/plugin/resource-group-managers/trino-resource-group-managers-390.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
390,trino-server-390/plugin/resource-group-managers/trino-resource-group-managers-390.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.user,"Username for a Redis server",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.password,"Password for a password-protected Redis server",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.default-schema,"The schema name to use in the connector",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
390,trino-server-390/plugin/redis/trino-redis-390.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
390,trino-server-390/plugin/example-http/trino-example-http-390.jar,example-http,metadata-uri,"",false
390,trino-server-390/plugin/local-file/trino-local-file-390.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
390,trino-server-390/plugin/local-file/trino-local-file-390.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
390,trino-server-390/plugin/jmx/trino-jmx-390.jar,jmx,jmx.dump-tables,"",false
390,trino-server-390/plugin/jmx/trino-jmx-390.jar,jmx,jmx.max-entries,"",false
390,trino-server-390/plugin/jmx/trino-jmx-390.jar,jmx,jmx.dump-period,"",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.number.rounding-mode,"",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.connection-pool.min-size,"",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.connection-pool.enabled,"",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.remarks-reporting.enabled,"",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.synonyms.enabled,"",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
390,trino-server-390/plugin/oracle/trino-oracle-390.jar,oracle,oracle.connection-pool.max-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.aws-secret-key,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.auto-purge,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.max-client-retries,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-cache-ttl,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.proxy.username,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.recursive-directories,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.abfs-storage-account,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.max-backoff-time,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-recording-duration,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.storage-format,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-refresh-interval,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.writer-identification,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.adl-client-id,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.endpoint,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs.domain-socket-path,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.location,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.ssl.enabled,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.writer-sort-buffer-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs.connect.timeout,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.max-retry-time,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.max-merge-distance,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-initial-split-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-concurrent-file-renames,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.max-read-block-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-register-partition-procedure,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.aws-access-key,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.proxy.host,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.wasb-storage-account,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.streaming.enabled,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.connect-timeout,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.config.resources,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.replay-metastore-recording,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.ignore-absent-partitions,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.writer.block-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-initial-splits,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-split-iterator-threads,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.proxy.password,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.stream-buffer-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.bookkeeper-port,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-split-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.file-status-cache-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.security,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.sts.endpoint,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.signer-class,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.writer.page-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs-timeout,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs.verify-checksum,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.max-connections,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3-file-system-type,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.compression-codec,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.sts.region,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.max-read-block-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.socket-timeout,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.signer-type,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.max-buffer-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.max-merge-distance,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-recording-path,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,parquet.max-buffer-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.adl-proxy-host,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.adl-credential,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.proxy.protocol,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs.connect.max-retries,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.split-loader-concurrency,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.file-status-cache-tables,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.max-error-retries,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.wasb-access-key,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.force-local-scheduling,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore-timeout,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.read-mode,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.adl-refresh-url,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hdfs.socks-proxy,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.version-compatibility,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.abfs-access-key,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.file-status-cache-expire-time,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.s3.proxy.port,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.cache.data-transfer-port,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
390,trino-server-390/plugin/delta-lake/trino-hive-390.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.max-initial-splits,"",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.max-split-size,"",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.max-initial-split-size,"",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
390,trino-server-390/plugin/delta-lake/trino-delta-lake-390.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
390,trino-server-390/plugin/session-property-managers/trino-session-property-managers-390.jar,session-property-managers,session-property-manager.db.password,"",false
390,trino-server-390/plugin/session-property-managers/trino-session-property-managers-390.jar,session-property-managers,session-property-manager.db.username,"",false
390,trino-server-390/plugin/session-property-managers/trino-session-property-managers-390.jar,session-property-managers,session-property-manager.db.url,"",false
390,trino-server-390/plugin/session-property-managers/trino-session-property-managers-390.jar,session-property-managers,session-property-manager.config-file,"",false
390,trino-server-390/plugin/session-property-managers/trino-session-property-managers-390.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.view-expire-duration,"",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.query-results-cache.enabled,"",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
390,trino-server-390/plugin/bigquery/trino-bigquery-390.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.write-concern,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.connections-per-host,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.credentials,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.max-connection-idle-time,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.connection-url,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.schema-collection,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.socket-timeout,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.read-preference,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.min-connections-per-host,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.ssl.enabled,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.cursor-batch-size,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.max-wait-time,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.required-replica-set,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.seeds,"",false
390,trino-server-390/plugin/mongodb/trino-mongodb-390.jar,mongodb,mongodb.connection-timeout,"",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.catalog.type,"",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.security,"",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.file-format,"",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.compression-codec,"",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
390,trino-server-390/plugin/iceberg/trino-iceberg-390.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
390,trino-server-390/plugin/phoenix5/trino-phoenix5-390.jar,phoenix5,phoenix.config.resources,"",false
390,trino-server-390/plugin/phoenix5/trino-phoenix5-390.jar,phoenix5,phoenix.connection-url,"",false
390,trino-server-390/plugin/phoenix5/trino-phoenix5-390.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
390,trino-server-390/plugin/thrift/trino-thrift-390.jar,thrift,trino-thrift.max-response-size,"",false
390,trino-server-390/plugin/thrift/trino-thrift-390.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
390,trino-server-390/plugin/thrift/trino-thrift-390.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.security,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.organization-enabled,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,metadata.db.filename,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,metadata.db.url,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.compaction-enabled,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.balancer-enabled,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.orc.nested-lazy,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.orc.max-read-size,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
390,trino-server-390/plugin/raptor-legacy/trino-raptor-legacy-390.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
390,trino-server-390/plugin/google-sheets/trino-google-sheets-390.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
390,trino-server-390/plugin/google-sheets/trino-google-sheets-390.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
390,trino-server-390/plugin/google-sheets/trino-google-sheets-390.jar,google-sheets,credentials-path,"Credential file path to google service account",false
390,trino-server-390/plugin/google-sheets/trino-google-sheets-390.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.config.resources,"Optional config files",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
390,trino-server-390/plugin/kafka/trino-kafka-390.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.consistency-level,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.protocol-version,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.split-size,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.tls.keystore-path,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.client.read-timeout,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.retry-policy,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.contact-points,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.speculative-execution.limit,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.splits-per-node,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.tls.truststore-password,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.tls.enabled,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.client.connect-timeout,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.tls.truststore-path,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.fetch-size,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.native-protocol-port,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.username,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.speculative-execution.delay,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.batch-size,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.password,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.tls.keystore-password,"",false
390,trino-server-390/plugin/cassandra/trino-cassandra-390.jar,cassandra,cassandra.client.so-linger,"",false
390,trino-server-390/plugin/mysql/trino-mysql-390.jar,mysql,mysql.max-reconnects,"",false
390,trino-server-390/plugin/mysql/trino-mysql-390.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
390,trino-server-390/plugin/mysql/trino-mysql-390.jar,mysql,mysql.connection-timeout,"",false
390,trino-server-390/plugin/mysql/trino-mysql-390.jar,mysql,mysql.auto-reconnect,"",false
390,trino-server-390/plugin/sqlserver/trino-sqlserver-390.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
390,trino-server-390/plugin/sqlserver/trino-sqlserver-390.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
390,trino-server-390/plugin/sqlserver/trino-sqlserver-390.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
390,trino-server-390/plugin/http-event-listener/trino-http-event-listener-390.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.client.default-operation-timeout,"",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.client.master-addresses,"",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.schema-emulation.enabled,"",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.schema-emulation.prefix,"",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.client.disable-statistics,"",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
390,trino-server-390/plugin/kudu/trino-kudu-390.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,ldap.cache-ttl,"",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
390,trino-server-390/plugin/password-authenticators/trino-password-authenticators-390.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.auth.user,"",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.auth.password,"",false
390,trino-server-390/plugin/prometheus/trino-prometheus-390.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.region,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.storage-class,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.azure.connection-string,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.endpoint,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.encryption-enabled,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
390,trino-server-390/plugin/exchange-filesystem/trino-exchange-filesystem-390.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.auth.user,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.tls.enabled,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.security,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.port,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.aws.access-key,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.host,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.aws.region,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.auth.password,"",false
390,trino-server-390/plugin/elasticsearch/trino-elasticsearch-390.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
390,trino-server-390/plugin/singlestore/trino-singlestore-390.jar,singlestore,singlestore.auto-reconnect,"",false
390,trino-server-390/plugin/singlestore/trino-singlestore-390.jar,singlestore,singlestore.connection-timeout,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.prefer-partial-aggregation,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.compression-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.jwt.principal-field,"",false
390,trino-server-390/lib/trino-main-390.jar,,sink.max-broadcast-buffer-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.remote-task.min-error-duration,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
390,trino-server-390/lib/trino-main-390.jar,,sql.default-catalog,"",false
390,trino-server-390/lib/trino-main-390.jar,,shutdown.grace-period,"",false
390,trino-server-390/lib/trino-main-390.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
390,trino-server-390/lib/trino-main-390.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.max-pending-splits-per-task,"",false
390,trino-server-390/lib/trino-main-390.jar,,enable-forced-exchange-below-group-id,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.deduplication-buffer-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,redistribute-writes,"",false
390,trino-server-390/lib/trino-main-390.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.client-threads,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-execution-time,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-planning-time,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-stage-count,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.remote-task.max-error-duration,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-memory-per-node,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.https.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.krb5.service-name,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.http-response-threads,"",false
390,trino-server-390/lib/trino-main-390.jar,,discovery-server.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.status-refresh-max-wait,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.default-filter-factor-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.execution-policy,"",false
390,trino-server-390/lib/trino-main-390.jar,,jmx.base-name,"",false
390,trino-server-390/lib/trino-main-390.jar,,retry-policy,"",false
390,trino-server-390/lib/trino-main-390.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
390,trino-server-390/lib/trino-main-390.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.min-drivers,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.jwt.required-issuer,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.jwt.required-audience,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
390,trino-server-390/lib/trino-main-390.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.password.user-mapping.file,"",false
390,trino-server-390/lib/trino-main-390.jar,,pages-index.eager-compaction-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.min-error-duration,"",false
390,trino-server-390/lib/trino-main-390.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
390,trino-server-390/lib/trino-main-390.jar,,enable-dynamic-filtering,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
390,trino-server-390/lib/trino-main-390.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
390,trino-server-390/lib/trino-main-390.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
390,trino-server-390/lib/trino-main-390.jar,,spill-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
390,trino-server-390/lib/trino-main-390.jar,,query.schedule-split-batch-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.split-concurrency-adjustment-interval,"",false
390,trino-server-390/lib/trino-main-390.jar,,internal-communication.https.truststore.key,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.krb5.keytab,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,parse-decimal-literals-as-double,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.optimize-hash-generation,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.network-topology.file,"",false
390,trino-server-390/lib/trino-main-390.jar,,spiller-max-used-space-threshold,"",false
390,trino-server-390/lib/trino-main-390.jar,,filter-and-project-min-output-page-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.allocator-type,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.ignore-downstream-preferences,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
390,trino-server-390/lib/trino-main-390.jar,,internal-communication.https.required,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
390,trino-server-390/lib/trino-main-390.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.push-table-write-through-union,"",false
390,trino-server-390/lib/trino-main-390.jar,,aggregation-operator-unspill-memory-limit,"",false
390,trino-server-390/lib/trino-main-390.jar,,event-listener.config-files,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.dictionary-aggregation,"",false
390,trino-server-390/lib/trino-main-390.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
390,trino-server-390/lib/trino-main-390.jar,,join-distribution-type,"",false
390,trino-server-390/lib/trino-main-390.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.push-aggregation-through-outer-join,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
390,trino-server-390/lib/trino-main-390.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.max-error-duration,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
390,trino-server-390/lib/trino-main-390.jar,,failure-detector.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,web-ui.user,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
390,trino-server-390/lib/trino-main-390.jar,,iterative-optimizer-timeout,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
390,trino-server-390/lib/trino-main-390.jar,,http.include-exception-in-response,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.min-schedule-split-batch-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,distributed-index-joins-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.max-buffer-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.network-topology.type,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.http-timeout-threads,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.min-candidates,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-scan-physical-bytes,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.optimize-top-n-ranking,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-memory,"",false
390,trino-server-390/lib/trino-main-390.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
390,trino-server-390/lib/trino-main-390.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.use-mark-distinct,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
390,trino-server-390/lib/trino-main-390.jar,,statistics-precalculation-for-pushdown.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
390,trino-server-390/lib/trino-main-390.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
390,trino-server-390/lib/trino-main-390.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
390,trino-server-390/lib/trino-main-390.jar,,query-max-spill-per-node,"",false
390,trino-server-390/lib/trino-main-390.jar,,catalog.config-dir,"",false
390,trino-server-390/lib/trino-main-390.jar,,web-ui.session-timeout,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.statistics-cpu-timer-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,query-retry-attempts,"",false
390,trino-server-390/lib/trino-main-390.jar,,warning-collector.max-warnings,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
390,trino-server-390/lib/trino-main-390.jar,,use-preferred-write-partitioning,"",false
390,trino-server-390/lib/trino-main-390.jar,,query-results.compression-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.max-partial-top-n-memory,"",false
390,trino-server-390/lib/trino-main-390.jar,,distributed-sort,"",false
390,trino-server-390/lib/trino-main-390.jar,,experimental.late-materialization.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.optimize-metadata-queries,"",false
390,trino-server-390/lib/trino-main-390.jar,,enable-stats-calculator,"",false
390,trino-server-390/lib/trino-main-390.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
390,trino-server-390/lib/trino-main-390.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
390,trino-server-390/lib/trino-main-390.jar,,task.per-operator-cpu-timer-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
390,trino-server-390/lib/trino-main-390.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
390,trino-server-390/lib/trino-main-390.jar,,re2j.dfa-states-limit,"",false
390,trino-server-390/lib/trino-main-390.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-queued-queries,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
390,trino-server-390/lib/trino-main-390.jar,,deprecated.legacy-row-to-json-cast,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.jwt.user-mapping.file,"",false
390,trino-server-390/lib/trino-main-390.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
390,trino-server-390/lib/trino-main-390.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
390,trino-server-390/lib/trino-main-390.jar,,query.low-memory-killer.policy,"",false
390,trino-server-390/lib/trino-main-390.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.complex-expression-pushdown.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,sink.max-buffer-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.concurrent-request-multiplier,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
390,trino-server-390/lib/trino-main-390.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
390,trino-server-390/lib/trino-main-390.jar,,task-retry-attempts-overall,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-history,"",false
390,trino-server-390/lib/trino-main-390.jar,,spiller-threads,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.include-coordinator,"",false
390,trino-server-390/lib/trino-main-390.jar,,internal-communication.shared-secret,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.max-splits-per-node,"",false
390,trino-server-390/lib/trino-main-390.jar,,network-cost-weight,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,failure-detector.heartbeat-interval,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.network-topology.refresh-period,"",false
390,trino-server-390/lib/trino-main-390.jar,,internal-communication.https.keystore.path,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
390,trino-server-390/lib/trino-main-390.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
390,trino-server-390/lib/trino-main-390.jar,,internal-communication.https.truststore.path,"",false
390,trino-server-390/lib/trino-main-390.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.certificate.user-mapping.file,"",false
390,trino-server-390/lib/trino-main-390.jar,,enable-large-dynamic-filters,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
390,trino-server-390/lib/trino-main-390.jar,,spiller-spill-path,"",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.policy,"",false
390,trino-server-390/lib/trino-main-390.jar,,filter-and-project-min-output-page-row-count,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.page-buffer-client.max-callback-threads,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.insecure.user-mapping.file,"",false
390,trino-server-390/lib/trino-main-390.jar,,re2j.dfa-retries,"",false
390,trino-server-390/lib/trino-main-390.jar,,memory-cost-weight,"",false
390,trino-server-390/lib/trino-main-390.jar,,failure-detector.threshold,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-length,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.jwt.key-file,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.client.timeout,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-concurrent-queries,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
390,trino-server-390/lib/trino-main-390.jar,,web-ui.shared-secret,"",false
390,trino-server-390/lib/trino-main-390.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
390,trino-server-390/lib/trino-main-390.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
390,trino-server-390/lib/trino-main-390.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.krb5.name-type,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-run-time,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.krb5.user-mapping.file,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
390,trino-server-390/lib/trino-main-390.jar,,internal-communication.https.keystore.key,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
390,trino-server-390/lib/trino-main-390.jar,,spill-compression-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
390,trino-server-390/lib/trino-main-390.jar,,regex-library,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.password.user-mapping.pattern,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-cpu-time,"",false
390,trino-server-390/lib/trino-main-390.jar,,web-ui.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,event.max-output-stage-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.min-expire-age,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.manager-executor-pool-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.share-index-loading,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.enable-intermediate-aggregations,"",false
390,trino-server-390/lib/trino-main-390.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
390,trino-server-390/lib/trino-main-390.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.skip-redundant-sort,"",false
390,trino-server-390/lib/trino-main-390.jar,,access-control.config-files,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.initial-splits-per-node,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
390,trino-server-390/lib/trino-main-390.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
390,trino-server-390/lib/trino-main-390.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
390,trino-server-390/lib/trino-main-390.jar,,adaptive-partial-aggregation.enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,scale-writers,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.client.timeout,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
390,trino-server-390/lib/trino-main-390.jar,,plugin.dir,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.data-integrity-verification,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.service-thread-count,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.acknowledge-pages,"",false
390,trino-server-390/lib/trino-main-390.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
390,trino-server-390/lib/trino-main-390.jar,,node-scheduler.optimized-local-scheduling,"",false
390,trino-server-390/lib/trino-main-390.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
390,trino-server-390/lib/trino-main-390.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
390,trino-server-390/lib/trino-main-390.jar,,query.max-total-memory,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.krb5.principal-hostname,"",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
390,trino-server-390/lib/trino-main-390.jar,,cpu-cost-weight,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.max-worker-threads,"",false
390,trino-server-390/lib/trino-main-390.jar,,catalog.disabled-catalogs,"",false
390,trino-server-390/lib/trino-main-390.jar,,sql.default-schema,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
390,trino-server-390/lib/trino-main-390.jar,,query.remote-task.max-callback-threads,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.info.max-age,"",false
390,trino-server-390/lib/trino-main-390.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
390,trino-server-390/lib/trino-main-390.jar,,driver.max-page-partitioning-buffer-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.writer-count,"Number of writers per task",false
390,trino-server-390/lib/trino-main-390.jar,,spill-encryption-enabled,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
390,trino-server-390/lib/trino-main-390.jar,,task.info-update-interval,"Interval between updating task data",false
390,trino-server-390/lib/trino-main-390.jar,,http.authentication.krb5.config,"",false
390,trino-server-390/lib/trino-main-390.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.force-single-node-output,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.push-partial-aggregation-through-join,"",false
390,trino-server-390/lib/trino-main-390.jar,,max-spill-per-node,"",false
390,trino-server-390/lib/trino-main-390.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
390,trino-server-390/lib/trino-main-390.jar,,analyzer.max-grouping-sets,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
390,trino-server-390/lib/trino-main-390.jar,,task-retry-attempts-per-task,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.max-local-exchange-buffer-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.low-memory-killer.policy,"",false
390,trino-server-390/lib/trino-main-390.jar,,compiler.expression-cache-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
390,trino-server-390/lib/trino-main-390.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
390,trino-server-390/lib/trino-main-390.jar,,optimizer.merge-project-with-values,"",false
390,trino-server-390/lib/trino-main-390.jar,,query.info-url-template,"",false
390,trino-server-390/lib/trino-main-390.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
390,trino-server-390/lib/trino-main-390.jar,,task.max-index-memory,"",false
390,trino-server-390/lib/trino-main-390.jar,,exchange.max-response-size,"",false
390,trino-server-390/lib/trino-main-390.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
390,trino-server-390/lib/trino-main-390.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
390,trino-server-390/lib/trino-main-390.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
390,trino-server-390/lib/trino-main-390.jar,,task.max-partial-aggregation-memory,"",false
390,trino-server-390/lib/trino-main-390.jar,,task.cpu-timer-enabled,"",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,jmx.base-name,"",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,security.refresh-period,"",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.url,"URL of the LDAP server",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,security.config-file,"",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
391,trino-server-391/plugin/kinesis/trino-plugin-toolkit-391.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
391,trino-server-391/plugin/kinesis/trino-kinesis-391.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
391,trino-server-391/plugin/clickhouse/trino-clickhouse-391.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
391,trino-server-391/plugin/clickhouse/trino-clickhouse-391.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,keystore-user-credential-name,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,keystore-password-credential-name,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,keystore-type,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,case-insensitive-name-matching,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,connection-url,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,connection-password,"Password for JDBC client",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,connection-user,"user name for JDBC client",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,keystore-file-path,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,keystore-password-credential-password,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,complex-expression-pushdown.enabled,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,keystore-user-credential-password,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,keystore-password,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,join-pushdown.strategy,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,statistics.enabled,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,credential-provider.type,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,password-credential-name,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
391,trino-server-391/plugin/clickhouse/trino-base-jdbc-391.jar,clickhouse,user-credential-name,"",false
391,trino-server-391/plugin/postgresql/trino-postgresql-391.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
391,trino-server-391/plugin/postgresql/trino-postgresql-391.jar,postgresql,postgresql.array-mapping,"",false
391,trino-server-391/plugin/postgresql/trino-postgresql-391.jar,postgresql,postgresql.include-system-tables,"",false
391,trino-server-391/plugin/atop/trino-atop-391.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
391,trino-server-391/plugin/atop/trino-atop-391.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
391,trino-server-391/plugin/atop/trino-atop-391.jar,atop,atop.executable-path,"",false
391,trino-server-391/plugin/atop/trino-atop-391.jar,atop,atop.security,"",false
391,trino-server-391/plugin/atop/trino-atop-391.jar,atop,atop.concurrent-readers-per-node,"",false
391,trino-server-391/plugin/atop/trino-atop-391.jar,atop,atop.max-history-days,"",false
391,trino-server-391/plugin/memory/trino-memory-391.jar,memory,memory.splits-per-node,"",false
391,trino-server-391/plugin/memory/trino-memory-391.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
391,trino-server-391/plugin/memory/trino-memory-391.jar,memory,memory.max-data-per-node,"",false
391,trino-server-391/plugin/accumulo/trino-accumulo-391.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
391,trino-server-391/plugin/accumulo/trino-accumulo-391.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
391,trino-server-391/plugin/accumulo/trino-accumulo-391.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
391,trino-server-391/plugin/accumulo/trino-accumulo-391.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
391,trino-server-391/plugin/accumulo/trino-accumulo-391.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
391,trino-server-391/plugin/accumulo/trino-accumulo-391.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
391,trino-server-391/plugin/accumulo/trino-accumulo-391.jar,accumulo,accumulo.instance,"Accumulo instance name",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.enabled,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.use-plain-text,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.prefer-broker-queries,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.forbid-segment-queries,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.tls.keystore-password,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.controller.authentication.user,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.broker.authentication.user,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.segments-per-split,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.tls.truststore-path,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.max-rows-for-broker-queries,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.tls.truststore-password,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.tls.truststore-type,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.connection-timeout,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.controller.authentication.type,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.fetch-retry-count,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.broker.authentication.type,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.controller-urls,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.port,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.tls.keystore-type,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.metadata-expiry,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.grpc.tls.keystore-path,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.controller.authentication.password,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.broker.authentication.password,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.target-segment-page-size,"",false
391,trino-server-391/plugin/pinot/trino-pinot-391.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
391,trino-server-391/plugin/resource-group-managers/trino-resource-group-managers-391.jar,resource-group-managers,jmx.base-name,"",false
391,trino-server-391/plugin/resource-group-managers/trino-resource-group-managers-391.jar,resource-group-managers,resource-groups.config-file,"",false
391,trino-server-391/plugin/resource-group-managers/trino-resource-group-managers-391.jar,resource-group-managers,resource-groups.config-db-url,"",false
391,trino-server-391/plugin/resource-group-managers/trino-resource-group-managers-391.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
391,trino-server-391/plugin/resource-group-managers/trino-resource-group-managers-391.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
391,trino-server-391/plugin/resource-group-managers/trino-resource-group-managers-391.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
391,trino-server-391/plugin/resource-group-managers/trino-resource-group-managers-391.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.default-schema,"The schema name to use in the connector",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.password,"Password for a password-protected Redis server",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.user,"Username for a Redis server",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
391,trino-server-391/plugin/redis/trino-redis-391.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
391,trino-server-391/plugin/example-http/trino-example-http-391.jar,example-http,metadata-uri,"",false
391,trino-server-391/plugin/local-file/trino-local-file-391.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
391,trino-server-391/plugin/local-file/trino-local-file-391.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
391,trino-server-391/plugin/jmx/trino-jmx-391.jar,jmx,jmx.max-entries,"",false
391,trino-server-391/plugin/jmx/trino-jmx-391.jar,jmx,jmx.dump-tables,"",false
391,trino-server-391/plugin/jmx/trino-jmx-391.jar,jmx,jmx.dump-period,"",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.synonyms.enabled,"",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.remarks-reporting.enabled,"",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.connection-pool.enabled,"",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.connection-pool.min-size,"",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.number.rounding-mode,"",false
391,trino-server-391/plugin/oracle/trino-oracle-391.jar,oracle,oracle.connection-pool.max-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.compression-codec,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.proxy.username,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.writer.block-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.signer-class,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hdfs.socks-proxy,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.replay-metastore-recording,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.max-backoff-time,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.security,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.aws-access-key,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.endpoint,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.proxy.password,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.file-status-cache-expire-time,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.writer.page-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3-file-system-type,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.sts.region,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.data-transfer-port,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.sts.endpoint,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.signer-type,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.writer-identification,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.adl-client-id,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.max-merge-distance,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.config.resources,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-cache-ttl,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs.connect.timeout,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.max-client-retries,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.proxy.port,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.location,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.file-status-cache-tables,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.abfs-storage-account,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.max-connections,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.wasb-storage-account,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.streaming.enabled,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.writer-sort-buffer-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.abfs-access-key,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.file-status-cache-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.max-retry-time,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.max-merge-distance,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-refresh-interval,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs.verify-checksum,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.wasb-access-key,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.max-read-block-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-initial-split-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.ssl.enabled,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs.domain-socket-path,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.proxy.protocol,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.max-error-retries,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.storage-format,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-split-iterator-threads,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-recording-path,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.adl-proxy-host,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.force-local-scheduling,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-timeout,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.allow-register-partition-procedure,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.recursive-directories,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.max-read-block-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs-timeout,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.socket-timeout,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.bookkeeper-port,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs.connect.max-retries,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.auto-purge,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.cache.read-mode,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.ignore-absent-partitions,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.proxy.host,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-split-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.split-loader-concurrency,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.stream-buffer-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore-recording-duration,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-concurrent-file-renames,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.aws-secret-key,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,parquet.max-buffer-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.max-initial-splits,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.connect-timeout,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.adl-credential,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.version-compatibility,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.adl-refresh-url,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.orc.max-buffer-size,"",false
391,trino-server-391/plugin/delta-lake/trino-hive-391.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.max-initial-split-size,"",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.max-split-size,"",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.max-initial-splits,"",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
391,trino-server-391/plugin/delta-lake/trino-delta-lake-391.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
391,trino-server-391/plugin/session-property-managers/trino-session-property-managers-391.jar,session-property-managers,session-property-manager.db.url,"",false
391,trino-server-391/plugin/session-property-managers/trino-session-property-managers-391.jar,session-property-managers,session-property-manager.db.username,"",false
391,trino-server-391/plugin/session-property-managers/trino-session-property-managers-391.jar,session-property-managers,session-property-manager.db.password,"",false
391,trino-server-391/plugin/session-property-managers/trino-session-property-managers-391.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
391,trino-server-391/plugin/session-property-managers/trino-session-property-managers-391.jar,session-property-managers,session-property-manager.config-file,"",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.query-results-cache.enabled,"",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.view-expire-duration,"",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
391,trino-server-391/plugin/bigquery/trino-bigquery-391.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.connection-timeout,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.seeds,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.required-replica-set,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.max-wait-time,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.cursor-batch-size,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.ssl.enabled,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.min-connections-per-host,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.read-preference,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.socket-timeout,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.schema-collection,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.connection-url,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.max-connection-idle-time,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.credentials,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.connections-per-host,"",false
391,trino-server-391/plugin/mongodb/trino-mongodb-391.jar,mongodb,mongodb.write-concern,"",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.compression-codec,"",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.file-format,"",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.security,"",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.catalog.type,"",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
391,trino-server-391/plugin/iceberg/trino-iceberg-391.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
391,trino-server-391/plugin/phoenix5/trino-phoenix5-391.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
391,trino-server-391/plugin/phoenix5/trino-phoenix5-391.jar,phoenix5,phoenix.connection-url,"",false
391,trino-server-391/plugin/phoenix5/trino-phoenix5-391.jar,phoenix5,phoenix.config.resources,"",false
391,trino-server-391/plugin/thrift/trino-thrift-391.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
391,trino-server-391/plugin/thrift/trino-thrift-391.jar,thrift,trino-thrift.max-response-size,"",false
391,trino-server-391/plugin/thrift/trino-thrift-391.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.orc.max-read-size,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.orc.nested-lazy,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.balancer-enabled,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.compaction-enabled,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,metadata.db.url,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,metadata.db.filename,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.organization-enabled,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,raptor.security,"",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
391,trino-server-391/plugin/raptor-legacy/trino-raptor-legacy-391.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
391,trino-server-391/plugin/google-sheets/trino-google-sheets-391.jar,google-sheets,credentials-path,"Credential file path to google service account",false
391,trino-server-391/plugin/google-sheets/trino-google-sheets-391.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
391,trino-server-391/plugin/google-sheets/trino-google-sheets-391.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
391,trino-server-391/plugin/google-sheets/trino-google-sheets-391.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.config.resources,"Optional config files",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
391,trino-server-391/plugin/kafka/trino-kafka-391.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.password,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.batch-size,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.speculative-execution.delay,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.username,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.native-protocol-port,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.fetch-size,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.tls.truststore-path,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.client.connect-timeout,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.tls.enabled,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.tls.truststore-password,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.splits-per-node,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.speculative-execution.limit,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.contact-points,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.retry-policy,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.client.read-timeout,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.tls.keystore-path,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.split-size,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.protocol-version,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.consistency-level,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.client.so-linger,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.tls.keystore-password,"",false
391,trino-server-391/plugin/cassandra/trino-cassandra-391.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
391,trino-server-391/plugin/mysql/trino-mysql-391.jar,mysql,mysql.connection-timeout,"",false
391,trino-server-391/plugin/mysql/trino-mysql-391.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
391,trino-server-391/plugin/mysql/trino-mysql-391.jar,mysql,mysql.max-reconnects,"",false
391,trino-server-391/plugin/mysql/trino-mysql-391.jar,mysql,mysql.auto-reconnect,"",false
391,trino-server-391/plugin/sqlserver/trino-sqlserver-391.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
391,trino-server-391/plugin/sqlserver/trino-sqlserver-391.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
391,trino-server-391/plugin/sqlserver/trino-sqlserver-391.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
391,trino-server-391/plugin/http-event-listener/trino-http-event-listener-391.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.client.disable-statistics,"",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.schema-emulation.prefix,"",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.schema-emulation.enabled,"",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.client.master-addresses,"",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.client.default-operation-timeout,"",false
391,trino-server-391/plugin/kudu/trino-kudu-391.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,ldap.cache-ttl,"",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
391,trino-server-391/plugin/password-authenticators/trino-password-authenticators-391.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.auth.password,"",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.auth.user,"",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
391,trino-server-391/plugin/prometheus/trino-prometheus-391.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.encryption-enabled,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.endpoint,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.azure.connection-string,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.storage-class,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.region,"",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
391,trino-server-391/plugin/exchange-filesystem/trino-exchange-filesystem-391.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.aws.region,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.host,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.aws.access-key,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.port,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.security,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.tls.enabled,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.auth.user,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
391,trino-server-391/plugin/elasticsearch/trino-elasticsearch-391.jar,elasticsearch,elasticsearch.auth.password,"",false
391,trino-server-391/plugin/singlestore/trino-singlestore-391.jar,singlestore,singlestore.connection-timeout,"",false
391,trino-server-391/plugin/singlestore/trino-singlestore-391.jar,singlestore,singlestore.auto-reconnect,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.allocator-type,"",false
391,trino-server-391/lib/trino-main-391.jar,,max-spill-per-node,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-length,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
391,trino-server-391/lib/trino-main-391.jar,,query.remote-task.max-error-duration,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
391,trino-server-391/lib/trino-main-391.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.include-coordinator,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.prefer-partial-aggregation,"",false
391,trino-server-391/lib/trino-main-391.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
391,trino-server-391/lib/trino-main-391.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
391,trino-server-391/lib/trino-main-391.jar,,task.min-drivers,"",false
391,trino-server-391/lib/trino-main-391.jar,,statistics-precalculation-for-pushdown.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
391,trino-server-391/lib/trino-main-391.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
391,trino-server-391/lib/trino-main-391.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-memory-per-node,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.split-concurrency-adjustment-interval,"",false
391,trino-server-391/lib/trino-main-391.jar,,plugin.dir,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.low-memory-killer.policy,"",false
391,trino-server-391/lib/trino-main-391.jar,,access-control.config-files,"",false
391,trino-server-391/lib/trino-main-391.jar,,filter-and-project-min-output-page-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,http.include-exception-in-response,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large.max-size-per-filter,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.optimize-hash-generation,"",false
391,trino-server-391/lib/trino-main-391.jar,,shutdown.grace-period,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.status-refresh-max-wait,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
391,trino-server-391/lib/trino-main-391.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-total-memory,"",false
391,trino-server-391/lib/trino-main-391.jar,,spill-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
391,trino-server-391/lib/trino-main-391.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
391,trino-server-391/lib/trino-main-391.jar,,enable-dynamic-filtering,"",false
391,trino-server-391/lib/trino-main-391.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
391,trino-server-391/lib/trino-main-391.jar,,parse-decimal-literals-as-double,"",false
391,trino-server-391/lib/trino-main-391.jar,,regex-library,"",false
391,trino-server-391/lib/trino-main-391.jar,,deprecated.legacy-row-to-json-cast,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,aggregation-operator-unspill-memory-limit,"",false
391,trino-server-391/lib/trino-main-391.jar,,failure-detector.heartbeat-interval,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
391,trino-server-391/lib/trino-main-391.jar,,task-retry-attempts-per-task,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small.max-size-per-filter,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.jwt.key-file,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.policy,"",false
391,trino-server-391/lib/trino-main-391.jar,,cpu-cost-weight,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.optimized-local-scheduling,"",false
391,trino-server-391/lib/trino-main-391.jar,,sql.default-catalog,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,query-results.compression-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-memory,"",false
391,trino-server-391/lib/trino-main-391.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
391,trino-server-391/lib/trino-main-391.jar,,scale-writers,"",false
391,trino-server-391/lib/trino-main-391.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
391,trino-server-391/lib/trino-main-391.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
391,trino-server-391/lib/trino-main-391.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.max-buffer-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.max-pending-splits-per-task,"",false
391,trino-server-391/lib/trino-main-391.jar,,jmx.base-name,"",false
391,trino-server-391/lib/trino-main-391.jar,,spiller-max-used-space-threshold,"",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.min-error-duration,"",false
391,trino-server-391/lib/trino-main-391.jar,,enable-stats-calculator,"",false
391,trino-server-391/lib/trino-main-391.jar,,internal-communication.https.keystore.path,"",false
391,trino-server-391/lib/trino-main-391.jar,,internal-communication.https.keystore.key,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
391,trino-server-391/lib/trino-main-391.jar,,internal-communication.https.truststore.key,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.min-expire-age,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-planning-time,"",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.deduplication-buffer-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
391,trino-server-391/lib/trino-main-391.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
391,trino-server-391/lib/trino-main-391.jar,,failure-detector.threshold,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.dictionary-aggregation,"",false
391,trino-server-391/lib/trino-main-391.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
391,trino-server-391/lib/trino-main-391.jar,,task.share-index-loading,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.client.timeout,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.writer-count,"Number of writers per task",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
391,trino-server-391/lib/trino-main-391.jar,,task.http-response-threads,"",false
391,trino-server-391/lib/trino-main-391.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
391,trino-server-391/lib/trino-main-391.jar,,query.remote-task.max-callback-threads,"",false
391,trino-server-391/lib/trino-main-391.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
391,trino-server-391/lib/trino-main-391.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
391,trino-server-391/lib/trino-main-391.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
391,trino-server-391/lib/trino-main-391.jar,,internal-communication.https.required,"",false
391,trino-server-391/lib/trino-main-391.jar,,experimental.late-materialization.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-concurrent-queries,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.force-single-node-output,"",false
391,trino-server-391/lib/trino-main-391.jar,,task-retry-attempts-overall,"",false
391,trino-server-391/lib/trino-main-391.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
391,trino-server-391/lib/trino-main-391.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
391,trino-server-391/lib/trino-main-391.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
391,trino-server-391/lib/trino-main-391.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.concurrent-request-multiplier,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.statistics-cpu-timer-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.max-index-memory,"",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-queued-queries,"",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.client-threads,"",false
391,trino-server-391/lib/trino-main-391.jar,,spill-encryption-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.max-error-duration,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.client.timeout,"",false
391,trino-server-391/lib/trino-main-391.jar,,re2j.dfa-retries,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.jwt.user-mapping.file,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.min-candidates,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.optimize-top-n-ranking,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
391,trino-server-391/lib/trino-main-391.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.jwt.principal-field,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.network-topology.file,"",false
391,trino-server-391/lib/trino-main-391.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
391,trino-server-391/lib/trino-main-391.jar,,memory-cost-weight,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.info-update-interval,"Interval between updating task data",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.password.user-mapping.file,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.push-table-write-through-union,"",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.use-mark-distinct,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.certificate.user-mapping.file,"",false
391,trino-server-391/lib/trino-main-391.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.data-integrity-verification,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.krb5.service-name,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.jwt.required-issuer,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.max-worker-threads,"",false
391,trino-server-391/lib/trino-main-391.jar,,spill-compression-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
391,trino-server-391/lib/trino-main-391.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
391,trino-server-391/lib/trino-main-391.jar,,sink.max-buffer-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
391,trino-server-391/lib/trino-main-391.jar,,network-cost-weight,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.jwt.required-audience,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
391,trino-server-391/lib/trino-main-391.jar,,failure-detector.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,sink.max-broadcast-buffer-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.optimize-metadata-queries,"",false
391,trino-server-391/lib/trino-main-391.jar,,filter-and-project-min-output-page-row-count,"",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,query-max-spill-per-node,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.max-partial-top-n-memory,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
391,trino-server-391/lib/trino-main-391.jar,,adaptive-partial-aggregation.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,re2j.dfa-states-limit,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.skip-redundant-sort,"",false
391,trino-server-391/lib/trino-main-391.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
391,trino-server-391/lib/trino-main-391.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
391,trino-server-391/lib/trino-main-391.jar,,task.cpu-timer-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.krb5.principal-hostname,"",false
391,trino-server-391/lib/trino-main-391.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.password.user-mapping.pattern,"",false
391,trino-server-391/lib/trino-main-391.jar,,web-ui.session-timeout,"",false
391,trino-server-391/lib/trino-main-391.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
391,trino-server-391/lib/trino-main-391.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
391,trino-server-391/lib/trino-main-391.jar,,query.remote-task.min-error-duration,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
391,trino-server-391/lib/trino-main-391.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
391,trino-server-391/lib/trino-main-391.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
391,trino-server-391/lib/trino-main-391.jar,,query.info-url-template,"",false
391,trino-server-391/lib/trino-main-391.jar,,analyzer.max-grouping-sets,"",false
391,trino-server-391/lib/trino-main-391.jar,,join-distribution-type,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.https.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.min-schedule-split-batch-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,spiller-threads,"",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
391,trino-server-391/lib/trino-main-391.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
391,trino-server-391/lib/trino-main-391.jar,,query.schedule-split-batch-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,catalog.config-dir,"",false
391,trino-server-391/lib/trino-main-391.jar,,event-listener.config-files,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
391,trino-server-391/lib/trino-main-391.jar,,task.max-partial-aggregation-memory,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-execution-time,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
391,trino-server-391/lib/trino-main-391.jar,,spiller-spill-path,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,web-ui.shared-secret,"",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.compression-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.manager-executor-pool-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.execution-policy,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.krb5.name-type,"",false
391,trino-server-391/lib/trino-main-391.jar,,redistribute-writes,"",false
391,trino-server-391/lib/trino-main-391.jar,,iterative-optimizer-timeout,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.insecure.user-mapping.file,"",false
391,trino-server-391/lib/trino-main-391.jar,,use-preferred-write-partitioning,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
391,trino-server-391/lib/trino-main-391.jar,,internal-communication.shared-secret,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.default-filter-factor-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.enable-intermediate-aggregations,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
391,trino-server-391/lib/trino-main-391.jar,,distributed-index-joins-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-scan-physical-bytes,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.krb5.user-mapping.file,"",false
391,trino-server-391/lib/trino-main-391.jar,,event.max-output-stage-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,enable-forced-exchange-below-group-id,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-history,"",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.max-response-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
391,trino-server-391/lib/trino-main-391.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-cpu-time,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-run-time,"",false
391,trino-server-391/lib/trino-main-391.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.network-topology.refresh-period,"",false
391,trino-server-391/lib/trino-main-391.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
391,trino-server-391/lib/trino-main-391.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
391,trino-server-391/lib/trino-main-391.jar,,task.per-operator-cpu-timer-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,internal-communication.https.truststore.path,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.max-stage-count,"",false
391,trino-server-391/lib/trino-main-391.jar,,sql.default-schema,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.page-buffer-client.max-callback-threads,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,retry-policy,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.max-splits-per-node,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.krb5.keytab,"",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.ignore-downstream-preferences,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.max-local-exchange-buffer-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,compiler.expression-cache-size,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
391,trino-server-391/lib/trino-main-391.jar,,discovery-server.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
391,trino-server-391/lib/trino-main-391.jar,,pages-index.eager-compaction-enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,http.authentication.krb5.config,"",false
391,trino-server-391/lib/trino-main-391.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
391,trino-server-391/lib/trino-main-391.jar,,web-ui.user,"",false
391,trino-server-391/lib/trino-main-391.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
391,trino-server-391/lib/trino-main-391.jar,,task.info.max-age,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.complex-expression-pushdown.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
391,trino-server-391/lib/trino-main-391.jar,,exchange.acknowledge-pages,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.http-timeout-threads,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
391,trino-server-391/lib/trino-main-391.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
391,trino-server-391/lib/trino-main-391.jar,,warning-collector.max-warnings,"",false
391,trino-server-391/lib/trino-main-391.jar,,query-retry-attempts,"",false
391,trino-server-391/lib/trino-main-391.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,task.low-memory-killer.policy,"",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
391,trino-server-391/lib/trino-main-391.jar,,task.initial-splits-per-node,"",false
391,trino-server-391/lib/trino-main-391.jar,,web-ui.enabled,"",false
391,trino-server-391/lib/trino-main-391.jar,,node-scheduler.network-topology.type,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.push-partial-aggregation-through-join,"",false
391,trino-server-391/lib/trino-main-391.jar,,catalog.disabled-catalogs,"",false
391,trino-server-391/lib/trino-main-391.jar,,enable-large-dynamic-filters,"",false
391,trino-server-391/lib/trino-main-391.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.merge-project-with-values,"",false
391,trino-server-391/lib/trino-main-391.jar,,distributed-sort,"",false
391,trino-server-391/lib/trino-main-391.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
391,trino-server-391/lib/trino-main-391.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
391,trino-server-391/lib/trino-main-391.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.push-aggregation-through-outer-join,"",false
391,trino-server-391/lib/trino-main-391.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
391,trino-server-391/lib/trino-main-391.jar,,driver.max-page-partitioning-buffer-size,"",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.url,"URL of the LDAP server",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,security.config-file,"",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,jmx.base-name,"",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
392,trino-server-392/plugin/kinesis/trino-plugin-toolkit-392.jar,kinesis,security.refresh-period,"",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
392,trino-server-392/plugin/kinesis/trino-kinesis-392.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
392,trino-server-392/plugin/clickhouse/trino-clickhouse-392.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
392,trino-server-392/plugin/clickhouse/trino-clickhouse-392.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,complex-expression-pushdown.enabled,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,keystore-user-credential-password,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,keystore-password,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,join-pushdown.strategy,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,statistics.enabled,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,credential-provider.type,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,password-credential-name,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,user-credential-name,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,keystore-user-credential-name,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,keystore-password-credential-name,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,keystore-type,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,case-insensitive-name-matching,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,connection-url,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,connection-password,"Password for JDBC client",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,connection-user,"user name for JDBC client",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,keystore-file-path,"",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
392,trino-server-392/plugin/clickhouse/trino-base-jdbc-392.jar,clickhouse,keystore-password-credential-password,"",false
392,trino-server-392/plugin/postgresql/trino-postgresql-392.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
392,trino-server-392/plugin/postgresql/trino-postgresql-392.jar,postgresql,postgresql.array-mapping,"",false
392,trino-server-392/plugin/postgresql/trino-postgresql-392.jar,postgresql,postgresql.include-system-tables,"",false
392,trino-server-392/plugin/atop/trino-atop-392.jar,atop,atop.concurrent-readers-per-node,"",false
392,trino-server-392/plugin/atop/trino-atop-392.jar,atop,atop.max-history-days,"",false
392,trino-server-392/plugin/atop/trino-atop-392.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
392,trino-server-392/plugin/atop/trino-atop-392.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
392,trino-server-392/plugin/atop/trino-atop-392.jar,atop,atop.executable-path,"",false
392,trino-server-392/plugin/atop/trino-atop-392.jar,atop,atop.security,"",false
392,trino-server-392/plugin/memory/trino-memory-392.jar,memory,memory.splits-per-node,"",false
392,trino-server-392/plugin/memory/trino-memory-392.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
392,trino-server-392/plugin/memory/trino-memory-392.jar,memory,memory.max-data-per-node,"",false
392,trino-server-392/plugin/accumulo/trino-accumulo-392.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
392,trino-server-392/plugin/accumulo/trino-accumulo-392.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
392,trino-server-392/plugin/accumulo/trino-accumulo-392.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
392,trino-server-392/plugin/accumulo/trino-accumulo-392.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
392,trino-server-392/plugin/accumulo/trino-accumulo-392.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
392,trino-server-392/plugin/accumulo/trino-accumulo-392.jar,accumulo,accumulo.instance,"Accumulo instance name",false
392,trino-server-392/plugin/accumulo/trino-accumulo-392.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.tls.truststore-path,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.max-rows-for-broker-queries,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.tls.truststore-password,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.tls.truststore-type,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.connection-timeout,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.controller.authentication.type,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.fetch-retry-count,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.broker.authentication.type,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.controller-urls,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.port,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.tls.keystore-type,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.metadata-expiry,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.tls.keystore-path,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.controller.authentication.password,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.broker.authentication.password,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.target-segment-page-size,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.enabled,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.use-plain-text,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.prefer-broker-queries,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.forbid-segment-queries,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.tls.keystore-password,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.controller.authentication.user,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.broker.authentication.user,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.segments-per-split,"",false
392,trino-server-392/plugin/pinot/trino-pinot-392.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
392,trino-server-392/plugin/resource-group-managers/trino-resource-group-managers-392.jar,resource-group-managers,resource-groups.config-file,"",false
392,trino-server-392/plugin/resource-group-managers/trino-resource-group-managers-392.jar,resource-group-managers,resource-groups.config-db-url,"",false
392,trino-server-392/plugin/resource-group-managers/trino-resource-group-managers-392.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
392,trino-server-392/plugin/resource-group-managers/trino-resource-group-managers-392.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
392,trino-server-392/plugin/resource-group-managers/trino-resource-group-managers-392.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
392,trino-server-392/plugin/resource-group-managers/trino-resource-group-managers-392.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
392,trino-server-392/plugin/resource-group-managers/trino-resource-group-managers-392.jar,resource-group-managers,jmx.base-name,"",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.password,"Password for a password-protected Redis server",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.user,"Username for a Redis server",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.default-schema,"The schema name to use in the connector",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
392,trino-server-392/plugin/redis/trino-redis-392.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
392,trino-server-392/plugin/example-http/trino-example-http-392.jar,example-http,metadata-uri,"",false
392,trino-server-392/plugin/local-file/trino-local-file-392.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
392,trino-server-392/plugin/local-file/trino-local-file-392.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
392,trino-server-392/plugin/jmx/trino-jmx-392.jar,jmx,jmx.dump-period,"",false
392,trino-server-392/plugin/jmx/trino-jmx-392.jar,jmx,jmx.max-entries,"",false
392,trino-server-392/plugin/jmx/trino-jmx-392.jar,jmx,jmx.dump-tables,"",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.connection-pool.enabled,"",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.connection-pool.min-size,"",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.number.rounding-mode,"",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.connection-pool.max-size,"",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.synonyms.enabled,"",false
392,trino-server-392/plugin/oracle/trino-oracle-392.jar,oracle,oracle.remarks-reporting.enabled,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.wasb-access-key,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.max-read-block-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-initial-split-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.ssl.enabled,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs.domain-socket-path,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.proxy.protocol,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.max-error-retries,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.storage-format,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-split-iterator-threads,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-recording-path,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.adl-proxy-host,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.force-local-scheduling,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-timeout,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-register-partition-procedure,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.recursive-directories,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.max-read-block-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs-timeout,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.socket-timeout,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.bookkeeper-port,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs.connect.max-retries,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.auto-purge,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.read-mode,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.ignore-absent-partitions,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.proxy.host,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-split-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.split-loader-concurrency,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.stream-buffer-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-recording-duration,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-concurrent-file-renames,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.aws-secret-key,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.max-buffer-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-initial-splits,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.connect-timeout,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.adl-credential,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.version-compatibility,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.adl-refresh-url,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.max-buffer-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.compression-codec,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.proxy.username,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.writer.block-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.signer-class,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hdfs.socks-proxy,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.replay-metastore-recording,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.max-backoff-time,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.security,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.aws-access-key,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.endpoint,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.proxy.password,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.file-status-cache-expire-time,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.writer.page-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3-file-system-type,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.sts.region,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.data-transfer-port,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.sts.endpoint,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.signer-type,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.writer-identification,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.adl-client-id,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.max-merge-distance,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.config.resources,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-cache-ttl,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs.connect.timeout,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.max-client-retries,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.proxy.port,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.location,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.file-status-cache-tables,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.abfs-storage-account,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.max-connections,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.wasb-storage-account,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.streaming.enabled,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.writer-sort-buffer-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.azure.abfs-access-key,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.file-status-cache-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.max-retry-time,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,parquet.max-merge-distance,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore-refresh-interval,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.dfs.verify-checksum,"",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
392,trino-server-392/plugin/delta-lake/trino-hive-392.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.max-split-size,"",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.max-initial-splits,"",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.max-initial-split-size,"",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
392,trino-server-392/plugin/delta-lake/trino-delta-lake-392.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
392,trino-server-392/plugin/session-property-managers/trino-session-property-managers-392.jar,session-property-managers,session-property-manager.db.password,"",false
392,trino-server-392/plugin/session-property-managers/trino-session-property-managers-392.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
392,trino-server-392/plugin/session-property-managers/trino-session-property-managers-392.jar,session-property-managers,session-property-manager.config-file,"",false
392,trino-server-392/plugin/session-property-managers/trino-session-property-managers-392.jar,session-property-managers,session-property-manager.db.url,"",false
392,trino-server-392/plugin/session-property-managers/trino-session-property-managers-392.jar,session-property-managers,session-property-manager.db.username,"",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.query-results-cache.enabled,"",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.view-expire-duration,"",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
392,trino-server-392/plugin/bigquery/trino-bigquery-392.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.socket-timeout,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.schema-collection,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.connection-url,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.max-connection-idle-time,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.credentials,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.connections-per-host,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.write-concern,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.connection-timeout,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.seeds,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.required-replica-set,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.max-wait-time,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.cursor-batch-size,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.ssl.enabled,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.min-connections-per-host,"",false
392,trino-server-392/plugin/mongodb/trino-mongodb-392.jar,mongodb,mongodb.read-preference,"",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.file-format,"",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.security,"",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.catalog.type,"",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
392,trino-server-392/plugin/iceberg/trino-iceberg-392.jar,iceberg,iceberg.compression-codec,"",false
392,trino-server-392/plugin/phoenix5/trino-phoenix5-392.jar,phoenix5,phoenix.config.resources,"",false
392,trino-server-392/plugin/phoenix5/trino-phoenix5-392.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
392,trino-server-392/plugin/phoenix5/trino-phoenix5-392.jar,phoenix5,phoenix.connection-url,"",false
392,trino-server-392/plugin/thrift/trino-thrift-392.jar,thrift,trino-thrift.max-response-size,"",false
392,trino-server-392/plugin/thrift/trino-thrift-392.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
392,trino-server-392/plugin/thrift/trino-thrift-392.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.compaction-enabled,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,metadata.db.url,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,metadata.db.filename,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.organization-enabled,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.security,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.orc.max-read-size,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.orc.nested-lazy,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.balancer-enabled,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
392,trino-server-392/plugin/raptor-legacy/trino-raptor-legacy-392.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
392,trino-server-392/plugin/google-sheets/trino-google-sheets-392.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
392,trino-server-392/plugin/google-sheets/trino-google-sheets-392.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
392,trino-server-392/plugin/google-sheets/trino-google-sheets-392.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
392,trino-server-392/plugin/google-sheets/trino-google-sheets-392.jar,google-sheets,credentials-path,"Credential file path to google service account",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.config.resources,"Optional config files",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
392,trino-server-392/plugin/kafka/trino-kafka-392.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.speculative-execution.limit,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.contact-points,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.retry-policy,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.client.read-timeout,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.tls.keystore-path,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.split-size,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.protocol-version,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.consistency-level,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.client.so-linger,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.tls.keystore-password,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.password,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.batch-size,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.speculative-execution.delay,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.username,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.native-protocol-port,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.fetch-size,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.tls.truststore-path,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.client.connect-timeout,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.tls.enabled,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.tls.truststore-password,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
392,trino-server-392/plugin/cassandra/trino-cassandra-392.jar,cassandra,cassandra.splits-per-node,"",false
392,trino-server-392/plugin/mysql/trino-mysql-392.jar,mysql,mysql.max-reconnects,"",false
392,trino-server-392/plugin/mysql/trino-mysql-392.jar,mysql,mysql.auto-reconnect,"",false
392,trino-server-392/plugin/mysql/trino-mysql-392.jar,mysql,mysql.connection-timeout,"",false
392,trino-server-392/plugin/mysql/trino-mysql-392.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
392,trino-server-392/plugin/sqlserver/trino-sqlserver-392.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
392,trino-server-392/plugin/sqlserver/trino-sqlserver-392.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
392,trino-server-392/plugin/sqlserver/trino-sqlserver-392.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
392,trino-server-392/plugin/http-event-listener/trino-http-event-listener-392.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.schema-emulation.prefix,"",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.schema-emulation.enabled,"",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.client.master-addresses,"",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.client.default-operation-timeout,"",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.client.disable-statistics,"",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
392,trino-server-392/plugin/kudu/trino-kudu-392.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
392,trino-server-392/plugin/password-authenticators/trino-password-authenticators-392.jar,password-authenticators,ldap.cache-ttl,"",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.auth.password,"",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.auth.user,"",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
392,trino-server-392/plugin/prometheus/trino-prometheus-392.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.endpoint,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.azure.connection-string,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.storage-class,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.region,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
392,trino-server-392/plugin/exchange-filesystem/trino-exchange-filesystem-392.jar,exchange-filesystem,exchange.encryption-enabled,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.port,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.security,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.tls.enabled,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.auth.user,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.auth.password,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.aws.region,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.host,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
392,trino-server-392/plugin/elasticsearch/trino-elasticsearch-392.jar,elasticsearch,elasticsearch.aws.access-key,"",false
392,trino-server-392/plugin/singlestore/trino-singlestore-392.jar,singlestore,singlestore.connection-timeout,"",false
392,trino-server-392/plugin/singlestore/trino-singlestore-392.jar,singlestore,singlestore.auto-reconnect,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.network-topology.file,"",false
392,trino-server-392/lib/trino-main-392.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
392,trino-server-392/lib/trino-main-392.jar,,memory-cost-weight,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.info-update-interval,"Interval between updating task data",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.password.user-mapping.file,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.push-table-write-through-union,"",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.use-mark-distinct,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.certificate.user-mapping.file,"",false
392,trino-server-392/lib/trino-main-392.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.data-integrity-verification,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.krb5.service-name,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.jwt.required-issuer,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.max-worker-threads,"",false
392,trino-server-392/lib/trino-main-392.jar,,spill-compression-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
392,trino-server-392/lib/trino-main-392.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
392,trino-server-392/lib/trino-main-392.jar,,sink.max-buffer-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
392,trino-server-392/lib/trino-main-392.jar,,network-cost-weight,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.jwt.required-audience,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
392,trino-server-392/lib/trino-main-392.jar,,failure-detector.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,sink.max-broadcast-buffer-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.optimize-metadata-queries,"",false
392,trino-server-392/lib/trino-main-392.jar,,filter-and-project-min-output-page-row-count,"",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,query-max-spill-per-node,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.max-partial-top-n-memory,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
392,trino-server-392/lib/trino-main-392.jar,,adaptive-partial-aggregation.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,re2j.dfa-states-limit,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.skip-redundant-sort,"",false
392,trino-server-392/lib/trino-main-392.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
392,trino-server-392/lib/trino-main-392.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
392,trino-server-392/lib/trino-main-392.jar,,task.cpu-timer-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.krb5.principal-hostname,"",false
392,trino-server-392/lib/trino-main-392.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.password.user-mapping.pattern,"",false
392,trino-server-392/lib/trino-main-392.jar,,web-ui.session-timeout,"",false
392,trino-server-392/lib/trino-main-392.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
392,trino-server-392/lib/trino-main-392.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
392,trino-server-392/lib/trino-main-392.jar,,query.remote-task.min-error-duration,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
392,trino-server-392/lib/trino-main-392.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
392,trino-server-392/lib/trino-main-392.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
392,trino-server-392/lib/trino-main-392.jar,,query.info-url-template,"",false
392,trino-server-392/lib/trino-main-392.jar,,analyzer.max-grouping-sets,"",false
392,trino-server-392/lib/trino-main-392.jar,,join-distribution-type,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.https.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.min-schedule-split-batch-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,spiller-threads,"",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
392,trino-server-392/lib/trino-main-392.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
392,trino-server-392/lib/trino-main-392.jar,,query.schedule-split-batch-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,catalog.config-dir,"",false
392,trino-server-392/lib/trino-main-392.jar,,event-listener.config-files,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
392,trino-server-392/lib/trino-main-392.jar,,task.max-partial-aggregation-memory,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-execution-time,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
392,trino-server-392/lib/trino-main-392.jar,,spiller-spill-path,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,web-ui.shared-secret,"",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.compression-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.manager-executor-pool-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.execution-policy,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.krb5.name-type,"",false
392,trino-server-392/lib/trino-main-392.jar,,redistribute-writes,"",false
392,trino-server-392/lib/trino-main-392.jar,,iterative-optimizer-timeout,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.insecure.user-mapping.file,"",false
392,trino-server-392/lib/trino-main-392.jar,,use-preferred-write-partitioning,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
392,trino-server-392/lib/trino-main-392.jar,,internal-communication.shared-secret,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.default-filter-factor-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.enable-intermediate-aggregations,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
392,trino-server-392/lib/trino-main-392.jar,,distributed-index-joins-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-scan-physical-bytes,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.krb5.user-mapping.file,"",false
392,trino-server-392/lib/trino-main-392.jar,,event.max-output-stage-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,enable-forced-exchange-below-group-id,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-history,"",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.max-response-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
392,trino-server-392/lib/trino-main-392.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-cpu-time,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-run-time,"",false
392,trino-server-392/lib/trino-main-392.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.network-topology.refresh-period,"",false
392,trino-server-392/lib/trino-main-392.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
392,trino-server-392/lib/trino-main-392.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
392,trino-server-392/lib/trino-main-392.jar,,task.per-operator-cpu-timer-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,internal-communication.https.truststore.path,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-stage-count,"",false
392,trino-server-392/lib/trino-main-392.jar,,sql.default-schema,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.page-buffer-client.max-callback-threads,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,retry-policy,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.max-splits-per-node,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.krb5.keytab,"",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.ignore-downstream-preferences,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.max-local-exchange-buffer-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,compiler.expression-cache-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
392,trino-server-392/lib/trino-main-392.jar,,discovery-server.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
392,trino-server-392/lib/trino-main-392.jar,,pages-index.eager-compaction-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,http.authentication.krb5.config,"",false
392,trino-server-392/lib/trino-main-392.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
392,trino-server-392/lib/trino-main-392.jar,,web-ui.user,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
392,trino-server-392/lib/trino-main-392.jar,,task.info.max-age,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.complex-expression-pushdown.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.acknowledge-pages,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.http-timeout-threads,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
392,trino-server-392/lib/trino-main-392.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
392,trino-server-392/lib/trino-main-392.jar,,warning-collector.max-warnings,"",false
392,trino-server-392/lib/trino-main-392.jar,,query-retry-attempts,"",false
392,trino-server-392/lib/trino-main-392.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,task.low-memory-killer.policy,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,task.initial-splits-per-node,"",false
392,trino-server-392/lib/trino-main-392.jar,,web-ui.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.network-topology.type,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.push-partial-aggregation-through-join,"",false
392,trino-server-392/lib/trino-main-392.jar,,catalog.disabled-catalogs,"",false
392,trino-server-392/lib/trino-main-392.jar,,enable-large-dynamic-filters,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.merge-project-with-values,"",false
392,trino-server-392/lib/trino-main-392.jar,,distributed-sort,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
392,trino-server-392/lib/trino-main-392.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.push-aggregation-through-outer-join,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
392,trino-server-392/lib/trino-main-392.jar,,driver.max-page-partitioning-buffer-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.allocator-type,"",false
392,trino-server-392/lib/trino-main-392.jar,,max-spill-per-node,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-length,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
392,trino-server-392/lib/trino-main-392.jar,,query.remote-task.max-error-duration,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
392,trino-server-392/lib/trino-main-392.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.include-coordinator,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.prefer-partial-aggregation,"",false
392,trino-server-392/lib/trino-main-392.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
392,trino-server-392/lib/trino-main-392.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
392,trino-server-392/lib/trino-main-392.jar,,task.min-drivers,"",false
392,trino-server-392/lib/trino-main-392.jar,,statistics-precalculation-for-pushdown.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
392,trino-server-392/lib/trino-main-392.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
392,trino-server-392/lib/trino-main-392.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-memory-per-node,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.split-concurrency-adjustment-interval,"",false
392,trino-server-392/lib/trino-main-392.jar,,plugin.dir,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.low-memory-killer.policy,"",false
392,trino-server-392/lib/trino-main-392.jar,,access-control.config-files,"",false
392,trino-server-392/lib/trino-main-392.jar,,filter-and-project-min-output-page-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,http.include-exception-in-response,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large.max-size-per-filter,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.optimize-hash-generation,"",false
392,trino-server-392/lib/trino-main-392.jar,,shutdown.grace-period,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.status-refresh-max-wait,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
392,trino-server-392/lib/trino-main-392.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-total-memory,"",false
392,trino-server-392/lib/trino-main-392.jar,,spill-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
392,trino-server-392/lib/trino-main-392.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
392,trino-server-392/lib/trino-main-392.jar,,enable-dynamic-filtering,"",false
392,trino-server-392/lib/trino-main-392.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
392,trino-server-392/lib/trino-main-392.jar,,parse-decimal-literals-as-double,"",false
392,trino-server-392/lib/trino-main-392.jar,,regex-library,"",false
392,trino-server-392/lib/trino-main-392.jar,,deprecated.legacy-row-to-json-cast,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,aggregation-operator-unspill-memory-limit,"",false
392,trino-server-392/lib/trino-main-392.jar,,failure-detector.heartbeat-interval,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
392,trino-server-392/lib/trino-main-392.jar,,task-retry-attempts-per-task,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small.max-size-per-filter,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.jwt.key-file,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.policy,"",false
392,trino-server-392/lib/trino-main-392.jar,,cpu-cost-weight,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.optimized-local-scheduling,"",false
392,trino-server-392/lib/trino-main-392.jar,,sql.default-catalog,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,query-results.compression-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-memory,"",false
392,trino-server-392/lib/trino-main-392.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
392,trino-server-392/lib/trino-main-392.jar,,scale-writers,"",false
392,trino-server-392/lib/trino-main-392.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
392,trino-server-392/lib/trino-main-392.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
392,trino-server-392/lib/trino-main-392.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.max-buffer-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.max-pending-splits-per-task,"",false
392,trino-server-392/lib/trino-main-392.jar,,jmx.base-name,"",false
392,trino-server-392/lib/trino-main-392.jar,,spiller-max-used-space-threshold,"",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.min-error-duration,"",false
392,trino-server-392/lib/trino-main-392.jar,,enable-stats-calculator,"",false
392,trino-server-392/lib/trino-main-392.jar,,internal-communication.https.keystore.path,"",false
392,trino-server-392/lib/trino-main-392.jar,,internal-communication.https.keystore.key,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
392,trino-server-392/lib/trino-main-392.jar,,internal-communication.https.truststore.key,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.min-expire-age,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-planning-time,"",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.deduplication-buffer-size,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
392,trino-server-392/lib/trino-main-392.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
392,trino-server-392/lib/trino-main-392.jar,,failure-detector.threshold,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.dictionary-aggregation,"",false
392,trino-server-392/lib/trino-main-392.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
392,trino-server-392/lib/trino-main-392.jar,,task.share-index-loading,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.client.timeout,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.writer-count,"Number of writers per task",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
392,trino-server-392/lib/trino-main-392.jar,,task.http-response-threads,"",false
392,trino-server-392/lib/trino-main-392.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
392,trino-server-392/lib/trino-main-392.jar,,query.remote-task.max-callback-threads,"",false
392,trino-server-392/lib/trino-main-392.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
392,trino-server-392/lib/trino-main-392.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
392,trino-server-392/lib/trino-main-392.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
392,trino-server-392/lib/trino-main-392.jar,,internal-communication.https.required,"",false
392,trino-server-392/lib/trino-main-392.jar,,experimental.late-materialization.enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-concurrent-queries,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.force-single-node-output,"",false
392,trino-server-392/lib/trino-main-392.jar,,task-retry-attempts-overall,"",false
392,trino-server-392/lib/trino-main-392.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
392,trino-server-392/lib/trino-main-392.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
392,trino-server-392/lib/trino-main-392.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
392,trino-server-392/lib/trino-main-392.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.concurrent-request-multiplier,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.statistics-cpu-timer-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.max-index-memory,"",false
392,trino-server-392/lib/trino-main-392.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
392,trino-server-392/lib/trino-main-392.jar,,query.max-queued-queries,"",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.client-threads,"",false
392,trino-server-392/lib/trino-main-392.jar,,spill-encryption-enabled,"",false
392,trino-server-392/lib/trino-main-392.jar,,exchange.max-error-duration,"",false
392,trino-server-392/lib/trino-main-392.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
392,trino-server-392/lib/trino-main-392.jar,,task.client.timeout,"",false
392,trino-server-392/lib/trino-main-392.jar,,re2j.dfa-retries,"",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.jwt.user-mapping.file,"",false
392,trino-server-392/lib/trino-main-392.jar,,node-scheduler.min-candidates,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.optimize-top-n-ranking,"",false
392,trino-server-392/lib/trino-main-392.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
392,trino-server-392/lib/trino-main-392.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
392,trino-server-392/lib/trino-main-392.jar,,http-server.authentication.jwt.principal-field,"",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,security.refresh-period,"",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.url,"URL of the LDAP server",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,security.config-file,"",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,jmx.base-name,"",false
393,trino-server-393/plugin/kinesis/trino-plugin-toolkit-393.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
393,trino-server-393/plugin/kinesis/trino-kinesis-393.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
393,trino-server-393/plugin/clickhouse/trino-clickhouse-393.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
393,trino-server-393/plugin/clickhouse/trino-clickhouse-393.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,keystore-password,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,join-pushdown.strategy,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,keystore-type,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,password-credential-name,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,credential-provider.type,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,keystore-file-path,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,keystore-user-credential-password,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,complex-expression-pushdown.enabled,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,connection-user,"user name for JDBC client",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,connection-url,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,keystore-password-credential-password,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,user-credential-name,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,statistics.enabled,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,connection-password,"Password for JDBC client",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,case-insensitive-name-matching,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,keystore-user-credential-name,"",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
393,trino-server-393/plugin/clickhouse/trino-base-jdbc-393.jar,clickhouse,keystore-password-credential-name,"",false
393,trino-server-393/plugin/postgresql/trino-postgresql-393.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
393,trino-server-393/plugin/postgresql/trino-postgresql-393.jar,postgresql,postgresql.array-mapping,"",false
393,trino-server-393/plugin/postgresql/trino-postgresql-393.jar,postgresql,postgresql.include-system-tables,"",false
393,trino-server-393/plugin/atop/trino-atop-393.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
393,trino-server-393/plugin/atop/trino-atop-393.jar,atop,atop.executable-path,"",false
393,trino-server-393/plugin/atop/trino-atop-393.jar,atop,atop.security,"",false
393,trino-server-393/plugin/atop/trino-atop-393.jar,atop,atop.concurrent-readers-per-node,"",false
393,trino-server-393/plugin/atop/trino-atop-393.jar,atop,atop.max-history-days,"",false
393,trino-server-393/plugin/atop/trino-atop-393.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
393,trino-server-393/plugin/memory/trino-memory-393.jar,memory,memory.splits-per-node,"",false
393,trino-server-393/plugin/memory/trino-memory-393.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
393,trino-server-393/plugin/memory/trino-memory-393.jar,memory,memory.max-data-per-node,"",false
393,trino-server-393/plugin/accumulo/trino-accumulo-393.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
393,trino-server-393/plugin/accumulo/trino-accumulo-393.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
393,trino-server-393/plugin/accumulo/trino-accumulo-393.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
393,trino-server-393/plugin/accumulo/trino-accumulo-393.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
393,trino-server-393/plugin/accumulo/trino-accumulo-393.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
393,trino-server-393/plugin/accumulo/trino-accumulo-393.jar,accumulo,accumulo.instance,"Accumulo instance name",false
393,trino-server-393/plugin/accumulo/trino-accumulo-393.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.prefer-broker-queries,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.forbid-segment-queries,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.tls.keystore-password,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.controller.authentication.user,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.broker.authentication.user,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.segments-per-split,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.tls.truststore-path,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.max-rows-for-broker-queries,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.tls.truststore-password,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.tls.truststore-type,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.connection-timeout,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.controller.authentication.type,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.fetch-retry-count,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.broker.authentication.type,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.controller-urls,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.port,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.tls.keystore-type,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.metadata-expiry,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.tls.keystore-path,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.controller.authentication.password,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.broker.authentication.password,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.target-segment-page-size,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.enabled,"",false
393,trino-server-393/plugin/pinot/trino-pinot-393.jar,pinot,pinot.grpc.use-plain-text,"",false
393,trino-server-393/plugin/resource-group-managers/trino-resource-group-managers-393.jar,resource-group-managers,resource-groups.config-file,"",false
393,trino-server-393/plugin/resource-group-managers/trino-resource-group-managers-393.jar,resource-group-managers,resource-groups.config-db-url,"",false
393,trino-server-393/plugin/resource-group-managers/trino-resource-group-managers-393.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
393,trino-server-393/plugin/resource-group-managers/trino-resource-group-managers-393.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
393,trino-server-393/plugin/resource-group-managers/trino-resource-group-managers-393.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
393,trino-server-393/plugin/resource-group-managers/trino-resource-group-managers-393.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
393,trino-server-393/plugin/resource-group-managers/trino-resource-group-managers-393.jar,resource-group-managers,jmx.base-name,"",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.default-schema,"The schema name to use in the connector",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.password,"Password for a password-protected Redis server",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.user,"Username for a Redis server",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
393,trino-server-393/plugin/redis/trino-redis-393.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
393,trino-server-393/plugin/example-http/trino-example-http-393.jar,example-http,metadata-uri,"",false
393,trino-server-393/plugin/local-file/trino-local-file-393.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
393,trino-server-393/plugin/local-file/trino-local-file-393.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
393,trino-server-393/plugin/jmx/trino-jmx-393.jar,jmx,jmx.dump-tables,"",false
393,trino-server-393/plugin/jmx/trino-jmx-393.jar,jmx,jmx.dump-period,"",false
393,trino-server-393/plugin/jmx/trino-jmx-393.jar,jmx,jmx.max-entries,"",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.remarks-reporting.enabled,"",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.connection-pool.enabled,"",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.connection-pool.min-size,"",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.number.rounding-mode,"",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.connection-pool.max-size,"",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
393,trino-server-393/plugin/oracle/trino-oracle-393.jar,oracle,oracle.synonyms.enabled,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-register-partition-procedure,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-split-iterator-threads,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.ssl.enabled,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.ignore-absent-partitions,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.recursive-directories,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-timeout,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.location,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.signer-class,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.sts.endpoint,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.signer-type,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.stream-buffer-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.version-compatibility,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.wasb-access-key,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.max-client-retries,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.proxy.username,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.max-backoff-time,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.abfs-access-key,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.adl-proxy-host,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.max-read-block-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.split-loader-concurrency,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-concurrent-file-renames,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-refresh-interval,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3-file-system-type,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.compression-codec,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.endpoint,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.data-transfer-port,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.max-merge-distance,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.adl-credential,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.writer-sort-buffer-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.adl-refresh-url,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.socket-timeout,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.max-connections,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.max-merge-distance,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.max-retry-time,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.security,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.adl-client-id,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.aws-access-key,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-cache-ttl,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.max-buffer-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.writer-identification,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.streaming.enabled,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.file-status-cache-tables,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.wasb-storage-account,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.writer.page-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.max-buffer-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.auto-purge,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,parquet.writer.block-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.proxy.password,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-split-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.force-local-scheduling,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.connect-timeout,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.abfs-storage-account,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-recording-path,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.max-error-retries,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-initial-split-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-recording-duration,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.storage-format,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.proxy.protocol,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-initial-splits,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.proxy.host,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.max-read-block-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.file-status-cache-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.proxy.port,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.read-mode,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.sts.region,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.file-status-cache-expire-time,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.replay-metastore-recording,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.cache.bookkeeper-port,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.s3.aws-secret-key,"",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
393,trino-server-393/plugin/delta-lake/trino-hive-393.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.max-initial-split-size,"",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.max-split-size,"",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.max-initial-splits,"",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
393,trino-server-393/plugin/delta-lake/trino-delta-lake-393.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.config.resources,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs.connect.timeout,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.hdfs.socks-proxy,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs.domain-socket-path,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs-timeout,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs.connect.max-retries,"",false
393,trino-server-393/plugin/delta-lake/trino-hdfs-393.jar,delta-lake,hive.dfs.verify-checksum,"",false
393,trino-server-393/plugin/session-property-managers/trino-session-property-managers-393.jar,session-property-managers,session-property-manager.db.url,"",false
393,trino-server-393/plugin/session-property-managers/trino-session-property-managers-393.jar,session-property-managers,session-property-manager.db.username,"",false
393,trino-server-393/plugin/session-property-managers/trino-session-property-managers-393.jar,session-property-managers,session-property-manager.db.password,"",false
393,trino-server-393/plugin/session-property-managers/trino-session-property-managers-393.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
393,trino-server-393/plugin/session-property-managers/trino-session-property-managers-393.jar,session-property-managers,session-property-manager.config-file,"",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.query-results-cache.enabled,"",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.view-expire-duration,"",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
393,trino-server-393/plugin/bigquery/trino-bigquery-393.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.max-wait-time,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.cursor-batch-size,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.ssl.enabled,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.min-connections-per-host,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.read-preference,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.socket-timeout,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.schema-collection,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.connection-url,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.max-connection-idle-time,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.credentials,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.connections-per-host,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.write-concern,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.connection-timeout,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.seeds,"",false
393,trino-server-393/plugin/mongodb/trino-mongodb-393.jar,mongodb,mongodb.required-replica-set,"",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.compression-codec,"",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.file-format,"",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.security,"",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.catalog.type,"",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
393,trino-server-393/plugin/iceberg/trino-iceberg-393.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
393,trino-server-393/plugin/phoenix5/trino-phoenix5-393.jar,phoenix5,phoenix.connection-url,"",false
393,trino-server-393/plugin/phoenix5/trino-phoenix5-393.jar,phoenix5,phoenix.config.resources,"",false
393,trino-server-393/plugin/phoenix5/trino-phoenix5-393.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
393,trino-server-393/plugin/thrift/trino-thrift-393.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
393,trino-server-393/plugin/thrift/trino-thrift-393.jar,thrift,trino-thrift.max-response-size,"",false
393,trino-server-393/plugin/thrift/trino-thrift-393.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.compaction-enabled,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,metadata.db.url,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,metadata.db.filename,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.organization-enabled,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,raptor.security,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.orc.max-read-size,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.orc.nested-lazy,"",false
393,trino-server-393/plugin/raptor-legacy/trino-raptor-legacy-393.jar,raptor-legacy,storage.balancer-enabled,"",false
393,trino-server-393/plugin/google-sheets/trino-google-sheets-393.jar,google-sheets,credentials-path,"Credential file path to google service account",false
393,trino-server-393/plugin/google-sheets/trino-google-sheets-393.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
393,trino-server-393/plugin/google-sheets/trino-google-sheets-393.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
393,trino-server-393/plugin/google-sheets/trino-google-sheets-393.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.config.resources,"Optional config files",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
393,trino-server-393/plugin/kafka/trino-kafka-393.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.fetch-size,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.tls.truststore-path,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.client.connect-timeout,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.tls.enabled,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.tls.truststore-password,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.splits-per-node,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.speculative-execution.limit,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.contact-points,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.retry-policy,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.client.read-timeout,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.tls.keystore-path,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.split-size,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.protocol-version,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.consistency-level,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.client.so-linger,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.tls.keystore-password,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.password,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.batch-size,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.speculative-execution.delay,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.username,"",false
393,trino-server-393/plugin/cassandra/trino-cassandra-393.jar,cassandra,cassandra.native-protocol-port,"",false
393,trino-server-393/plugin/mysql/trino-mysql-393.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
393,trino-server-393/plugin/mysql/trino-mysql-393.jar,mysql,mysql.max-reconnects,"",false
393,trino-server-393/plugin/mysql/trino-mysql-393.jar,mysql,mysql.auto-reconnect,"",false
393,trino-server-393/plugin/mysql/trino-mysql-393.jar,mysql,mysql.connection-timeout,"",false
393,trino-server-393/plugin/sqlserver/trino-sqlserver-393.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
393,trino-server-393/plugin/sqlserver/trino-sqlserver-393.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
393,trino-server-393/plugin/sqlserver/trino-sqlserver-393.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
393,trino-server-393/plugin/http-event-listener/trino-http-event-listener-393.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.schema-emulation.prefix,"",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.schema-emulation.enabled,"",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.client.master-addresses,"",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.client.default-operation-timeout,"",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
393,trino-server-393/plugin/kudu/trino-kudu-393.jar,kudu,kudu.client.disable-statistics,"",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,ldap.cache-ttl,"",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
393,trino-server-393/plugin/password-authenticators/trino-password-authenticators-393.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.auth.password,"",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.auth.user,"",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
393,trino-server-393/plugin/prometheus/trino-prometheus-393.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.encryption-enabled,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.region,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.storage-class,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.endpoint,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.azure.connection-string,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
393,trino-server-393/plugin/exchange-filesystem/trino-exchange-filesystem-393.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.aws.region,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.host,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.aws.access-key,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.port,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.security,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.tls.enabled,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.auth.user,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.auth.password,"",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
393,trino-server-393/plugin/elasticsearch/trino-elasticsearch-393.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
393,trino-server-393/plugin/singlestore/trino-singlestore-393.jar,singlestore,singlestore.connection-timeout,"",false
393,trino-server-393/plugin/singlestore/trino-singlestore-393.jar,singlestore,singlestore.auto-reconnect,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.krb5.service-name,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.password.user-mapping.pattern,"",false
393,trino-server-393/lib/trino-main-393.jar,,re2j.dfa-retries,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
393,trino-server-393/lib/trino-main-393.jar,,catalog.disabled-catalogs,"",false
393,trino-server-393/lib/trino-main-393.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
393,trino-server-393/lib/trino-main-393.jar,,task-retry-attempts-overall,"",false
393,trino-server-393/lib/trino-main-393.jar,,http.authentication.krb5.config,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.optimize-hash-generation,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
393,trino-server-393/lib/trino-main-393.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
393,trino-server-393/lib/trino-main-393.jar,,plugin.dir,"",false
393,trino-server-393/lib/trino-main-393.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
393,trino-server-393/lib/trino-main-393.jar,,event-listener.config-files,"",false
393,trino-server-393/lib/trino-main-393.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
393,trino-server-393/lib/trino-main-393.jar,,compiler.expression-cache-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,regex-library,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
393,trino-server-393/lib/trino-main-393.jar,,query-retry-attempts,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
393,trino-server-393/lib/trino-main-393.jar,,adaptive-partial-aggregation.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.http-timeout-threads,"",false
393,trino-server-393/lib/trino-main-393.jar,,aggregation-operator-unspill-memory-limit,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.info-update-interval,"Interval between updating task data",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
393,trino-server-393/lib/trino-main-393.jar,,parse-decimal-literals-as-double,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-memory,"",false
393,trino-server-393/lib/trino-main-393.jar,,pages-index.eager-compaction-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
393,trino-server-393/lib/trino-main-393.jar,,task.info.max-age,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,task.min-drivers,"",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.compression-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,use-preferred-write-partitioning,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.min-error-duration,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.password.user-mapping.file,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.jwt.key-file,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
393,trino-server-393/lib/trino-main-393.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
393,trino-server-393/lib/trino-main-393.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.client-threads,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.acknowledge-pages,"",false
393,trino-server-393/lib/trino-main-393.jar,,driver.max-page-partitioning-buffer-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,retry-policy,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.remote-task.max-error-duration,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
393,trino-server-393/lib/trino-main-393.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-scan-physical-bytes,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.dictionary-aggregation,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
393,trino-server-393/lib/trino-main-393.jar,,task.initial-splits-per-node,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.jwt.required-issuer,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
393,trino-server-393/lib/trino-main-393.jar,,spill-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,statistics-precalculation-for-pushdown.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.max-index-memory,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,analyzer.max-grouping-sets,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.https.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
393,trino-server-393/lib/trino-main-393.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
393,trino-server-393/lib/trino-main-393.jar,,warning-collector.max-warnings,"",false
393,trino-server-393/lib/trino-main-393.jar,,enable-forced-exchange-below-group-id,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.min-candidates,"",false
393,trino-server-393/lib/trino-main-393.jar,,enable-stats-calculator,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.remote-task.min-error-duration,"",false
393,trino-server-393/lib/trino-main-393.jar,,http.include-exception-in-response,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
393,trino-server-393/lib/trino-main-393.jar,,task.per-operator-cpu-timer-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.optimize-metadata-queries,"",false
393,trino-server-393/lib/trino-main-393.jar,,failure-detector.heartbeat-interval,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
393,trino-server-393/lib/trino-main-393.jar,,filter-and-project-min-output-page-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.jwt.principal-field,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
393,trino-server-393/lib/trino-main-393.jar,,sink.max-buffer-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.certificate.user-mapping.file,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.network-topology.file,"",false
393,trino-server-393/lib/trino-main-393.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.krb5.keytab,"",false
393,trino-server-393/lib/trino-main-393.jar,,scale-writers,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
393,trino-server-393/lib/trino-main-393.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
393,trino-server-393/lib/trino-main-393.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
393,trino-server-393/lib/trino-main-393.jar,,failure-detector.threshold,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
393,trino-server-393/lib/trino-main-393.jar,,task.client.timeout,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.remote-task.max-callback-threads,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
393,trino-server-393/lib/trino-main-393.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-length,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.writer-count,"Number of writers per task",false
393,trino-server-393/lib/trino-main-393.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
393,trino-server-393/lib/trino-main-393.jar,,query.low-memory-killer.policy,"",false
393,trino-server-393/lib/trino-main-393.jar,,query-max-spill-per-node,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
393,trino-server-393/lib/trino-main-393.jar,,task.http-response-threads,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.jwt.required-audience,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
393,trino-server-393/lib/trino-main-393.jar,,deprecated.legacy-row-to-json-cast,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
393,trino-server-393/lib/trino-main-393.jar,,sql.default-schema,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,task-retry-attempts-per-task,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.complex-expression-pushdown.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
393,trino-server-393/lib/trino-main-393.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
393,trino-server-393/lib/trino-main-393.jar,,access-control.config-files,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.max-pending-splits-per-task,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
393,trino-server-393/lib/trino-main-393.jar,,experimental.late-materialization.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.allocator-type,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.manager-executor-pool-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.max-local-exchange-buffer-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.concurrent-request-multiplier,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.include-coordinator,"",false
393,trino-server-393/lib/trino-main-393.jar,,enable-dynamic-filtering,"",false
393,trino-server-393/lib/trino-main-393.jar,,failure-detector.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
393,trino-server-393/lib/trino-main-393.jar,,query.min-schedule-split-batch-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-queued-queries,"",false
393,trino-server-393/lib/trino-main-393.jar,,web-ui.user,"",false
393,trino-server-393/lib/trino-main-393.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
393,trino-server-393/lib/trino-main-393.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
393,trino-server-393/lib/trino-main-393.jar,,web-ui.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.optimize-top-n-ranking,"",false
393,trino-server-393/lib/trino-main-393.jar,,spill-compression-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
393,trino-server-393/lib/trino-main-393.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
393,trino-server-393/lib/trino-main-393.jar,,catalog.management,"",false
393,trino-server-393/lib/trino-main-393.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
393,trino-server-393/lib/trino-main-393.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.prefer-partial-aggregation,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.use-mark-distinct,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
393,trino-server-393/lib/trino-main-393.jar,,web-ui.shared-secret,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.cpu-timer-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
393,trino-server-393/lib/trino-main-393.jar,,task.split-concurrency-adjustment-interval,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.force-single-node-output,"",false
393,trino-server-393/lib/trino-main-393.jar,,sink.max-broadcast-buffer-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,internal-communication.https.truststore.key,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
393,trino-server-393/lib/trino-main-393.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.jwt.user-mapping.file,"",false
393,trino-server-393/lib/trino-main-393.jar,,catalog.config-dir,"",false
393,trino-server-393/lib/trino-main-393.jar,,join-distribution-type,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.max-partial-top-n-memory,"",false
393,trino-server-393/lib/trino-main-393.jar,,query-results.compression-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.merge-project-with-values,"",false
393,trino-server-393/lib/trino-main-393.jar,,shutdown.grace-period,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small.max-size-per-filter,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
393,trino-server-393/lib/trino-main-393.jar,,spiller-max-used-space-threshold,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
393,trino-server-393/lib/trino-main-393.jar,,internal-communication.shared-secret,"",false
393,trino-server-393/lib/trino-main-393.jar,,web-ui.session-timeout,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.network-topology.type,"",false
393,trino-server-393/lib/trino-main-393.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.krb5.user-mapping.file,"",false
393,trino-server-393/lib/trino-main-393.jar,,enable-large-dynamic-filters,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-execution-time,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.push-aggregation-through-outer-join,"",false
393,trino-server-393/lib/trino-main-393.jar,,spiller-threads,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
393,trino-server-393/lib/trino-main-393.jar,,internal-communication.https.keystore.path,"",false
393,trino-server-393/lib/trino-main-393.jar,,re2j.dfa-states-limit,"",false
393,trino-server-393/lib/trino-main-393.jar,,internal-communication.https.keystore.key,"",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.max-buffer-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.max-error-duration,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.client.timeout,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
393,trino-server-393/lib/trino-main-393.jar,,event.max-output-stage-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,internal-communication.https.truststore.path,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used allocating nodes for tasks execution",false
393,trino-server-393/lib/trino-main-393.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
393,trino-server-393/lib/trino-main-393.jar,,sql.default-catalog,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.skip-redundant-sort,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.max-worker-threads,"",false
393,trino-server-393/lib/trino-main-393.jar,,jmx.base-name,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.krb5.principal-hostname,"",false
393,trino-server-393/lib/trino-main-393.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
393,trino-server-393/lib/trino-main-393.jar,,discovery-server.enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
393,trino-server-393/lib/trino-main-393.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-history,"",false
393,trino-server-393/lib/trino-main-393.jar,,iterative-optimizer-timeout,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
393,trino-server-393/lib/trino-main-393.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
393,trino-server-393/lib/trino-main-393.jar,,spiller-spill-path,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.push-partial-aggregation-through-join,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.execution-policy,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.network-topology.refresh-period,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.krb5.name-type,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
393,trino-server-393/lib/trino-main-393.jar,,task.status-refresh-max-wait,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.optimized-local-scheduling,"",false
393,trino-server-393/lib/trino-main-393.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
393,trino-server-393/lib/trino-main-393.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
393,trino-server-393/lib/trino-main-393.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
393,trino-server-393/lib/trino-main-393.jar,,redistribute-writes,"",false
393,trino-server-393/lib/trino-main-393.jar,,distributed-index-joins-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
393,trino-server-393/lib/trino-main-393.jar,,spill-encryption-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.ignore-downstream-preferences,"",false
393,trino-server-393/lib/trino-main-393.jar,,internal-communication.https.required,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
393,trino-server-393/lib/trino-main-393.jar,,task.low-memory-killer.policy,"",false
393,trino-server-393/lib/trino-main-393.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
393,trino-server-393/lib/trino-main-393.jar,,network-cost-weight,"",false
393,trino-server-393/lib/trino-main-393.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-run-time,"",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.max-response-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.statistics-cpu-timer-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
393,trino-server-393/lib/trino-main-393.jar,,filter-and-project-min-output-page-row-count,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-total-memory,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.schedule-split-batch-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
393,trino-server-393/lib/trino-main-393.jar,,task.share-index-loading,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.page-buffer-client.max-callback-threads,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large.max-size-per-filter,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
393,trino-server-393/lib/trino-main-393.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-stage-count,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.max-splits-per-node,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
393,trino-server-393/lib/trino-main-393.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
393,trino-server-393/lib/trino-main-393.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-planning-time,"",false
393,trino-server-393/lib/trino-main-393.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
393,trino-server-393/lib/trino-main-393.jar,,task.max-partial-aggregation-memory,"",false
393,trino-server-393/lib/trino-main-393.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-cpu-time,"",false
393,trino-server-393/lib/trino-main-393.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.default-filter-factor-enabled,"",false
393,trino-server-393/lib/trino-main-393.jar,,cpu-cost-weight,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.push-table-write-through-union,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
393,trino-server-393/lib/trino-main-393.jar,,catalog.store,"",false
393,trino-server-393/lib/trino-main-393.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
393,trino-server-393/lib/trino-main-393.jar,,query.min-expire-age,"",false
393,trino-server-393/lib/trino-main-393.jar,,distributed-sort,"",false
393,trino-server-393/lib/trino-main-393.jar,,memory-cost-weight,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-memory-per-node,"",false
393,trino-server-393/lib/trino-main-393.jar,,node-scheduler.policy,"",false
393,trino-server-393/lib/trino-main-393.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
393,trino-server-393/lib/trino-main-393.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.deduplication-buffer-size,"",false
393,trino-server-393/lib/trino-main-393.jar,,query.info-url-template,"",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.enable-intermediate-aggregations,"",false
393,trino-server-393/lib/trino-main-393.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
393,trino-server-393/lib/trino-main-393.jar,,query.max-concurrent-queries,"",false
393,trino-server-393/lib/trino-main-393.jar,,http-server.authentication.insecure.user-mapping.file,"",false
393,trino-server-393/lib/trino-main-393.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
393,trino-server-393/lib/trino-main-393.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
393,trino-server-393/lib/trino-main-393.jar,,exchange.data-integrity-verification,"",false
393,trino-server-393/lib/trino-main-393.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
393,trino-server-393/lib/trino-main-393.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
393,trino-server-393/lib/trino-main-393.jar,,max-spill-per-node,"",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,security.refresh-period,"",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,jmx.base-name,"",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,security.config-file,"",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.url,"URL of the LDAP server",false
394,trino-server-394/plugin/kinesis/trino-plugin-toolkit-394.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
394,trino-server-394/plugin/kinesis/trino-kinesis-394.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
394,trino-server-394/plugin/clickhouse/trino-clickhouse-394.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
394,trino-server-394/plugin/clickhouse/trino-clickhouse-394.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,credential-provider.type,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,password-credential-name,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,keystore-type,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,join-pushdown.strategy,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,keystore-password,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,keystore-password-credential-name,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,keystore-user-credential-name,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,case-insensitive-name-matching,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,connection-password,"Password for JDBC client",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,statistics.enabled,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,user-credential-name,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,keystore-password-credential-password,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,connection-url,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,connection-user,"user name for JDBC client",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,complex-expression-pushdown.enabled,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,keystore-user-credential-password,"",false
394,trino-server-394/plugin/clickhouse/trino-base-jdbc-394.jar,clickhouse,keystore-file-path,"",false
394,trino-server-394/plugin/postgresql/trino-postgresql-394.jar,postgresql,postgresql.include-system-tables,"",false
394,trino-server-394/plugin/postgresql/trino-postgresql-394.jar,postgresql,postgresql.array-mapping,"",false
394,trino-server-394/plugin/postgresql/trino-postgresql-394.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
394,trino-server-394/plugin/atop/trino-atop-394.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
394,trino-server-394/plugin/atop/trino-atop-394.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
394,trino-server-394/plugin/atop/trino-atop-394.jar,atop,atop.max-history-days,"",false
394,trino-server-394/plugin/atop/trino-atop-394.jar,atop,atop.concurrent-readers-per-node,"",false
394,trino-server-394/plugin/atop/trino-atop-394.jar,atop,atop.security,"",false
394,trino-server-394/plugin/atop/trino-atop-394.jar,atop,atop.executable-path,"",false
394,trino-server-394/plugin/memory/trino-memory-394.jar,memory,memory.max-data-per-node,"",false
394,trino-server-394/plugin/memory/trino-memory-394.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
394,trino-server-394/plugin/memory/trino-memory-394.jar,memory,memory.splits-per-node,"",false
394,trino-server-394/plugin/accumulo/trino-accumulo-394.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
394,trino-server-394/plugin/accumulo/trino-accumulo-394.jar,accumulo,accumulo.instance,"Accumulo instance name",false
394,trino-server-394/plugin/accumulo/trino-accumulo-394.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
394,trino-server-394/plugin/accumulo/trino-accumulo-394.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
394,trino-server-394/plugin/accumulo/trino-accumulo-394.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
394,trino-server-394/plugin/accumulo/trino-accumulo-394.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
394,trino-server-394/plugin/accumulo/trino-accumulo-394.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.controller.authentication.user,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.tls.keystore-password,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.forbid-segment-queries,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.prefer-broker-queries,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.use-plain-text,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.enabled,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.target-segment-page-size,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.broker.authentication.password,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.controller.authentication.password,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.tls.keystore-path,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.metadata-expiry,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.tls.keystore-type,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.port,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.controller-urls,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.broker.authentication.type,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.fetch-retry-count,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.controller.authentication.type,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.connection-timeout,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.tls.truststore-type,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.tls.truststore-password,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.max-rows-for-broker-queries,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.tls.truststore-path,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.segments-per-split,"",false
394,trino-server-394/plugin/pinot/trino-pinot-394.jar,pinot,pinot.broker.authentication.user,"",false
394,trino-server-394/plugin/resource-group-managers/trino-resource-group-managers-394.jar,resource-group-managers,jmx.base-name,"",false
394,trino-server-394/plugin/resource-group-managers/trino-resource-group-managers-394.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
394,trino-server-394/plugin/resource-group-managers/trino-resource-group-managers-394.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
394,trino-server-394/plugin/resource-group-managers/trino-resource-group-managers-394.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
394,trino-server-394/plugin/resource-group-managers/trino-resource-group-managers-394.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
394,trino-server-394/plugin/resource-group-managers/trino-resource-group-managers-394.jar,resource-group-managers,resource-groups.config-db-url,"",false
394,trino-server-394/plugin/resource-group-managers/trino-resource-group-managers-394.jar,resource-group-managers,resource-groups.config-file,"",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.default-schema,"The schema name to use in the connector",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.user,"Username for a Redis server",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.password,"Password for a password-protected Redis server",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
394,trino-server-394/plugin/redis/trino-redis-394.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
394,trino-server-394/plugin/example-http/trino-example-http-394.jar,example-http,metadata-uri,"",false
394,trino-server-394/plugin/local-file/trino-local-file-394.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
394,trino-server-394/plugin/local-file/trino-local-file-394.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
394,trino-server-394/plugin/jmx/trino-jmx-394.jar,jmx,jmx.max-entries,"",false
394,trino-server-394/plugin/jmx/trino-jmx-394.jar,jmx,jmx.dump-period,"",false
394,trino-server-394/plugin/jmx/trino-jmx-394.jar,jmx,jmx.dump-tables,"",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.remarks-reporting.enabled,"",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.synonyms.enabled,"",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.connection-pool.max-size,"",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.number.rounding-mode,"",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.connection-pool.min-size,"",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
394,trino-server-394/plugin/oracle/trino-oracle-394.jar,oracle,oracle.connection-pool.enabled,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.compression-codec,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.adl-client-id,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.wasb-access-key,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.max-backoff-time,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.adl-proxy-host,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.proxy.username,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-refresh-interval,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.data-transfer-port,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.split-loader-concurrency,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3-file-system-type,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.file-status-cache-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.connect-timeout,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-cache-ttl,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.signer-type,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.writer.page-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.bookkeeper-port,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.max-buffer-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.recursive-directories,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-register-partition-procedure,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.max-client-retries,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.wasb-storage-account,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.storage-format,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.writer-identification,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.file-status-cache-expire-time,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.version-compatibility,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-split-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.max-buffer-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.signer-class,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.aws-access-key,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.aws-secret-key,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.ignore-absent-partitions,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.proxy.port,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-recording-duration,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.max-read-block-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.proxy.password,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.abfs-access-key,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.adl-refresh-url,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-concurrent-file-renames,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-split-iterator-threads,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.sts.region,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.streaming.enabled,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.max-error-retries,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.abfs-storage-account,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.max-retry-time,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-timeout,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.sts.endpoint,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-initial-split-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.read-mode,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.ssl.enabled,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.proxy.protocol,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.azure.adl-credential,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.stream-buffer-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.max-connections,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.socket-timeout,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.auto-purge,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.max-initial-splits,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.file-status-cache-tables,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.max-read-block-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.max-merge-distance,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.writer-sort-buffer-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.replay-metastore-recording,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.cache.location,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.proxy.host,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.max-merge-distance,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.endpoint,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-recording-path,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.security,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.force-local-scheduling,"",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
394,trino-server-394/plugin/delta-lake/trino-hive-394.jar,delta-lake,parquet.writer.block-size,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs.domain-socket-path,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs-timeout,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.hdfs.socks-proxy,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs.connect.timeout,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.config.resources,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs.verify-checksum,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs.connect.max-retries,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
394,trino-server-394/plugin/delta-lake/trino-hdfs-394.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.max-initial-split-size,"",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.max-initial-splits,"",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.max-split-size,"",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
394,trino-server-394/plugin/delta-lake/trino-delta-lake-394.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
394,trino-server-394/plugin/session-property-managers/trino-session-property-managers-394.jar,session-property-managers,session-property-manager.db.url,"",false
394,trino-server-394/plugin/session-property-managers/trino-session-property-managers-394.jar,session-property-managers,session-property-manager.config-file,"",false
394,trino-server-394/plugin/session-property-managers/trino-session-property-managers-394.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
394,trino-server-394/plugin/session-property-managers/trino-session-property-managers-394.jar,session-property-managers,session-property-manager.db.password,"",false
394,trino-server-394/plugin/session-property-managers/trino-session-property-managers-394.jar,session-property-managers,session-property-manager.db.username,"",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.view-expire-duration,"",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.query-results-cache.enabled,"",false
394,trino-server-394/plugin/bigquery/trino-bigquery-394.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.ssl.enabled,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.cursor-batch-size,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.max-wait-time,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.required-replica-set,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.seeds,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.connection-timeout,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.write-concern,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.connections-per-host,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.credentials,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.max-connection-idle-time,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.connection-url,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.schema-collection,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.socket-timeout,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.read-preference,"",false
394,trino-server-394/plugin/mongodb/trino-mongodb-394.jar,mongodb,mongodb.min-connections-per-host,"",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.compression-codec,"",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.catalog.type,"",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.security,"",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.file-format,"",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
394,trino-server-394/plugin/iceberg/trino-iceberg-394.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
394,trino-server-394/plugin/phoenix5/trino-phoenix5-394.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
394,trino-server-394/plugin/phoenix5/trino-phoenix5-394.jar,phoenix5,phoenix.config.resources,"",false
394,trino-server-394/plugin/phoenix5/trino-phoenix5-394.jar,phoenix5,phoenix.connection-url,"",false
394,trino-server-394/plugin/thrift/trino-thrift-394.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
394,trino-server-394/plugin/thrift/trino-thrift-394.jar,thrift,trino-thrift.max-response-size,"",false
394,trino-server-394/plugin/thrift/trino-thrift-394.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.balancer-enabled,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.orc.nested-lazy,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.orc.max-read-size,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.security,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.organization-enabled,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,metadata.db.filename,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,metadata.db.url,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.compaction-enabled,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
394,trino-server-394/plugin/raptor-legacy/trino-raptor-legacy-394.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
394,trino-server-394/plugin/google-sheets/trino-google-sheets-394.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
394,trino-server-394/plugin/google-sheets/trino-google-sheets-394.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
394,trino-server-394/plugin/google-sheets/trino-google-sheets-394.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
394,trino-server-394/plugin/google-sheets/trino-google-sheets-394.jar,google-sheets,credentials-path,"Credential file path to google service account",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.config.resources,"Optional config files",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
394,trino-server-394/plugin/kafka/trino-kafka-394.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.tls.enabled,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.client.connect-timeout,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.tls.truststore-path,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.fetch-size,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.native-protocol-port,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.username,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.speculative-execution.delay,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.batch-size,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.password,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.tls.keystore-password,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.client.so-linger,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.consistency-level,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.protocol-version,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.split-size,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.tls.keystore-path,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.client.read-timeout,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.retry-policy,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.contact-points,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.speculative-execution.limit,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.splits-per-node,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
394,trino-server-394/plugin/cassandra/trino-cassandra-394.jar,cassandra,cassandra.tls.truststore-password,"",false
394,trino-server-394/plugin/mysql/trino-mysql-394.jar,mysql,mysql.connection-timeout,"",false
394,trino-server-394/plugin/mysql/trino-mysql-394.jar,mysql,mysql.auto-reconnect,"",false
394,trino-server-394/plugin/mysql/trino-mysql-394.jar,mysql,mysql.max-reconnects,"",false
394,trino-server-394/plugin/mysql/trino-mysql-394.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
394,trino-server-394/plugin/sqlserver/trino-sqlserver-394.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
394,trino-server-394/plugin/sqlserver/trino-sqlserver-394.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
394,trino-server-394/plugin/sqlserver/trino-sqlserver-394.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
394,trino-server-394/plugin/http-event-listener/trino-http-event-listener-394.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.client.disable-statistics,"",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.client.default-operation-timeout,"",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.client.master-addresses,"",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.schema-emulation.enabled,"",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
394,trino-server-394/plugin/kudu/trino-kudu-394.jar,kudu,kudu.schema-emulation.prefix,"",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
394,trino-server-394/plugin/password-authenticators/trino-password-authenticators-394.jar,password-authenticators,ldap.cache-ttl,"",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.auth.user,"",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.auth.password,"",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
394,trino-server-394/plugin/prometheus/trino-prometheus-394.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.region,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.encryption-enabled,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.azure.connection-string,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.endpoint,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.storage-class,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
394,trino-server-394/plugin/exchange-filesystem/trino-exchange-filesystem-394.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.host,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.aws.region,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.auth.password,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.auth.user,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.tls.enabled,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.security,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.port,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.aws.access-key,"",false
394,trino-server-394/plugin/elasticsearch/trino-elasticsearch-394.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
394,trino-server-394/plugin/singlestore/trino-singlestore-394.jar,singlestore,singlestore.auto-reconnect,"",false
394,trino-server-394/plugin/singlestore/trino-singlestore-394.jar,singlestore,singlestore.connection-timeout,"",false
394,trino-server-394/lib/trino-main-394.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
394,trino-server-394/lib/trino-main-394.jar,,task.initial-splits-per-node,"",false
394,trino-server-394/lib/trino-main-394.jar,,pages-index.eager-compaction-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.krb5.service-name,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.password.user-mapping.pattern,"",false
394,trino-server-394/lib/trino-main-394.jar,,query-retry-attempts,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
394,trino-server-394/lib/trino-main-394.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
394,trino-server-394/lib/trino-main-394.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
394,trino-server-394/lib/trino-main-394.jar,,max-spill-per-node,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.max-pending-splits-per-task,"",false
394,trino-server-394/lib/trino-main-394.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
394,trino-server-394/lib/trino-main-394.jar,,internal-communication.https.keystore.key,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
394,trino-server-394/lib/trino-main-394.jar,,driver.max-page-partitioning-buffer-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,filter-and-project-min-output-page-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,enable-large-dynamic-filters,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.certificate.user-mapping.file,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.per-operator-cpu-timer-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
394,trino-server-394/lib/trino-main-394.jar,,task.client.timeout,"",false
394,trino-server-394/lib/trino-main-394.jar,,catalog.config-dir,"",false
394,trino-server-394/lib/trino-main-394.jar,,failure-detector.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.max-local-exchange-buffer-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,enable-stats-calculator,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large.max-size-per-filter,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.remote-task.max-error-duration,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-total-memory,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.schedule-split-batch-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.optimize-metadata-queries,"",false
394,trino-server-394/lib/trino-main-394.jar,,internal-communication.https.truststore.path,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.use-mark-distinct,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.min-drivers,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.info-url-template,"",false
394,trino-server-394/lib/trino-main-394.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.client-threads,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.acknowledge-pages,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.insecure.user-mapping.file,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.push-table-write-through-union,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-run-time,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.max-response-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
394,trino-server-394/lib/trino-main-394.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
394,trino-server-394/lib/trino-main-394.jar,,task.info.max-age,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,compiler.expression-cache-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
394,trino-server-394/lib/trino-main-394.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
394,trino-server-394/lib/trino-main-394.jar,,task.split-concurrency-adjustment-interval,"",false
394,trino-server-394/lib/trino-main-394.jar,,re2j.dfa-states-limit,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.manager-executor-pool-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.page-buffer-client.max-callback-threads,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,aggregation-operator-unspill-memory-limit,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.default-filter-factor-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.low-memory-killer.policy,"",false
394,trino-server-394/lib/trino-main-394.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
394,trino-server-394/lib/trino-main-394.jar,,parse-decimal-literals-as-double,"",false
394,trino-server-394/lib/trino-main-394.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
394,trino-server-394/lib/trino-main-394.jar,,spiller-max-used-space-threshold,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.low-memory-killer.policy,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.krb5.principal-hostname,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
394,trino-server-394/lib/trino-main-394.jar,,spill-encryption-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.compression-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,iterative-optimizer-timeout,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.optimized-local-scheduling,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-queued-queries,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
394,trino-server-394/lib/trino-main-394.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.dictionary-aggregation,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
394,trino-server-394/lib/trino-main-394.jar,,query-results.compression-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-scan-physical-bytes,"",false
394,trino-server-394/lib/trino-main-394.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-memory,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.cpu-timer-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
394,trino-server-394/lib/trino-main-394.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
394,trino-server-394/lib/trino-main-394.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
394,trino-server-394/lib/trino-main-394.jar,,plugin.dir,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-execution-time,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.include-coordinator,"",false
394,trino-server-394/lib/trino-main-394.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.optimize-top-n-ranking,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
394,trino-server-394/lib/trino-main-394.jar,,task.max-index-memory,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.max-splits-per-node,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
394,trino-server-394/lib/trino-main-394.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
394,trino-server-394/lib/trino-main-394.jar,,catalog.store,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
394,trino-server-394/lib/trino-main-394.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
394,trino-server-394/lib/trino-main-394.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.network-topology.refresh-period,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.optimize-hash-generation,"",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.max-error-duration,"",false
394,trino-server-394/lib/trino-main-394.jar,,web-ui.session-timeout,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.min-error-duration,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,http.authentication.krb5.config,"",false
394,trino-server-394/lib/trino-main-394.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.force-single-node-output,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
394,trino-server-394/lib/trino-main-394.jar,,sql.default-catalog,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
394,trino-server-394/lib/trino-main-394.jar,,warning-collector.max-warnings,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
394,trino-server-394/lib/trino-main-394.jar,,failure-detector.heartbeat-interval,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
394,trino-server-394/lib/trino-main-394.jar,,join-distribution-type,"",false
394,trino-server-394/lib/trino-main-394.jar,,sink.max-broadcast-buffer-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,internal-communication.https.required,"",false
394,trino-server-394/lib/trino-main-394.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
394,trino-server-394/lib/trino-main-394.jar,,task.info-update-interval,"Interval between updating task data",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.jwt.user-mapping.file,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.min-schedule-split-batch-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
394,trino-server-394/lib/trino-main-394.jar,,task.http-response-threads,"",false
394,trino-server-394/lib/trino-main-394.jar,,scale-writers,"",false
394,trino-server-394/lib/trino-main-394.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
394,trino-server-394/lib/trino-main-394.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
394,trino-server-394/lib/trino-main-394.jar,,internal-communication.https.keystore.path,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.max-partial-aggregation-memory,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.writer-count,"Number of writers per task",false
394,trino-server-394/lib/trino-main-394.jar,,filter-and-project-min-output-page-row-count,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.prefer-partial-aggregation,"",false
394,trino-server-394/lib/trino-main-394.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.network-topology.type,"",false
394,trino-server-394/lib/trino-main-394.jar,,web-ui.shared-secret,"",false
394,trino-server-394/lib/trino-main-394.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
394,trino-server-394/lib/trino-main-394.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
394,trino-server-394/lib/trino-main-394.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
394,trino-server-394/lib/trino-main-394.jar,,http.include-exception-in-response,"",false
394,trino-server-394/lib/trino-main-394.jar,,statistics-precalculation-for-pushdown.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
394,trino-server-394/lib/trino-main-394.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
394,trino-server-394/lib/trino-main-394.jar,,query.execution-policy,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
394,trino-server-394/lib/trino-main-394.jar,,re2j.dfa-retries,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-concurrent-queries,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.ignore-downstream-preferences,"",false
394,trino-server-394/lib/trino-main-394.jar,,spiller-threads,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.skip-redundant-sort,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.client.timeout,"",false
394,trino-server-394/lib/trino-main-394.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
394,trino-server-394/lib/trino-main-394.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
394,trino-server-394/lib/trino-main-394.jar,,jmx.base-name,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-planning-time,"",false
394,trino-server-394/lib/trino-main-394.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.jwt.required-issuer,"",false
394,trino-server-394/lib/trino-main-394.jar,,event.max-output-stage-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.share-index-loading,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.enable-intermediate-aggregations,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
394,trino-server-394/lib/trino-main-394.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,enable-forced-exchange-below-group-id,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
394,trino-server-394/lib/trino-main-394.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
394,trino-server-394/lib/trino-main-394.jar,,task.http-timeout-threads,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.push-aggregation-through-outer-join,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
394,trino-server-394/lib/trino-main-394.jar,,sql.default-schema,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
394,trino-server-394/lib/trino-main-394.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.jwt.required-audience,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-memory-per-node,"",false
394,trino-server-394/lib/trino-main-394.jar,,query-max-spill-per-node,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
394,trino-server-394/lib/trino-main-394.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.min-candidates,"",false
394,trino-server-394/lib/trino-main-394.jar,,access-control.config-files,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.push-partial-aggregation-through-join,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
394,trino-server-394/lib/trino-main-394.jar,,distributed-index-joins-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.krb5.keytab,"",false
394,trino-server-394/lib/trino-main-394.jar,,adaptive-partial-aggregation.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,redistribute-writes,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
394,trino-server-394/lib/trino-main-394.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.policy,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
394,trino-server-394/lib/trino-main-394.jar,,shutdown.grace-period,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-history,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
394,trino-server-394/lib/trino-main-394.jar,,web-ui.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
394,trino-server-394/lib/trino-main-394.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
394,trino-server-394/lib/trino-main-394.jar,,regex-library,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small.max-size-per-filter,"",false
394,trino-server-394/lib/trino-main-394.jar,,event-listener.config-files,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
394,trino-server-394/lib/trino-main-394.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
394,trino-server-394/lib/trino-main-394.jar,,deprecated.legacy-row-to-json-cast,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.https.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
394,trino-server-394/lib/trino-main-394.jar,,discovery-server.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,failure-detector.threshold,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.status-refresh-max-wait,"",false
394,trino-server-394/lib/trino-main-394.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.jwt.key-file,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
394,trino-server-394/lib/trino-main-394.jar,,task-retry-attempts-overall,"",false
394,trino-server-394/lib/trino-main-394.jar,,internal-communication.https.truststore.key,"",false
394,trino-server-394/lib/trino-main-394.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
394,trino-server-394/lib/trino-main-394.jar,,sink.max-buffer-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.krb5.name-type,"",false
394,trino-server-394/lib/trino-main-394.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
394,trino-server-394/lib/trino-main-394.jar,,enable-dynamic-filtering,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.allocator-type,"",false
394,trino-server-394/lib/trino-main-394.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
394,trino-server-394/lib/trino-main-394.jar,,experimental.late-materialization.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,distributed-sort,"",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.data-integrity-verification,"",false
394,trino-server-394/lib/trino-main-394.jar,,internal-communication.shared-secret,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
394,trino-server-394/lib/trino-main-394.jar,,catalog.disabled-catalogs,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
394,trino-server-394/lib/trino-main-394.jar,,task.max-partial-top-n-memory,"",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.deduplication-buffer-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,cpu-cost-weight,"",false
394,trino-server-394/lib/trino-main-394.jar,,node-scheduler.network-topology.file,"",false
394,trino-server-394/lib/trino-main-394.jar,,retry-policy,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-cpu-time,"",false
394,trino-server-394/lib/trino-main-394.jar,,use-preferred-write-partitioning,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.concurrent-request-multiplier,"",false
394,trino-server-394/lib/trino-main-394.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
394,trino-server-394/lib/trino-main-394.jar,,spiller-spill-path,"",false
394,trino-server-394/lib/trino-main-394.jar,,spill-compression-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,analyzer.max-grouping-sets,"",false
394,trino-server-394/lib/trino-main-394.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
394,trino-server-394/lib/trino-main-394.jar,,network-cost-weight,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.jwt.principal-field,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-stage-count,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.remote-task.max-callback-threads,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
394,trino-server-394/lib/trino-main-394.jar,,query.max-length,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.complex-expression-pushdown.enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,catalog.management,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
394,trino-server-394/lib/trino-main-394.jar,,task.max-worker-threads,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.password.user-mapping.file,"",false
394,trino-server-394/lib/trino-main-394.jar,,task-retry-attempts-per-task,"",false
394,trino-server-394/lib/trino-main-394.jar,,task.statistics-cpu-timer-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,web-ui.user,"",false
394,trino-server-394/lib/trino-main-394.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
394,trino-server-394/lib/trino-main-394.jar,,memory-cost-weight,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.krb5.user-mapping.file,"",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.merge-project-with-values,"",false
394,trino-server-394/lib/trino-main-394.jar,,exchange.max-buffer-size,"",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
394,trino-server-394/lib/trino-main-394.jar,,spill-enabled,"",false
394,trino-server-394/lib/trino-main-394.jar,,query.min-expire-age,"",false
394,trino-server-394/lib/trino-main-394.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
394,trino-server-394/lib/trino-main-394.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
394,trino-server-394/lib/trino-main-394.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
394,trino-server-394/lib/trino-main-394.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
394,trino-server-394/lib/trino-main-394.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
394,trino-server-394/lib/trino-main-394.jar,,query.remote-task.min-error-duration,"",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,security.refresh-period,"",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,jmx.base-name,"",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,security.config-file,"",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.url,"URL of the LDAP server",false
395,trino-server-395/plugin/kinesis/trino-plugin-toolkit-395.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
395,trino-server-395/plugin/kinesis/trino-kinesis-395.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
395,trino-server-395/plugin/clickhouse/trino-clickhouse-395.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
395,trino-server-395/plugin/clickhouse/trino-clickhouse-395.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,password-credential-name,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,keystore-type,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,join-pushdown.strategy,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,keystore-password,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,keystore-password-credential-name,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,keystore-user-credential-name,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,case-insensitive-name-matching,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,connection-password,"Password for JDBC client",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,statistics.enabled,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,user-credential-name,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,keystore-password-credential-password,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,connection-url,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,connection-user,"user name for JDBC client",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,complex-expression-pushdown.enabled,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,keystore-user-credential-password,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,keystore-file-path,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,credential-provider.type,"",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
395,trino-server-395/plugin/clickhouse/trino-base-jdbc-395.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
395,trino-server-395/plugin/postgresql/trino-postgresql-395.jar,postgresql,postgresql.include-system-tables,"",false
395,trino-server-395/plugin/postgresql/trino-postgresql-395.jar,postgresql,postgresql.array-mapping,"",false
395,trino-server-395/plugin/postgresql/trino-postgresql-395.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
395,trino-server-395/plugin/atop/trino-atop-395.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
395,trino-server-395/plugin/atop/trino-atop-395.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
395,trino-server-395/plugin/atop/trino-atop-395.jar,atop,atop.max-history-days,"",false
395,trino-server-395/plugin/atop/trino-atop-395.jar,atop,atop.concurrent-readers-per-node,"",false
395,trino-server-395/plugin/atop/trino-atop-395.jar,atop,atop.security,"",false
395,trino-server-395/plugin/atop/trino-atop-395.jar,atop,atop.executable-path,"",false
395,trino-server-395/plugin/memory/trino-memory-395.jar,memory,memory.max-data-per-node,"",false
395,trino-server-395/plugin/memory/trino-memory-395.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
395,trino-server-395/plugin/memory/trino-memory-395.jar,memory,memory.splits-per-node,"",false
395,trino-server-395/plugin/accumulo/trino-accumulo-395.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
395,trino-server-395/plugin/accumulo/trino-accumulo-395.jar,accumulo,accumulo.instance,"Accumulo instance name",false
395,trino-server-395/plugin/accumulo/trino-accumulo-395.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
395,trino-server-395/plugin/accumulo/trino-accumulo-395.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
395,trino-server-395/plugin/accumulo/trino-accumulo-395.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
395,trino-server-395/plugin/accumulo/trino-accumulo-395.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
395,trino-server-395/plugin/accumulo/trino-accumulo-395.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.forbid-segment-queries,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.prefer-broker-queries,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.use-plain-text,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.enabled,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.target-segment-page-size,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.broker.authentication.password,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.controller.authentication.password,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.tls.keystore-path,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.metadata-expiry,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.tls.keystore-type,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.port,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.controller-urls,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.broker.authentication.type,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.fetch-retry-count,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.controller.authentication.type,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.connection-timeout,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.tls.truststore-type,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.tls.truststore-password,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.max-rows-for-broker-queries,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.tls.truststore-path,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.segments-per-split,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.broker.authentication.user,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.controller.authentication.user,"",false
395,trino-server-395/plugin/pinot/trino-pinot-395.jar,pinot,pinot.grpc.tls.keystore-password,"",false
395,trino-server-395/plugin/resource-group-managers/trino-resource-group-managers-395.jar,resource-group-managers,jmx.base-name,"",false
395,trino-server-395/plugin/resource-group-managers/trino-resource-group-managers-395.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
395,trino-server-395/plugin/resource-group-managers/trino-resource-group-managers-395.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
395,trino-server-395/plugin/resource-group-managers/trino-resource-group-managers-395.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
395,trino-server-395/plugin/resource-group-managers/trino-resource-group-managers-395.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
395,trino-server-395/plugin/resource-group-managers/trino-resource-group-managers-395.jar,resource-group-managers,resource-groups.config-db-url,"",false
395,trino-server-395/plugin/resource-group-managers/trino-resource-group-managers-395.jar,resource-group-managers,resource-groups.config-file,"",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.user,"Username for a Redis server",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.password,"Password for a password-protected Redis server",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
395,trino-server-395/plugin/redis/trino-redis-395.jar,redis,redis.default-schema,"The schema name to use in the connector",false
395,trino-server-395/plugin/example-http/trino-example-http-395.jar,example-http,metadata-uri,"",false
395,trino-server-395/plugin/local-file/trino-local-file-395.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
395,trino-server-395/plugin/local-file/trino-local-file-395.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
395,trino-server-395/plugin/jmx/trino-jmx-395.jar,jmx,jmx.max-entries,"",false
395,trino-server-395/plugin/jmx/trino-jmx-395.jar,jmx,jmx.dump-period,"",false
395,trino-server-395/plugin/jmx/trino-jmx-395.jar,jmx,jmx.dump-tables,"",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.remarks-reporting.enabled,"",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.synonyms.enabled,"",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.connection-pool.max-size,"",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.number.rounding-mode,"",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.connection-pool.min-size,"",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
395,trino-server-395/plugin/oracle/trino-oracle-395.jar,oracle,oracle.connection-pool.enabled,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.wasb-access-key,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.max-backoff-time,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.adl-proxy-host,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.proxy.username,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-refresh-interval,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.data-transfer-port,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.split-loader-concurrency,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3-file-system-type,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.file-status-cache-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.connect-timeout,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-cache-ttl,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.signer-type,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.writer.page-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.bookkeeper-port,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.max-buffer-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.recursive-directories,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-register-partition-procedure,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.max-client-retries,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.wasb-storage-account,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.storage-format,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.writer-identification,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.file-status-cache-expire-time,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.version-compatibility,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-split-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.max-buffer-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.signer-class,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.aws-access-key,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.aws-secret-key,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.ignore-absent-partitions,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.proxy.port,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-recording-duration,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.max-read-block-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.proxy.password,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.abfs-access-key,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.adl-refresh-url,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-concurrent-file-renames,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-split-iterator-threads,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.sts.region,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.streaming.enabled,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.max-error-retries,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.abfs-storage-account,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.max-retry-time,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-timeout,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.sts.endpoint,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-initial-split-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.read-mode,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.ssl.enabled,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.proxy.protocol,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.adl-credential,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.stream-buffer-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.max-connections,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.socket-timeout,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.auto-purge,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-initial-splits,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.file-status-cache-tables,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.max-read-block-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.max-merge-distance,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.writer-sort-buffer-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.replay-metastore-recording,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.cache.location,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.proxy.host,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.max-merge-distance,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.endpoint,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-recording-path,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.security,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.force-local-scheduling,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,parquet.writer.block-size,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.compression-codec,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.azure.adl-client-id,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
395,trino-server-395/plugin/delta-lake/trino-hive-395.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.max-initial-splits,"",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.experimental.ignore-checkpoint-write-failures,"",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.max-initial-split-size,"",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.security,"Authorization checks for Delta Lake connector",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.max-split-size,"",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
395,trino-server-395/plugin/delta-lake/trino-delta-lake-395.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs.domain-socket-path,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs-timeout,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.hdfs.socks-proxy,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs.connect.timeout,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.config.resources,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs.verify-checksum,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs.connect.max-retries,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
395,trino-server-395/plugin/delta-lake/trino-hdfs-395.jar,delta-lake,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
395,trino-server-395/plugin/session-property-managers/trino-session-property-managers-395.jar,session-property-managers,session-property-manager.db.url,"",false
395,trino-server-395/plugin/session-property-managers/trino-session-property-managers-395.jar,session-property-managers,session-property-manager.config-file,"",false
395,trino-server-395/plugin/session-property-managers/trino-session-property-managers-395.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
395,trino-server-395/plugin/session-property-managers/trino-session-property-managers-395.jar,session-property-managers,session-property-manager.db.password,"",false
395,trino-server-395/plugin/session-property-managers/trino-session-property-managers-395.jar,session-property-managers,session-property-manager.db.username,"",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.view-expire-duration,"",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.query-results-cache.enabled,"",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
395,trino-server-395/plugin/bigquery/trino-bigquery-395.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.max-wait-time,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.required-replica-set,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.seeds,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.connection-timeout,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.write-concern,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.connections-per-host,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.credentials,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.max-connection-idle-time,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.connection-url,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.schema-collection,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.socket-timeout,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.read-preference,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.min-connections-per-host,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.ssl.enabled,"",false
395,trino-server-395/plugin/mongodb/trino-mongodb-395.jar,mongodb,mongodb.cursor-batch-size,"",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.file-format,"",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.security,"",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.compression-codec,"",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.allow-legacy-snapshot-syntax,"",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.experimental.extended-statistics.enabled,"Allow ANALYZE and use of extended statistics collected by it. Currently, the statistics are collected in Trino-specific format",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.catalog.type,"",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
395,trino-server-395/plugin/iceberg/trino-iceberg-395.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
395,trino-server-395/plugin/phoenix5/trino-phoenix5-395.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
395,trino-server-395/plugin/phoenix5/trino-phoenix5-395.jar,phoenix5,phoenix.config.resources,"",false
395,trino-server-395/plugin/phoenix5/trino-phoenix5-395.jar,phoenix5,phoenix.connection-url,"",false
395,trino-server-395/plugin/thrift/trino-thrift-395.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
395,trino-server-395/plugin/thrift/trino-thrift-395.jar,thrift,trino-thrift.max-response-size,"",false
395,trino-server-395/plugin/thrift/trino-thrift-395.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.balancer-enabled,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.orc.nested-lazy,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.orc.max-read-size,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.security,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.organization-enabled,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,metadata.db.filename,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,metadata.db.url,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.compaction-enabled,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
395,trino-server-395/plugin/raptor-legacy/trino-raptor-legacy-395.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
395,trino-server-395/plugin/google-sheets/trino-google-sheets-395.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
395,trino-server-395/plugin/google-sheets/trino-google-sheets-395.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
395,trino-server-395/plugin/google-sheets/trino-google-sheets-395.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
395,trino-server-395/plugin/google-sheets/trino-google-sheets-395.jar,google-sheets,credentials-path,"Credential file path to google service account",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.config.resources,"Optional config files",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
395,trino-server-395/plugin/kafka/trino-kafka-395.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.client.connect-timeout,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.tls.truststore-path,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.fetch-size,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.native-protocol-port,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.username,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.speculative-execution.delay,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.batch-size,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.password,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.tls.keystore-password,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.client.so-linger,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.consistency-level,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.protocol-version,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.split-size,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.tls.keystore-path,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.client.read-timeout,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.retry-policy,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.contact-points,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.speculative-execution.limit,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.splits-per-node,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.tls.truststore-password,"",false
395,trino-server-395/plugin/cassandra/trino-cassandra-395.jar,cassandra,cassandra.tls.enabled,"",false
395,trino-server-395/plugin/mysql/trino-mysql-395.jar,mysql,mysql.connection-timeout,"",false
395,trino-server-395/plugin/mysql/trino-mysql-395.jar,mysql,mysql.auto-reconnect,"",false
395,trino-server-395/plugin/mysql/trino-mysql-395.jar,mysql,mysql.max-reconnects,"",false
395,trino-server-395/plugin/mysql/trino-mysql-395.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
395,trino-server-395/plugin/sqlserver/trino-sqlserver-395.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
395,trino-server-395/plugin/sqlserver/trino-sqlserver-395.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
395,trino-server-395/plugin/sqlserver/trino-sqlserver-395.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
395,trino-server-395/plugin/http-event-listener/trino-http-event-listener-395.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.client.disable-statistics,"",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.client.default-operation-timeout,"",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.client.master-addresses,"",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.schema-emulation.enabled,"",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.schema-emulation.prefix,"",false
395,trino-server-395/plugin/kudu/trino-kudu-395.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,ldap.cache-ttl,"",false
395,trino-server-395/plugin/password-authenticators/trino-password-authenticators-395.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.auth.password,"",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.case-insensitive-name-matching,"Where to match the prometheus metric name case insensitively ",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.auth.user,"",false
395,trino-server-395/plugin/prometheus/trino-prometheus-395.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.azure.connection-string,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.endpoint,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.region,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.source-handle-target-data-size,"Target size of the data referenced by a single source handle",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.storage-class,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
395,trino-server-395/plugin/exchange-filesystem/trino-exchange-filesystem-395.jar,exchange-filesystem,exchange.encryption-enabled,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.host,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.aws.region,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.auth.password,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.auth.user,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.tls.enabled,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.security,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.port,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.aws.access-key,"",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
395,trino-server-395/plugin/elasticsearch/trino-elasticsearch-395.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
395,trino-server-395/plugin/singlestore/trino-singlestore-395.jar,singlestore,singlestore.auto-reconnect,"",false
395,trino-server-395/plugin/singlestore/trino-singlestore-395.jar,singlestore,singlestore.connection-timeout,"",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
395,trino-server-395/lib/trino-main-395.jar,,web-ui.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
395,trino-server-395/lib/trino-main-395.jar,,re2j.dfa-retries,"",false
395,trino-server-395/lib/trino-main-395.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
395,trino-server-395/lib/trino-main-395.jar,,enable-large-dynamic-filters,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
395,trino-server-395/lib/trino-main-395.jar,,query-retry-attempts,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-scan-physical-bytes,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-memory,"",false
395,trino-server-395/lib/trino-main-395.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
395,trino-server-395/lib/trino-main-395.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-run-time,"",false
395,trino-server-395/lib/trino-main-395.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
395,trino-server-395/lib/trino-main-395.jar,,internal-communication.https.truststore.key,"",false
395,trino-server-395/lib/trino-main-395.jar,,analyzer.max-grouping-sets,"",false
395,trino-server-395/lib/trino-main-395.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-stage-count,"",false
395,trino-server-395/lib/trino-main-395.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
395,trino-server-395/lib/trino-main-395.jar,,event.max-output-stage-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
395,trino-server-395/lib/trino-main-395.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
395,trino-server-395/lib/trino-main-395.jar,,max-spill-per-node,"",false
395,trino-server-395/lib/trino-main-395.jar,,query-results.compression-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.include-coordinator,"",false
395,trino-server-395/lib/trino-main-395.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
395,trino-server-395/lib/trino-main-395.jar,,task-retry-attempts-overall,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.max-local-exchange-buffer-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
395,trino-server-395/lib/trino-main-395.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.policy,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
395,trino-server-395/lib/trino-main-395.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
395,trino-server-395/lib/trino-main-395.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
395,trino-server-395/lib/trino-main-395.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
395,trino-server-395/lib/trino-main-395.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-cpu-time,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.push-table-write-through-union,"",false
395,trino-server-395/lib/trino-main-395.jar,,failure-detector.threshold,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,sink.max-broadcast-buffer-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.client-threads,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-history,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.ignore-downstream-preferences,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
395,trino-server-395/lib/trino-main-395.jar,,cpu-cost-weight,"",false
395,trino-server-395/lib/trino-main-395.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
395,trino-server-395/lib/trino-main-395.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
395,trino-server-395/lib/trino-main-395.jar,,query.execution-policy,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.info-url-template,"",false
395,trino-server-395/lib/trino-main-395.jar,,pages-index.eager-compaction-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-queued-queries,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.deduplication-buffer-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,sink.max-buffer-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.page-buffer-client.max-callback-threads,"",false
395,trino-server-395/lib/trino-main-395.jar,,experimental.late-materialization.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
395,trino-server-395/lib/trino-main-395.jar,,join-distribution-type,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
395,trino-server-395/lib/trino-main-395.jar,,distributed-index-joins-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-concurrent-queries,"",false
395,trino-server-395/lib/trino-main-395.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
395,trino-server-395/lib/trino-main-395.jar,,enable-stats-calculator,"",false
395,trino-server-395/lib/trino-main-395.jar,,shutdown.grace-period,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
395,trino-server-395/lib/trino-main-395.jar,,failure-detector.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,web-ui.user,"",false
395,trino-server-395/lib/trino-main-395.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.min-candidates,"",false
395,trino-server-395/lib/trino-main-395.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
395,trino-server-395/lib/trino-main-395.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
395,trino-server-395/lib/trino-main-395.jar,,aggregation-operator-unspill-memory-limit,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.https.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.skip-redundant-sort,"",false
395,trino-server-395/lib/trino-main-395.jar,,re2j.dfa-states-limit,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.push-aggregation-through-outer-join,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.krb5.user-mapping.file,"",false
395,trino-server-395/lib/trino-main-395.jar,,enable-dynamic-filtering,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
395,trino-server-395/lib/trino-main-395.jar,,sql.default-catalog,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-total-memory,"",false
395,trino-server-395/lib/trino-main-395.jar,,catalog.config-dir,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.dictionary-aggregation,"",false
395,trino-server-395/lib/trino-main-395.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
395,trino-server-395/lib/trino-main-395.jar,,deprecated.legacy-row-to-json-cast,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.optimize-metadata-queries,"",false
395,trino-server-395/lib/trino-main-395.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.network-topology.file,"",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
395,trino-server-395/lib/trino-main-395.jar,,access-control.config-files,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.low-memory-killer.policy,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
395,trino-server-395/lib/trino-main-395.jar,,adaptive-partial-aggregation.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
395,trino-server-395/lib/trino-main-395.jar,,task.client.timeout,"",false
395,trino-server-395/lib/trino-main-395.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.use-mark-distinct,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.max-error-duration,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-length,"",false
395,trino-server-395/lib/trino-main-395.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.default-filter-factor-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.merge-project-with-values,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.jwt.key-file,"",false
395,trino-server-395/lib/trino-main-395.jar,,query-max-spill-per-node,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
395,trino-server-395/lib/trino-main-395.jar,,query.min-schedule-split-batch-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,spill-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.concurrent-request-multiplier,"",false
395,trino-server-395/lib/trino-main-395.jar,,use-preferred-write-partitioning,"",false
395,trino-server-395/lib/trino-main-395.jar,,spiller-spill-path,"",false
395,trino-server-395/lib/trino-main-395.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
395,trino-server-395/lib/trino-main-395.jar,,jmx.base-name,"",false
395,trino-server-395/lib/trino-main-395.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
395,trino-server-395/lib/trino-main-395.jar,,driver.max-page-partitioning-buffer-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.jwt.principal-field,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.data-integrity-verification,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
395,trino-server-395/lib/trino-main-395.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
395,trino-server-395/lib/trino-main-395.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.krb5.principal-hostname,"",false
395,trino-server-395/lib/trino-main-395.jar,,internal-communication.https.keystore.path,"",false
395,trino-server-395/lib/trino-main-395.jar,,internal-communication.shared-secret,"",false
395,trino-server-395/lib/trino-main-395.jar,,internal-communication.https.truststore.path,"",false
395,trino-server-395/lib/trino-main-395.jar,,regex-library,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.insecure.user-mapping.file,"",false
395,trino-server-395/lib/trino-main-395.jar,,task-retry-attempts-per-task,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
395,trino-server-395/lib/trino-main-395.jar,,query.remote-task.max-callback-threads,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.max-response-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.optimize-hash-generation,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.optimized-local-scheduling,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.jwt.required-audience,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.max-worker-threads,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.enable-intermediate-aggregations,"",false
395,trino-server-395/lib/trino-main-395.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-execution-time,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
395,trino-server-395/lib/trino-main-395.jar,,task.scale-writers.max-writer-count,"Maximum number of writers per task up to which scaling will happen if task.scale-writers.enabled is set",false
395,trino-server-395/lib/trino-main-395.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
395,trino-server-395/lib/trino-main-395.jar,,catalog.management,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.info-update-interval,"Interval between updating task data",false
395,trino-server-395/lib/trino-main-395.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
395,trino-server-395/lib/trino-main-395.jar,,internal-communication.https.keystore.key,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,catalog.disabled-catalogs,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.min-error-duration,"",false
395,trino-server-395/lib/trino-main-395.jar,,web-ui.session-timeout,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
395,trino-server-395/lib/trino-main-395.jar,,query.schedule-split-batch-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.min-drivers,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.push-partial-aggregation-through-join,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.low-memory-killer.policy,"",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.max-pending-splits-per-task,"",false
395,trino-server-395/lib/trino-main-395.jar,,spill-encryption-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,spiller-threads,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
395,trino-server-395/lib/trino-main-395.jar,,distributed-sort,"",false
395,trino-server-395/lib/trino-main-395.jar,,filter-and-project-min-output-page-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.krb5.keytab,"",false
395,trino-server-395/lib/trino-main-395.jar,,plugin.dir,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.max-buffer-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,internal-communication.https.required,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
395,trino-server-395/lib/trino-main-395.jar,,query.client.timeout,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.optimize-top-n-ranking,"",false
395,trino-server-395/lib/trino-main-395.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.complex-expression-pushdown.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-memory-per-node,"",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.allocator-type,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.share-index-loading,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.statistics-cpu-timer-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.password.user-mapping.pattern,"",false
395,trino-server-395/lib/trino-main-395.jar,,network-cost-weight,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.password.user-mapping.file,"",false
395,trino-server-395/lib/trino-main-395.jar,,failure-detector.heartbeat-interval,"",false
395,trino-server-395/lib/trino-main-395.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
395,trino-server-395/lib/trino-main-395.jar,,task.status-refresh-max-wait,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.per-operator-cpu-timer-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.scale-writers.enabled,"Scale the number of concurrent table writers per task based on throughput",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
395,trino-server-395/lib/trino-main-395.jar,,filter-and-project-min-output-page-row-count,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
395,trino-server-395/lib/trino-main-395.jar,,task.info.max-age,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.initial-splits-per-node,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,memory-cost-weight,"",false
395,trino-server-395/lib/trino-main-395.jar,,retry-policy,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.max-partial-aggregation-memory,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.max-planning-time,"",false
395,trino-server-395/lib/trino-main-395.jar,,spiller-max-used-space-threshold,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
395,trino-server-395/lib/trino-main-395.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
395,trino-server-395/lib/trino-main-395.jar,,compiler.expression-cache-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
395,trino-server-395/lib/trino-main-395.jar,,sql.default-schema,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.remote-task.max-error-duration,"",false
395,trino-server-395/lib/trino-main-395.jar,,enable-forced-exchange-below-group-id,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.acknowledge-pages,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.remote-task.min-error-duration,"",false
395,trino-server-395/lib/trino-main-395.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
395,trino-server-395/lib/trino-main-395.jar,,task.max-partial-top-n-memory,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
395,trino-server-395/lib/trino-main-395.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.jwt.required-issuer,"",false
395,trino-server-395/lib/trino-main-395.jar,,parse-decimal-literals-as-double,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,task.http-timeout-threads,"",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.max-splits-per-node,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
395,trino-server-395/lib/trino-main-395.jar,,task.max-index-memory,"",false
395,trino-server-395/lib/trino-main-395.jar,,http.authentication.krb5.config,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
395,trino-server-395/lib/trino-main-395.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.network-topology.refresh-period,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.writer-count,"Number of writers per task",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.krb5.service-name,"",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.force-single-node-output,"",false
395,trino-server-395/lib/trino-main-395.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
395,trino-server-395/lib/trino-main-395.jar,,discovery-server.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
395,trino-server-395/lib/trino-main-395.jar,,query.manager-executor-pool-size,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.krb5.name-type,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
395,trino-server-395/lib/trino-main-395.jar,,spill-compression-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,redistribute-writes,"",false
395,trino-server-395/lib/trino-main-395.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
395,trino-server-395/lib/trino-main-395.jar,,node-scheduler.network-topology.type,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large.max-size-per-filter,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
395,trino-server-395/lib/trino-main-395.jar,,statistics-precalculation-for-pushdown.enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
395,trino-server-395/lib/trino-main-395.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
395,trino-server-395/lib/trino-main-395.jar,,event-listener.config-files,"",false
395,trino-server-395/lib/trino-main-395.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.prefer-partial-aggregation,"",false
395,trino-server-395/lib/trino-main-395.jar,,catalog.store,"",false
395,trino-server-395/lib/trino-main-395.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.certificate.user-mapping.file,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.jwt.user-mapping.file,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
395,trino-server-395/lib/trino-main-395.jar,,task.cpu-timer-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,task.split-concurrency-adjustment-interval,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
395,trino-server-395/lib/trino-main-395.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
395,trino-server-395/lib/trino-main-395.jar,,task.http-response-threads,"",false
395,trino-server-395/lib/trino-main-395.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
395,trino-server-395/lib/trino-main-395.jar,,warning-collector.max-warnings,"",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
395,trino-server-395/lib/trino-main-395.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
395,trino-server-395/lib/trino-main-395.jar,,query.min-expire-age,"",false
395,trino-server-395/lib/trino-main-395.jar,,scale-writers,"",false
395,trino-server-395/lib/trino-main-395.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
395,trino-server-395/lib/trino-main-395.jar,,http.include-exception-in-response,"",false
395,trino-server-395/lib/trino-main-395.jar,,web-ui.shared-secret,"",false
395,trino-server-395/lib/trino-main-395.jar,,iterative-optimizer-timeout,"",false
395,trino-server-395/lib/trino-main-395.jar,,exchange.compression-enabled,"",false
395,trino-server-395/lib/trino-main-395.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
395,trino-server-395/lib/trino-main-395.jar,,dynamic-filtering.small.max-size-per-filter,"",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,jmx.base-name,"",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,security.refresh-period,"",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.url,"URL of the LDAP server",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,security.config-file,"",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
396,trino-server-396/plugin/kinesis/trino-plugin-toolkit-396.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
396,trino-server-396/plugin/kinesis/trino-kinesis-396.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
396,trino-server-396/plugin/clickhouse/trino-clickhouse-396.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
396,trino-server-396/plugin/clickhouse/trino-clickhouse-396.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,case-insensitive-name-matching,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,keystore-user-credential-name,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,keystore-password-credential-name,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,keystore-password,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,join-pushdown.strategy,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,keystore-type,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,password-credential-name,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,credential-provider.type,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,keystore-file-path,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,keystore-user-credential-password,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,complex-expression-pushdown.enabled,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,connection-user,"user name for JDBC client",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,connection-url,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,keystore-password-credential-password,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,user-credential-name,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,statistics.enabled,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,connection-password,"Password for JDBC client",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
396,trino-server-396/plugin/clickhouse/trino-base-jdbc-396.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
396,trino-server-396/plugin/postgresql/trino-postgresql-396.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
396,trino-server-396/plugin/postgresql/trino-postgresql-396.jar,postgresql,postgresql.array-mapping,"",false
396,trino-server-396/plugin/postgresql/trino-postgresql-396.jar,postgresql,postgresql.include-system-tables,"",false
396,trino-server-396/plugin/atop/trino-atop-396.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
396,trino-server-396/plugin/atop/trino-atop-396.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
396,trino-server-396/plugin/atop/trino-atop-396.jar,atop,atop.executable-path,"",false
396,trino-server-396/plugin/atop/trino-atop-396.jar,atop,atop.security,"",false
396,trino-server-396/plugin/atop/trino-atop-396.jar,atop,atop.concurrent-readers-per-node,"",false
396,trino-server-396/plugin/atop/trino-atop-396.jar,atop,atop.max-history-days,"",false
396,trino-server-396/plugin/memory/trino-memory-396.jar,memory,memory.splits-per-node,"",false
396,trino-server-396/plugin/memory/trino-memory-396.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
396,trino-server-396/plugin/memory/trino-memory-396.jar,memory,memory.max-data-per-node,"",false
396,trino-server-396/plugin/accumulo/trino-accumulo-396.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
396,trino-server-396/plugin/accumulo/trino-accumulo-396.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
396,trino-server-396/plugin/accumulo/trino-accumulo-396.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
396,trino-server-396/plugin/accumulo/trino-accumulo-396.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
396,trino-server-396/plugin/accumulo/trino-accumulo-396.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
396,trino-server-396/plugin/accumulo/trino-accumulo-396.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
396,trino-server-396/plugin/accumulo/trino-accumulo-396.jar,accumulo,accumulo.instance,"Accumulo instance name",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.enabled,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.use-plain-text,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.prefer-broker-queries,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.forbid-segment-queries,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.tls.keystore-password,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.controller.authentication.user,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.broker.authentication.user,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.segments-per-split,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.tls.truststore-path,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.max-rows-for-broker-queries,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.tls.truststore-password,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.tls.truststore-type,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.connection-timeout,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.controller.authentication.type,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.fetch-retry-count,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.broker.authentication.type,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.controller-urls,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.port,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.tls.keystore-type,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.metadata-expiry,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.grpc.tls.keystore-path,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.controller.authentication.password,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.broker.authentication.password,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.target-segment-page-size,"",false
396,trino-server-396/plugin/pinot/trino-pinot-396.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
396,trino-server-396/plugin/resource-group-managers/trino-resource-group-managers-396.jar,resource-group-managers,resource-groups.config-file,"",false
396,trino-server-396/plugin/resource-group-managers/trino-resource-group-managers-396.jar,resource-group-managers,resource-groups.config-db-url,"",false
396,trino-server-396/plugin/resource-group-managers/trino-resource-group-managers-396.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
396,trino-server-396/plugin/resource-group-managers/trino-resource-group-managers-396.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
396,trino-server-396/plugin/resource-group-managers/trino-resource-group-managers-396.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
396,trino-server-396/plugin/resource-group-managers/trino-resource-group-managers-396.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
396,trino-server-396/plugin/resource-group-managers/trino-resource-group-managers-396.jar,resource-group-managers,jmx.base-name,"",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.default-schema,"The schema name to use in the connector",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.password,"Password for a password-protected Redis server",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.user,"Username for a Redis server",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
396,trino-server-396/plugin/redis/trino-redis-396.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
396,trino-server-396/plugin/example-http/trino-example-http-396.jar,example-http,metadata-uri,"",false
396,trino-server-396/plugin/local-file/trino-local-file-396.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
396,trino-server-396/plugin/local-file/trino-local-file-396.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
396,trino-server-396/plugin/jmx/trino-jmx-396.jar,jmx,jmx.max-entries,"",false
396,trino-server-396/plugin/jmx/trino-jmx-396.jar,jmx,jmx.dump-tables,"",false
396,trino-server-396/plugin/jmx/trino-jmx-396.jar,jmx,jmx.dump-period,"",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.synonyms.enabled,"",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.remarks-reporting.enabled,"",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.connection-pool.enabled,"",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.connection-pool.min-size,"",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.number.rounding-mode,"",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.connection-pool.max-size,"",false
396,trino-server-396/plugin/oracle/trino-oracle-396.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.file-status-cache-tables,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.signer-type,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.split-loader-concurrency,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.writer-sort-buffer-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.storage-format,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.max-error-retries,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.replay-metastore-recording,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-cache-ttl,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.adl-proxy-host,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-refresh-interval,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.max-buffer-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.data-transfer-port,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.signer-class,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-concurrent-file-renames,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.writer.block-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.auto-purge,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.max-retry-time,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.proxy.username,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-recording-path,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.sts.endpoint,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.writer-identification,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.compression-codec,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.adl-credential,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-recording-duration,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.max-read-block-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.file-status-cache-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.sts.region,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.stream-buffer-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.recursive-directories,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.streaming.enabled,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.endpoint,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.ssl.enabled,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.aws-secret-key,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.optimized-writer.validation-percentage,"Percentage of parquet files to validate after write by re-reading the whole file",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.socket-timeout,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.proxy.host,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.bookkeeper-port,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.max-client-retries,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.adl-client-id,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.proxy.port,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.version-compatibility,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.max-read-block-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.writer.page-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-initial-split-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.wasb-access-key,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.file-status-cache-expire-time,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3-file-system-type,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.adl-refresh-url,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.max-connections,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.read-mode,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.connect-timeout,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.ignore-absent-partitions,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.wasb-storage-account,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.security,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.orc.max-merge-distance,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.allow-register-partition-procedure,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.max-buffer-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-split-iterator-threads,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore-timeout,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.force-local-scheduling,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.abfs-storage-account,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.cache.location,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.proxy.protocol,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.experimental-optimized-writer.enabled,"Experimental: Enable optimized Parquet writer",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-split-size,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.proxy.password,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.max-backoff-time,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.azure.abfs-access-key,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.aws-access-key,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,parquet.max-merge-distance,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
396,trino-server-396/plugin/delta-lake/trino-hive-396.jar,delta-lake,hive.max-initial-splits,"",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.max-initial-split-size,"",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.security,"Authorization checks for Delta Lake connector",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.max-split-size,"",false
396,trino-server-396/plugin/delta-lake/trino-delta-lake-396.jar,delta-lake,delta.max-initial-splits,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs.connect.max-retries,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs.verify-checksum,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.config.resources,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs.connect.timeout,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.hdfs.socks-proxy,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs-timeout,"",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
396,trino-server-396/plugin/delta-lake/trino-hdfs-396.jar,delta-lake,hive.dfs.domain-socket-path,"",false
396,trino-server-396/plugin/session-property-managers/trino-session-property-managers-396.jar,session-property-managers,session-property-manager.db.url,"",false
396,trino-server-396/plugin/session-property-managers/trino-session-property-managers-396.jar,session-property-managers,session-property-manager.db.username,"",false
396,trino-server-396/plugin/session-property-managers/trino-session-property-managers-396.jar,session-property-managers,session-property-manager.db.password,"",false
396,trino-server-396/plugin/session-property-managers/trino-session-property-managers-396.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
396,trino-server-396/plugin/session-property-managers/trino-session-property-managers-396.jar,session-property-managers,session-property-manager.config-file,"",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.query-results-cache.enabled,"",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.view-expire-duration,"",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
396,trino-server-396/plugin/bigquery/trino-bigquery-396.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.required-replica-set,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.max-wait-time,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.cursor-batch-size,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.ssl.enabled,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.min-connections-per-host,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.read-preference,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.socket-timeout,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.schema-collection,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.connection-url,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.max-connection-idle-time,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.credentials,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.connections-per-host,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.write-concern,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.connection-timeout,"",false
396,trino-server-396/plugin/mongodb/trino-mongodb-396.jar,mongodb,mongodb.seeds,"",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.compression-codec,"",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.experimental.extended-statistics.enabled,"Allow ANALYZE and use of extended statistics collected by it. Currently, the statistics are collected in Trino-specific format",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.file-format,"",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.security,"",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.catalog.type,"",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
396,trino-server-396/plugin/iceberg/trino-iceberg-396.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
396,trino-server-396/plugin/phoenix5/trino-phoenix5-396.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
396,trino-server-396/plugin/phoenix5/trino-phoenix5-396.jar,phoenix5,phoenix.connection-url,"",false
396,trino-server-396/plugin/phoenix5/trino-phoenix5-396.jar,phoenix5,phoenix.config.resources,"",false
396,trino-server-396/plugin/thrift/trino-thrift-396.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
396,trino-server-396/plugin/thrift/trino-thrift-396.jar,thrift,trino-thrift.max-response-size,"",false
396,trino-server-396/plugin/thrift/trino-thrift-396.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.orc.nested-lazy,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.balancer-enabled,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.compaction-enabled,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,metadata.db.url,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,metadata.db.filename,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.organization-enabled,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,raptor.security,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
396,trino-server-396/plugin/raptor-legacy/trino-raptor-legacy-396.jar,raptor-legacy,storage.orc.max-read-size,"",false
396,trino-server-396/plugin/google-sheets/trino-google-sheets-396.jar,google-sheets,credentials-path,"Credential file path to google service account",false
396,trino-server-396/plugin/google-sheets/trino-google-sheets-396.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
396,trino-server-396/plugin/google-sheets/trino-google-sheets-396.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
396,trino-server-396/plugin/google-sheets/trino-google-sheets-396.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.config.resources,"Optional config files",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
396,trino-server-396/plugin/kafka/trino-kafka-396.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.username,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.native-protocol-port,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.fetch-size,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.tls.truststore-path,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.client.connect-timeout,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.tls.enabled,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.tls.truststore-password,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.splits-per-node,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.speculative-execution.limit,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.contact-points,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.retry-policy,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.client.read-timeout,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.tls.keystore-path,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.split-size,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.protocol-version,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.consistency-level,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.client.so-linger,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.tls.keystore-password,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.password,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.batch-size,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
396,trino-server-396/plugin/cassandra/trino-cassandra-396.jar,cassandra,cassandra.speculative-execution.delay,"",false
396,trino-server-396/plugin/mysql/trino-mysql-396.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
396,trino-server-396/plugin/mysql/trino-mysql-396.jar,mysql,mysql.max-reconnects,"",false
396,trino-server-396/plugin/mysql/trino-mysql-396.jar,mysql,mysql.auto-reconnect,"",false
396,trino-server-396/plugin/mysql/trino-mysql-396.jar,mysql,mysql.connection-timeout,"",false
396,trino-server-396/plugin/sqlserver/trino-sqlserver-396.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
396,trino-server-396/plugin/sqlserver/trino-sqlserver-396.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
396,trino-server-396/plugin/sqlserver/trino-sqlserver-396.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
396,trino-server-396/plugin/http-event-listener/trino-http-event-listener-396.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.client.disable-statistics,"",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.schema-emulation.prefix,"",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.schema-emulation.enabled,"",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.client.master-addresses,"",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.client.default-operation-timeout,"",false
396,trino-server-396/plugin/kudu/trino-kudu-396.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,ldap.cache-ttl,"",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
396,trino-server-396/plugin/password-authenticators/trino-password-authenticators-396.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.auth.password,"",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.auth.user,"",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.case-insensitive-name-matching,"Where to match the prometheus metric name case insensitively ",false
396,trino-server-396/plugin/prometheus/trino-prometheus-396.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.endpoint,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.azure.connection-string,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.encryption-enabled,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.storage-class,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.source-handle-target-data-size,"Target size of the data referenced by a single source handle",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.region,"",false
396,trino-server-396/plugin/exchange-filesystem/trino-exchange-filesystem-396.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.aws.region,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.host,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.aws.access-key,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.port,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.security,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.tls.enabled,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.auth.user,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.auth.password,"",false
396,trino-server-396/plugin/elasticsearch/trino-elasticsearch-396.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
396,trino-server-396/plugin/singlestore/trino-singlestore-396.jar,singlestore,singlestore.connection-timeout,"",false
396,trino-server-396/plugin/singlestore/trino-singlestore-396.jar,singlestore,singlestore.auto-reconnect,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
396,trino-server-396/lib/trino-main-396.jar,,join-distribution-type,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
396,trino-server-396/lib/trino-main-396.jar,,experimental.late-materialization.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.page-buffer-client.max-callback-threads,"",false
396,trino-server-396/lib/trino-main-396.jar,,sink.max-buffer-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.deduplication-buffer-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-queued-queries,"",false
396,trino-server-396/lib/trino-main-396.jar,,pages-index.eager-compaction-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.info-url-template,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.execution-policy,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
396,trino-server-396/lib/trino-main-396.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
396,trino-server-396/lib/trino-main-396.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
396,trino-server-396/lib/trino-main-396.jar,,cpu-cost-weight,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.ignore-downstream-preferences,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-history,"",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.client-threads,"",false
396,trino-server-396/lib/trino-main-396.jar,,sink.max-broadcast-buffer-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,failure-detector.threshold,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.push-table-write-through-union,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-cpu-time,"",false
396,trino-server-396/lib/trino-main-396.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
396,trino-server-396/lib/trino-main-396.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
396,trino-server-396/lib/trino-main-396.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
396,trino-server-396/lib/trino-main-396.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.policy,"",false
396,trino-server-396/lib/trino-main-396.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
396,trino-server-396/lib/trino-main-396.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
396,trino-server-396/lib/trino-main-396.jar,,task.max-local-exchange-buffer-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,task-retry-attempts-overall,"",false
396,trino-server-396/lib/trino-main-396.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.include-coordinator,"",false
396,trino-server-396/lib/trino-main-396.jar,,query-results.compression-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,max-spill-per-node,"",false
396,trino-server-396/lib/trino-main-396.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
396,trino-server-396/lib/trino-main-396.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
396,trino-server-396/lib/trino-main-396.jar,,event.max-output-stage-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-stage-count,"",false
396,trino-server-396/lib/trino-main-396.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
396,trino-server-396/lib/trino-main-396.jar,,analyzer.max-grouping-sets,"",false
396,trino-server-396/lib/trino-main-396.jar,,internal-communication.https.truststore.key,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
396,trino-server-396/lib/trino-main-396.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-run-time,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
396,trino-server-396/lib/trino-main-396.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-memory,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-scan-physical-bytes,"",false
396,trino-server-396/lib/trino-main-396.jar,,query-retry-attempts,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
396,trino-server-396/lib/trino-main-396.jar,,enable-large-dynamic-filters,"",false
396,trino-server-396/lib/trino-main-396.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
396,trino-server-396/lib/trino-main-396.jar,,re2j.dfa-retries,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
396,trino-server-396/lib/trino-main-396.jar,,web-ui.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small.max-size-per-filter,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.compression-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,iterative-optimizer-timeout,"",false
396,trino-server-396/lib/trino-main-396.jar,,web-ui.shared-secret,"",false
396,trino-server-396/lib/trino-main-396.jar,,http.include-exception-in-response,"",false
396,trino-server-396/lib/trino-main-396.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
396,trino-server-396/lib/trino-main-396.jar,,scale-writers,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.min-expire-age,"",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,warning-collector.max-warnings,"",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
396,trino-server-396/lib/trino-main-396.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
396,trino-server-396/lib/trino-main-396.jar,,task.http-response-threads,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
396,trino-server-396/lib/trino-main-396.jar,,task.split-concurrency-adjustment-interval,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.cpu-timer-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
396,trino-server-396/lib/trino-main-396.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.jwt.user-mapping.file,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.certificate.user-mapping.file,"",false
396,trino-server-396/lib/trino-main-396.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
396,trino-server-396/lib/trino-main-396.jar,,catalog.store,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.prefer-partial-aggregation,"",false
396,trino-server-396/lib/trino-main-396.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
396,trino-server-396/lib/trino-main-396.jar,,event-listener.config-files,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,statistics-precalculation-for-pushdown.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large.max-size-per-filter,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.network-topology.type,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
396,trino-server-396/lib/trino-main-396.jar,,redistribute-writes,"",false
396,trino-server-396/lib/trino-main-396.jar,,spill-compression-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.krb5.name-type,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.manager-executor-pool-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
396,trino-server-396/lib/trino-main-396.jar,,discovery-server.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.force-single-node-output,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.krb5.service-name,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.writer-count,"Number of writers per task",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.network-topology.refresh-period,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
396,trino-server-396/lib/trino-main-396.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
396,trino-server-396/lib/trino-main-396.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
396,trino-server-396/lib/trino-main-396.jar,,http.authentication.krb5.config,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.max-index-memory,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.max-splits-per-node,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.http-timeout-threads,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
396,trino-server-396/lib/trino-main-396.jar,,parse-decimal-literals-as-double,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.jwt.required-issuer,"",false
396,trino-server-396/lib/trino-main-396.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
396,trino-server-396/lib/trino-main-396.jar,,task.max-partial-top-n-memory,"",false
396,trino-server-396/lib/trino-main-396.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
396,trino-server-396/lib/trino-main-396.jar,,query.remote-task.min-error-duration,"",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.acknowledge-pages,"",false
396,trino-server-396/lib/trino-main-396.jar,,enable-forced-exchange-below-group-id,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.remote-task.max-error-duration,"",false
396,trino-server-396/lib/trino-main-396.jar,,sql.default-schema,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
396,trino-server-396/lib/trino-main-396.jar,,compiler.expression-cache-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
396,trino-server-396/lib/trino-main-396.jar,,spiller-max-used-space-threshold,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-planning-time,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.max-partial-aggregation-memory,"",false
396,trino-server-396/lib/trino-main-396.jar,,retry-policy,"",false
396,trino-server-396/lib/trino-main-396.jar,,memory-cost-weight,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.initial-splits-per-node,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.info.max-age,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
396,trino-server-396/lib/trino-main-396.jar,,filter-and-project-min-output-page-row-count,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.scale-writers.enabled,"Scale the number of concurrent table writers per task based on throughput",false
396,trino-server-396/lib/trino-main-396.jar,,task.per-operator-cpu-timer-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.status-refresh-max-wait,"",false
396,trino-server-396/lib/trino-main-396.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
396,trino-server-396/lib/trino-main-396.jar,,failure-detector.heartbeat-interval,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.password.user-mapping.file,"",false
396,trino-server-396/lib/trino-main-396.jar,,network-cost-weight,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.password.user-mapping.pattern,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.statistics-cpu-timer-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.share-index-loading,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.allocator-type,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-memory-per-node,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.complex-expression-pushdown.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.optimize-top-n-ranking,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.client.timeout,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
396,trino-server-396/lib/trino-main-396.jar,,internal-communication.https.required,"",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.max-buffer-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
396,trino-server-396/lib/trino-main-396.jar,,plugin.dir,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.krb5.keytab,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
396,trino-server-396/lib/trino-main-396.jar,,filter-and-project-min-output-page-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,distributed-sort,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
396,trino-server-396/lib/trino-main-396.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
396,trino-server-396/lib/trino-main-396.jar,,spiller-threads,"",false
396,trino-server-396/lib/trino-main-396.jar,,spill-encryption-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.max-pending-splits-per-task,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.low-memory-killer.policy,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.push-partial-aggregation-through-join,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.min-drivers,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
396,trino-server-396/lib/trino-main-396.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
396,trino-server-396/lib/trino-main-396.jar,,query.schedule-split-batch-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
396,trino-server-396/lib/trino-main-396.jar,,web-ui.session-timeout,"",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.min-error-duration,"",false
396,trino-server-396/lib/trino-main-396.jar,,catalog.disabled-catalogs,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,internal-communication.https.keystore.key,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
396,trino-server-396/lib/trino-main-396.jar,,task.info-update-interval,"Interval between updating task data",false
396,trino-server-396/lib/trino-main-396.jar,,catalog.management,"",false
396,trino-server-396/lib/trino-main-396.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
396,trino-server-396/lib/trino-main-396.jar,,task.scale-writers.max-writer-count,"Maximum number of writers per task up to which scaling will happen if task.scale-writers.enabled is set",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-execution-time,"",false
396,trino-server-396/lib/trino-main-396.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.enable-intermediate-aggregations,"",false
396,trino-server-396/lib/trino-main-396.jar,,task.max-worker-threads,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.jwt.required-audience,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.optimized-local-scheduling,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.optimize-hash-generation,"",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.max-response-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
396,trino-server-396/lib/trino-main-396.jar,,query.remote-task.max-callback-threads,"",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
396,trino-server-396/lib/trino-main-396.jar,,task-retry-attempts-per-task,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.insecure.user-mapping.file,"",false
396,trino-server-396/lib/trino-main-396.jar,,regex-library,"",false
396,trino-server-396/lib/trino-main-396.jar,,internal-communication.https.truststore.path,"",false
396,trino-server-396/lib/trino-main-396.jar,,internal-communication.shared-secret,"",false
396,trino-server-396/lib/trino-main-396.jar,,internal-communication.https.keystore.path,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.krb5.principal-hostname,"",false
396,trino-server-396/lib/trino-main-396.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
396,trino-server-396/lib/trino-main-396.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.data-integrity-verification,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.jwt.principal-field,"",false
396,trino-server-396/lib/trino-main-396.jar,,driver.max-page-partitioning-buffer-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
396,trino-server-396/lib/trino-main-396.jar,,jmx.base-name,"",false
396,trino-server-396/lib/trino-main-396.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
396,trino-server-396/lib/trino-main-396.jar,,spiller-spill-path,"",false
396,trino-server-396/lib/trino-main-396.jar,,use-preferred-write-partitioning,"",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.concurrent-request-multiplier,"",false
396,trino-server-396/lib/trino-main-396.jar,,spill-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.min-schedule-split-batch-size,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,query-max-spill-per-node,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.jwt.key-file,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.merge-project-with-values,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.default-filter-factor-enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-length,"",false
396,trino-server-396/lib/trino-main-396.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
396,trino-server-396/lib/trino-main-396.jar,,exchange.max-error-duration,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.use-mark-distinct,"",false
396,trino-server-396/lib/trino-main-396.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
396,trino-server-396/lib/trino-main-396.jar,,task.client.timeout,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
396,trino-server-396/lib/trino-main-396.jar,,adaptive-partial-aggregation.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
396,trino-server-396/lib/trino-main-396.jar,,query.low-memory-killer.policy,"",false
396,trino-server-396/lib/trino-main-396.jar,,access-control.config-files,"",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.network-topology.file,"",false
396,trino-server-396/lib/trino-main-396.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
396,trino-server-396/lib/trino-main-396.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.optimize-metadata-queries,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
396,trino-server-396/lib/trino-main-396.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
396,trino-server-396/lib/trino-main-396.jar,,deprecated.legacy-row-to-json-cast,"",false
396,trino-server-396/lib/trino-main-396.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.dictionary-aggregation,"",false
396,trino-server-396/lib/trino-main-396.jar,,catalog.config-dir,"",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-total-memory,"",false
396,trino-server-396/lib/trino-main-396.jar,,sql.default-catalog,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
396,trino-server-396/lib/trino-main-396.jar,,enable-dynamic-filtering,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.authentication.krb5.user-mapping.file,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.push-aggregation-through-outer-join,"",false
396,trino-server-396/lib/trino-main-396.jar,,re2j.dfa-states-limit,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.skip-redundant-sort,"",false
396,trino-server-396/lib/trino-main-396.jar,,http-server.https.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,aggregation-operator-unspill-memory-limit,"",false
396,trino-server-396/lib/trino-main-396.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
396,trino-server-396/lib/trino-main-396.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
396,trino-server-396/lib/trino-main-396.jar,,node-scheduler.min-candidates,"",false
396,trino-server-396/lib/trino-main-396.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
396,trino-server-396/lib/trino-main-396.jar,,web-ui.user,"",false
396,trino-server-396/lib/trino-main-396.jar,,failure-detector.enabled,"",false
396,trino-server-396/lib/trino-main-396.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
396,trino-server-396/lib/trino-main-396.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
396,trino-server-396/lib/trino-main-396.jar,,shutdown.grace-period,"",false
396,trino-server-396/lib/trino-main-396.jar,,enable-stats-calculator,"",false
396,trino-server-396/lib/trino-main-396.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
396,trino-server-396/lib/trino-main-396.jar,,query.max-concurrent-queries,"",false
396,trino-server-396/lib/trino-main-396.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
396,trino-server-396/lib/trino-main-396.jar,,distributed-index-joins-enabled,"",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,security.refresh-period,"",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,jmx.base-name,"",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,security.config-file,"",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.url,"URL of the LDAP server",false
397,trino-server-397/plugin/kinesis/trino-plugin-toolkit-397.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
397,trino-server-397/plugin/kinesis/trino-kinesis-397.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
397,trino-server-397/plugin/clickhouse/trino-clickhouse-397.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
397,trino-server-397/plugin/clickhouse/trino-clickhouse-397.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,keystore-type,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,join-pushdown.strategy,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,keystore-password,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,keystore-password-credential-name,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,keystore-user-credential-name,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,case-insensitive-name-matching,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,connection-password,"Password for JDBC client",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,statistics.enabled,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,user-credential-name,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,keystore-password-credential-password,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,connection-url,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,connection-user,"user name for JDBC client",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,complex-expression-pushdown.enabled,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,keystore-user-credential-password,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,keystore-file-path,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,credential-provider.type,"",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
397,trino-server-397/plugin/clickhouse/trino-base-jdbc-397.jar,clickhouse,password-credential-name,"",false
397,trino-server-397/plugin/postgresql/trino-postgresql-397.jar,postgresql,postgresql.include-system-tables,"",false
397,trino-server-397/plugin/postgresql/trino-postgresql-397.jar,postgresql,postgresql.array-mapping,"",false
397,trino-server-397/plugin/postgresql/trino-postgresql-397.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
397,trino-server-397/plugin/atop/trino-atop-397.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
397,trino-server-397/plugin/atop/trino-atop-397.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
397,trino-server-397/plugin/atop/trino-atop-397.jar,atop,atop.max-history-days,"",false
397,trino-server-397/plugin/atop/trino-atop-397.jar,atop,atop.concurrent-readers-per-node,"",false
397,trino-server-397/plugin/atop/trino-atop-397.jar,atop,atop.security,"",false
397,trino-server-397/plugin/atop/trino-atop-397.jar,atop,atop.executable-path,"",false
397,trino-server-397/plugin/memory/trino-memory-397.jar,memory,memory.max-data-per-node,"",false
397,trino-server-397/plugin/memory/trino-memory-397.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
397,trino-server-397/plugin/memory/trino-memory-397.jar,memory,memory.splits-per-node,"",false
397,trino-server-397/plugin/accumulo/trino-accumulo-397.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
397,trino-server-397/plugin/accumulo/trino-accumulo-397.jar,accumulo,accumulo.instance,"Accumulo instance name",false
397,trino-server-397/plugin/accumulo/trino-accumulo-397.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
397,trino-server-397/plugin/accumulo/trino-accumulo-397.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
397,trino-server-397/plugin/accumulo/trino-accumulo-397.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
397,trino-server-397/plugin/accumulo/trino-accumulo-397.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
397,trino-server-397/plugin/accumulo/trino-accumulo-397.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.forbid-segment-queries,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.prefer-broker-queries,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.use-plain-text,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.enabled,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.target-segment-page-size,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.broker.authentication.password,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.controller.authentication.password,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.tls.keystore-path,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.metadata-expiry,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.tls.keystore-type,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.port,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.controller-urls,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.broker.authentication.type,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.fetch-retry-count,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.controller.authentication.type,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.connection-timeout,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.tls.truststore-type,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.tls.truststore-password,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.max-rows-for-broker-queries,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.tls.truststore-path,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.segments-per-split,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.broker.authentication.user,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.controller.authentication.user,"",false
397,trino-server-397/plugin/pinot/trino-pinot-397.jar,pinot,pinot.grpc.tls.keystore-password,"",false
397,trino-server-397/plugin/resource-group-managers/trino-resource-group-managers-397.jar,resource-group-managers,jmx.base-name,"",false
397,trino-server-397/plugin/resource-group-managers/trino-resource-group-managers-397.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
397,trino-server-397/plugin/resource-group-managers/trino-resource-group-managers-397.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
397,trino-server-397/plugin/resource-group-managers/trino-resource-group-managers-397.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
397,trino-server-397/plugin/resource-group-managers/trino-resource-group-managers-397.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
397,trino-server-397/plugin/resource-group-managers/trino-resource-group-managers-397.jar,resource-group-managers,resource-groups.config-db-url,"",false
397,trino-server-397/plugin/resource-group-managers/trino-resource-group-managers-397.jar,resource-group-managers,resource-groups.config-file,"",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.user,"Username for a Redis server",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.password,"Password for a password-protected Redis server",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
397,trino-server-397/plugin/redis/trino-redis-397.jar,redis,redis.default-schema,"The schema name to use in the connector",false
397,trino-server-397/plugin/example-http/trino-example-http-397.jar,example-http,metadata-uri,"",false
397,trino-server-397/plugin/local-file/trino-local-file-397.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
397,trino-server-397/plugin/local-file/trino-local-file-397.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
397,trino-server-397/plugin/jmx/trino-jmx-397.jar,jmx,jmx.max-entries,"",false
397,trino-server-397/plugin/jmx/trino-jmx-397.jar,jmx,jmx.dump-period,"",false
397,trino-server-397/plugin/jmx/trino-jmx-397.jar,jmx,jmx.dump-tables,"",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.remarks-reporting.enabled,"",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.synonyms.enabled,"",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.connection-pool.max-size,"",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.number.rounding-mode,"",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.connection-pool.min-size,"",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
397,trino-server-397/plugin/oracle/trino-oracle-397.jar,oracle,oracle.connection-pool.enabled,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.auto-purge,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.writer.block-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-concurrent-file-renames,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.max-compression-buffer-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.text.max-line-length,"Maximum line length for text files",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.signer-class,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.socks-proxy,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-concurrent-metastore-updates,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.service.principal,"Hive Metastore service principal",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.stripe-max-rows,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.data-transfer-port,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.max-buffer-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.abfs.oauth.secret,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.partition-batch-size.min,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-refresh-interval,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.adl-proxy-host,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-cache-ttl,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.replay-metastore-recording,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.max-error-retries,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.client.principal,"Hive Metastore client principal",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-drop-table,"Allow Hive connector to drop table",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.nested-lazy,"ORC lazily read nested data",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.table-statistics-enabled,"Enable use of table statistics",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.storage-format,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.user-metastore-cache-ttl,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.start-server-on-coordinator,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3select-pushdown.max-connections,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.writer-sort-buffer-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.split-loader-concurrency,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.abfs.oauth.client-id,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-concurrent-metastore-drops,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.size-based-split-weights-enabled,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.signer-type,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.user,"Hive file-based metastore username for file access",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.file-status-cache-tables,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-initial-splits,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.assume-canonical-partition-keys,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.max-merge-distance,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.aws-access-key,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.abfs-access-key,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.max-backoff-time,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.proxy.password,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-split-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.proxy.protocol,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.location,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.abfs-storage-account,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.abfs.oauth.endpoint,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.partition-batch-size.max,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.force-local-scheduling,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-timeout,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-split-iterator-threads,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.max-buffer-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-register-partition-procedure,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.max-merge-distance,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.optimized-writer.enabled,"Enable optimized Parquet writer",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.security,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.proxy.preemptive-basic-auth,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.wasb-storage-account,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.ignore-absent-partitions,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.skip-glacier-objects,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.username,"Optional username for accessing the Hive metastore",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.connect-timeout,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-cache.cache-partitions,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.read-mode,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.max-connections,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.row-group-max-rows,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.adl-refresh-url,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3-file-system-type,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.requester-pays.enabled,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.stripe-max-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.file-status-cache-expire-time,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.wasb-access-key,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.tiny-stripe-threshold,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-add-column,"Allow Hive connector to add column",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-initial-split-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.writer.page-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.max-read-block-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.use-column-index,"Enable using Parquet column indexes",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.version-compatibility,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.user-metastore-cache-maximum-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.query-partition-filter-required,"Require filter on at least one partition column",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.proxy.port,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.proxy.non-proxy-hosts,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.authentication.type,"Thrift metastore authentication type",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-rename-column,"Allow Hive connector to rename column",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.use-column-names,"Access ORC columns using names from the file",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.adl-client-id,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.alluxio.master.address,"Alluxio master address",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.max-client-retries,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.bookkeeper-port,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-refresh-max-threads,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.proxy.host,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.socket-timeout,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.path-style-access,"Use path-style access for all request to S3",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.per-transaction-metastore-cache-maximum-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.optimized-writer.validation-percentage,"Percentage of parquet files to validate after write by re-reading the whole file",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.bloom-filters.enabled,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.optimize-mismatched-bucket-count,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.aws-secret-key,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.ssl.enabled,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.string-statistics-limit,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.parquet.time-zone,"Time zone for Parquet read and write",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.endpoint,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.streaming.enabled,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.recursive-directories,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.stream-buffer-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-drop-column,"Allow Hive connector to drop column",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.sts.region,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-rename-table,"Allow Hive connector to rename table",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.file-status-cache-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.max-read-block-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-recording-duration,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.azure.adl-credential,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.compression-codec,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.writer-identification,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.timestamp-precision,"Precision used to represent timestamps",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.sts.endpoint,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.stripe-min-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.sse.enabled,"Enable S3 server side encryption",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-cache-maximum-size,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore-recording-path,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.orc.writer.dictionary-max-memory,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.proxy.username,"",false
397,trino-server-397/plugin/delta-lake/trino-hive-397.jar,delta-lake,hive.s3.max-retry-time,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs.domain-socket-path,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.fs.new-directory-permissions,"File system permissions for new directories",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs-timeout,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs.replication,"Hadoop FileSystem replication factor",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs.key-provider.cache-ttl,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.hdfs.socks-proxy,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs.connect.timeout,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.config.resources,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs.verify-checksum,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs.connect.max-retries,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.hdfs.authentication.type,"HDFS authentication type",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.dfs.ipc-ping-interval,"",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
397,trino-server-397/plugin/delta-lake/trino-hdfs-397.jar,delta-lake,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.max-initial-split-size,"",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.max-initial-splits,"",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.max-split-size,"",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.security,"Authorization checks for Delta Lake connector",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
397,trino-server-397/plugin/delta-lake/trino-delta-lake-397.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
397,trino-server-397/plugin/session-property-managers/trino-session-property-managers-397.jar,session-property-managers,session-property-manager.db.url,"",false
397,trino-server-397/plugin/session-property-managers/trino-session-property-managers-397.jar,session-property-managers,session-property-manager.config-file,"",false
397,trino-server-397/plugin/session-property-managers/trino-session-property-managers-397.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
397,trino-server-397/plugin/session-property-managers/trino-session-property-managers-397.jar,session-property-managers,session-property-manager.db.password,"",false
397,trino-server-397/plugin/session-property-managers/trino-session-property-managers-397.jar,session-property-managers,session-property-manager.db.username,"",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.view-expire-duration,"",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.query-results-cache.enabled,"",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
397,trino-server-397/plugin/bigquery/trino-bigquery-397.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.max-wait-time,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.required-replica-set,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.seeds,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.connection-timeout,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.write-concern,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.connections-per-host,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.credentials,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.max-connection-idle-time,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.connection-url,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.schema-collection,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.socket-timeout,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.read-preference,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.min-connections-per-host,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.ssl.enabled,"",false
397,trino-server-397/plugin/mongodb/trino-mongodb-397.jar,mongodb,mongodb.cursor-batch-size,"",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.compression-codec,"",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.catalog.type,"",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.security,"",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.file-format,"",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
397,trino-server-397/plugin/iceberg/trino-iceberg-397.jar,iceberg,iceberg.experimental.extended-statistics.enabled,"Allow ANALYZE and use of extended statistics collected by it. Currently, the statistics are collected in Trino-specific format",false
397,trino-server-397/plugin/phoenix5/trino-phoenix5-397.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
397,trino-server-397/plugin/phoenix5/trino-phoenix5-397.jar,phoenix5,phoenix.config.resources,"",false
397,trino-server-397/plugin/phoenix5/trino-phoenix5-397.jar,phoenix5,phoenix.connection-url,"",false
397,trino-server-397/plugin/thrift/trino-thrift-397.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
397,trino-server-397/plugin/thrift/trino-thrift-397.jar,thrift,trino-thrift.max-response-size,"",false
397,trino-server-397/plugin/thrift/trino-thrift-397.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.balancer-enabled,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.orc.nested-lazy,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.orc.max-read-size,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.security,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.organization-enabled,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,metadata.db.filename,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,metadata.db.url,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.compaction-enabled,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
397,trino-server-397/plugin/raptor-legacy/trino-raptor-legacy-397.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
397,trino-server-397/plugin/google-sheets/trino-google-sheets-397.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
397,trino-server-397/plugin/google-sheets/trino-google-sheets-397.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
397,trino-server-397/plugin/google-sheets/trino-google-sheets-397.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
397,trino-server-397/plugin/google-sheets/trino-google-sheets-397.jar,google-sheets,credentials-path,"Credential file path to google service account",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.config.resources,"Optional config files",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
397,trino-server-397/plugin/kafka/trino-kafka-397.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.tls.truststore-path,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.fetch-size,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.native-protocol-port,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.username,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.speculative-execution.delay,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.batch-size,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.password,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.tls.keystore-password,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.client.so-linger,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.consistency-level,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.protocol-version,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.split-size,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.tls.keystore-path,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.client.read-timeout,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.retry-policy,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.contact-points,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.speculative-execution.limit,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.splits-per-node,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.tls.truststore-password,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.tls.enabled,"",false
397,trino-server-397/plugin/cassandra/trino-cassandra-397.jar,cassandra,cassandra.client.connect-timeout,"",false
397,trino-server-397/plugin/mysql/trino-mysql-397.jar,mysql,mysql.connection-timeout,"",false
397,trino-server-397/plugin/mysql/trino-mysql-397.jar,mysql,mysql.auto-reconnect,"",false
397,trino-server-397/plugin/mysql/trino-mysql-397.jar,mysql,mysql.max-reconnects,"",false
397,trino-server-397/plugin/mysql/trino-mysql-397.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
397,trino-server-397/plugin/sqlserver/trino-sqlserver-397.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
397,trino-server-397/plugin/sqlserver/trino-sqlserver-397.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
397,trino-server-397/plugin/sqlserver/trino-sqlserver-397.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
397,trino-server-397/plugin/http-event-listener/trino-http-event-listener-397.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.client.disable-statistics,"",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.client.default-operation-timeout,"",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.client.master-addresses,"",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.schema-emulation.enabled,"",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.schema-emulation.prefix,"",false
397,trino-server-397/plugin/kudu/trino-kudu-397.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,ldap.cache-ttl,"",false
397,trino-server-397/plugin/password-authenticators/trino-password-authenticators-397.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.auth.password,"",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.case-insensitive-name-matching,"Where to match the prometheus metric name case insensitively ",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.auth.user,"",false
397,trino-server-397/plugin/prometheus/trino-prometheus-397.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.azure.connection-string,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.endpoint,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.region,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.source-handle-target-data-size,"Target size of the data referenced by a single source handle",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.storage-class,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.encryption-enabled,"",false
397,trino-server-397/plugin/exchange-filesystem/trino-exchange-filesystem-397.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.host,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.aws.region,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.auth.password,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.auth.user,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.tls.enabled,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.security,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.port,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.aws.access-key,"",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
397,trino-server-397/plugin/elasticsearch/trino-elasticsearch-397.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
397,trino-server-397/plugin/singlestore/trino-singlestore-397.jar,singlestore,singlestore.auto-reconnect,"",false
397,trino-server-397/plugin/singlestore/trino-singlestore-397.jar,singlestore,singlestore.connection-timeout,"",false
397,trino-server-397/lib/trino-main-397.jar,,re2j.dfa-retries,"",false
397,trino-server-397/lib/trino-main-397.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
397,trino-server-397/lib/trino-main-397.jar,,enable-large-dynamic-filters,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
397,trino-server-397/lib/trino-main-397.jar,,query-retry-attempts,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-scan-physical-bytes,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-memory,"",false
397,trino-server-397/lib/trino-main-397.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
397,trino-server-397/lib/trino-main-397.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-run-time,"",false
397,trino-server-397/lib/trino-main-397.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
397,trino-server-397/lib/trino-main-397.jar,,internal-communication.https.truststore.key,"",false
397,trino-server-397/lib/trino-main-397.jar,,analyzer.max-grouping-sets,"",false
397,trino-server-397/lib/trino-main-397.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-stage-count,"",false
397,trino-server-397/lib/trino-main-397.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
397,trino-server-397/lib/trino-main-397.jar,,event.max-output-stage-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
397,trino-server-397/lib/trino-main-397.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
397,trino-server-397/lib/trino-main-397.jar,,max-spill-per-node,"",false
397,trino-server-397/lib/trino-main-397.jar,,query-results.compression-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.include-coordinator,"",false
397,trino-server-397/lib/trino-main-397.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
397,trino-server-397/lib/trino-main-397.jar,,task-retry-attempts-overall,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.max-local-exchange-buffer-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
397,trino-server-397/lib/trino-main-397.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.policy,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
397,trino-server-397/lib/trino-main-397.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
397,trino-server-397/lib/trino-main-397.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
397,trino-server-397/lib/trino-main-397.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
397,trino-server-397/lib/trino-main-397.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-cpu-time,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.push-table-write-through-union,"",false
397,trino-server-397/lib/trino-main-397.jar,,failure-detector.threshold,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,sink.max-broadcast-buffer-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.client-threads,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-history,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.ignore-downstream-preferences,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
397,trino-server-397/lib/trino-main-397.jar,,cpu-cost-weight,"",false
397,trino-server-397/lib/trino-main-397.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
397,trino-server-397/lib/trino-main-397.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
397,trino-server-397/lib/trino-main-397.jar,,query.execution-policy,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.info-url-template,"",false
397,trino-server-397/lib/trino-main-397.jar,,pages-index.eager-compaction-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-queued-queries,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.deduplication-buffer-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,sink.max-buffer-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.page-buffer-client.max-callback-threads,"",false
397,trino-server-397/lib/trino-main-397.jar,,experimental.late-materialization.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
397,trino-server-397/lib/trino-main-397.jar,,join-distribution-type,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
397,trino-server-397/lib/trino-main-397.jar,,distributed-index-joins-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-concurrent-queries,"",false
397,trino-server-397/lib/trino-main-397.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
397,trino-server-397/lib/trino-main-397.jar,,enable-stats-calculator,"",false
397,trino-server-397/lib/trino-main-397.jar,,shutdown.grace-period,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
397,trino-server-397/lib/trino-main-397.jar,,failure-detector.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,web-ui.user,"",false
397,trino-server-397/lib/trino-main-397.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.min-candidates,"",false
397,trino-server-397/lib/trino-main-397.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
397,trino-server-397/lib/trino-main-397.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
397,trino-server-397/lib/trino-main-397.jar,,aggregation-operator-unspill-memory-limit,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.https.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.skip-redundant-sort,"",false
397,trino-server-397/lib/trino-main-397.jar,,re2j.dfa-states-limit,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.push-aggregation-through-outer-join,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.krb5.user-mapping.file,"",false
397,trino-server-397/lib/trino-main-397.jar,,enable-dynamic-filtering,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
397,trino-server-397/lib/trino-main-397.jar,,sql.default-catalog,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-total-memory,"",false
397,trino-server-397/lib/trino-main-397.jar,,catalog.config-dir,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.dictionary-aggregation,"",false
397,trino-server-397/lib/trino-main-397.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
397,trino-server-397/lib/trino-main-397.jar,,deprecated.legacy-row-to-json-cast,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.optimize-metadata-queries,"",false
397,trino-server-397/lib/trino-main-397.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.network-topology.file,"",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
397,trino-server-397/lib/trino-main-397.jar,,access-control.config-files,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.low-memory-killer.policy,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
397,trino-server-397/lib/trino-main-397.jar,,adaptive-partial-aggregation.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
397,trino-server-397/lib/trino-main-397.jar,,task.client.timeout,"",false
397,trino-server-397/lib/trino-main-397.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.use-mark-distinct,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.max-error-duration,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-length,"",false
397,trino-server-397/lib/trino-main-397.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.default-filter-factor-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.merge-project-with-values,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.jwt.key-file,"",false
397,trino-server-397/lib/trino-main-397.jar,,query-max-spill-per-node,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
397,trino-server-397/lib/trino-main-397.jar,,query.min-schedule-split-batch-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,spill-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.concurrent-request-multiplier,"",false
397,trino-server-397/lib/trino-main-397.jar,,use-preferred-write-partitioning,"",false
397,trino-server-397/lib/trino-main-397.jar,,spiller-spill-path,"",false
397,trino-server-397/lib/trino-main-397.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
397,trino-server-397/lib/trino-main-397.jar,,jmx.base-name,"",false
397,trino-server-397/lib/trino-main-397.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
397,trino-server-397/lib/trino-main-397.jar,,driver.max-page-partitioning-buffer-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.jwt.principal-field,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.data-integrity-verification,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
397,trino-server-397/lib/trino-main-397.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
397,trino-server-397/lib/trino-main-397.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.krb5.principal-hostname,"",false
397,trino-server-397/lib/trino-main-397.jar,,internal-communication.https.keystore.path,"",false
397,trino-server-397/lib/trino-main-397.jar,,internal-communication.shared-secret,"",false
397,trino-server-397/lib/trino-main-397.jar,,internal-communication.https.truststore.path,"",false
397,trino-server-397/lib/trino-main-397.jar,,regex-library,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.insecure.user-mapping.file,"",false
397,trino-server-397/lib/trino-main-397.jar,,task-retry-attempts-per-task,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
397,trino-server-397/lib/trino-main-397.jar,,query.remote-task.max-callback-threads,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.max-response-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.optimize-hash-generation,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.optimized-local-scheduling,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.jwt.required-audience,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.max-worker-threads,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.enable-intermediate-aggregations,"",false
397,trino-server-397/lib/trino-main-397.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-execution-time,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
397,trino-server-397/lib/trino-main-397.jar,,task.scale-writers.max-writer-count,"Maximum number of writers per task up to which scaling will happen if task.scale-writers.enabled is set",false
397,trino-server-397/lib/trino-main-397.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
397,trino-server-397/lib/trino-main-397.jar,,catalog.management,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.info-update-interval,"Interval between updating task data",false
397,trino-server-397/lib/trino-main-397.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
397,trino-server-397/lib/trino-main-397.jar,,internal-communication.https.keystore.key,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,catalog.disabled-catalogs,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.min-error-duration,"",false
397,trino-server-397/lib/trino-main-397.jar,,web-ui.session-timeout,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
397,trino-server-397/lib/trino-main-397.jar,,query.schedule-split-batch-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.min-drivers,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.push-partial-aggregation-through-join,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.low-memory-killer.policy,"",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.max-pending-splits-per-task,"",false
397,trino-server-397/lib/trino-main-397.jar,,spill-encryption-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,spiller-threads,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
397,trino-server-397/lib/trino-main-397.jar,,distributed-sort,"",false
397,trino-server-397/lib/trino-main-397.jar,,filter-and-project-min-output-page-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.krb5.keytab,"",false
397,trino-server-397/lib/trino-main-397.jar,,plugin.dir,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.max-buffer-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,internal-communication.https.required,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
397,trino-server-397/lib/trino-main-397.jar,,query.client.timeout,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.optimize-top-n-ranking,"",false
397,trino-server-397/lib/trino-main-397.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.complex-expression-pushdown.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-memory-per-node,"",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.allocator-type,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.share-index-loading,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.statistics-cpu-timer-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.password.user-mapping.pattern,"",false
397,trino-server-397/lib/trino-main-397.jar,,network-cost-weight,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.password.user-mapping.file,"",false
397,trino-server-397/lib/trino-main-397.jar,,failure-detector.heartbeat-interval,"",false
397,trino-server-397/lib/trino-main-397.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
397,trino-server-397/lib/trino-main-397.jar,,task.status-refresh-max-wait,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.per-operator-cpu-timer-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.scale-writers.enabled,"Scale the number of concurrent table writers per task based on throughput",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
397,trino-server-397/lib/trino-main-397.jar,,filter-and-project-min-output-page-row-count,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
397,trino-server-397/lib/trino-main-397.jar,,task.info.max-age,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.initial-splits-per-node,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,memory-cost-weight,"",false
397,trino-server-397/lib/trino-main-397.jar,,retry-policy,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.max-partial-aggregation-memory,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.max-planning-time,"",false
397,trino-server-397/lib/trino-main-397.jar,,spiller-max-used-space-threshold,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
397,trino-server-397/lib/trino-main-397.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
397,trino-server-397/lib/trino-main-397.jar,,compiler.expression-cache-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
397,trino-server-397/lib/trino-main-397.jar,,sql.default-schema,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.remote-task.max-error-duration,"",false
397,trino-server-397/lib/trino-main-397.jar,,enable-forced-exchange-below-group-id,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.acknowledge-pages,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.remote-task.min-error-duration,"",false
397,trino-server-397/lib/trino-main-397.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
397,trino-server-397/lib/trino-main-397.jar,,task.max-partial-top-n-memory,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
397,trino-server-397/lib/trino-main-397.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.jwt.required-issuer,"",false
397,trino-server-397/lib/trino-main-397.jar,,parse-decimal-literals-as-double,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,task.http-timeout-threads,"",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.max-splits-per-node,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
397,trino-server-397/lib/trino-main-397.jar,,task.max-index-memory,"",false
397,trino-server-397/lib/trino-main-397.jar,,http.authentication.krb5.config,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
397,trino-server-397/lib/trino-main-397.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.network-topology.refresh-period,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.writer-count,"Number of writers per task",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.krb5.service-name,"",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.force-single-node-output,"",false
397,trino-server-397/lib/trino-main-397.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
397,trino-server-397/lib/trino-main-397.jar,,discovery-server.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
397,trino-server-397/lib/trino-main-397.jar,,query.manager-executor-pool-size,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.krb5.name-type,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
397,trino-server-397/lib/trino-main-397.jar,,spill-compression-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,redistribute-writes,"",false
397,trino-server-397/lib/trino-main-397.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.network-topology.type,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large.max-size-per-filter,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
397,trino-server-397/lib/trino-main-397.jar,,statistics-precalculation-for-pushdown.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
397,trino-server-397/lib/trino-main-397.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
397,trino-server-397/lib/trino-main-397.jar,,event-listener.config-files,"",false
397,trino-server-397/lib/trino-main-397.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.prefer-partial-aggregation,"",false
397,trino-server-397/lib/trino-main-397.jar,,catalog.store,"",false
397,trino-server-397/lib/trino-main-397.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.certificate.user-mapping.file,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.jwt.user-mapping.file,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
397,trino-server-397/lib/trino-main-397.jar,,task.cpu-timer-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,task.split-concurrency-adjustment-interval,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
397,trino-server-397/lib/trino-main-397.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
397,trino-server-397/lib/trino-main-397.jar,,task.http-response-threads,"",false
397,trino-server-397/lib/trino-main-397.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
397,trino-server-397/lib/trino-main-397.jar,,warning-collector.max-warnings,"",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
397,trino-server-397/lib/trino-main-397.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
397,trino-server-397/lib/trino-main-397.jar,,query.min-expire-age,"",false
397,trino-server-397/lib/trino-main-397.jar,,scale-writers,"",false
397,trino-server-397/lib/trino-main-397.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
397,trino-server-397/lib/trino-main-397.jar,,http.include-exception-in-response,"",false
397,trino-server-397/lib/trino-main-397.jar,,web-ui.shared-secret,"",false
397,trino-server-397/lib/trino-main-397.jar,,iterative-optimizer-timeout,"",false
397,trino-server-397/lib/trino-main-397.jar,,exchange.compression-enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
397,trino-server-397/lib/trino-main-397.jar,,dynamic-filtering.small.max-size-per-filter,"",false
397,trino-server-397/lib/trino-main-397.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
397,trino-server-397/lib/trino-main-397.jar,,web-ui.enabled,"",false
397,trino-server-397/lib/trino-main-397.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
398,trino-server-398/plugin/kinesis/trino-kinesis-398.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,security.config-file,"",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.url,"URL of the LDAP server",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,security.refresh-period,"",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
398,trino-server-398/plugin/kinesis/trino-plugin-toolkit-398.jar,kinesis,jmx.base-name,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,connection-password,"Password for JDBC client",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,statistics.enabled,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,user-credential-name,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,keystore-password-credential-password,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,connection-url,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,connection-user,"user name for JDBC client",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,complex-expression-pushdown.enabled,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,keystore-user-credential-password,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,keystore-file-path,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,credential-provider.type,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,password-credential-name,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,keystore-type,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,join-pushdown.strategy,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,keystore-password,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,keystore-password-credential-name,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,keystore-user-credential-name,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
398,trino-server-398/plugin/clickhouse/trino-base-jdbc-398.jar,clickhouse,case-insensitive-name-matching,"",false
398,trino-server-398/plugin/clickhouse/trino-clickhouse-398.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
398,trino-server-398/plugin/clickhouse/trino-clickhouse-398.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
398,trino-server-398/plugin/postgresql/trino-postgresql-398.jar,postgresql,postgresql.array-mapping,"",false
398,trino-server-398/plugin/postgresql/trino-postgresql-398.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
398,trino-server-398/plugin/postgresql/trino-postgresql-398.jar,postgresql,postgresql.include-system-tables,"",false
398,trino-server-398/plugin/atop/trino-atop-398.jar,atop,atop.max-history-days,"",false
398,trino-server-398/plugin/atop/trino-atop-398.jar,atop,atop.concurrent-readers-per-node,"",false
398,trino-server-398/plugin/atop/trino-atop-398.jar,atop,atop.security,"",false
398,trino-server-398/plugin/atop/trino-atop-398.jar,atop,atop.executable-path,"",false
398,trino-server-398/plugin/atop/trino-atop-398.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
398,trino-server-398/plugin/atop/trino-atop-398.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs.domain-socket-path,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.fs.new-directory-permissions,"File system permissions for new directories",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs-timeout,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs.replication,"Hadoop FileSystem replication factor",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs.key-provider.cache-ttl,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.hdfs.socks-proxy,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs.connect.timeout,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.config.resources,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs.verify-checksum,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs.connect.max-retries,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.hdfs.authentication.type,"HDFS authentication type",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.dfs.ipc-ping-interval,"",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
398,trino-server-398/plugin/hudi/trino-hdfs-398.jar,hudi,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.assume-canonical-partition-keys,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.max-merge-distance,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.aws-access-key,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.abfs-access-key,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.max-backoff-time,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.proxy.password,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-split-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.proxy.protocol,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.location,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.abfs-storage-account,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.abfs.oauth.endpoint,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.partition-batch-size.max,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.force-local-scheduling,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-timeout,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-split-iterator-threads,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.max-buffer-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-register-partition-procedure,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.max-merge-distance,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.optimized-writer.enabled,"Enable optimized Parquet writer",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.security,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.proxy.preemptive-basic-auth,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.wasb-storage-account,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.ignore-absent-partitions,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.skip-glacier-objects,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.username,"Optional username for accessing the Hive metastore",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.connect-timeout,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-cache.cache-partitions,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.read-mode,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.max-connections,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.row-group-max-rows,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.adl-refresh-url,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3-file-system-type,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.requester-pays.enabled,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.stripe-max-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.file-status-cache-expire-time,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.wasb-access-key,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.tiny-stripe-threshold,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-add-column,"Allow Hive connector to add column",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-initial-split-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.writer.page-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.max-read-block-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.use-column-index,"Enable using Parquet column indexes",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.version-compatibility,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.user-metastore-cache-maximum-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.query-partition-filter-required,"Require filter on at least one partition column",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.proxy.port,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.proxy.non-proxy-hosts,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.authentication.type,"Thrift metastore authentication type",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-rename-column,"Allow Hive connector to rename column",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.use-column-names,"Access ORC columns using names from the file",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.adl-client-id,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.alluxio.master.address,"Alluxio master address",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.max-client-retries,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.bookkeeper-port,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-refresh-max-threads,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.proxy.host,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.socket-timeout,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.path-style-access,"Use path-style access for all request to S3",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.per-transaction-metastore-cache-maximum-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.optimized-writer.validation-percentage,"Percentage of parquet files to validate after write by re-reading the whole file",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.bloom-filters.enabled,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.optimize-mismatched-bucket-count,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.aws-secret-key,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.ssl.enabled,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.string-statistics-limit,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.parquet.time-zone,"Time zone for Parquet read and write",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.endpoint,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.streaming.enabled,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.recursive-directories,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.stream-buffer-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-drop-column,"Allow Hive connector to drop column",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.sts.region,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-rename-table,"Allow Hive connector to rename table",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.file-status-cache-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.max-read-block-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-recording-duration,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.adl-credential,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.compression-codec,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.writer-identification,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.timestamp-precision,"Precision used to represent timestamps",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.sts.endpoint,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.stripe-min-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.sse.enabled,"Enable S3 server side encryption",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-cache-maximum-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-recording-path,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.dictionary-max-memory,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.proxy.username,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.max-retry-time,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.auto-purge,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,parquet.writer.block-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-concurrent-file-renames,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.max-compression-buffer-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.text.max-line-length,"Maximum line length for text files",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.signer-class,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.client.socks-proxy,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-concurrent-metastore-updates,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.service.principal,"Hive Metastore service principal",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.writer.stripe-max-rows,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.data-transfer-port,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.max-buffer-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.abfs.oauth.secret,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.partition-batch-size.min,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-refresh-interval,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.adl-proxy-host,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore-cache-ttl,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.replay-metastore-recording,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.max-error-retries,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.client.principal,"Hive Metastore client principal",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.allow-drop-table,"Allow Hive connector to drop table",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.orc.nested-lazy,"ORC lazily read nested data",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.table-statistics-enabled,"Enable use of table statistics",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.storage-format,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.user-metastore-cache-ttl,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.cache.start-server-on-coordinator,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3select-pushdown.max-connections,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.writer-sort-buffer-size,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.split-loader-concurrency,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.azure.abfs.oauth.client-id,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-concurrent-metastore-drops,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.size-based-split-weights-enabled,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.s3.signer-type,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.user,"Hive file-based metastore username for file access",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.file-status-cache-tables,"",false
398,trino-server-398/plugin/hudi/trino-hive-398.jar,hudi,hive.max-initial-splits,"",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.columns-to-hide,"List of column names that will be hidden from the query output. It can be used to hide Hudi meta fields. By default, no fields are hidden.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.min-partition-batch-size,"Minimum number of partitions returned in a single batch.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.standard-split-weight-size,"The split size corresponding to the standard weight (1.0) when size based split weights are enabled.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.max-outstanding-splits,"Maximum outstanding splits in a batch enqueued for processing.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.metadata-enabled,"Fetch the list of file names and sizes from metadata rather than storage.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.size-based-split-weights-enabled,"Unlike uniform splitting, size-based splitting ensures that each batch of splits has enough data to process. By default, it is enabled to improve performance.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.max-partition-batch-size,"Maximum number of partitions returned in a single batch.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.max-splits-per-second,"Rate at which splits are enqueued for processing. The queue will throttle if this rate limit is breached.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled.",false
398,trino-server-398/plugin/hudi/trino-hudi-398.jar,hudi,hudi.parquet.use-column-names,"Access Parquet columns using names from the file. If disabled, then columns are accessed using index.Only applicable to Parquet file format.",false
398,trino-server-398/plugin/memory/trino-memory-398.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
398,trino-server-398/plugin/memory/trino-memory-398.jar,memory,memory.splits-per-node,"",false
398,trino-server-398/plugin/memory/trino-memory-398.jar,memory,memory.max-data-per-node,"",false
398,trino-server-398/plugin/accumulo/trino-accumulo-398.jar,accumulo,accumulo.instance,"Accumulo instance name",false
398,trino-server-398/plugin/accumulo/trino-accumulo-398.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
398,trino-server-398/plugin/accumulo/trino-accumulo-398.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
398,trino-server-398/plugin/accumulo/trino-accumulo-398.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
398,trino-server-398/plugin/accumulo/trino-accumulo-398.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
398,trino-server-398/plugin/accumulo/trino-accumulo-398.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
398,trino-server-398/plugin/accumulo/trino-accumulo-398.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.target-segment-page-size,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.broker.authentication.password,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.controller.authentication.password,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.tls.keystore-path,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.metadata-expiry,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.tls.keystore-type,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.port,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.controller-urls,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.broker.authentication.type,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.fetch-retry-count,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.controller.authentication.type,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.connection-timeout,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.tls.truststore-type,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.tls.truststore-password,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.max-rows-for-broker-queries,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.tls.truststore-path,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.segments-per-split,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.broker.authentication.user,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.controller.authentication.user,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.tls.keystore-password,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.forbid-segment-queries,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.prefer-broker-queries,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.use-plain-text,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.enabled,"",false
398,trino-server-398/plugin/pinot/trino-pinot-398.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
398,trino-server-398/plugin/resource-group-managers/trino-resource-group-managers-398.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
398,trino-server-398/plugin/resource-group-managers/trino-resource-group-managers-398.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
398,trino-server-398/plugin/resource-group-managers/trino-resource-group-managers-398.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
398,trino-server-398/plugin/resource-group-managers/trino-resource-group-managers-398.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
398,trino-server-398/plugin/resource-group-managers/trino-resource-group-managers-398.jar,resource-group-managers,resource-groups.config-db-url,"",false
398,trino-server-398/plugin/resource-group-managers/trino-resource-group-managers-398.jar,resource-group-managers,resource-groups.config-file,"",false
398,trino-server-398/plugin/resource-group-managers/trino-resource-group-managers-398.jar,resource-group-managers,jmx.base-name,"",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.user,"Username for a Redis server",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.password,"Password for a password-protected Redis server",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.default-schema,"The schema name to use in the connector",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
398,trino-server-398/plugin/redis/trino-redis-398.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
398,trino-server-398/plugin/example-http/trino-example-http-398.jar,example-http,metadata-uri,"",false
398,trino-server-398/plugin/local-file/trino-local-file-398.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
398,trino-server-398/plugin/local-file/trino-local-file-398.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
398,trino-server-398/plugin/jmx/trino-jmx-398.jar,jmx,jmx.dump-tables,"",false
398,trino-server-398/plugin/jmx/trino-jmx-398.jar,jmx,jmx.max-entries,"",false
398,trino-server-398/plugin/jmx/trino-jmx-398.jar,jmx,jmx.dump-period,"",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.connection-pool.max-size,"",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.number.rounding-mode,"",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.connection-pool.min-size,"",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.connection-pool.enabled,"",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.remarks-reporting.enabled,"",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.synonyms.enabled,"",false
398,trino-server-398/plugin/oracle/trino-oracle-398.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.max-split-size,"",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.security,"Authorization checks for Delta Lake connector",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.max-initial-split-size,"",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
398,trino-server-398/plugin/delta-lake/trino-delta-lake-398.jar,delta-lake,delta.max-initial-splits,"",false
398,trino-server-398/plugin/session-property-managers/trino-session-property-managers-398.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
398,trino-server-398/plugin/session-property-managers/trino-session-property-managers-398.jar,session-property-managers,session-property-manager.db.password,"",false
398,trino-server-398/plugin/session-property-managers/trino-session-property-managers-398.jar,session-property-managers,session-property-manager.db.username,"",false
398,trino-server-398/plugin/session-property-managers/trino-session-property-managers-398.jar,session-property-managers,session-property-manager.db.url,"",false
398,trino-server-398/plugin/session-property-managers/trino-session-property-managers-398.jar,session-property-managers,session-property-manager.config-file,"",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.view-expire-duration,"",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.query-results-cache.enabled,"",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
398,trino-server-398/plugin/bigquery/trino-bigquery-398.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.connection-timeout,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.write-concern,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.connections-per-host,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.credentials,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.max-connection-idle-time,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.connection-url,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.schema-collection,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.socket-timeout,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.read-preference,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.min-connections-per-host,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.ssl.enabled,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.cursor-batch-size,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.max-wait-time,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.required-replica-set,"",false
398,trino-server-398/plugin/mongodb/trino-mongodb-398.jar,mongodb,mongodb.seeds,"",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.catalog.type,"",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.security,"",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.file-format,"",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.experimental.extended-statistics.enabled,"Allow ANALYZE and use of extended statistics collected by it. Currently, the statistics are collected in Trino-specific format",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.compression-codec,"",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
398,trino-server-398/plugin/iceberg/trino-iceberg-398.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
398,trino-server-398/plugin/phoenix5/trino-phoenix5-398.jar,phoenix5,phoenix.config.resources,"",false
398,trino-server-398/plugin/phoenix5/trino-phoenix5-398.jar,phoenix5,phoenix.connection-url,"",false
398,trino-server-398/plugin/phoenix5/trino-phoenix5-398.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
398,trino-server-398/plugin/thrift/trino-thrift-398.jar,thrift,trino-thrift.max-response-size,"",false
398,trino-server-398/plugin/thrift/trino-thrift-398.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
398,trino-server-398/plugin/thrift/trino-thrift-398.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.security,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.organization-enabled,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,metadata.db.filename,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,metadata.db.url,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.compaction-enabled,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.balancer-enabled,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.orc.nested-lazy,"",false
398,trino-server-398/plugin/raptor-legacy/trino-raptor-legacy-398.jar,raptor-legacy,storage.orc.max-read-size,"",false
398,trino-server-398/plugin/google-sheets/trino-google-sheets-398.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
398,trino-server-398/plugin/google-sheets/trino-google-sheets-398.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
398,trino-server-398/plugin/google-sheets/trino-google-sheets-398.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
398,trino-server-398/plugin/google-sheets/trino-google-sheets-398.jar,google-sheets,credentials-path,"Credential file path to google service account",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.config.resources,"Optional config files",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
398,trino-server-398/plugin/kafka/trino-kafka-398.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.batch-size,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.password,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.tls.keystore-password,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.client.so-linger,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.consistency-level,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.protocol-version,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.split-size,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.tls.keystore-path,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.client.read-timeout,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.retry-policy,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.contact-points,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.speculative-execution.limit,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.splits-per-node,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.tls.truststore-password,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.tls.enabled,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.client.connect-timeout,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.tls.truststore-path,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.fetch-size,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.native-protocol-port,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.username,"",false
398,trino-server-398/plugin/cassandra/trino-cassandra-398.jar,cassandra,cassandra.speculative-execution.delay,"",false
398,trino-server-398/plugin/mysql/trino-mysql-398.jar,mysql,mysql.auto-reconnect,"",false
398,trino-server-398/plugin/mysql/trino-mysql-398.jar,mysql,mysql.max-reconnects,"",false
398,trino-server-398/plugin/mysql/trino-mysql-398.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
398,trino-server-398/plugin/mysql/trino-mysql-398.jar,mysql,mysql.connection-timeout,"",false
398,trino-server-398/plugin/sqlserver/trino-sqlserver-398.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
398,trino-server-398/plugin/sqlserver/trino-sqlserver-398.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
398,trino-server-398/plugin/sqlserver/trino-sqlserver-398.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
398,trino-server-398/plugin/http-event-listener/trino-http-event-listener-398.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.client.default-operation-timeout,"",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.client.master-addresses,"",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.schema-emulation.enabled,"",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.schema-emulation.prefix,"",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.client.disable-statistics,"",false
398,trino-server-398/plugin/kudu/trino-kudu-398.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,ldap.cache-ttl,"",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
398,trino-server-398/plugin/password-authenticators/trino-password-authenticators-398.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.case-insensitive-name-matching,"Where to match the prometheus metric name case insensitively ",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.auth.user,"",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.auth.password,"",false
398,trino-server-398/plugin/prometheus/trino-prometheus-398.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.region,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.source-handle-target-data-size,"Target size of the data referenced by a single source handle",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.storage-class,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.encryption-enabled,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.azure.connection-string,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.endpoint,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
398,trino-server-398/plugin/exchange-filesystem/trino-exchange-filesystem-398.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.auth.password,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.auth.user,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.host,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.port,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.aws.region,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.legacy-pass-through-query.enabled,"Enable legacy Elasticsearch pass-through query",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.security,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.aws.access-key,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.tls.enabled,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
398,trino-server-398/plugin/elasticsearch/trino-elasticsearch-398.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
398,trino-server-398/plugin/singlestore/trino-singlestore-398.jar,singlestore,singlestore.auto-reconnect,"",false
398,trino-server-398/plugin/singlestore/trino-singlestore-398.jar,singlestore,singlestore.connection-timeout,"",false
398,trino-server-398/lib/trino-main-398.jar,,event.max-output-stage-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-scan-physical-bytes,"",false
398,trino-server-398/lib/trino-main-398.jar,,query-retry-attempts,"",false
398,trino-server-398/lib/trino-main-398.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
398,trino-server-398/lib/trino-main-398.jar,,task.status-refresh-max-wait,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.jwt.principal-field,"",false
398,trino-server-398/lib/trino-main-398.jar,,catalog.config-dir,"",false
398,trino-server-398/lib/trino-main-398.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.https.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.client.timeout,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.optimized-local-scheduling,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.min-expire-age,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,use-preferred-write-partitioning,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.optimize-hash-generation,"",false
398,trino-server-398/lib/trino-main-398.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
398,trino-server-398/lib/trino-main-398.jar,,distributed-sort,"",false
398,trino-server-398/lib/trino-main-398.jar,,compiler.expression-cache-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
398,trino-server-398/lib/trino-main-398.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
398,trino-server-398/lib/trino-main-398.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.min-candidates,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-history,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.writer-count,"Number of writers per task",false
398,trino-server-398/lib/trino-main-398.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
398,trino-server-398/lib/trino-main-398.jar,,warning-collector.max-warnings,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.push-table-write-through-union,"",false
398,trino-server-398/lib/trino-main-398.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.krb5.user-mapping.file,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.force-single-node-output,"",false
398,trino-server-398/lib/trino-main-398.jar,,spiller-spill-path,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
398,trino-server-398/lib/trino-main-398.jar,,deprecated.legacy-row-to-json-cast,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.max-response-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
398,trino-server-398/lib/trino-main-398.jar,,catalog.management,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
398,trino-server-398/lib/trino-main-398.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.jwt.key-file,"",false
398,trino-server-398/lib/trino-main-398.jar,,plugin.dir,"",false
398,trino-server-398/lib/trino-main-398.jar,,web-ui.user,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
398,trino-server-398/lib/trino-main-398.jar,,scale-writers,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small.max-size-per-filter,"",false
398,trino-server-398/lib/trino-main-398.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
398,trino-server-398/lib/trino-main-398.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
398,trino-server-398/lib/trino-main-398.jar,,analyzer.max-grouping-sets,"",false
398,trino-server-398/lib/trino-main-398.jar,,pages-index.eager-compaction-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,distributed-index-joins-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.push-partial-aggregation-through-join,"",false
398,trino-server-398/lib/trino-main-398.jar,,re2j.dfa-retries,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.enable-intermediate-aggregations,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.client.timeout,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
398,trino-server-398/lib/trino-main-398.jar,,statistics-precalculation-for-pushdown.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
398,trino-server-398/lib/trino-main-398.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
398,trino-server-398/lib/trino-main-398.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
398,trino-server-398/lib/trino-main-398.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
398,trino-server-398/lib/trino-main-398.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
398,trino-server-398/lib/trino-main-398.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
398,trino-server-398/lib/trino-main-398.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
398,trino-server-398/lib/trino-main-398.jar,,network-cost-weight,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.statistics-cpu-timer-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.min-drivers,"",false
398,trino-server-398/lib/trino-main-398.jar,,enable-large-dynamic-filters,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
398,trino-server-398/lib/trino-main-398.jar,,task.low-memory-killer.policy,"",false
398,trino-server-398/lib/trino-main-398.jar,,join-distribution-type,"",false
398,trino-server-398/lib/trino-main-398.jar,,internal-communication.https.keystore.path,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-planning-time,"",false
398,trino-server-398/lib/trino-main-398.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.optimize-top-n-ranking,"",false
398,trino-server-398/lib/trino-main-398.jar,,spiller-max-used-space-threshold,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.skip-redundant-sort,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,failure-detector.threshold,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.info.max-age,"",false
398,trino-server-398/lib/trino-main-398.jar,,adaptive-partial-aggregation.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
398,trino-server-398/lib/trino-main-398.jar,,enable-forced-exchange-below-group-id,"",false
398,trino-server-398/lib/trino-main-398.jar,,redistribute-writes,"",false
398,trino-server-398/lib/trino-main-398.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
398,trino-server-398/lib/trino-main-398.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
398,trino-server-398/lib/trino-main-398.jar,,query.min-schedule-split-batch-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
398,trino-server-398/lib/trino-main-398.jar,,query.executor-pool-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.compression-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-length,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.certificate.user-mapping.file,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.remote-task.min-error-duration,"",false
398,trino-server-398/lib/trino-main-398.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
398,trino-server-398/lib/trino-main-398.jar,,driver.max-page-partitioning-buffer-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.prefer-partial-aggregation,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.jwt.required-audience,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.use-mark-distinct,"",false
398,trino-server-398/lib/trino-main-398.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.max-buffer-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,internal-communication.https.truststore.path,"",false
398,trino-server-398/lib/trino-main-398.jar,,failure-detector.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.max-local-exchange-buffer-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.ignore-downstream-preferences,"",false
398,trino-server-398/lib/trino-main-398.jar,,internal-communication.https.keystore.key,"",false
398,trino-server-398/lib/trino-main-398.jar,,task-retry-attempts-per-task,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.concurrent-request-multiplier,"",false
398,trino-server-398/lib/trino-main-398.jar,,filter-and-project-min-output-page-row-count,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.info-update-interval,"Interval between updating task data",false
398,trino-server-398/lib/trino-main-398.jar,,jmx.base-name,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.max-error-duration,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.info-url-template,"",false
398,trino-server-398/lib/trino-main-398.jar,,web-ui.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.dictionary-aggregation,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
398,trino-server-398/lib/trino-main-398.jar,,http.include-exception-in-response,"",false
398,trino-server-398/lib/trino-main-398.jar,,regex-library,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
398,trino-server-398/lib/trino-main-398.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
398,trino-server-398/lib/trino-main-398.jar,,task.per-operator-cpu-timer-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
398,trino-server-398/lib/trino-main-398.jar,,iterative-optimizer-timeout,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.max-partial-top-n-memory,"",false
398,trino-server-398/lib/trino-main-398.jar,,aggregation-operator-unspill-memory-limit,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.complex-expression-pushdown.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.max-splits-per-node,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.krb5.name-type,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.default-filter-factor-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
398,trino-server-398/lib/trino-main-398.jar,,task-retry-attempts-overall,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,cpu-cost-weight,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.merge-project-with-values,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
398,trino-server-398/lib/trino-main-398.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
398,trino-server-398/lib/trino-main-398.jar,,sql.default-catalog,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.jwt.required-issuer,"",false
398,trino-server-398/lib/trino-main-398.jar,,shutdown.grace-period,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
398,trino-server-398/lib/trino-main-398.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
398,trino-server-398/lib/trino-main-398.jar,,spiller-threads,"",false
398,trino-server-398/lib/trino-main-398.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.password.user-mapping.pattern,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-queued-queries,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
398,trino-server-398/lib/trino-main-398.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
398,trino-server-398/lib/trino-main-398.jar,,event-listener.config-files,"",false
398,trino-server-398/lib/trino-main-398.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-cpu-time,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
398,trino-server-398/lib/trino-main-398.jar,,catalog.disabled-catalogs,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.push-aggregation-through-outer-join,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
398,trino-server-398/lib/trino-main-398.jar,,max-spill-per-node,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
398,trino-server-398/lib/trino-main-398.jar,,enable-stats-calculator,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
398,trino-server-398/lib/trino-main-398.jar,,task.max-worker-threads,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-execution-time,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,retry-policy,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.execution-policy,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.split-concurrency-adjustment-interval,"",false
398,trino-server-398/lib/trino-main-398.jar,,discovery-server.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
398,trino-server-398/lib/trino-main-398.jar,,query-max-spill-per-node,"",false
398,trino-server-398/lib/trino-main-398.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.allocator-type,"",false
398,trino-server-398/lib/trino-main-398.jar,,sql.default-schema,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-run-time,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.krb5.service-name,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
398,trino-server-398/lib/trino-main-398.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.acknowledge-pages,"",false
398,trino-server-398/lib/trino-main-398.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.jwt.user-mapping.file,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
398,trino-server-398/lib/trino-main-398.jar,,internal-communication.shared-secret,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.network-topology.refresh-period,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
398,trino-server-398/lib/trino-main-398.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.insecure.user-mapping.file,"",false
398,trino-server-398/lib/trino-main-398.jar,,spill-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
398,trino-server-398/lib/trino-main-398.jar,,task.http-timeout-threads,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.network-topology.file,"",false
398,trino-server-398/lib/trino-main-398.jar,,sink.max-buffer-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.manager-executor-pool-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,parse-decimal-literals-as-double,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.low-memory-killer.policy,"",false
398,trino-server-398/lib/trino-main-398.jar,,http.authentication.krb5.config,"",false
398,trino-server-398/lib/trino-main-398.jar,,memory-cost-weight,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.deduplication-buffer-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.krb5.principal-hostname,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.policy,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.schedule-split-batch-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-memory-per-node,"",false
398,trino-server-398/lib/trino-main-398.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
398,trino-server-398/lib/trino-main-398.jar,,sink.max-broadcast-buffer-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,catalog.store,"",false
398,trino-server-398/lib/trino-main-398.jar,,web-ui.session-timeout,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.data-integrity-verification,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.client-threads,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.include-coordinator,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-total-memory,"",false
398,trino-server-398/lib/trino-main-398.jar,,filter-and-project-min-output-page-size,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.cpu-timer-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
398,trino-server-398/lib/trino-main-398.jar,,failure-detector.heartbeat-interval,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.scale-writers.enabled,"Scale the number of concurrent table writers per task based on throughput",false
398,trino-server-398/lib/trino-main-398.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
398,trino-server-398/lib/trino-main-398.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
398,trino-server-398/lib/trino-main-398.jar,,enable-dynamic-filtering,"",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
398,trino-server-398/lib/trino-main-398.jar,,task.initial-splits-per-node,"",false
398,trino-server-398/lib/trino-main-398.jar,,access-control.config-files,"",false
398,trino-server-398/lib/trino-main-398.jar,,internal-communication.https.required,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
398,trino-server-398/lib/trino-main-398.jar,,query.remote-task.max-error-duration,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
398,trino-server-398/lib/trino-main-398.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
398,trino-server-398/lib/trino-main-398.jar,,task.http-response-threads,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.krb5.keytab,"",false
398,trino-server-398/lib/trino-main-398.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
398,trino-server-398/lib/trino-main-398.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
398,trino-server-398/lib/trino-main-398.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-concurrent-queries,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.password.user-mapping.file,"",false
398,trino-server-398/lib/trino-main-398.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
398,trino-server-398/lib/trino-main-398.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
398,trino-server-398/lib/trino-main-398.jar,,spill-compression-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.min-error-duration,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
398,trino-server-398/lib/trino-main-398.jar,,re2j.dfa-states-limit,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.max-pending-splits-per-task,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
398,trino-server-398/lib/trino-main-398.jar,,internal-communication.https.truststore.key,"",false
398,trino-server-398/lib/trino-main-398.jar,,task.scale-writers.max-writer-count,"Maximum number of writers per task up to which scaling will happen if task.scale-writers.enabled is set",false
398,trino-server-398/lib/trino-main-398.jar,,web-ui.shared-secret,"",false
398,trino-server-398/lib/trino-main-398.jar,,spill-encryption-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
398,trino-server-398/lib/trino-main-398.jar,,task.share-index-loading,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
398,trino-server-398/lib/trino-main-398.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
398,trino-server-398/lib/trino-main-398.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-memory,"",false
398,trino-server-398/lib/trino-main-398.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.optimize-metadata-queries,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.network-topology.type,"",false
398,trino-server-398/lib/trino-main-398.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
398,trino-server-398/lib/trino-main-398.jar,,task.max-partial-aggregation-memory,"",false
398,trino-server-398/lib/trino-main-398.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
398,trino-server-398/lib/trino-main-398.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
398,trino-server-398/lib/trino-main-398.jar,,exchange.page-buffer-client.max-callback-threads,"",false
398,trino-server-398/lib/trino-main-398.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large.max-size-per-filter,"",false
398,trino-server-398/lib/trino-main-398.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,query-results.compression-enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,experimental.late-materialization.enabled,"",false
398,trino-server-398/lib/trino-main-398.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
398,trino-server-398/lib/trino-main-398.jar,,query.remote-task.max-callback-threads,"",false
398,trino-server-398/lib/trino-main-398.jar,,query.max-stage-count,"",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
398,trino-server-398/lib/trino-main-398.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
398,trino-server-398/lib/trino-main-398.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
398,trino-server-398/lib/trino-main-398.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
398,trino-server-398/lib/trino-main-398.jar,,task.max-index-memory,"",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
399,trino-server-399/plugin/kinesis/trino-kinesis-399.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.url,"URL of the LDAP server",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,security.config-file,"",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,jmx.base-name,"",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
399,trino-server-399/plugin/kinesis/trino-plugin-toolkit-399.jar,kinesis,security.refresh-period,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,credential-provider.type,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,keystore-file-path,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,keystore-user-credential-password,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,complex-expression-pushdown.enabled,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,connection-user,"user name for JDBC client",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,connection-url,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,keystore-password-credential-password,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,user-credential-name,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,statistics.enabled,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,connection-password,"Password for JDBC client",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,case-insensitive-name-matching,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,keystore-user-credential-name,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,keystore-password-credential-name,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,keystore-password,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,join-pushdown.strategy,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,keystore-type,"",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
399,trino-server-399/plugin/clickhouse/trino-base-jdbc-399.jar,clickhouse,password-credential-name,"",false
399,trino-server-399/plugin/clickhouse/trino-clickhouse-399.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
399,trino-server-399/plugin/clickhouse/trino-clickhouse-399.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
399,trino-server-399/plugin/postgresql/trino-postgresql-399.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
399,trino-server-399/plugin/postgresql/trino-postgresql-399.jar,postgresql,postgresql.array-mapping,"",false
399,trino-server-399/plugin/postgresql/trino-postgresql-399.jar,postgresql,postgresql.include-system-tables,"",false
399,trino-server-399/plugin/atop/trino-atop-399.jar,atop,atop.security,"",false
399,trino-server-399/plugin/atop/trino-atop-399.jar,atop,atop.concurrent-readers-per-node,"",false
399,trino-server-399/plugin/atop/trino-atop-399.jar,atop,atop.max-history-days,"",false
399,trino-server-399/plugin/atop/trino-atop-399.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
399,trino-server-399/plugin/atop/trino-atop-399.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
399,trino-server-399/plugin/atop/trino-atop-399.jar,atop,atop.executable-path,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs.ipc-ping-interval,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.hdfs.authentication.type,"HDFS authentication type",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs.connect.max-retries,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs.verify-checksum,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.config.resources,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs.connect.timeout,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.hdfs.socks-proxy,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs.key-provider.cache-ttl,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs.replication,"Hadoop FileSystem replication factor",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs-timeout,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.fs.new-directory-permissions,"File system permissions for new directories",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.dfs.domain-socket-path,"",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
399,trino-server-399/plugin/hudi/trino-hdfs-399.jar,hudi,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.ignore-absent-partitions,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.stream-buffer-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.abfs.oauth.secret,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.max-client-retries,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.row-group-max-rows,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.service.principal,"Hive Metastore service principal",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.region,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.use-column-index,"Enable using Parquet column indexes",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.abfs.oauth.client-id,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-concurrent-metastore-updates,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.compression-codec,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.max-retry-time,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.proxy.non-proxy-hosts,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.authentication.type,"Thrift metastore authentication type",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.file-status-cache-tables,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.force-local-scheduling,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.max-error-retries,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.user-metastore-cache-maximum-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.sts.endpoint,"AWS STS endpoint for Glue authentication",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.writer.page-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-initial-split-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-recording-duration,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.text.max-line-length,"Maximum line length for text files",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.proxy.preemptive-basic-auth,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.file-status-cache-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.optimized-writer.validation-percentage,"Percentage of parquet files to validate after write by re-reading the whole file",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.optimize-mismatched-bucket-count,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.version-compatibility,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-refresh-max-threads,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.table-statistics-enabled,"Enable use of table statistics",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.signer-class,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.dictionary-max-memory,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.bloom-filters.enabled,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.aws-secret-key,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.client.principal,"Hive Metastore client principal",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.streaming.enabled,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3select-pushdown.max-connections,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.stripe-min-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.sts.region,"AWS STS signing region for Glue authentication",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-concurrent-metastore-drops,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-drop-table,"Allow Hive connector to drop table",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-split-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.ssl.enabled,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.recursive-directories,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.adl-proxy-host,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.start-server-on-coordinator,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.adl-client-id,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-cache-maximum-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.username,"Optional username for accessing the Hive metastore",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.replay-metastore-recording,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-partition-drops-per-query,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.wasb-access-key,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-register-partition-procedure,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.location,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-rename-column,"Allow Hive connector to rename column",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.adl-refresh-url,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-refresh-interval,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-cache-ttl,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.proxy.port,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.max-merge-distance,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.parquet.time-zone,"Time zone for Parquet read and write",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.proxy.host,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.stripe-max-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.use-column-names,"Access ORC columns using names from the file",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.proxy.password,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.max-backoff-time,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.timestamp-precision,"Precision used to represent timestamps",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-concurrent-file-renames,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.abfs-access-key,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.partition-batch-size.max,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.connect-timeout,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-add-column,"Allow Hive connector to add column",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.requester-pays.enabled,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.security,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.assume-canonical-partition-keys,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.alluxio.master.address,"Alluxio master address",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.abfs-storage-account,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.writer-identification,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.endpoint,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-initial-splits,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.file-status-cache-expire-time,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-drop-column,"Allow Hive connector to drop column",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.per-transaction-metastore-cache-maximum-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.adl-credential,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.aws-access-key,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.partition-batch-size.min,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.wasb-storage-account,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.max-read-block-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.sts.region,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.writer.block-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.size-based-split-weights-enabled,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.skip-glacier-objects,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3-file-system-type,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.stripe-max-rows,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.read-mode,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.max-merge-distance,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.socket-timeout,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-rename-table,"Allow Hive connector to rename table",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-cache.cache-partitions,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.signer-type,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.proxy.protocol,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.user-metastore-cache-ttl,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.storage-format,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.socks-proxy,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.optimized-writer.enabled,"Enable optimized Parquet writer",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-recording-path,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.max-buffer-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.data-transfer-port,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.proxy.username,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.max-split-iterator-threads,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.auto-purge,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.sse.enabled,"Enable S3 server side encryption",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.max-buffer-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.tiny-stripe-threshold,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.cache.bookkeeper-port,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.nested-lazy,"ORC lazily read nested data",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,parquet.max-read-block-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.path-style-access,"Use path-style access for all request to S3",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.user,"Hive file-based metastore username for file access",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.query-partition-filter-required,"Require filter on at least one partition column",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.string-statistics-limit,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.azure.abfs.oauth.endpoint,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.writer-sort-buffer-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.split-loader-concurrency,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.orc.writer.max-compression-buffer-size,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.sts.endpoint,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.s3.max-connections,"",false
399,trino-server-399/plugin/hudi/trino-hive-399.jar,hudi,hive.metastore-timeout,"",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.max-splits-per-second,"Rate at which splits are enqueued for processing. The queue will throttle if this rate limit is breached.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.max-partition-batch-size,"Maximum number of partitions returned in a single batch.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.size-based-split-weights-enabled,"Unlike uniform splitting, size-based splitting ensures that each batch of splits has enough data to process. By default, it is enabled to improve performance.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.metadata-enabled,"Fetch the list of file names and sizes from metadata rather than storage.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.max-outstanding-splits,"Maximum outstanding splits in a batch enqueued for processing.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.standard-split-weight-size,"The split size corresponding to the standard weight (1.0) when size based split weights are enabled.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.min-partition-batch-size,"Minimum number of partitions returned in a single batch.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.columns-to-hide,"List of column names that will be hidden from the query output. It can be used to hide Hudi meta fields. By default, no fields are hidden.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.parquet.use-column-names,"Access Parquet columns using names from the file. If disabled, then columns are accessed using index.Only applicable to Parquet file format.",false
399,trino-server-399/plugin/hudi/trino-hudi-399.jar,hudi,hudi.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled.",false
399,trino-server-399/plugin/memory/trino-memory-399.jar,memory,memory.splits-per-node,"",false
399,trino-server-399/plugin/memory/trino-memory-399.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
399,trino-server-399/plugin/memory/trino-memory-399.jar,memory,memory.max-data-per-node,"",false
399,trino-server-399/plugin/accumulo/trino-accumulo-399.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
399,trino-server-399/plugin/accumulo/trino-accumulo-399.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
399,trino-server-399/plugin/accumulo/trino-accumulo-399.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
399,trino-server-399/plugin/accumulo/trino-accumulo-399.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
399,trino-server-399/plugin/accumulo/trino-accumulo-399.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
399,trino-server-399/plugin/accumulo/trino-accumulo-399.jar,accumulo,accumulo.instance,"Accumulo instance name",false
399,trino-server-399/plugin/accumulo/trino-accumulo-399.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.tls.keystore-password,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.controller.authentication.user,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.broker.authentication.user,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.segments-per-split,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.tls.truststore-path,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.max-rows-for-broker-queries,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.tls.truststore-password,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.tls.truststore-type,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.connection-timeout,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.controller.authentication.type,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.fetch-retry-count,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.broker.authentication.type,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.controller-urls,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.port,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.tls.keystore-type,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.metadata-expiry,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.tls.keystore-path,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.controller.authentication.password,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.broker.authentication.password,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.target-segment-page-size,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.enabled,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.grpc.use-plain-text,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.prefer-broker-queries,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.forbid-segment-queries,"",false
399,trino-server-399/plugin/pinot/trino-pinot-399.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
399,trino-server-399/plugin/resource-group-managers/trino-resource-group-managers-399.jar,resource-group-managers,resource-groups.config-file,"",false
399,trino-server-399/plugin/resource-group-managers/trino-resource-group-managers-399.jar,resource-group-managers,resource-groups.config-db-url,"",false
399,trino-server-399/plugin/resource-group-managers/trino-resource-group-managers-399.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
399,trino-server-399/plugin/resource-group-managers/trino-resource-group-managers-399.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
399,trino-server-399/plugin/resource-group-managers/trino-resource-group-managers-399.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
399,trino-server-399/plugin/resource-group-managers/trino-resource-group-managers-399.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
399,trino-server-399/plugin/resource-group-managers/trino-resource-group-managers-399.jar,resource-group-managers,jmx.base-name,"",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.password,"Password for a password-protected Redis server",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.user,"Username for a Redis server",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
399,trino-server-399/plugin/redis/trino-redis-399.jar,redis,redis.default-schema,"The schema name to use in the connector",false
399,trino-server-399/plugin/example-http/trino-example-http-399.jar,example-http,metadata-uri,"",false
399,trino-server-399/plugin/local-file/trino-local-file-399.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
399,trino-server-399/plugin/local-file/trino-local-file-399.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
399,trino-server-399/plugin/jmx/trino-jmx-399.jar,jmx,jmx.dump-period,"",false
399,trino-server-399/plugin/jmx/trino-jmx-399.jar,jmx,jmx.max-entries,"",false
399,trino-server-399/plugin/jmx/trino-jmx-399.jar,jmx,jmx.dump-tables,"",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.connection-pool.enabled,"",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.connection-pool.min-size,"",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.number.rounding-mode,"",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.connection-pool.max-size,"",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.synonyms.enabled,"",false
399,trino-server-399/plugin/oracle/trino-oracle-399.jar,oracle,oracle.remarks-reporting.enabled,"",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.security,"Authorization checks for Delta Lake connector",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.max-split-size,"",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.max-initial-splits,"",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.max-initial-split-size,"",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
399,trino-server-399/plugin/delta-lake/trino-delta-lake-399.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
399,trino-server-399/plugin/session-property-managers/trino-session-property-managers-399.jar,session-property-managers,session-property-manager.db.password,"",false
399,trino-server-399/plugin/session-property-managers/trino-session-property-managers-399.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
399,trino-server-399/plugin/session-property-managers/trino-session-property-managers-399.jar,session-property-managers,session-property-manager.config-file,"",false
399,trino-server-399/plugin/session-property-managers/trino-session-property-managers-399.jar,session-property-managers,session-property-manager.db.url,"",false
399,trino-server-399/plugin/session-property-managers/trino-session-property-managers-399.jar,session-property-managers,session-property-manager.db.username,"",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.channel-pool.initial-size,"",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.channel-pool.min-size,"",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.channel-pool.max-size,"",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.view-expire-duration,"",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.channel-pool.min-rpc-per-channel,"",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.query-results-cache.enabled,"",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
399,trino-server-399/plugin/bigquery/trino-bigquery-399.jar,bigquery,bigquery.channel-pool.max-rpc-per-channel,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.ssl.enabled,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.min-connections-per-host,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.read-preference,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.socket-timeout,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.schema-collection,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.connection-url,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.max-connection-idle-time,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.credentials,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.connections-per-host,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.write-concern,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.connection-timeout,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.seeds,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.required-replica-set,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.max-wait-time,"",false
399,trino-server-399/plugin/mongodb/trino-mongodb-399.jar,mongodb,mongodb.cursor-batch-size,"",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.experimental.extended-statistics.enabled,"Allow ANALYZE and use of extended statistics collected by it. Currently, the statistics are collected in Trino-specific format",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.file-format,"",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.security,"",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.catalog.type,"",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
399,trino-server-399/plugin/iceberg/trino-iceberg-399.jar,iceberg,iceberg.compression-codec,"",false
399,trino-server-399/plugin/phoenix5/trino-phoenix5-399.jar,phoenix5,phoenix.config.resources,"",false
399,trino-server-399/plugin/phoenix5/trino-phoenix5-399.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
399,trino-server-399/plugin/phoenix5/trino-phoenix5-399.jar,phoenix5,phoenix.connection-url,"",false
399,trino-server-399/plugin/thrift/trino-thrift-399.jar,thrift,trino-thrift.max-response-size,"",false
399,trino-server-399/plugin/thrift/trino-thrift-399.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
399,trino-server-399/plugin/thrift/trino-thrift-399.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.compaction-enabled,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,metadata.db.url,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,metadata.db.filename,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.organization-enabled,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.security,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.orc.max-read-size,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.orc.nested-lazy,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.balancer-enabled,"",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
399,trino-server-399/plugin/raptor-legacy/trino-raptor-legacy-399.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
399,trino-server-399/plugin/google-sheets/trino-google-sheets-399.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
399,trino-server-399/plugin/google-sheets/trino-google-sheets-399.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
399,trino-server-399/plugin/google-sheets/trino-google-sheets-399.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
399,trino-server-399/plugin/google-sheets/trino-google-sheets-399.jar,google-sheets,credentials-path,"Credential file path to google service account",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.config.resources,"Optional config files",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
399,trino-server-399/plugin/kafka/trino-kafka-399.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.tls.enabled,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.tls.truststore-password,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.splits-per-node,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.speculative-execution.limit,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.contact-points,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.retry-policy,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.client.read-timeout,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.tls.keystore-path,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.split-size,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.protocol-version,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.consistency-level,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.client.so-linger,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.tls.keystore-password,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.password,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.batch-size,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.speculative-execution.delay,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.username,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.native-protocol-port,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.fetch-size,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.tls.truststore-path,"",false
399,trino-server-399/plugin/cassandra/trino-cassandra-399.jar,cassandra,cassandra.client.connect-timeout,"",false
399,trino-server-399/plugin/mysql/trino-mysql-399.jar,mysql,mysql.max-reconnects,"",false
399,trino-server-399/plugin/mysql/trino-mysql-399.jar,mysql,mysql.auto-reconnect,"",false
399,trino-server-399/plugin/mysql/trino-mysql-399.jar,mysql,mysql.connection-timeout,"",false
399,trino-server-399/plugin/mysql/trino-mysql-399.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
399,trino-server-399/plugin/sqlserver/trino-sqlserver-399.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
399,trino-server-399/plugin/sqlserver/trino-sqlserver-399.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
399,trino-server-399/plugin/sqlserver/trino-sqlserver-399.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
399,trino-server-399/plugin/http-event-listener/trino-http-event-listener-399.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.schema-emulation.prefix,"",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.schema-emulation.enabled,"",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.client.master-addresses,"",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.client.default-operation-timeout,"",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.client.disable-statistics,"",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
399,trino-server-399/plugin/kudu/trino-kudu-399.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,ldap.cache-ttl,"",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
399,trino-server-399/plugin/password-authenticators/trino-password-authenticators-399.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.auth.user,"",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.case-insensitive-name-matching,"Where to match the prometheus metric name case insensitively ",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.auth.password,"",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
399,trino-server-399/plugin/prometheus/trino-prometheus-399.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.encryption-enabled,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.storage-class,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.source-handle-target-data-size,"Target size of the data referenced by a single source handle",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.region,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.endpoint,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.azure.connection-string,"",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
399,trino-server-399/plugin/exchange-filesystem/trino-exchange-filesystem-399.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.tls.enabled,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.aws.access-key,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.security,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.legacy-pass-through-query.enabled,"Enable legacy Elasticsearch pass-through query",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.aws.region,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.port,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.host,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.auth.user,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.auth.password,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
399,trino-server-399/plugin/elasticsearch/trino-elasticsearch-399.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
399,trino-server-399/plugin/singlestore/trino-singlestore-399.jar,singlestore,singlestore.connection-timeout,"",false
399,trino-server-399/plugin/singlestore/trino-singlestore-399.jar,singlestore,singlestore.auto-reconnect,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
399,trino-server-399/lib/trino-main-399.jar,,web-ui.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small.max-size-per-filter,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.compression-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,iterative-optimizer-timeout,"",false
399,trino-server-399/lib/trino-main-399.jar,,web-ui.shared-secret,"",false
399,trino-server-399/lib/trino-main-399.jar,,http.include-exception-in-response,"",false
399,trino-server-399/lib/trino-main-399.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
399,trino-server-399/lib/trino-main-399.jar,,scale-writers,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.min-expire-age,"",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,warning-collector.max-warnings,"",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
399,trino-server-399/lib/trino-main-399.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
399,trino-server-399/lib/trino-main-399.jar,,task.http-response-threads,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
399,trino-server-399/lib/trino-main-399.jar,,task.split-concurrency-adjustment-interval,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.cpu-timer-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
399,trino-server-399/lib/trino-main-399.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.jwt.user-mapping.file,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.certificate.user-mapping.file,"",false
399,trino-server-399/lib/trino-main-399.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
399,trino-server-399/lib/trino-main-399.jar,,catalog.store,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.prefer-partial-aggregation,"",false
399,trino-server-399/lib/trino-main-399.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
399,trino-server-399/lib/trino-main-399.jar,,event-listener.config-files,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,statistics-precalculation-for-pushdown.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large.max-size-per-filter,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.network-topology.type,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
399,trino-server-399/lib/trino-main-399.jar,,redistribute-writes,"",false
399,trino-server-399/lib/trino-main-399.jar,,spill-compression-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.krb5.name-type,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.manager-executor-pool-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
399,trino-server-399/lib/trino-main-399.jar,,discovery-server.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.force-single-node-output,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.krb5.service-name,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.writer-count,"Number of writers per task",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.network-topology.refresh-period,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
399,trino-server-399/lib/trino-main-399.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
399,trino-server-399/lib/trino-main-399.jar,,query.executor-pool-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
399,trino-server-399/lib/trino-main-399.jar,,http.authentication.krb5.config,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.max-index-memory,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.max-splits-per-node,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.http-timeout-threads,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
399,trino-server-399/lib/trino-main-399.jar,,parse-decimal-literals-as-double,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.jwt.required-issuer,"",false
399,trino-server-399/lib/trino-main-399.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
399,trino-server-399/lib/trino-main-399.jar,,task.max-partial-top-n-memory,"",false
399,trino-server-399/lib/trino-main-399.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
399,trino-server-399/lib/trino-main-399.jar,,query.remote-task.min-error-duration,"",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.acknowledge-pages,"",false
399,trino-server-399/lib/trino-main-399.jar,,enable-forced-exchange-below-group-id,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.remote-task.max-error-duration,"",false
399,trino-server-399/lib/trino-main-399.jar,,sql.default-schema,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
399,trino-server-399/lib/trino-main-399.jar,,compiler.expression-cache-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
399,trino-server-399/lib/trino-main-399.jar,,spiller-max-used-space-threshold,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-planning-time,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.max-partial-aggregation-memory,"",false
399,trino-server-399/lib/trino-main-399.jar,,retry-policy,"",false
399,trino-server-399/lib/trino-main-399.jar,,memory-cost-weight,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.initial-splits-per-node,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.info.max-age,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
399,trino-server-399/lib/trino-main-399.jar,,filter-and-project-min-output-page-row-count,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.scale-writers.enabled,"Scale the number of concurrent table writers per task based on throughput",false
399,trino-server-399/lib/trino-main-399.jar,,task.per-operator-cpu-timer-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.status-refresh-max-wait,"",false
399,trino-server-399/lib/trino-main-399.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
399,trino-server-399/lib/trino-main-399.jar,,failure-detector.heartbeat-interval,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.password.user-mapping.file,"",false
399,trino-server-399/lib/trino-main-399.jar,,network-cost-weight,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.password.user-mapping.pattern,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.statistics-cpu-timer-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.share-index-loading,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.allocator-type,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-memory-per-node,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.complex-expression-pushdown.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.optimize-top-n-ranking,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.client.timeout,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
399,trino-server-399/lib/trino-main-399.jar,,internal-communication.https.required,"",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.max-buffer-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
399,trino-server-399/lib/trino-main-399.jar,,plugin.dir,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.krb5.keytab,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
399,trino-server-399/lib/trino-main-399.jar,,filter-and-project-min-output-page-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,distributed-sort,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
399,trino-server-399/lib/trino-main-399.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
399,trino-server-399/lib/trino-main-399.jar,,spiller-threads,"",false
399,trino-server-399/lib/trino-main-399.jar,,spill-encryption-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.max-pending-splits-per-task,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.low-memory-killer.policy,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.push-partial-aggregation-through-join,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.min-drivers,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
399,trino-server-399/lib/trino-main-399.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
399,trino-server-399/lib/trino-main-399.jar,,query.schedule-split-batch-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
399,trino-server-399/lib/trino-main-399.jar,,web-ui.session-timeout,"",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.min-error-duration,"",false
399,trino-server-399/lib/trino-main-399.jar,,catalog.disabled-catalogs,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,internal-communication.https.keystore.key,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
399,trino-server-399/lib/trino-main-399.jar,,task.info-update-interval,"Interval between updating task data",false
399,trino-server-399/lib/trino-main-399.jar,,catalog.management,"",false
399,trino-server-399/lib/trino-main-399.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
399,trino-server-399/lib/trino-main-399.jar,,task.scale-writers.max-writer-count,"Maximum number of writers per task up to which scaling will happen if task.scale-writers.enabled is set",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-execution-time,"",false
399,trino-server-399/lib/trino-main-399.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.enable-intermediate-aggregations,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.max-worker-threads,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.jwt.required-audience,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.optimized-local-scheduling,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.optimize-hash-generation,"",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.max-response-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
399,trino-server-399/lib/trino-main-399.jar,,query.remote-task.max-callback-threads,"",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
399,trino-server-399/lib/trino-main-399.jar,,task-retry-attempts-per-task,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.insecure.user-mapping.file,"",false
399,trino-server-399/lib/trino-main-399.jar,,regex-library,"",false
399,trino-server-399/lib/trino-main-399.jar,,internal-communication.https.truststore.path,"",false
399,trino-server-399/lib/trino-main-399.jar,,internal-communication.shared-secret,"",false
399,trino-server-399/lib/trino-main-399.jar,,internal-communication.https.keystore.path,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.krb5.principal-hostname,"",false
399,trino-server-399/lib/trino-main-399.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
399,trino-server-399/lib/trino-main-399.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.data-integrity-verification,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.jwt.principal-field,"",false
399,trino-server-399/lib/trino-main-399.jar,,driver.max-page-partitioning-buffer-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
399,trino-server-399/lib/trino-main-399.jar,,jmx.base-name,"",false
399,trino-server-399/lib/trino-main-399.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
399,trino-server-399/lib/trino-main-399.jar,,spiller-spill-path,"",false
399,trino-server-399/lib/trino-main-399.jar,,use-preferred-write-partitioning,"",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.concurrent-request-multiplier,"",false
399,trino-server-399/lib/trino-main-399.jar,,spill-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.min-schedule-split-batch-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,query-max-spill-per-node,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.jwt.key-file,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.merge-project-with-values,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.default-filter-factor-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-length,"",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.max-error-duration,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.use-mark-distinct,"",false
399,trino-server-399/lib/trino-main-399.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
399,trino-server-399/lib/trino-main-399.jar,,task.client.timeout,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
399,trino-server-399/lib/trino-main-399.jar,,adaptive-partial-aggregation.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
399,trino-server-399/lib/trino-main-399.jar,,query.low-memory-killer.policy,"",false
399,trino-server-399/lib/trino-main-399.jar,,access-control.config-files,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.network-topology.file,"",false
399,trino-server-399/lib/trino-main-399.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
399,trino-server-399/lib/trino-main-399.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.optimize-metadata-queries,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
399,trino-server-399/lib/trino-main-399.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
399,trino-server-399/lib/trino-main-399.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.dictionary-aggregation,"",false
399,trino-server-399/lib/trino-main-399.jar,,catalog.config-dir,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-total-memory,"",false
399,trino-server-399/lib/trino-main-399.jar,,sql.default-catalog,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
399,trino-server-399/lib/trino-main-399.jar,,enable-dynamic-filtering,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.krb5.user-mapping.file,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.push-aggregation-through-outer-join,"",false
399,trino-server-399/lib/trino-main-399.jar,,re2j.dfa-states-limit,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.skip-redundant-sort,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.https.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,aggregation-operator-unspill-memory-limit,"",false
399,trino-server-399/lib/trino-main-399.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
399,trino-server-399/lib/trino-main-399.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.min-candidates,"",false
399,trino-server-399/lib/trino-main-399.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
399,trino-server-399/lib/trino-main-399.jar,,web-ui.user,"",false
399,trino-server-399/lib/trino-main-399.jar,,failure-detector.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,shutdown.grace-period,"",false
399,trino-server-399/lib/trino-main-399.jar,,enable-stats-calculator,"",false
399,trino-server-399/lib/trino-main-399.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-concurrent-queries,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
399,trino-server-399/lib/trino-main-399.jar,,distributed-index-joins-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
399,trino-server-399/lib/trino-main-399.jar,,join-distribution-type,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
399,trino-server-399/lib/trino-main-399.jar,,experimental.late-materialization.enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.page-buffer-client.max-callback-threads,"",false
399,trino-server-399/lib/trino-main-399.jar,,sink.max-buffer-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.deduplication-buffer-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-queued-queries,"",false
399,trino-server-399/lib/trino-main-399.jar,,pages-index.eager-compaction-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.info-url-template,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.execution-policy,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
399,trino-server-399/lib/trino-main-399.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
399,trino-server-399/lib/trino-main-399.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
399,trino-server-399/lib/trino-main-399.jar,,cpu-cost-weight,"",false
399,trino-server-399/lib/trino-main-399.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.ignore-downstream-preferences,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-history,"",false
399,trino-server-399/lib/trino-main-399.jar,,exchange.client-threads,"",false
399,trino-server-399/lib/trino-main-399.jar,,sink.max-broadcast-buffer-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
399,trino-server-399/lib/trino-main-399.jar,,failure-detector.threshold,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.push-table-write-through-union,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-cpu-time,"",false
399,trino-server-399/lib/trino-main-399.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
399,trino-server-399/lib/trino-main-399.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
399,trino-server-399/lib/trino-main-399.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
399,trino-server-399/lib/trino-main-399.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.policy,"",false
399,trino-server-399/lib/trino-main-399.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
399,trino-server-399/lib/trino-main-399.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
399,trino-server-399/lib/trino-main-399.jar,,task.max-local-exchange-buffer-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,task-retry-attempts-overall,"",false
399,trino-server-399/lib/trino-main-399.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
399,trino-server-399/lib/trino-main-399.jar,,node-scheduler.include-coordinator,"",false
399,trino-server-399/lib/trino-main-399.jar,,query-results.compression-enabled,"",false
399,trino-server-399/lib/trino-main-399.jar,,max-spill-per-node,"",false
399,trino-server-399/lib/trino-main-399.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
399,trino-server-399/lib/trino-main-399.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
399,trino-server-399/lib/trino-main-399.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
399,trino-server-399/lib/trino-main-399.jar,,event.max-output-stage-size,"",false
399,trino-server-399/lib/trino-main-399.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-stage-count,"",false
399,trino-server-399/lib/trino-main-399.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
399,trino-server-399/lib/trino-main-399.jar,,analyzer.max-grouping-sets,"",false
399,trino-server-399/lib/trino-main-399.jar,,internal-communication.https.truststore.key,"",false
399,trino-server-399/lib/trino-main-399.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
399,trino-server-399/lib/trino-main-399.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
399,trino-server-399/lib/trino-main-399.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-run-time,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
399,trino-server-399/lib/trino-main-399.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-memory,"",false
399,trino-server-399/lib/trino-main-399.jar,,query.max-scan-physical-bytes,"",false
399,trino-server-399/lib/trino-main-399.jar,,query-retry-attempts,"",false
399,trino-server-399/lib/trino-main-399.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
399,trino-server-399/lib/trino-main-399.jar,,enable-large-dynamic-filters,"",false
399,trino-server-399/lib/trino-main-399.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
399,trino-server-399/lib/trino-main-399.jar,,re2j.dfa-retries,"",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.default-schema,"Sets default schema for kinesis catalogs",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.table-description-refresh-interval,"How often to get the table description from S3",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.aws-region,"Region to set while creating S3 client",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.access-key,"S3 Access Key to access s3 locations",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.batch-size,"Limit maximum number of rows to return in a batch",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.dynamo-read-capacity,"DynamoDB read capacity to be set in client",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.fetch-attempts,"Maximum number of attempts to fetch the next batch from a shard iterator",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.table-description-location,"S3 or local filesystem directory location where table schema descriptions are present",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.log-batches,"Decides whether to log batch fetch details",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.hide-internal-columns,"Toggle to decide whether to show Kinesis internal columns or not",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.secret-key,"S3 Secret Key to access s3 locations",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.checkpoint-enabled,"Whether to remember last read sequence number and use it in later requests",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.iterator-offset-seconds,"Seconds before current time to start fetching records from",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.checkpoint-logical-name,"Prefix to the checkpoint name",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.iterator-number,"Checkpoint iteration number",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.dynamo-write-capacity,"DynamoDB read capacity to be set in client",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.iterator-from-timestamp,"Whether to use start timestamp from shard iterator",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.max-batches,"Maximum number of calls to Kinesis per query",false
400,trino-server-400/plugin/kinesis/trino-kinesis-400.jar,kinesis,kinesis.sleep-time,"Sleep time between fetch attempt retries",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.timeout.read,"Timeout for reading data from LDAP",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,security.refresh-period,"",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.allow-insecure,"Allow insecure connection to the LDAP server",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.url,"URL of the LDAP server",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.ssl.keystore.path,"Path to the PEM or JKS key store",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.ssl.keystore.password,"Password for the key store",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.ignore-referrals,"Referrals allow finding entries across multiple LDAP servers. Ignore them to only search within 1 LDAP server",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,security.config-file,"",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.ssl.truststore.password,"Password for the trust store",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.ssl.truststore.path,"Path to the PEM or JKS trust store",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,ldap.timeout.connect,"Timeout for establishing a connection",false
400,trino-server-400/plugin/kinesis/trino-plugin-toolkit-400.jar,kinesis,jmx.base-name,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,keystore-user-credential-name,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,write.batch-size,"Maximum number of rows to write in a single batch",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,keystore-password-credential-name,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,keystore-password,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,join-pushdown.strategy,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,keystore-type,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,password-credential-name,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,remote-query-async-cancellation.enabled,"Enable asynchronous remote query cancellation",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,decimal-mapping,"Decimal mapping for unspecified and exceeding precision decimals. STRICT skips them. ALLOW_OVERFLOW requires setting proper decimal scale and rounding mode",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,join-pushdown.enabled,"Enable join pushdown",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,credential-provider.type,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,keystore-file-path,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,keystore-user-credential-password,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,experimental.join-pushdown.automatic.max-join-to-tables-ratio,"If estimated join output size is greater than or equal to ratio * sum of table sizes, then join pushdown will not be performed",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,metadata.cache-missing,"Determines if missing information will be cached",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,complex-expression-pushdown.enabled,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,connection-user,"user name for JDBC client",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,connection-credential-file,"Location of the file where credentials are present",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,connection-url,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,keystore-password-credential-password,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,unsupported-type-handling,"Unsupported type handling strategy",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,user-credential-name,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,topn-pushdown.enabled,"Enable TopN pushdown",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,insert.non-transactional-insert.enabled,"Do not create temporary table during insert. This means that the write operation can fail and leave the table in an inconsistent state.",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,decimal-default-scale,"Default decimal scale for mapping unspecified and exceeding precision decimals. Not used when decimal_mapping is set to STRICT",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,experimental.join-pushdown.automatic.max-table-size,"Maximum table size to be considered for join pushdown",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,case-insensitive-name-matching.config-file,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,statistics.enabled,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,connection-password,"Password for JDBC client",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,dynamic-filtering.enabled,"Wait for dynamic filters before starting JDBC query",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,aggregation-pushdown.enabled,"Enable aggregation pushdown",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,jdbc-types-mapped-to-varchar,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,decimal-rounding-mode,"Rounding mode for mapping unspecified and exceeding precision decimals. Not used whendecimal_mappingis set to STRICT",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,case-insensitive-name-matching.cache-ttl,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,metadata.cache-maximum-size,"Maximum number of objects stored in the metadata cache",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,metadata.cache-ttl,"Determines how long meta information will be cached",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,case-insensitive-name-matching,"",false
400,trino-server-400/plugin/clickhouse/trino-base-jdbc-400.jar,clickhouse,case-insensitive-name-matching.config-file.refresh-period,"",false
400,trino-server-400/plugin/clickhouse/trino-clickhouse-400.jar,clickhouse,clickhouse.legacy-driver,"Whether to use a legacy driver",false
400,trino-server-400/plugin/clickhouse/trino-clickhouse-400.jar,clickhouse,clickhouse.map-string-as-varchar,"Map ClickHouse String and FixedString as varchar instead of varbinary",false
400,trino-server-400/plugin/postgresql/trino-postgresql-400.jar,postgresql,postgresql.experimental.enable-string-pushdown-with-collate,"",false
400,trino-server-400/plugin/postgresql/trino-postgresql-400.jar,postgresql,postgresql.array-mapping,"",false
400,trino-server-400/plugin/postgresql/trino-postgresql-400.jar,postgresql,postgresql.include-system-tables,"",false
400,trino-server-400/plugin/atop/trino-atop-400.jar,atop,atop.time-zone,"The timezone in which the atop data was collected. Generally the timezone of the host.",false
400,trino-server-400/plugin/atop/trino-atop-400.jar,atop,atop.executable-read-timeout,"The timeout when reading from the atop process.",false
400,trino-server-400/plugin/atop/trino-atop-400.jar,atop,atop.executable-path,"",false
400,trino-server-400/plugin/atop/trino-atop-400.jar,atop,atop.security,"",false
400,trino-server-400/plugin/atop/trino-atop-400.jar,atop,atop.concurrent-readers-per-node,"",false
400,trino-server-400/plugin/atop/trino-atop-400.jar,atop,atop.max-history-days,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.fs.cache.max-size,"Hadoop FileSystem cache size",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.hdfs.trino.principal,"Trino principal used to access HDFS",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.hdfs.wire-encryption.enabled,"Should be turned on when HDFS wire encryption is enabled",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.hdfs.trino.credential-cache.location,"Trino credential-cache location used to access HDFS",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.hdfs.trino.keytab,"Trino keytab used to access HDFS",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.fs.new-file-inherit-ownership,"File system permissions for new directories",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs.ipc-ping-interval,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.hdfs.impersonation.enabled,"Should Trino user be impersonated when communicating with HDFS",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.hdfs.authentication.type,"HDFS authentication type",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs.connect.max-retries,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs.verify-checksum,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.config.resources,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs.connect.timeout,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.hdfs.socks-proxy,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs.key-provider.cache-ttl,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs.replication,"Hadoop FileSystem replication factor",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs-timeout,"",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.fs.new-directory-permissions,"File system permissions for new directories",false
400,trino-server-400/plugin/hudi/trino-hdfs-400.jar,hudi,hive.dfs.domain-socket-path,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.endpoint,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.abfs.oauth.secret,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.propagate-table-scan-sorting-properties,"Use sorted table layout to generate more efficient execution plans. May lead to incorrect results if files are not sorted as per table definition.",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.delegate-transactional-managed-table-location-to-metastore,"When transactional, managed table is created via Trino the location will not be set in request sent to HMS and location will be determined by metastore; if this value is set to true, CREATE TABLE AS queries are not supported.",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.client.keytab,"Hive Metastore client keytab location",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.stripe-min-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.txn-lock-max-wait,"Maximum time to wait to acquire hive transaction lock",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.create-empty-bucket-files,"Create empty files for buckets that have no data",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.connect-timeout,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.proxy.protocol,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.use-column-index,"Enable using Parquet column indexes",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.row-group-max-rows,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.delegation-token.cache-ttl,"Time to live delegation token cache for metastore",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.default-bloom-filter-fpp,"ORC Bloom filter false positive probability",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.max-client-retries,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.split-loader-concurrency,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.client.principal,"Hive Metastore client principal",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.storage-class,"AWS S3 storage class to use when writing the data",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.write-validation-threads,"Number of threads used for verifying data after a write",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-outstanding-splits-size,"Maximum amount of memory allowed for split buffering for each table scan in a query, before the query is failed",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.security-mapping.colon-replacement,"Value used in place of colon for IAM role name in extra credentials",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.use-column-names,"Access ORC columns using names from the file",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.catalogid,"Hive Glue metastore catalog id",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-recording-duration,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.max-buffer-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.writer.batch-size,"Maximum number of rows passed to the writer in each batch",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.proxy.password,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.hive-views.enabled,"Experimental: Allow translation of Hive views into Trino views",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.lazy-read-small-ranges,"ORC read small disk ranges lazily",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.immutable-partitions,"Can new data be inserted into existing partitions or existing unpartitioned tables",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.security-mapping.iam-role-credential-name,"Name of the extra credential used to provide IAM role",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.assume-canonical-partition-keys,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.user-metastore-cache-ttl,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.skip-glacier-objects,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.assume-canonical-partition-keys,"Allow conversion of non-char types (eg BIGINT, timestamp) to canonical string formats",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.max-retries,"Maximum number of retry attempts for metastore requests",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.optimize-mismatched-bucket-count,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.abfs-storage-account,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-concurrent-file-renames,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.force-local-scheduling,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-partitions-for-eager-load,"Maximum allowed partitions for a single table scan to be loaded eagerly on coordinator. Certain optimizations are not possible without eager loading.",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.optimize-symlink-listing,"Optimize listing for SymlinkTextFormat tables with files in a single directory",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.parallel-partitioned-bucketed-writes,"Improve parallelism of partitioned and bucketed table writes",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.partition-statistics-sample-size,"Maximum sample size of the partitions column statistics",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.ssl.key-password,"Password for the key store",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.auto-purge,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-register-partition-procedure,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.ignore-statistics,"Ignore statistics from Parquet to allow querying files with corrupted or incorrect statistics",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.max-connections,"Max number of concurrent connections to Glue",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-cache-maximum-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.user,"Hive file-based metastore username for file access",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.disk-usage-percentage,"Percentage of disk space used for cached data",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.sse.kms-key-id,"KMS Key ID to use for S3 server-side encryption with KMS-managed key",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.replay-metastore-recording,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.read-statistics-threads,"Number of threads for parallel statistics reads from Glue",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.transaction-heartbeat-threads,"Number of threads to run in the Hive transaction heartbeat service",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.pin-client-to-current-region,"Should the S3 client be pinned to the current EC2 region",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.stream-buffer-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.read-mode,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-drop-column,"Allow Hive connector to drop column",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.version-compatibility,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.validate-bucketing,"Verify that data is bucketed correctly when reading",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.optimized-writer.enabled,"Enable optimized Parquet writer",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.ignore-absent-partitions,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.hive-views.legacy-translation,"Use legacy Hive view translation mechanism",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.insert-existing-partitions-behavior,"Default value for insert existing partitions behavior",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.username,"Optional username for accessing the Hive metastore",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.time-zone,"Time zone for legacy ORC files that do not contain a time zone",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.pin-client-to-current-region,"Should the Glue client be pinned to the current EC2 region",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.adl-refresh-url,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.upload-acl-type,"Canned ACL type for S3 uploads",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.temporary-staging-directory-path,"Location of temporary staging directory for write operations. Use ${USER} placeholder to use different location for each user.",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-partitions-per-scan,"Maximum allowed partitions for a single table scan",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3select-pushdown.enabled,"Enable query pushdown to AWS S3 Select service",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.max-buffer-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.aws-credentials-provider,"Fully qualified name of the Java class to use for obtaining AWS credentials",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.security,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.non-managed-table-creates-enabled,"Enable non-managed (external) table creates",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.query-partition-filter-required-schemas,"List of schemas for which filter on partition column is enforced",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.partition-projection-enabled,"Enables AWS Athena partition projection",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-comment-column,"Allow Hive connector to set comment for a column",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.string-statistics-limit,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.sts.region,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.external-id,"External ID for the IAM role trust policy when connecting to Glue",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-initial-splits,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.projection-pushdown-enabled,"Projection pushdown into hive is enabled through applyProjection",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-cache.cache-partitions,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-add-column,"Allow Hive connector to add column",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.dictionary-max-memory,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.aws-access-key,"Hive Glue metastore AWS access key",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.max-error-retries,"Maximum number of error retries for the Glue client",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.partition-batch-size.min,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.alluxio.master.address,"Alluxio master address",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.optimized-writer.validation-percentage,"Percentage of parquet files to validate after write by re-reading the whole file",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-split-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.proxy.non-proxy-hosts,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.socks-proxy,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.max-merge-distance,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.stripe-max-rows,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.storage-format,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.abfs-access-key,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-recording-path,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.service.principal,"Hive Metastore service principal",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.ssl.key,"Path to the key store",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.nested-lazy,"ORC lazily read nested data",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-comment-table,"Allow Hive connector to set comment for a table",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.uri,"Hive metastore URIs (comma separated)",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.sorted-writing,"Enable writing to bucketed sorted tables",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.ssl.trust-certificate,"Path to the trust store",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.delegation-token.cache-maximum-size,"Delegation token cache maximum size",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.kms-key-id,"Use an AWS KMS key for S3 data encryption",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.transaction-heartbeat-interval,"Interval after which heartbeat is sent for open Hive transaction",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.impersonation.enabled,"Should end user be impersonated when communicating with metastore",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.socket-timeout,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.text.max-line-length,"Maximum line length for text files",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.encryption-materials-provider,"Use a custom encryption materials provider for S3 data encryption",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.location,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.recursive-directories,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.abfs.oauth.client-id,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.partitions-segments,"Number of segments for partitioned Glue tables",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.proxy.host,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-partition-drops-per-query,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.aws-access-key,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.sts.region,"AWS STS signing region for Glue authentication",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.query-partition-filter-required,"Require filter on at least one partition column",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.proxy.username,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.security-mapping.kms-key-id-credential-name,"Name of the extra credential used to provide KMS Key ID",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.gcs.use-access-token,"Use client-provided OAuth token to access Google Cloud Storage",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.compression-codec,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.ignore-corrupted-statistics,"Ignore corrupted statistics rather than failing",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.enabled,"Experimental: Cache HDFS file segments to distributed local storage",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-drop-table,"Allow Hive connector to drop table",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-open-sort-files,"Maximum number of writer temporary files to read in one pass",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.ttl,"Time files will be kept in cache prior to eviction",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.parquet.use-column-names,"Access Parquet columns using names from the file",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-timeout,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.collect-column-statistics-on-write,"Enables automatic column level statistics collection on write",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.bookkeeper-port,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.adl-client-id,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.sse.type,"Key management type for S3 server-side encryption (S3 or KMS)",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.signer-class,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.wasb-access-key,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.iceberg-catalog-name,"The catalog to redirect iceberg tables to",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.max-retry-time,"Total time limit for a metastore request to be retried",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.writer.page-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.path-style-access,"Use path-style access for all request to S3",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.max-connections,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.max-backoff-time,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.adl-proxy-host,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.write-statistics-threads,"Number of threads for parallel statistics writes to Glue",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.temporary-staging-directory-enabled,"Should use (if possible) temporary staging directory for write operations",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.writer.block-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.adl-credential,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.iam-role,"ARN of an IAM role to assume when connecting to Glue",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.proxy.port,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.respect-table-format,"Should new partitions be written using the existing table format or the default Trino format",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.max-compression-buffer-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.wasb-storage-account,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.sse.enabled,"Enable S3 server side encryption",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.skip-target-cleanup-on-rollback,"Skip deletion of target directories when a metastore operation fails",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.per-transaction-file-status-cache-maximum-size,"Maximum number of file statuses cached by transactional file status cache",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.client.credential-cache.location,"Hive Metastore client credential cache location",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.file-status-cache-tables,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.rcfile.time-zone,"Time zone for RCFile binary read and write",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.multipart.min-file-size,"Minimum file size for an S3 multipart upload",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.bloom-filters.enabled,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.hide-delta-lake-tables,"Hide Delta Lake tables in table listings",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.stripe-max-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.max-error-retries,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.backoff-scale-factor,"Scale factor for metastore request retry delay",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.bucket-execution,"Enable bucket-aware execution: only use a single worker per bucket",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.ssl.enabled,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.sts.endpoint,"AWS STS endpoint for Glue authentication",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.file-status-cache-expire-time,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.max-backoff-delay,"Maximum delay between metastore request retries",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.max-merge-distance,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.non-managed-table-writes-enabled,"Enable writes to non-managed (external) tables",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.writer-sort-buffer-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.validation-mode,"Level of detail in ORC validation. Lower levels require more memory.",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.partition-batch-size.max,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-concurrent-metastore-drops,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,parquet.max-read-block-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.tiny-stripe-threshold,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-refresh-max-threads,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.default-warehouse-dir,"Hive Glue metastore default warehouse directory",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.min-backoff-delay,"Minimum delay between metastore request retries",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.aws-secret-key,"Hive Glue metastore AWS secret key",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-refresh-interval,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.staging-directory,"Temporary directory for staging files before uploading to S3",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3select-pushdown.max-connections,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.requester-pays.enabled,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.catalog.dir,"Hive file-based metastore catalog directory",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.rcfile.writer.validate,"Validate RCFile after write by re-reading the whole file",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.data-transfer-port,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.user-metastore-cache-maximum-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore-cache-ttl,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.gcs.json-key-file-path,"JSON key file used to access Google Cloud Storage",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.validation-percentage,"Percentage of ORC files to validate after write by re-reading the whole file",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.file-status-cache-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.ssl.enabled,"Whether TLS security is enabled",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.max-read-block-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.authentication.type,"Thrift metastore authentication type",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.security-mapping.json-pointer,"JSON pointer (RFC 6901) to mappings inside JSON config",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.max-retry-time,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.hive-views.run-as-invoker,"Execute Hive views with permissions of invoker",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.streaming.enabled,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.single-statement-writes,"Require transaction to be in auto-commit mode for writes",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.client.ssl.trust-certificate-password,"Password for the trust store",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.streaming.part-size,"Part size for S3 streaming upload",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.cache.start-server-on-coordinator,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.user-agent-prefix,"The user agent prefix to use for S3 calls",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-split-iterator-threads,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-partitions-per-writers,"Maximum number of partitions per writer",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.endpoint-url,"Glue API endpoint URL",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.per-transaction-metastore-cache-maximum-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.aws-secret-key,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3-file-system-type,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.sts.endpoint,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.get-partition-threads,"Number of threads for parallel partition fetches from Glue",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.orc.writer.writer-identification,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.glue.region,"AWS Region for Glue Data Catalog",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.proxy.preemptive-basic-auth,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.region,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.security-mapping.refresh-period,"How often to refresh the security mapping configuration",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.delta-lake-catalog-name,"Catalog to redirect to when a Delta Lake table is referenced",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.skip-deletion-for-alter,"Skip deletion of old partition data when a partition is deleted and then inserted in the same transaction",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-concurrent-metastore-updates,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.azure.abfs.oauth.endpoint,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.signer-type,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.timestamp-precision,"Precision used to represent timestamps",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-rename-column,"Allow Hive connector to rename column",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.parquet.time-zone,"Time zone for Parquet read and write",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.metastore.thrift.delete-files-on-drop,"Delete files on drop in case the metastore doesn't do it",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.max-initial-split-size,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.multipart.min-part-size,"Minimum part size for an S3 multipart upload",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.allow-rename-table,"Allow Hive connector to rename table",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.security-mapping.config-file,"JSON configuration file containing security mappings",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.table-statistics-enabled,"Enable use of table statistics",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.size-based-split-weights-enabled,"",false
400,trino-server-400/plugin/hudi/trino-hive-400.jar,hudi,hive.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.parquet.use-column-names,"Access Parquet columns using names from the file. If disabled, then columns are accessed using index.Only applicable to Parquet file format.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.minimum-assigned-split-weight,"Minimum weight that a split can be assigned when size based split weights are enabled.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.max-splits-per-second,"Rate at which splits are enqueued for processing. The queue will throttle if this rate limit is breached.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.max-partition-batch-size,"Maximum number of partitions returned in a single batch.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.size-based-split-weights-enabled,"Unlike uniform splitting, size-based splitting ensures that each batch of splits has enough data to process. By default, it is enabled to improve performance.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.metadata-enabled,"Fetch the list of file names and sizes from metadata rather than storage.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.max-outstanding-splits,"Maximum outstanding splits in a batch enqueued for processing.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.standard-split-weight-size,"The split size corresponding to the standard weight (1.0) when size based split weights are enabled.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.min-partition-batch-size,"Minimum number of partitions returned in a single batch.",false
400,trino-server-400/plugin/hudi/trino-hudi-400.jar,hudi,hudi.columns-to-hide,"List of column names that will be hidden from the query output. It can be used to hide Hudi meta fields. By default, no fields are hidden.",false
400,trino-server-400/plugin/memory/trino-memory-400.jar,memory,memory.splits-per-node,"",false
400,trino-server-400/plugin/memory/trino-memory-400.jar,memory,memory.enable-lazy-dynamic-filtering,"",false
400,trino-server-400/plugin/memory/trino-memory-400.jar,memory,memory.max-data-per-node,"",false
400,trino-server-400/plugin/accumulo/trino-accumulo-400.jar,accumulo,accumulo.cardinality.cache.size,"Sets the cardinality cache size",false
400,trino-server-400/plugin/accumulo/trino-accumulo-400.jar,accumulo,accumulo.username,"Sets the user to use when interacting with Accumulo. This user will require administrative permissions",false
400,trino-server-400/plugin/accumulo/trino-accumulo-400.jar,accumulo,accumulo.zookeeper.metadata.root,"Sets the root znode for metadata storage",false
400,trino-server-400/plugin/accumulo/trino-accumulo-400.jar,accumulo,accumulo.cardinality.cache.expire.duration,"Sets the cardinality cache expiration",false
400,trino-server-400/plugin/accumulo/trino-accumulo-400.jar,accumulo,accumulo.password,"Sets the password for the configured user",false
400,trino-server-400/plugin/accumulo/trino-accumulo-400.jar,accumulo,accumulo.zookeepers,"ZooKeeper quorum connect string for Accumulo",false
400,trino-server-400/plugin/accumulo/trino-accumulo-400.jar,accumulo,accumulo.instance,"Accumulo instance name",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.max-rows-for-broker-queries,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.metadata-expiry,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.controller.authentication.user,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.max-inbound-message-size,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.count-distinct-pushdown.enabled,"Controls whether distinct count is pushed down to Pinot. Distinct count pushdown can cause Pinot to do a full scan. Aggregation pushdown must also be enabled in addition to this parameter otherwise no pushdowns will be enabled.",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.target-segment-page-size,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.tls.ssl-provider,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.controller.authentication.type,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.proxy-uri,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.broker.authentication.password,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.tls.keystore-path,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.broker.authentication.user,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.prefer-broker-queries,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.controller-urls,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.use-plain-text,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.controller.authentication.password,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.non-aggregate-limit-for-broker-queries,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.max-rows-per-split-for-segment-queries,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.fetch-retry-count,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.tls.keystore-type,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.port,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.aggregation-pushdown.enabled,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.estimated-size-in-bytes-for-non-numeric-column,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.proxy.enabled,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.tls.truststore-password,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.tls.truststore-type,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.connection-timeout,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.segments-per-split,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.tls.keystore-password,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.forbid-segment-queries,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.broker.authentication.type,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.enabled,"",false
400,trino-server-400/plugin/pinot/trino-pinot-400.jar,pinot,pinot.grpc.tls.truststore-path,"",false
400,trino-server-400/plugin/resource-group-managers/trino-resource-group-managers-400.jar,resource-group-managers,resource-groups.config-file,"",false
400,trino-server-400/plugin/resource-group-managers/trino-resource-group-managers-400.jar,resource-group-managers,resource-groups.config-db-url,"",false
400,trino-server-400/plugin/resource-group-managers/trino-resource-group-managers-400.jar,resource-group-managers,resource-groups.max-refresh-interval,"Time period for which the cluster will continue to accept queries after refresh failures cause configuration to become stale",false
400,trino-server-400/plugin/resource-group-managers/trino-resource-group-managers-400.jar,resource-group-managers,resource-groups.config-db-password,"Database password",false
400,trino-server-400/plugin/resource-group-managers/trino-resource-group-managers-400.jar,resource-group-managers,resource-groups.config-db-user,"Database user name",false
400,trino-server-400/plugin/resource-group-managers/trino-resource-group-managers-400.jar,resource-group-managers,resource-groups.exact-match-selector-enabled,"",false
400,trino-server-400/plugin/resource-group-managers/trino-resource-group-managers-400.jar,resource-group-managers,jmx.base-name,"",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.table-description-cache-ttl,"The cache time for redis table description files",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.key-delimiter,"Delimiter for separating schema name and table name in the KEY prefix",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.database-index,"Index of the Redis DB to connect to",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.default-schema,"The schema name to use in the connector",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.table-description-dir,"Folder holding the JSON description files for Redis values",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.connect-timeout,"Timeout to connect to Redis",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.password,"Password for a password-protected Redis server",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.user,"Username for a Redis server",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.scan-count,"Count parameter for Redis scan command",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.key-prefix-schema-table,"Whether Redis key string follows ""schema:table:*"" format",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.table-names,"Set of tables known to this connector. For each table, a description file may be present in the catalog folder which describes columns for the given table",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.max-keys-per-fetch,"Get values associated with the specified number of keys in the command such as MGET(key...)",false
400,trino-server-400/plugin/redis/trino-redis-400.jar,redis,redis.nodes,"Seed nodes for Redis cluster. At least one must exist",false
400,trino-server-400/plugin/example-http/trino-example-http-400.jar,example-http,metadata-uri,"",false
400,trino-server-400/plugin/local-file/trino-local-file-400.jar,local-file,trino-logs.http-request-log.pattern,"If log location is a directory this glob is used to match the file names in the directory",false
400,trino-server-400/plugin/local-file/trino-local-file-400.jar,local-file,trino-logs.http-request-log.location,"Directory or file where http request logs are written",false
400,trino-server-400/plugin/jmx/trino-jmx-400.jar,jmx,jmx.max-entries,"",false
400,trino-server-400/plugin/jmx/trino-jmx-400.jar,jmx,jmx.dump-tables,"",false
400,trino-server-400/plugin/jmx/trino-jmx-400.jar,jmx,jmx.dump-period,"",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.remarks-reporting.enabled,"",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.connection-pool.enabled,"",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.connection-pool.inactive-timeout,"How long a connection in the pool can remain idle before it is closed",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.connection-pool.min-size,"",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.number.rounding-mode,"",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.connection-pool.max-size,"",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.number.default-scale,"Default Trino DECIMAL scale for Oracle NUMBER data type",false
400,trino-server-400/plugin/oracle/trino-oracle-400.jar,oracle,oracle.synonyms.enabled,"",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.max-outstanding-splits,"Target number of buffered splits for each table scan in a query, before the scheduler tries to pause itself",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.metadata.live-files.cache-ttl,"Caching duration for Delta data file metadata (e.g. table schema, partition info)",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.unique-table-location,"Use randomized, unique table locations",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.compression-codec,"Compression codec to use when writing new data files",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.vacuum.min-retention,"Minimal retention period for vacuum procedure",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.checkpoint-row-statistics-writing.enabled,"",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.max-initial-splits,"",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.enable-non-concurrent-writes,"",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.extended-statistics.enabled,"Use extended statistics collected by ANALYZE",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.metadata.cache-ttl,"Caching duration for Delta table metadata (e.g. table schema, partition info)",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.hide-non-delta-lake-tables,"Hide non-Delta Lake tables in table listings",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.max-split-size,"",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.per-transaction-metastore-cache-maximum-size,"",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.default-checkpoint-writing-interval,"How often (in number of transactions) to write checkpoint of transaction log",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.table-statistics-enabled,"Expose table statistics",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.domain-compaction-threshold,"Maximum ranges to allow in a tuple domain without compacting it",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.security,"Authorization checks for Delta Lake connector",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.max-partitions-per-writer,"Maximum number of partitions per writer",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.max-initial-split-size,"",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.metadata.cache-size,"Maximum number of Delta table metadata entries to cache",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.parquet.time-zone,"Time zone for Parquet read and write",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.metadata.live-files.cache-size,"Maximum in memory cache size for Delta data file metadata (e.g. file path, statistics, partition values). Defaults to 10% of the available heap size.",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
400,trino-server-400/plugin/delta-lake/trino-delta-lake-400.jar,delta-lake,delta.max-splits-per-second,"Throttles the maximum number of splits that can be assigned to tasks per second",false
400,trino-server-400/plugin/session-property-managers/trino-session-property-managers-400.jar,session-property-managers,session-property-manager.db.url,"",false
400,trino-server-400/plugin/session-property-managers/trino-session-property-managers-400.jar,session-property-managers,session-property-manager.db.username,"",false
400,trino-server-400/plugin/session-property-managers/trino-session-property-managers-400.jar,session-property-managers,session-property-manager.db.password,"",false
400,trino-server-400/plugin/session-property-managers/trino-session-property-managers-400.jar,session-property-managers,session-property-manager.db.refresh-period,"",false
400,trino-server-400/plugin/session-property-managers/trino-session-property-managers-400.jar,session-property-managers,session-property-manager.config-file,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.query-results-cache.enabled,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.views-enabled,"Enables the connector to read from views and not only tables",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.channel-pool.max-rpc-per-channel,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.case-insensitive-name-matching,"Match dataset and table names case-insensitively",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.credentials-key,"The base64 encoded credentials key",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.channel-pool.initial-size,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.channel-pool.min-size,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.parent-project-id,"The Google Cloud Project ID to bill for the export",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.view-materialization-dataset,"The dataset where the materialized view is going to be created",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.view-materialization-project,"The project where the materialized view is going to be created",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.project-id,"The Google Cloud Project ID where the data reside",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.skip-view-materialization,"Skip materializing views",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.channel-pool.max-size,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.view-expire-duration,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.max-read-rows-retries,"The number of retries in case of retryable server issues",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.channel-pool.min-rpc-per-channel,"",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.service-cache-ttl,"Duration for which BigQuery client service instances are cached",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.views-cache-ttl,"Duration for which the materialization of a view will be cached and reused",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.parallelism,"The number of partitions to split the data into.",false
400,trino-server-400/plugin/bigquery/trino-bigquery-400.jar,bigquery,bigquery.credentials-file,"The path to the JSON credentials file",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.required-replica-set,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.max-wait-time,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.cursor-batch-size,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.ssl.enabled,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.min-connections-per-host,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.read-preference,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.case-insensitive-name-matching,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.socket-timeout,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.schema-collection,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.implicit-row-field-prefix,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.connection-url,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.max-connection-idle-time,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.credentials,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.connections-per-host,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.write-concern,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.connection-timeout,"",false
400,trino-server-400/plugin/mongodb/trino-mongodb-400.jar,mongodb,mongodb.seeds,"",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.use-file-size-from-metadata,"",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.max-partitions-per-writer,"Maximum number of partitions per writer",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters during split generation",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.materialized-views.storage-schema,"Schema for creating materialized views storage tables",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.compression-codec,"",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.experimental.extended-statistics.enabled,"Allow ANALYZE and use of extended statistics collected by it. Currently, the statistics are collected in Trino-specific format",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.unique-table-location,"Use randomized, unique table locations",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.target-max-file-size,"Target maximum size of written files; the actual size may be larger",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.file-format,"",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.remove_orphan_files.min-retention,"Minimal retention period for remove_orphan_files procedure",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.hive-catalog-name,"Catalog to redirect to when a Hive table is referenced",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.security,"",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.expire_snapshots.min-retention,"Minimal retention period for expire_snapshot procedure",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.catalog.type,"",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.projection-pushdown-enabled,"Read only required fields from a struct",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.delete-schema-locations-fallback,"Whether schema locations should be deleted when Trino can't determine whether they contain external files.",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.minimum-assigned-split-weight,"Minimum weight that a split can be assigned",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.format-version,"Default Iceberg table format version",false
400,trino-server-400/plugin/iceberg/trino-iceberg-400.jar,iceberg,iceberg.table-statistics-enabled,"Enable use of table statistics",false
400,trino-server-400/plugin/phoenix5/trino-phoenix5-400.jar,phoenix5,phoenix.max-scans-per-split,"Maximum number of HBase scans that will be performed in a single split.",false
400,trino-server-400/plugin/phoenix5/trino-phoenix5-400.jar,phoenix5,phoenix.connection-url,"",false
400,trino-server-400/plugin/phoenix5/trino-phoenix5-400.jar,phoenix5,phoenix.config.resources,"",false
400,trino-server-400/plugin/thrift/trino-thrift-400.jar,thrift,trino-thrift.lookup-requests-concurrency,"",false
400,trino-server-400/plugin/thrift/trino-thrift-400.jar,thrift,trino-thrift.max-response-size,"",false
400,trino-server-400/plugin/thrift/trino-thrift-400.jar,thrift,trino-thrift.metadata-refresh-threads,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.one-split-per-bucket-threshold,"Experimental: Maximum bucket count at which to produce multiple splits per bucket",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.organization-interval,"How long to wait between table organization iterations",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,backup.provider,"Backup provider to use (supported types: file)",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,backup.directory,"Base directory to use for the backup copy of shard data",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.startup-grace-period,"Minimum uptime before allowing bucket or shard reassignments",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,metadata.db.type,"Metadata database type (supported types: h2, mysql)",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.shard-recovery-timeout,"Maximum time to wait for a shard to recover from backup while running a query",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.max-buffer-size,"Maximum data to buffer before flushing to disk",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.ejector-interval,"How often to check for local shards that need ejection to balance capacity",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.local-clean-time,"How long to wait after discovery before cleaning local shards",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.orc.stream-buffer-size,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.reassignment-interval,"Minimum interval between reassignments for different nodes",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,backup.timeout-threads,"Maximum number of timeout threads for backup operations",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.orc.lazy-read-small-ranges,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.balancer-interval,"How often to run the global bucket balancer",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.max-completed-transaction-age,"Maximum time a record of a successful or failed transaction is kept",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.compaction-enabled,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.max-shard-rows,"Approximate maximum number of rows per shard",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.max-shard-size,"Approximate maximum uncompressed size of a shard",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,backup.threads,"Maximum number of shards to backup at once",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,backup.http.uri,"Backup service base URI",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.orc.tiny-stripe-threshold,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.backup-cleaner-interval,"How often to check for backup shards that need to be cleaned up",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.reassignment-delay,"Minimum delay before allowing reassignments for a node",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,metadata.db.url,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.max-transaction-age,"Maximum time a transaction may run before it is aborted",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,backup.timeout,"Timeout for per-shard backup operations",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.backup-clean-time,"How long to wait after deletion before cleaning backup shards",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.data-directory,"Base directory to use for storing shard data",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.max-organization-threads,"Maximum number of threads to use for organization",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,metadata.db.filename,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.compaction-interval,"How often to check for local shards that need compaction",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.min-available-space,"Minimum space that must be available on the data directory file system",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.backup-deletion-threads,"Maximum number of threads to use for deleting shards from backup store",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.organization-discovery-interval,"How long to wait between discovering tables that need to be organized",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.transaction-cleaner-interval,"How often to cleanup expired transactions",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.local-cleaner-interval,"How often to discover local shards that need to be cleaned up",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.organization-enabled,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.max-deletion-threads,"Maximum number of threads to use for deletions",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,raptor.security,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.missing-shard-discovery-interval,"How often to check the database and local file system missing shards",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.max-recovery-threads,"Maximum number of threads to use for recovery",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.orc.max-merge-distance,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.orc.max-read-size,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.orc.nested-lazy,"",false
400,trino-server-400/plugin/raptor-legacy/trino-raptor-legacy-400.jar,raptor-legacy,storage.balancer-enabled,"",false
400,trino-server-400/plugin/google-sheets/trino-google-sheets-400.jar,google-sheets,credentials-path,"Credential file path to google service account",false
400,trino-server-400/plugin/google-sheets/trino-google-sheets-400.jar,google-sheets,metadata-sheet-id,"Metadata sheet id containing table sheet mapping",false
400,trino-server-400/plugin/google-sheets/trino-google-sheets-400.jar,google-sheets,sheets-data-expire-after-write,"Sheets data expire after write duration",false
400,trino-server-400/plugin/google-sheets/trino-google-sheets-400.jar,google-sheets,sheets-data-max-cache-size,"Sheet data max cache size",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.confluent-subjects-cache-refresh-interval,"The interval that the topic to subjects cache will be refreshed",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.keystore.location,"The location of the key store file. This can be used for two-way authentication for client",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.security-protocol,"Kafka communication security protocol",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.table-description-dir,"Folder holding JSON description files for Kafka topics",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.key.password,"The password of the private key in the key store file",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.truststore.password,"The password for the trust store file",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.nodes,"Seed nodes for Kafka cluster. At least one must exist",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.timestamp-upper-bound-force-push-down-enabled,"timestamp upper bound force pushing down enabled",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.keystore.password,"The store password for the key store file",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.endpoint-identification-algorithm,"The endpoint identification algorithm to validate server hostname using server certificate",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.default-schema,"Schema name to use in the connector",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.config.resources,"Optional config files",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.truststore.type,"The file format of the trust store file",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.table-names,"Set of tables known to this connector",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.keystore.type,"The file format of the key store file",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.hide-internal-columns,"Whether internal columns are shown in table metadata or not. Default is no",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.confluent-schema-registry-url,"The url of the Confluent Schema Registry",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.table-description-supplier,"The table description supplier to use, default is FILE",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.buffer-size,"Kafka message consumer buffer size",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.messages-per-split,"Count of Kafka messages to be processed by single Trino Kafka connector split",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.confluent-schema-registry-client-cache-size,"The maximum number of subjects that can be stored in the Confluent Schema Registry client cache",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.ssl.truststore.location,"The location of the trust store file",false
400,trino-server-400/plugin/kafka/trino-kafka-400.jar,kafka,kafka.empty-field-strategy,"How to handle struct types with no fields: ignore, add a boolean field named 'dummy' or fail the query",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.username,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.native-protocol-port,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.fetch-size,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.tls.truststore-path,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.client.connect-timeout,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.tls.enabled,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.tls.truststore-password,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.load-policy.dc-aware.used-hosts-per-remote-dc,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.load-policy.use-dc-aware,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.splits-per-node,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.load-policy.dc-aware.allow-remote-dc-for-local,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.speculative-execution.limit,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.contact-points,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.retry-policy,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.client.read-timeout,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.load-policy.dc-aware.local-dc,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.tls.keystore-path,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.split-size,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.protocol-version,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.consistency-level,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.allow-drop-table,"Allow Cassandra connector to drop table",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.client.so-linger,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.tls.keystore-password,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.no-host-available-retry-timeout,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.password,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.batch-size,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.partition-size-for-batch-select,"",false
400,trino-server-400/plugin/cassandra/trino-cassandra-400.jar,cassandra,cassandra.speculative-execution.delay,"",false
400,trino-server-400/plugin/mysql/trino-mysql-400.jar,mysql,mysql.jdbc.use-information-schema,"Value of useInformationSchema MySQL JDBC driver connection property",false
400,trino-server-400/plugin/mysql/trino-mysql-400.jar,mysql,mysql.max-reconnects,"",false
400,trino-server-400/plugin/mysql/trino-mysql-400.jar,mysql,mysql.auto-reconnect,"",false
400,trino-server-400/plugin/mysql/trino-mysql-400.jar,mysql,mysql.connection-timeout,"",false
400,trino-server-400/plugin/sqlserver/trino-sqlserver-400.jar,sqlserver,sqlserver.bulk-copy-for-write.lock-destination-table,"Obtain a Bulk Update lock on destination table on write",false
400,trino-server-400/plugin/sqlserver/trino-sqlserver-400.jar,sqlserver,sqlserver.bulk-copy-for-write.enabled,"Use SQL Server Bulk Copy API for writes",false
400,trino-server-400/plugin/sqlserver/trino-sqlserver-400.jar,sqlserver,sqlserver.snapshot-isolation.disabled,"Disables automatic use of snapshot isolation for transactions issued by Trino in SQL Server",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.connect-backoff-base,"Base used for exponential backoff when retying on server error. Formula is attemptDelay = retryDelay * backoffBase ^ attemptCount. Attempt counting starts from 0. Leave empty or set to 1 to disable.",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.connect-max-delay,"Maximum delay between retries. This should be used with exponential backoff.",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.connect-http-headers,"List of custom custom HTTP headers provided as: ""Header-Name-1: header value 1, Header-Value-2: header value 2, ..."" ",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.connect-ingest-uri,"URL of receiving server. Explicitly set the scheme https:// to use symmetric encryption",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.connect-retry-delay,"Delay in seconds between retries",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.log-split,"Will log io.trino.spi.eventlistener.SplitCompletedEvent",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.log-completed,"Will log io.trino.spi.eventlistener.QueryCompletedEvent",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.log-created,"Will log io.trino.spi.eventlistener.QueryCreatedEvent",false
400,trino-server-400/plugin/http-event-listener/trino-http-event-listener-400.jar,http-event-listener,http-event-listener.connect-retry-count,"Number of retries on server error",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.client.disable-statistics,"",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.authentication.config,"Kudu Kerberos service configuration file",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.authentication.client.keytab,"Kudu Kerberos client keytab location",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.dynamic-filtering.wait-timeout,"Duration to wait for completion of dynamic filters",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.schema-emulation.prefix,"",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.authentication.client.principal,"Kudu Kerberos client principal",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.schema-emulation.enabled,"",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.client.master-addresses,"",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.client.default-admin-operation-timeout,"",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.client.default-operation-timeout,"",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.authentication.type,"Kudu authentication type",false
400,trino-server-400/plugin/kudu/trino-kudu-400.jar,kudu,kudu.authentication.server.principal.primary,"The 'primary' portion of the kudu service principal name",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,salesforce.allowed-organizations,"Comma separated list of Salesforce 18 Character Organization Ids.",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,salesforce.cache-size,"Maximum size of the cache that holds authenticated users.  Default is 4096 entries.",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,file.auth-token-cache.max-size,"Max number of cached authenticated passwords",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,ldap.cache-ttl,"",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,ldap.group-auth-pattern,"Custom group authorization check query. Example: &(objectClass=user)(memberOf=cn=group)(user=username)",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,salesforce.cache-expire-duration,"Expire duration for an entry in cache since last write.",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,ldap.user-base-dn,"Base distinguished name of the user. Example: dc=example,dc=com",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,file.refresh-period,"How often to reload the password file",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,file.group-file,"Location of the file that provides user group membership",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,ldap.bind-dn,"Bind distinguished name. Example: CN=User Name,OU=CITY_OU,OU=STATE_OU,DC=domain,DC=domain_root",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,file.refresh-period,"How often to reload the group file",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,ldap.bind-password,"Bind password used. Example: password1234",false
400,trino-server-400/plugin/password-authenticators/trino-password-authenticators-400.jar,password-authenticators,file.password-file,"Location of the file that provides user names and passwords",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.bearer.token.file,"File holding bearer token if needed for access to Prometheus",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.auth.password,"",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.cache.ttl,"How long values from this config file are cached",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.max.query.range.duration,"Width of overall query to Prometheus, will be divided into prometheus.query.chunk.size.duration queries",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.auth.user,"",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.read-timeout,"How much time a query to Prometheus has before timing out",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.query.chunk.size.duration,"The duration of each query to Prometheus",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.case-insensitive-name-matching,"Where to match the prometheus metric name case insensitively ",false
400,trino-server-400/plugin/prometheus/trino-prometheus-400.jar,prometheus,prometheus.uri,"Where to find Prometheus coordinator host",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.max-page-storage-size,"Max storage size of a page written to a sink, including the page itself and its size represented as an int",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.max-error-retries,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.async-client-connection-acquisition-timeout,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.gcs.json-key,"Your Google Cloud Platform service account key in JSON format. Not to be set together with `exchange.gcs.json-key-file-path`",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.encryption-enabled,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.max-output-partition-count,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.azure.connection-string,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.region,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.azure.block-size,"Block size for Azure High-Throughput Block Blob",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.endpoint,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.gcs.json-key-file-path,"Path to the JSON file that contains your Google Cloud Platform service account key. Not to be set together with `exchange.gcs.json-key`",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.retry-mode,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.base-directories,"List of base directories separated by commas",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.iam-role,"ARN of an IAM role to assume when connecting to S3",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.sink-buffers-per-partition,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.source-max-files-per-reader,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.file-listing-parallelism,"Max parallelism of file listing calls when enumerating spooling files. The actual parallelism will depend on implementation",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.source-concurrent-readers,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.async-client-concurrency,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.upload.part-size,"Part size for S3 multi-part upload",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.aws-secret-key,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.storage-class,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.azure.max-error-retries,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.source-handle-target-data-size,"Target size of the data referenced by a single source handle",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.sink-buffer-pool-min-size,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.sink-max-file-size,"Max size of files written by exchange sinks",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.aws-access-key,"",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.external-id,"External ID for the IAM role trust policy when connecting to S3",false
400,trino-server-400/plugin/exchange-filesystem/trino-exchange-filesystem-400.jar,exchange-filesystem,exchange.s3.async-client-max-pending-connection-acquires,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.scroll-timeout,"Scroll timeout",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.tls.verify-hostnames,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.aws.external-id,"Optional external id to pass to AWS STS while assuming a role",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.backoff-max-delay,"Maximum delay to wait between backpressure retries",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.tls.enabled,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.node-refresh-interval,"How often to refresh the list of available Elasticsearch nodes",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.backoff-init-delay,"Initial delay to wait between backpressure retries",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.aws.access-key,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.tls.truststore-path,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.aws.iam-role,"Optional AWS IAM role to assume for authenticating. If set, this role will be used to get credentials to sign requests to ES.",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.security,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.tls.keystore-path,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.aws.secret-key,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.legacy-pass-through-query.enabled,"Enable legacy Elasticsearch pass-through query",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.aws.region,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.default-schema-name,"Default schema name to use",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.port,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.ignore-publish-address,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.connect-timeout,"Elasticsearch connect timeout",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.max-http-connections,"Maximum number of persistent HTTP connections to Elasticsearch",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.host,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.auth.user,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.tls.keystore-password,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.max-retry-time,"Maximum timeout in case of multiple retries",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.auth.password,"",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.scroll-size,"Scroll batch size",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.http-thread-count,"Number of threads handling HTTP connections to Elasticsearch",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.request-timeout,"Elasticsearch request timeout",false
400,trino-server-400/plugin/elasticsearch/trino-elasticsearch-400.jar,elasticsearch,elasticsearch.tls.truststore-password,"",false
400,trino-server-400/plugin/singlestore/trino-singlestore-400.jar,singlestore,singlestore.connection-timeout,"",false
400,trino-server-400/plugin/singlestore/trino-singlestore-400.jar,singlestore,singlestore.auto-reconnect,"",false
400,trino-server-400/lib/trino-main-400.jar,,pages-index.eager-compaction-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.info-url-template,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.execution-policy,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.client-secret,"Client secret",false
400,trino-server-400/lib/trino-main-400.jar,,legacy.allow-set-view-authorization,"For security reasons ALTER VIEW SET AUTHORIZATION is disabled for SECURITY DEFINER; setting this option to true will re-enable this functionality",false
400,trino-server-400/lib/trino-main-400.jar,,retry-delay-scale-factor,"Factor by which retry delay is scaled on subsequent failures",false
400,trino-server-400/lib/trino-main-400.jar,,cpu-cost-weight,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.max-clock-skew,"Max clock skew between the Authorization Server and the coordinator",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-preserve-input-partitions-in-write-stage,"Ensure single task reads single hash partitioned input partition for stages which write table data",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.ignore-downstream-preferences,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.optimize-mixed-distinct-aggregations,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-history,"",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.client-threads,"",false
400,trino-server-400/lib/trino-main-400.jar,,sink.max-broadcast-buffer-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-partitioned.max-size-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,max-recursion-depth,"Maximum recursion depth for recursive common table expression",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-broadcast.max-distinct-values-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,failure-detector.threshold,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.push-table-write-through-union,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-cpu-time,"",false
400,trino-server-400/lib/trino-main-400.jar,,transaction.idle-check-interval,"Time interval between idle transactions checks",false
400,trino-server-400/lib/trino-main-400.jar,,transaction.idle-timeout,"Amount of time before an inactive transaction is considered expired",false
400,trino-server-400/lib/trino-main-400.jar,,task.task-notification-threads,"Number of threads used for internal task event notifications",false
400,trino-server-400/lib/trino-main-400.jar,,retry-initial-delay,"Initial delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt up to 'retry_max_delay'",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-partitioned.max-size-per-operator,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.policy,"",false
400,trino-server-400/lib/trino-main-400.jar,,adaptive-partial-aggregation.min-rows,"Minimum number of processed rows before partial aggregation might be adaptively turned off",false
400,trino-server-400/lib/trino-main-400.jar,,task.interrupt-stuck-split-tasks-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.max-reordered-joins,"The maximum number of tables to reorder in cost-based join reordering",false
400,trino-server-400/lib/trino-main-400.jar,,task.max-local-exchange-buffer-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,task-retry-attempts-overall,"",false
400,trino-server-400/lib/trino-main-400.jar,,testing-warning-collector.preloaded-warnings,"Preloads warning collector with test warnings",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.include-coordinator,"",false
400,trino-server-400/lib/trino-main-400.jar,,query-results.compression-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,max-spill-per-node,"",false
400,trino-server-400/lib/trino-main-400.jar,,deprecated.omit-datetime-type-precision,"Enable compatibility mode for legacy clients when rendering datetime type names with default precision",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-target-task-split-count,"Target number of splits for a single fault tolerant task (split weight aware)",false
400,trino-server-400/lib/trino-main-400.jar,,max-tasks-waiting-for-node-per-stage,"Maximum possible number of tasks waiting for node allocation per stage before scheduling of new tasks for stage is paused",false
400,trino-server-400/lib/trino-main-400.jar,,event.max-output-stage-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,deprecated.legacy-catalog-roles,"Enable legacy role management syntax that assumed all roles are catalog scoped",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-stage-count,"",false
400,trino-server-400/lib/trino-main-400.jar,,header-authenticator.config-files,"Ordered list of header authenticator configuration files",false
400,trino-server-400/lib/trino-main-400.jar,,analyzer.max-grouping-sets,"",false
400,trino-server-400/lib/trino-main-400.jar,,internal-communication.https.truststore.key,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.predicate-pushdown-use-table-properties,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-partitioned.max-size-per-operator,"",false
400,trino-server-400/lib/trino-main-400.jar,,sql.forced-session-time-zone,"User session time zone overriding value sent by client",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-run-time,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.low-memory-killer.delay,"Delay between cluster running low on memory and invoking killer",false
400,trino-server-400/lib/trino-main-400.jar,,failure-injection.request-timeout,"Period after which requests blocked to emulate a timeout are released",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-memory,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-scan-physical-bytes,"",false
400,trino-server-400/lib/trino-main-400.jar,,query-retry-attempts,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.interrupt-stuck-split-tasks-warning-threshold,"Print out call stacks and generate JMX metrics for splits running longer than the threshold",false
400,trino-server-400/lib/trino-main-400.jar,,enable-large-dynamic-filters,"",false
400,trino-server-400/lib/trino-main-400.jar,,memory-revoking-target,"When revoking memory, try to revoke so much that pool is filled below target at the end",false
400,trino-server-400/lib/trino-main-400.jar,,re2j.dfa-retries,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.timeout,"Expiration time for issued token. It needs to be equal or lower than duration of refresh token issued by IdP",false
400,trino-server-400/lib/trino-main-400.jar,,web-ui.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.network-topology.subnet.ip-address-protocol,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small.max-size-per-filter,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.header.user-mapping.file,"An optional user mapping file containing the mapping rules to be applied to the authenticated principal",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.compression-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,iterative-optimizer-timeout,"",false
400,trino-server-400/lib/trino-main-400.jar,,web-ui.shared-secret,"",false
400,trino-server-400/lib/trino-main-400.jar,,http.include-exception-in-response,"",false
400,trino-server-400/lib/trino-main-400.jar,,protocol.v1.prepared-statement-compression.min-gain,"Prepared statement compression is not applied if the size gain is less than the configured value",false
400,trino-server-400/lib/trino-main-400.jar,,scale-writers,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.min-expire-age,"",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-task-memory-estimation-quantile,"What quantile of memory usage of completed tasks to look at when estimating memory usage for upcoming tasks",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-partitioned.max-size-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,warning-collector.max-warnings,"",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-task-descriptor-storage-max-memory,"Maximum amount of memory to be used to store task descriptors for fault tolerant queries on coordinator",false
400,trino-server-400/lib/trino-main-400.jar,,web-ui.authentication.type,"Authentication type for the web ui",false
400,trino-server-400/lib/trino-main-400.jar,,task.http-response-threads,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.ignore-stats-calculator-failures,"Ignore statistics calculator failures",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-task-runtime-memory-estimation-overhead,"Extra memory to account for when estimating actual task runtime memory consumption",false
400,trino-server-400/lib/trino-main-400.jar,,task.split-concurrency-adjustment-interval,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.cpu-timer-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.user-mapping.file,"File containing rules for mapping user",false
400,trino-server-400/lib/trino-main-400.jar,,enable-coordinator-dynamic-filters-distribution,"Enable distribution of dynamic filters from coordinator to all workers",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-partitioned.range-row-limit-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.jwt.user-mapping.file,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.oidc.discovery,"Enable OpenID Provider Issuer discovery",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.certificate.user-mapping.file,"",false
400,trino-server-400/lib/trino-main-400.jar,,failure-detector.warmup-interval,"How long to wait after transitioning to success before considering a service alive",false
400,trino-server-400/lib/trino-main-400.jar,,catalog.store,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.prefer-partial-aggregation,"",false
400,trino-server-400/lib/trino-main-400.jar,,collect-plan-statistics-for-all-queries,"Collect plan statistics for non-EXPLAIN queries",false
400,trino-server-400/lib/trino-main-400.jar,,event-listener.config-files,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.level-time-multiplier,"Factor that determines the target scheduled time for a level relative to the next",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.optimize-duplicate-insensitive-joins,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.jwks-url,"URL of the authorization server's JWKS (JSON Web Key Set) endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,statistics-precalculation-for-pushdown.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.audience,"Audience representing this coordinator instance, that will be used in issued token",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-broadcast.max-size-per-operator,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-broadcast.range-row-limit-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large.max-size-per-filter,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.network-topology.type,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.stage-count-warning-threshold,"Emit a warning when stage count exceeds this threshold",false
400,trino-server-400/lib/trino-main-400.jar,,redistribute-writes,"",false
400,trino-server-400/lib/trino-main-400.jar,,spill-compression-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-partition-count,"Number of partitions for distributed joins and aggregations executed with fault tolerant execution enabled",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.krb5.name-type,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-broadcast.max-size-per-operator,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.manager-executor-pool-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,testing-warning-collector.add-warnings,"Adds a warning each time getWarnings is called",false
400,trino-server-400/lib/trino-main-400.jar,,discovery-server.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,management.user,"Optional fixed user for all requests to management endpoints",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.force-single-node-output,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.krb5.service-name,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.writer-count,"Number of writers per task",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.network-topology.refresh-period,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.pre-aggregate-case-aggregations.enabled,"Pre-aggregate rows before GROUP BY with multiple CASE aggregations on same column",false
400,trino-server-400/lib/trino-main-400.jar,,task.interrupt-stuck-split-tasks-timeout,"Interrupt task processing thread after this timeout if the thread is stuck in certain external libraries used by Trino functions",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.join-reordering-strategy,"The strategy to use for reordering joins",false
400,trino-server-400/lib/trino-main-400.jar,,query.executor-pool-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.interrupt-stuck-split-tasks-detection-interval,"Interval between detecting stuck split",false
400,trino-server-400/lib/trino-main-400.jar,,http.authentication.krb5.config,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.max-index-memory,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.join-multi-clause-independence-factor,"Scales the strength of independence assumption for selectivity estimates of multi-clause joins",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.principal-field,"The claim to use as the principal",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.rewrite-filtering-semi-join-to-inner-join,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.max-splits-per-node,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.http-timeout-threads,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.userinfo-url,"URL of the userinfo endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-min-task-split-count,"Minimal number of splits for a single fault tolerant task (count based)",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.krb5.user-mapping.pattern,"",false
400,trino-server-400/lib/trino-main-400.jar,,parse-decimal-literals-as-double,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.jwt.required-issuer,"",false
400,trino-server-400/lib/trino-main-400.jar,,transaction.max-finishing-concurrency,"Maximum parallelism for committing or aborting a transaction",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-coordinator-task-memory,"Estimated amount of memory a single coordinator task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
400,trino-server-400/lib/trino-main-400.jar,,task.max-partial-top-n-memory,"",false
400,trino-server-400/lib/trino-main-400.jar,,adaptive-partial-aggregation.unique-rows-ratio-threshold,"Ratio between aggregation output and input rows above which partial aggregation might be adaptively turned off",false
400,trino-server-400/lib/trino-main-400.jar,,query.remote-task.min-error-duration,"",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.acknowledge-pages,"",false
400,trino-server-400/lib/trino-main-400.jar,,enable-forced-exchange-below-group-id,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.remote-task.max-error-duration,"",false
400,trino-server-400/lib/trino-main-400.jar,,sql.default-schema,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.max-unacknowledged-splits-per-task,"Maximum number of leaf splits not yet delivered to a given task",false
400,trino-server-400/lib/trino-main-400.jar,,compiler.expression-cache-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,protocol.v1.prepared-statement-compression.length-threshold,"Compression is applied to prepared statements longer than the configured value",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.refresh-tokens.secret-key,"Base64 encoded secret key used to encrypt generated token",false
400,trino-server-400/lib/trino-main-400.jar,,spiller-max-used-space-threshold,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-planning-time,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.max-partial-aggregation-memory,"",false
400,trino-server-400/lib/trino-main-400.jar,,retry-policy,"",false
400,trino-server-400/lib/trino-main-400.jar,,memory-cost-weight,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-partitioned.range-row-limit-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.initial-splits-per-node,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.info.max-age,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.scopes,"Scopes requested by the server during OAuth2 authorization challenge",false
400,trino-server-400/lib/trino-main-400.jar,,filter-and-project-min-output-page-row-count,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.join-partitioned-build-min-row-count,"Minimum number of join build side rows required to use partitioned join lookup",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-partitioned.max-distinct-values-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.scale-writers.enabled,"Scale the number of concurrent table writers per task based on throughput",false
400,trino-server-400/lib/trino-main-400.jar,,task.per-operator-cpu-timer-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.status-refresh-max-wait,"",false
400,trino-server-400/lib/trino-main-400.jar,,preferred-write-partitioning-min-number-of-partitions,"Use preferred write partitioning when the number of written partitions exceeds the configured threshold",false
400,trino-server-400/lib/trino-main-400.jar,,failure-detector.heartbeat-interval,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.password.user-mapping.file,"",false
400,trino-server-400/lib/trino-main-400.jar,,network-cost-weight,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.password.user-mapping.pattern,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.statistics-cpu-timer-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.share-index-loading,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.allocator-type,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-memory-per-node,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.use-legacy-window-filter-pushdown,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.min-drivers-per-task,"Minimum number of drivers guaranteed to run per task given there is sufficient work to do",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.complex-expression-pushdown.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,query-manager.required-workers,"Minimum number of active workers that must be available before a query will start",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.optimize-top-n-ranking,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.client.timeout,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.oidc.use-userinfo-endpoint,"Use userinfo endpoint from OpenID connect metadata document",false
400,trino-server-400/lib/trino-main-400.jar,,internal-communication.https.required,"",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.max-buffer-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-task-memory-growth-factor,"Factor by which estimated task memory is increased if task execution runs out of memory; value is used allocating nodes for tasks execution",false
400,trino-server-400/lib/trino-main-400.jar,,plugin.dir,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.krb5.keytab,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.max-drivers-per-task,"Maximum number of drivers a task can run",false
400,trino-server-400/lib/trino-main-400.jar,,filter-and-project-min-output-page-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,distributed-sort,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.filter-conjunction-independence-factor,"Scales the strength of independence assumption for selectivity estimates of the conjunction of multiple filters",false
400,trino-server-400/lib/trino-main-400.jar,,task.concurrency,"Default number of local parallel jobs per worker",false
400,trino-server-400/lib/trino-main-400.jar,,spiller-threads,"",false
400,trino-server-400/lib/trino-main-400.jar,,spill-encryption-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.max-pending-splits-per-task,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.low-memory-killer.policy,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.push-partial-aggregation-through-join,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.min-drivers,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.jwt.user-mapping.pattern,"",false
400,trino-server-400/lib/trino-main-400.jar,,protocol.v1.alternate-header-name,"Alternate header name for V1 protocol",false
400,trino-server-400/lib/trino-main-400.jar,,query.schedule-split-batch-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.issuer,"The required issuer of a token",false
400,trino-server-400/lib/trino-main-400.jar,,web-ui.session-timeout,"",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.min-error-duration,"",false
400,trino-server-400/lib/trino-main-400.jar,,catalog.disabled-catalogs,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-broadcast.range-row-limit-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-broadcast.max-size-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,internal-communication.https.keystore.key,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.task-yield-threads,"Number of threads used for setting yield signals",false
400,trino-server-400/lib/trino-main-400.jar,,task.info-update-interval,"Interval between updating task data",false
400,trino-server-400/lib/trino-main-400.jar,,catalog.management,"",false
400,trino-server-400/lib/trino-main-400.jar,,colocated-joins-enabled,"Experimental: Use a colocated join when possible",false
400,trino-server-400/lib/trino-main-400.jar,,task.scale-writers.max-writer-count,"Maximum number of writers per task up to which scaling will happen if task.scale-writers.enabled is set",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.state-key,"A secret key used by HMAC algorithm to sign the state parameter",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-execution-time,"",false
400,trino-server-400/lib/trino-main-400.jar,,query-manager.required-workers-max-wait,"Maximum time to wait for minimum number of workers before the query is failed",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.enable-intermediate-aggregations,"",false
400,trino-server-400/lib/trino-main-400.jar,,task.max-worker-threads,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.jwt.required-audience,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.optimized-local-scheduling,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.splits-balancing-policy,"Strategy for balancing new splits on worker nodes",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.use-table-scan-node-partitioning,"Adapt plan to node pre-partitioned tables",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.optimize-hash-generation,"",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.max-response-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.oidc.discovery.timeout,"OpenID Connect discovery timeout",false
400,trino-server-400/lib/trino-main-400.jar,,query.remote-task.max-callback-threads,"",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-target-task-input-size,"Target size in bytes of all task inputs for a single fault tolerant task",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-task-memory,"Estimated amount of memory a single task will use when task level retries are used; value is used when allocating nodes for tasks execution",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.table-scan-node-partitioning-min-bucket-to-task-ratio,"Min table scan bucket to task ratio for which plan will be adopted to node pre-partitioned tables",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.allow-insecure-over-http,"Insecure authentication over HTTP (non-secure) enabled",false
400,trino-server-400/lib/trino-main-400.jar,,task-retry-attempts-per-task,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.insecure.user-mapping.file,"",false
400,trino-server-400/lib/trino-main-400.jar,,regex-library,"",false
400,trino-server-400/lib/trino-main-400.jar,,internal-communication.https.truststore.path,"",false
400,trino-server-400/lib/trino-main-400.jar,,internal-communication.shared-secret,"",false
400,trino-server-400/lib/trino-main-400.jar,,internal-communication.https.keystore.path,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.krb5.principal-hostname,"",false
400,trino-server-400/lib/trino-main-400.jar,,failure-detector.expiration-grace-interval,"How long to wait before 'forgetting' a service after it disappears from discovery",false
400,trino-server-400/lib/trino-main-400.jar,,failure-injection.expiration-period,"Period after which an injected failure is considered expired and will no longer be triggering a failure",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.refresh-tokens,"Enables OpenID refresh tokens usage",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.data-integrity-verification,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.jwt.principal-field,"",false
400,trino-server-400/lib/trino-main-400.jar,,driver.max-page-partitioning-buffer-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,hide-inaccessible-columns,"When enabled non-accessible columns are silently filtered from results from SELECT * statements",false
400,trino-server-400/lib/trino-main-400.jar,,jmx.base-name,"",false
400,trino-server-400/lib/trino-main-400.jar,,internal-communication.http2.enabled,"Enable the HTTP/2 transport",false
400,trino-server-400/lib/trino-main-400.jar,,spiller-spill-path,"",false
400,trino-server-400/lib/trino-main-400.jar,,use-preferred-write-partitioning,"",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.concurrent-request-multiplier,"",false
400,trino-server-400/lib/trino-main-400.jar,,spill-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.min-schedule-split-batch-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.hash-partition-count,"Number of partitions for distributed joins and aggregations",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-broadcast.max-distinct-values-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,query-max-spill-per-node,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.jwt.key-file,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.merge-project-with-values,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.default-filter-factor-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,writer-min-size,"Target minimum size of writer output when scaling writers",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-length,"",false
400,trino-server-400/lib/trino-main-400.jar,,fault-tolerant-execution-max-task-split-count,"Maximal number of splits for a single fault tolerant task (count based)",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.max-error-duration,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.certificate.user-mapping.pattern,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.use-mark-distinct,"",false
400,trino-server-400/lib/trino-main-400.jar,,password-authenticator.config-files,"Ordered list of password authenticator config files",false
400,trino-server-400/lib/trino-main-400.jar,,task.client.timeout,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.refresh-tokens.issued-token.issuer,"Issuer representing this coordinator instance, that will be used in issued token. In addition current Version will be added to it",false
400,trino-server-400/lib/trino-main-400.jar,,adaptive-partial-aggregation.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.client-id,"Client ID",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.additional-audiences,"Additional audiences to trust in addition to the Client ID",false
400,trino-server-400/lib/trino-main-400.jar,,query.low-memory-killer.policy,"",false
400,trino-server-400/lib/trino-main-400.jar,,access-control.config-files,"",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.network-topology.file,"",false
400,trino-server-400/lib/trino-main-400.jar,,memory-revoking-threshold,"Revoke memory when memory pool is filled over threshold",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.token-url,"URL of the authorization server's token endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.allowed-no-matching-node-period,"How long scheduler should wait before failing a query for which hard task requirements (e.g. node exposing specific catalog) cannot be satisfied",false
400,trino-server-400/lib/trino-main-400.jar,,spatial-joins-enabled,"Use spatial index for spatial joins when possible",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.optimize-metadata-queries,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.user-mapping.pattern,"Regex to match against user name",false
400,trino-server-400/lib/trino-main-400.jar,,force-spilling-join-operator,"Force spilling join operator in favour of the non-spilling one even when there is no spill",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.small-broadcast.max-size-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.header.user-mapping.pattern,"An optional user mapping pattern to be applied to the authenticated principal",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.groups-field,"Groups field in the claim",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.non-estimatable-predicate-approximation.enabled,"Approximate the cost of filters which cannot be accurately estimated even with complete statistics",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.network-topology.subnet.cidr-prefix-lengths,"",false
400,trino-server-400/lib/trino-main-400.jar,,management.user.https-enabled,"Use fixed management user for secure HTTPS requests",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.dictionary-aggregation,"",false
400,trino-server-400/lib/trino-main-400.jar,,catalog.config-dir,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-total-memory,"",false
400,trino-server-400/lib/trino-main-400.jar,,sql.default-catalog,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.challenge-timeout,"Maximum duration of OAuth2 authorization challenge",false
400,trino-server-400/lib/trino-main-400.jar,,enable-dynamic-filtering,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.krb5.user-mapping.file,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.push-aggregation-through-outer-join,"",false
400,trino-server-400/lib/trino-main-400.jar,,re2j.dfa-states-limit,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.skip-redundant-sort,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.https.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,aggregation-operator-unspill-memory-limit,"",false
400,trino-server-400/lib/trino-main-400.jar,,join-max-broadcast-table-size,"Maximum estimated size of a table that can be broadcast when using automatic join type selection",false
400,trino-server-400/lib/trino-main-400.jar,,incremental-hash-array-load-factor.enabled,"Use smaller load factor for small hash arrays in order to improve performance",false
400,trino-server-400/lib/trino-main-400.jar,,node-scheduler.min-candidates,"",false
400,trino-server-400/lib/trino-main-400.jar,,memory.heap-headroom-per-node,"The amount of heap memory to set aside as headroom/buffer (e.g., for untracked allocations)",false
400,trino-server-400/lib/trino-main-400.jar,,web-ui.user,"",false
400,trino-server-400/lib/trino-main-400.jar,,failure-detector.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,experimental.concurrent-startup,"Parallelize work during server startup",false
400,trino-server-400/lib/trino-main-400.jar,,dynamic-filtering.large-partitioned.max-distinct-values-per-driver,"",false
400,trino-server-400/lib/trino-main-400.jar,,shutdown.grace-period,"",false
400,trino-server-400/lib/trino-main-400.jar,,enable-stats-calculator,"",false
400,trino-server-400/lib/trino-main-400.jar,,retry-max-delay,"Maximum delay before initiating a retry attempt. Delay increases exponentially for each subsequent attempt starting from 'retry_initial_delay'",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-concurrent-queries,"",false
400,trino-server-400/lib/trino-main-400.jar,,optimizer.use-exact-partitioning,"When enabled this forces data repartitioning unless the partitioning of upstream stage matches exactly what downstream stage expects",false
400,trino-server-400/lib/trino-main-400.jar,,distributed-index-joins-enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
400,trino-server-400/lib/trino-main-400.jar,,join-distribution-type,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.access-token-issuer,"The required issuer for access tokens",false
400,trino-server-400/lib/trino-main-400.jar,,experimental.late-materialization.enabled,"",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.page-buffer-client.max-callback-threads,"",false
400,trino-server-400/lib/trino-main-400.jar,,sink.max-buffer-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.oauth2.auth-url,"URL of the authorization server's authorization endpoint",false
400,trino-server-400/lib/trino-main-400.jar,,exchange.deduplication-buffer-size,"",false
400,trino-server-400/lib/trino-main-400.jar,,http-server.authentication.insecure.user-mapping.pattern,"",false
400,trino-server-400/lib/trino-main-400.jar,,query.max-queued-queries,"",false
